{"title": "IncidentNet: Traffic Incident Detection, Localization and Severity\n  Estimation with Sparse Sensing", "authors": [], "abstract": "Prior art in traffic incident detection relies on high sensor coverage and is\nprimarily based on decision-tree and random forest models that have limited\nrepresentation capacity and, as a result, cannot detect incidents with high\naccuracy. This paper presents IncidentNet - a novel approach for classifying,\nlocalizing, and estimating the severity of traffic incidents using deep\nlearning models trained on data captured from sparsely placed sensors in urban\nenvironments. Our model works on microscopic traffic data that can be collected\nusing cameras installed at traffic intersections. Due to the unavailability of\ndatasets that provide microscopic traffic details and traffic incident details\nsimultaneously, we also present a methodology to generate a synthetic\nmicroscopic traffic dataset that matches given macroscopic traffic data.\nIncidentNet achieves a traffic incident detection rate of 98%, with false alarm\nrates of less than 7% in 197 seconds on average in urban environments with\ncameras on less than 20% of the traffic intersections.", "categories": "cs.LG cs.AI", "created": "2024-08-02", "doi": null, "arxiv_id": "2408.00996"}
{"title": "A Safe Exploration Strategy for Model-free Task Adaptation in\n  Safety-constrained Grid Environments", "authors": [], "abstract": "Training a model-free reinforcement learning agent requires allowing the\nagent to sufficiently explore the environment to search for an optimal policy.\nIn safety-constrained environments, utilizing unsupervised exploration or a\nnon-optimal policy may lead the agent to undesirable states, resulting in\noutcomes that are potentially costly or hazardous for both the agent and the\nenvironment. In this paper, we introduce a new exploration framework for\nnavigating the grid environments that enables model-free agents to interact\nwith the environment while adhering to safety constraints. Our framework\nincludes a pre-training phase, during which the agent learns to identify\npotentially unsafe states based on both observable features and specified\nsafety constraints in the environment. Subsequently, a binary classification\nmodel is trained to predict those unsafe states in new environments that\nexhibit similar dynamics. This trained classifier empowers model-free agents to\ndetermine situations in which employing random exploration or a suboptimal\npolicy may pose safety risks, in which case our framework prompts the agent to\nfollow a predefined safe policy to mitigate the potential for hazardous\nconsequences. We evaluated our framework on three randomly generated grid\nenvironments and demonstrated how model-free agents can safely adapt to new\ntasks and learn optimal policies for new environments. Our results indicate\nthat by defining an appropriate safe policy and utilizing a well-trained model\nto detect unsafe states, our framework enables a model-free agent to adapt to\nnew tasks and environments with significantly fewer safety violations.", "categories": "cs.AI", "created": "2024-08-02", "doi": null, "arxiv_id": "2408.00997"}
{"title": "Community Cellular Networks Coverage Visualizer", "authors": [], "abstract": "The community cellular networks volunteers and researchers currently rarely\nhave an access to information about the networks for each site. This makes it\ndifficult for them to evaluate network performance, identify outrages and\ndowntimes, or even to show the current site locations. In this paper, we\npropose the Community Cellular Networks Coverage Visualizer, a performance\ndashboard to help reduce the workload of technicians and gain trust from\nillustrating the reliability of the networks. The map displays the overall and\nin-depth performance for each current and future CCNs sites with\nprivacy-focused implementation, while the multi-series line chart emphasizes on\nproviding the capability of network overtime. Not only it will help users\nidentify locations that have stronger and reliable signals nearby, but our\napplicaiton will also be an essential tool for volunteers and engineers to\ndetermine the optimal locations to install a new site and quickly identify\npossible network failures.", "categories": "cs.HC cs.CY cs.NI", "created": "2024-08-02", "doi": null, "arxiv_id": "2408.00999"}
{"title": "Adaptive Two-Stage Cloud Resource Scaling via Hierarchical\n  Multi-Indicator Forecasting and Bayesian Decision-Making", "authors": [], "abstract": "The surging demand for cloud computing resources, driven by the rapid growth\nof sophisticated large-scale models and data centers, underscores the critical\nimportance of efficient and adaptive resource allocation. As major tech\nenterprises deploy massive infrastructures with thousands of GPUs, existing\ncloud platforms still struggle with low resource utilization due to key\nchallenges: capturing hierarchical indicator structures, modeling non-Gaussian\ndistributions, and decision-making under uncertainty. To address these\nchallenges, we propose HRAMONY, an adaptive Hierarchical Attention-based\nResource Modeling and Decision-Making System. HARMONY combines hierarchical\nmulti-indicator distribution forecasting and uncertainty-aware Bayesian\ndecision-making. It introduces a novel hierarchical attention mechanism that\ncomprehensively models complex inter-indicator dependencies, enabling accurate\npredictions that can adapt to evolving environment states. By transforming\nGaussian projections into adaptive non-Gaussian distributions via Normalizing\nFlows. Crucially, HARMONY leverages the full predictive distributions in an\nadaptive Bayesian process, proactively incorporating uncertainties to optimize\nresource allocation while robustly meeting SLA constraints under varying\nconditions. Extensive evaluations across four large-scale cloud datasets\ndemonstrate HARMONY's state-of-the-art performance, significantly outperforming\nnine established methods. A month-long real-world deployment validated\nHARMONY's substantial practical impact, realizing over 35,000 GPU hours in\nsavings and translating to $100K+ in cost reduction, showcasing its remarkable\neconomic value through adaptive, uncertainty-aware scaling. Our code is\navailable at https://github.com/Floating-LY/HARMONY1.", "categories": "cs.LG", "created": "2024-08-02", "doi": null, "arxiv_id": "2408.01000"}
{"title": "A Logarithmic Depth Quantum Carry-Lookahead Modulo $(2^n-1)$ Adder", "authors": [], "abstract": "Quantum Computing is making significant advancements toward creating machines\ncapable of implementing quantum algorithms in various fields, such as quantum\ncryptography, quantum image processing, and optimization. The development of\nquantum arithmetic circuits for modulo addition is vital for implementing these\nquantum algorithms. While it is ideal to use quantum circuits based on\nfault-tolerant gates to overcome noise and decoherence errors, the current\nNoisy Intermediate Scale Quantum (NISQ) era quantum computers cannot handle the\nadditional computational cost associated with fault-tolerant designs. Our\nresearch aims to minimize circuit depth, which can reduce noise and facilitate\nthe implementation of quantum modulo addition circuits on NISQ machines. This\nwork presents quantum carry-lookahead modulo $(2^n - 1)$ adder (QCLMA), which\nis designed to receive two n-bit numbers and perform their addition with an\nO(log n) depth. Compared to existing work of O(n) depth, our proposed QCLMA\nreduces the depth and helps increase the noise fidelity. In order to increase\nerror resilience, we also focus on creating a tree structure based Carry path,\nunlike the chain based Carry path of the current work. We run experiments on\nQuantum Computer IBM Cairo to evaluate the performance of the proposed QCLMA\nagainst the existing work and define Quantum State Fidelity Ratio (QSFR) to\nquantify the closeness of the correct output to the top output. When compared\nagainst existing work, the proposed QCLMA achieves a 47.21% increase in QSFR\nfor 4-qubit modulo addition showcasing its superior noise fidelity.", "categories": "quant-ph cs.AR", "created": "2024-08-02", "doi": null, "arxiv_id": "2408.01002"}
{"title": "Piculet: Specialized Models-Guided Hallucination Decrease for MultiModal\n  Large Language Models", "authors": [], "abstract": "Multimodal Large Language Models (MLLMs) have made significant progress in\nbridging the gap between visual and language modalities. However,\nhallucinations in MLLMs, where the generated text does not align with image\ncontent, continue to be a major challenge. Existing methods for addressing\nhallucinations often rely on instruction-tuning, which requires retraining the\nmodel with specific data, which increases the cost of utilizing MLLMs further.\nIn this paper, we introduce a novel training-free method, named Piculet, for\nenhancing the input representation of MLLMs. Piculet leverages multiple\nspecialized models to extract descriptions of visual information from the input\nimage and combine these descriptions with the original image and query as input\nto the MLLM. We evaluate our method both quantitively and qualitatively, and\nthe results demonstrate that Piculet greatly decreases hallucinations of MLLMs.\nOur method can be easily extended to different MLLMs while being universal.", "categories": "cs.AI", "created": "2024-08-02", "doi": null, "arxiv_id": "2408.01003"}
{"title": "Enhancing Financial Market Predictions: Causality-Driven Feature\n  Selection", "authors": [], "abstract": "This paper introduces the FinSen dataset that revolutionizes financial market\nanalysis by integrating economic and financial news articles from 197 countries\nwith stock market data. The dataset's extensive coverage spans 15 years from\n2007 to 2023 with temporal information, offering a rich, global perspective\nwith 160,000 records on financial market news. Our study leverages causally\nvalidated sentiment scores and LSTM models to enhance market forecast accuracy\nand reliability. Utilizing the FinSen dataset, we introduce an innovative Focal\nCalibration Loss, reducing Expected Calibration Error (ECE) to 3.34 percent\nwith the DAN 3 model. This not only improves prediction accuracy but also\naligns probabilistic forecasts closely with real outcomes, crucial for the\nfinancial sector where predicted probability is paramount. Our approach\ndemonstrates the effectiveness of combining sentiment analysis with precise\ncalibration techniques for trustworthy financial forecasting where the cost of\nmisinterpretation can be high. Finsen Data can be found at [this github\nURL](https://github.com/EagleAdelaide/FinSen_Dataset.git).", "categories": "cs.LG cs.CE cs.CL cs.DB", "created": "2024-08-02", "doi": null, "arxiv_id": "2408.01005"}
{"title": "Tensor Train Low-rank Approximation (TT-LoRA): Democratizing AI with\n  Accelerated LLMs", "authors": [], "abstract": "In recent years, Large Language Models (LLMs) have demonstrated remarkable\ncapabilities across a wide range of natural language processing (NLP) tasks,\nsuch as question-answering, sentiment analysis, text summarization, and machine\ntranslation. However, the ever-growing complexity of LLMs demands immense\ncomputational resources, hindering the broader research and application of\nthese models. To address this, various parameter-efficient fine-tuning\nstrategies, such as Low-Rank Approximation (LoRA) and Adapters, have been\ndeveloped. Despite their potential, these methods often face limitations in\ncompressibility. Specifically, LoRA struggles to scale effectively with the\nincreasing number of trainable parameters in modern large scale LLMs.\nAdditionally, Low-Rank Economic Tensor-Train Adaptation (LoRETTA), which\nutilizes tensor train decomposition, has not yet achieved the level of\ncompression necessary for fine-tuning very large scale models with limited\nresources. This paper introduces Tensor Train Low-Rank Approximation (TT-LoRA),\na novel parameter-efficient fine-tuning (PEFT) approach that extends LoRETTA\nwith optimized tensor train (TT) decomposition integration. By eliminating\nAdapters and traditional LoRA-based structures, TT-LoRA achieves greater model\ncompression without compromising downstream task performance, along with\nreduced inference latency and computational overhead. We conduct an exhaustive\nparameter search to establish benchmarks that highlight the trade-off between\nmodel compression and performance. Our results demonstrate significant\ncompression of LLMs while maintaining comparable performance to larger models,\nfacilitating their deployment on resource-constraint platforms.", "categories": "cs.LG cs.AI", "created": "2024-08-02", "doi": null, "arxiv_id": "2408.01008"}
{"title": "Understanding and Enhancing Linux Kernel-based Packet Switching on WiFi\n  Access Points", "authors": [], "abstract": "As the number of WiFi devices and their traffic demands continue to rise, the\nneed for a scalable and high-performance wireless infrastructure becomes\nincreasingly essential. Central to this infrastructure are WiFi Access Points\n(APs), which facilitate packet switching between Ethernet and WiFi interfaces.\nDespite APs' reliance on the Linux kernel's data plane for packet switching,\nthe detailed operations and complexities of switching packets between Ethernet\nand WiFi interfaces have not been investigated in existing works. This paper\nmakes the following contributions towards filling this research gap. Through\nmacro and micro-analysis of empirical experiments, our study reveals insights\nin two distinct categories. Firstly, while the kernel's statistics offer\nvaluable insights into system operations, we identify and discuss potential\npitfalls that can severely affect system analysis. For instance, we reveal the\nimplications of device drivers on the meaning and accuracy of the statistics\nrelated to packet-switching tasks and processor utilization. Secondly, we\nanalyze the impact of the packet switching path and core configuration on\nperformance and power consumption. Specifically, we identify the differences in\nEthernet-to-WiFi and WiFi-to-Ethernet data paths regarding processing\ncomponents, multi-core utilization, and energy efficiency. We show that the\nWiFi-to-Ethernet data path leverages better multi-core processing and exhibits\nlower power consumption.", "categories": "cs.NI cs.AR cs.OS cs.PF", "created": "2024-08-02", "doi": null, "arxiv_id": "2408.01013"}
{"title": "EIUP: A Training-Free Approach to Erase Non-Compliant Concepts\n  Conditioned on Implicit Unsafe Prompts", "authors": [], "abstract": "Text-to-image diffusion models have shown the ability to learn a diverse\nrange of concepts. However, it is worth noting that they may also generate\nundesirable outputs, consequently giving rise to significant security concerns.\nSpecifically, issues such as Not Safe for Work (NSFW) content and potential\nviolations of style copyright may be encountered. Since image generation is\nconditioned on text, prompt purification serves as a straightforward solution\nfor content safety. Similar to the approach taken by LLM, some efforts have\nbeen made to control the generation of safe outputs by purifying prompts.\nHowever, it is also important to note that even with these efforts, non-toxic\ntext still carries a risk of generating non-compliant images, which is referred\nto as implicit unsafe prompts. Furthermore, some existing works fine-tune the\nmodels to erase undesired concepts from model weights. This type of method\nnecessitates multiple training iterations whenever the concept is updated,\nwhich can be time-consuming and may potentially lead to catastrophic\nforgetting. To address these challenges, we propose a simple yet effective\napproach that incorporates non-compliant concepts into an erasure prompt. This\nerasure prompt proactively participates in the fusion of image spatial features\nand text embeddings. Through attention mechanisms, our method is capable of\nidentifying feature representations of non-compliant concepts in the image\nspace. We re-weight these features to effectively suppress the generation of\nunsafe images conditioned on original implicit unsafe prompts. Our method\nexhibits superior erasure effectiveness while achieving high scores in image\nfidelity compared to the state-of-the-art baselines. WARNING: This paper\ncontains model outputs that may be offensive.", "categories": "cs.CV", "created": "2024-08-02", "doi": null, "arxiv_id": "2408.01014"}
{"title": "IBB Traffic Graph Data: Benchmarking and Road Traffic Prediction Model", "authors": [], "abstract": "Road traffic congestion prediction is a crucial component of intelligent\ntransportation systems, since it enables proactive traffic management, enhances\nsuburban experience, reduces environmental impact, and improves overall safety\nand efficiency. Although there are several public datasets, especially for\nmetropolitan areas, these datasets may not be applicable to practical scenarios\ndue to insufficiency in the scale of data (i.e. number of sensors and road\nlinks) and several external factors like different characteristics of the\ntarget area such as urban, highways and the data collection location. To\naddress this, this paper introduces a novel IBB Traffic graph dataset as an\nalternative benchmark dataset to mitigate these limitations and enrich the\nliterature with new geographical characteristics. IBB Traffic graph dataset\ncovers the sensor data collected at 2451 distinct locations. Moreover, we\npropose a novel Road Traffic Prediction Model that strengthens temporal links\nthrough feature engineering, node embedding with GLEE to represent\ninter-related relationships within the traffic network, and traffic prediction\nwith ExtraTrees. The results indicate that the proposed model consistently\noutperforms the baseline models, demonstrating an average accuracy improvement\nof 4%.", "categories": "cs.LG cs.AI cs.IT math.IT", "created": "2024-08-02", "doi": null, "arxiv_id": "2408.01016"}
{"title": "GNN-MolKAN: Harnessing the Power of KAN to Advance Molecular\n  Representation Learning with GNNs", "authors": [], "abstract": "Effective molecular representation learning is crucial for molecular property\nprediction and drug design. However, existing approaches struggle with\nlimitations in insufficient annotations and suboptimal architecture design. For\ninstance, Graph Neural Networks (GNNs) suffer from over-squashing, causing the\nloss of important structural details in molecules, thus impairing molecular\nrepresentations. In this work, we propose a new class of GNNs, GNN-MolKAN and\nits augmented variant, GNN-MolKAN+, that integrate the Kolmogorov-Arnold\nNetworks (KAN) architecture from AI + Science into GNNs to address these\nchallenges. Additionally, we introduce Adaptive FastKAN (AdFastKAN), an\nadvanced KAN that offers increased stability and speed, further enhancing the\nperformance of standard GNNs. Notably, our approach holds three key benefits:\n1) Superior Performance: GNN-MolKAN and GNN-MolKAN+ demonstrate superior\nprediction ability, robust generalization to unseen scaffolds, and versatile\ntransferability across different GNN architectures. 2) Efficiency: These models\nrequire less computational time and fewer parameters while matching or\nsurpassing the state-of-the-art (SOTA) self-supervised methods. 3) Few-shot\nLearning Ability: GNN-MolKAN demonstrates great potential in few-shot learning\nscenarios, achieving an average improvement of 6.97% across few-shot\nbenchmarks. Overall, we validate our architecture on 6 classification datasets,\n6 regression datasets, and 4 few-shot learning datasets, consistently achieving\nhighly competitive results across all of them.", "categories": "cs.LG cs.AI", "created": "2024-08-02", "doi": null, "arxiv_id": "2408.01018"}
{"title": "A Family of Distributions of Random Subsets for Controlling Positive and\n  Negative Dependence", "authors": [], "abstract": "Positive and negative dependence are fundamental concepts that characterize\nthe attractive and repulsive behavior of random subsets. Although some\nprobabilistic models are known to exhibit positive or negative dependence, it\nis challenging to seamlessly bridge them with a practicable probabilistic\nmodel. In this study, we introduce a new family of distributions, named the\ndiscrete kernel point process (DKPP), which includes determinantal point\nprocesses and parts of Boltzmann machines. We also develop some computational\nmethods for probabilistic operations and inference with DKPPs, such as\ncalculating marginal and conditional probabilities and learning the parameters.\nOur numerical experiments demonstrate the controllability of positive and\nnegative dependence and the effectiveness of the computational methods for\nDKPPs.", "categories": "stat.ML cs.LG", "created": "2024-08-02", "doi": null, "arxiv_id": "2408.01022"}
{"title": "Distilling interpretable causal trees from causal forests", "authors": [], "abstract": "Machine learning methods for estimating treatment effect heterogeneity\npromise greater flexibility than existing methods that test a few pre-specified\nhypotheses. However, one problem these methods can have is that it can be\nchallenging to extract insights from complicated machine learning models. A\nhigh-dimensional distribution of conditional average treatment effects may give\naccurate, individual-level estimates, but it can be hard to understand the\nunderlying patterns; hard to know what the implications of the analysis are.\nThis paper proposes the Distilled Causal Tree, a method for distilling a\nsingle, interpretable causal tree from a causal forest. This compares well to\nexisting methods of extracting a single tree, particularly in noisy data or\nhigh-dimensional data where there are many correlated features. Here it even\noutperforms the base causal forest in most simulations. Its estimates are\ndoubly robust and asymptotically normal just as those of the causal forest are.", "categories": "econ.EM cs.LG", "created": "2024-08-02", "doi": null, "arxiv_id": "2408.01023"}
{"title": "Semantic Skill Grounding for Embodied Instruction-Following in\n  Cross-Domain Environments", "authors": [], "abstract": "In embodied instruction-following (EIF), the integration of pretrained\nlanguage models (LMs) as task planners emerges as a significant branch, where\ntasks are planned at the skill level by prompting LMs with pretrained skills\nand user instructions. However, grounding these pretrained skills in different\ndomains remains challenging due to their intricate entanglement with the\ndomain-specific knowledge. To address this challenge, we present a semantic\nskill grounding (SemGro) framework that leverages the hierarchical nature of\nsemantic skills. SemGro recognizes the broad spectrum of these skills, ranging\nfrom short-horizon low-semantic skills that are universally applicable across\ndomains to long-horizon rich-semantic skills that are highly specialized and\ntailored for particular domains. The framework employs an iterative skill\ndecomposition approach, starting from the higher levels of semantic skill\nhierarchy and then moving downwards, so as to ground each planned skill to an\nexecutable level within the target domain. To do so, we use the reasoning\ncapabilities of LMs for composing and decomposing semantic skills, as well as\ntheir multi-modal extension for assessing the skill feasibility in the target\ndomain. Our experiments in the VirtualHome benchmark show the efficacy of\nSemGro in 300 cross-domain EIF scenarios.", "categories": "cs.AI", "created": "2024-08-02", "doi": null, "arxiv_id": "2408.01024"}
{"title": "PINNs for Medical Image Analysis: A Survey", "authors": [], "abstract": "The incorporation of physical information in machine learning frameworks is\ntransforming medical image analysis (MIA). By integrating fundamental knowledge\nand governing physical laws, these models achieve enhanced robustness and\ninterpretability. In this work, we explore the utility of physics-informed\napproaches for MIA (PIMIA) tasks such as registration, generation,\nclassification, and reconstruction. We present a systematic literature review\nof over 80 papers on physics-informed methods dedicated to MIA. We propose a\nunified taxonomy to investigate what physics knowledge and processes are\nmodelled, how they are represented, and the strategies to incorporate them into\nMIA models. We delve deep into a wide range of image analysis tasks, from\nimaging, generation, prediction, inverse imaging (super-resolution and\nreconstruction), registration, and image analysis (segmentation and\nclassification). For each task, we thoroughly examine and present in a tabular\nformat the central physics-guided operation, the region of interest (with\nrespect to human anatomy), the corresponding imaging modality, the dataset used\nfor model training, the deep network architecture employed, and the primary\nphysical process, equation, or principle utilized. Additionally, we also\nintroduce a novel metric to compare the performance of PIMIA methods across\ndifferent tasks and datasets. Based on this review, we summarize and distil our\nperspectives on the challenges, open research questions, and directions for\nfuture research. We highlight key open challenges in PIMIA, including selecting\nsuitable physics priors and establishing a standardized benchmarking platform.", "categories": "eess.IV cs.CV", "created": "2024-08-02", "doi": null, "arxiv_id": "2408.01026"}
{"title": "Randomized Strategyproof Mechanisms with Best of Both Worlds Fairness\n  and Efficiency", "authors": [], "abstract": "We study the problem of mechanism design for allocating a set of indivisible\nitems among agents with private preferences on items. We are interested in such\na mechanism that is strategyproof (where agents' best strategy is to report\ntheir true preferences) and is expected to ensure fairness and efficiency to a\ncertain degree. We first present an impossibility result that a deterministic\nmechanism does not exist that is strategyproof, fair and efficient for\nallocating indivisible chores. We then utilize randomness to overcome the\nstrong impossibility. For allocating indivisible chores, we propose a\nrandomized mechanism that is strategyproof in expectation as well as ex-ante\nand ex-post (best of both worlds) fair and efficient. For allocating mixed\nitems, where an item can be a good (i.e., with a positive utility) for one\nagent but a chore (i.e., a with negative utility) for another, we propose a\nrandomized mechanism that is strategyproof in expectation with best of both\nworlds fairness and efficiency when there are two agents.", "categories": "cs.GT", "created": "2024-08-02", "doi": null, "arxiv_id": "2408.01027"}
{"title": "Harnessing Ferro-Valleytricity in Penta-Layer Rhombohedral Graphene for\n  Memory and Compute", "authors": [], "abstract": "Two-dimensional materials with multiple degrees of freedom, including spin,\nvalleys, and orbitals, open up an exciting avenue for engineering\nmultifunctional devices. Beyond spintronics, these degrees of freedom can lead\nto novel quantum effects such as valley-dependent Hall effects and orbital\nmagnetism, which could revolutionize next-generation electronics. However,\nachieving independent control over valley polarization and orbital magnetism\nhas been a challenge due to the need for large electric fields. A recent\nbreakthrough involving penta-layer rhombohedral graphene has demonstrated the\nability to individually manipulate anomalous Hall signals and orbital magnetic\nhysteresis, forming what is known as a valley-magnetic quartet. Here, we\nleverage the electrically tunable Ferro-valleytricity of penta-layer\nrhombohedral graphene to develop non-volatile memory and in-memory computation\napplications. We propose an architecture for a dense, scalable, and\nselector-less non-volatile memory array that harnesses the electrically tunable\nferro-valleytricity. In our designed array architecture, non-destructive read\nand write operations are conducted by sensing the valley state through two\ndifferent pairs of terminals, allowing for independent optimization of\nread/write peripheral circuits. The power consumption of our PRG-based array is\nremarkably low, with only ~ 6 nW required per write operation and ~ 2.3 nW per\nread operation per cell. This consumption is orders of magnitude lower than\nthat of the majority of state-of-the-art cryogenic memories. Additionally, we\nengineer in-memory computation by implementing majority logic operations within\nour proposed non-volatile memory array without modifying the peripheral\ncircuitry. Our framework presents a promising pathway toward achieving\nultra-dense cryogenic memory and in-memory computation capabilities.", "categories": "cond-mat.mes-hall cs.AR", "created": "2024-08-02", "doi": null, "arxiv_id": "2408.01028"}
{"title": "POA: Pre-training Once for Models of All Sizes", "authors": [], "abstract": "Large-scale self-supervised pre-training has paved the way for one foundation\nmodel to handle many different vision tasks. Most pre-training methodologies\ntrain a single model of a certain size at one time. Nevertheless, various\ncomputation or storage constraints in real-world scenarios require substantial\nefforts to develop a series of models with different sizes to deploy. Thus, in\nthis study, we propose a novel tri-branch self-supervised training framework,\ntermed as POA (Pre-training Once for All), to tackle this aforementioned issue.\nOur approach introduces an innovative elastic student branch into a modern\nself-distillation paradigm. At each pre-training step, we randomly sample a\nsub-network from the original student to form the elastic student and train all\nbranches in a self-distilling fashion. Once pre-trained, POA allows the\nextraction of pre-trained models of diverse sizes for downstream tasks.\nRemarkably, the elastic student facilitates the simultaneous pre-training of\nmultiple models with different sizes, which also acts as an additional ensemble\nof models of various sizes to enhance representation learning. Extensive\nexperiments, including k-nearest neighbors, linear probing evaluation and\nassessments on multiple downstream tasks demonstrate the effectiveness and\nadvantages of our POA. It achieves state-of-the-art performance using ViT, Swin\nTransformer and ResNet backbones, producing around a hundred models with\ndifferent sizes through a single pre-training session. The code is available\nat: https://github.com/Qichuzyy/POA.", "categories": "cs.CV", "created": "2024-08-02", "doi": null, "arxiv_id": "2408.01031"}
{"title": "Structure from Motion-based Motion Estimation and 3D Reconstruction of\n  Unknown Shaped Space Debris", "authors": [], "abstract": "With the boost in the number of spacecraft launches in the current decades,\nthe space debris problem is daily becoming significantly crucial. For\nsustainable space utilization, the continuous removal of space debris is the\nmost severe problem for humanity. To maximize the reliability of the debris\ncapture mission in orbit, accurate motion estimation of the target is\nessential. Space debris has lost its attitude and orbit control capabilities,\nand its shape is unknown due to the break. This paper proposes the Structure\nfrom Motion-based algorithm to perform unknown shaped space debris motion\nestimation with limited resources, where only 2D images are required as input.\nThe method then outputs the reconstructed shape of the unknown object and the\nrelative pose trajectory between the target and the camera simultaneously,\nwhich are exploited to estimate the target's motion. The method is\nquantitatively validated with the realistic image dataset generated by the\nmicrogravity experiment in a 2D air-floating testbed and 3D kinematic\nsimulation.", "categories": "cs.RO cs.CV", "created": "2024-08-02", "doi": null, "arxiv_id": "2408.01035"}
{"title": "MambaST: A Plug-and-Play Cross-Spectral Spatial-Temporal Fuser for\n  Efficient Pedestrian Detection", "authors": [], "abstract": "This paper proposes MambaST, a plug-and-play cross-spectral spatial-temporal\nfusion pipeline for efficient pedestrian detection. Several challenges exist\nfor pedestrian detection in autonomous driving applications. First, it is\ndifficult to perform accurate detection using RGB cameras under dark or\nlow-light conditions. Cross-spectral systems must be developed to integrate\ncomplementary information from multiple sensor modalities, such as thermal and\nvisible cameras, to improve the robustness of the detections. Second,\npedestrian detection models are latency-sensitive. Efficient and easy-to-scale\ndetection models with fewer parameters are highly desirable for real-time\napplications such as autonomous driving. Third, pedestrian video data provides\nspatial-temporal correlations of pedestrian movement. It is beneficial to\nincorporate temporal as well as spatial information to enhance pedestrian\ndetection. This work leverages recent advances in the state space model (Mamba)\nand proposes a novel Multi-head Hierarchical Patching and Aggregation (MHHPA)\nstructure to extract both fine-grained and coarse-grained information from both\nRGB and thermal imagery. Experimental results show that the proposed MHHPA is\nan effective and efficient alternative to a Transformer model for\ncross-spectral pedestrian detection. Our proposed model also achieves superior\nperformance on small-scale pedestrian detection. The code is available at\nhttps://github.com/XiangboGaoBarry/MambaST}{https://github.com/XiangboGaoBarry/MambaST.", "categories": "cs.CV", "created": "2024-08-02", "doi": null, "arxiv_id": "2408.01037"}
{"title": "Privacy-Preserving Split Learning with Vision Transformers using\n  Patch-Wise Random and Noisy CutMix", "authors": [], "abstract": "In computer vision, the vision transformer (ViT) has increasingly superseded\nthe convolutional neural network (CNN) for improved accuracy and robustness.\nHowever, ViT's large model sizes and high sample complexity make it difficult\nto train on resource-constrained edge devices. Split learning (SL) emerges as a\nviable solution, leveraging server-side resources to train ViTs while utilizing\nprivate data from distributed devices. However, SL requires additional\ninformation exchange for weight updates between the device and the server,\nwhich can be exposed to various attacks on private training data. To mitigate\nthe risk of data breaches in classification tasks, inspired from the CutMix\nregularization, we propose a novel privacy-preserving SL framework that injects\nGaussian noise into smashed data and mixes randomly chosen patches of smashed\ndata across clients, coined DP-CutMixSL. Our analysis demonstrates that\nDP-CutMixSL is a differentially private (DP) mechanism that strengthens privacy\nprotection against membership inference attacks during forward propagation.\nThrough simulations, we show that DP-CutMixSL improves privacy protection\nagainst membership inference attacks, reconstruction attacks, and label\ninference attacks, while also improving accuracy compared to DP-SL and\nDP-MixSL.", "categories": "cs.DC cs.CR cs.CV cs.LG", "created": "2024-08-02", "doi": null, "arxiv_id": "2408.01040"}
{"title": "Boosting Gaze Object Prediction via Pixel-level Supervision from Vision\n  Foundation Model", "authors": [], "abstract": "Gaze object prediction (GOP) aims to predict the category and location of the\nobject that a human is looking at. Previous methods utilized box-level\nsupervision to identify the object that a person is looking at, but struggled\nwith semantic ambiguity, ie, a single box may contain several items since\nobjects are close together. The Vision foundation model (VFM) has improved in\nobject segmentation using box prompts, which can reduce confusion by more\nprecisely locating objects, offering advantages for fine-grained prediction of\ngaze objects. This paper presents a more challenging gaze object segmentation\n(GOS) task, which involves inferring the pixel-level mask corresponding to the\nobject captured by human gaze behavior. In particular, we propose that the\npixel-level supervision provided by VFM can be integrated into gaze object\nprediction to mitigate semantic ambiguity. This leads to our gaze object\ndetection and segmentation framework that enables accurate pixel-level\npredictions. Different from previous methods that require additional head input\nor ignore head features, we propose to automatically obtain head features from\nscene features to ensure the model's inference efficiency and flexibility in\nthe real world. Moreover, rather than directly fuse features to predict gaze\nheatmap as in existing methods, which may overlook spatial location and subtle\ndetails of the object, we develop a space-to-object gaze regression method to\nfacilitate human-object gaze interaction. Specifically, it first constructs an\ninitial human-object spatial connection, then refines this connection by\ninteracting with semantically clear features in the segmentation branch,\nultimately predicting a gaze heatmap for precise localization. Extensive\nexperiments on GOO-Synth and GOO-Real datasets demonstrate the effectiveness of\nour method.", "categories": "cs.CV", "created": "2024-08-02", "doi": null, "arxiv_id": "2408.01044"}
{"title": "QUDSELECT: Selective Decoding for Questions Under Discussion Parsing", "authors": [], "abstract": "Question Under Discussion (QUD) is a discourse framework that uses implicit\nquestions to reveal discourse relationships between sentences. In QUD parsing,\neach sentence is viewed as an answer to a question triggered by an anchor\nsentence in prior context. The resulting QUD structure is required to conform\nto several theoretical criteria like answer compatibility (how well the\nquestion is answered), making QUD parsing a challenging task. Previous works\nconstruct QUD parsers in a pipelined manner (i.e. detect the trigger sentence\nin context and then generate the question). However, these parsers lack a\nholistic view of the task and can hardly satisfy all the criteria. In this\nwork, we introduce QUDSELECT, a joint-training framework that selectively\ndecodes the QUD dependency structures considering the QUD criteria. Using\ninstruction-tuning, we train models to simultaneously predict the anchor\nsentence and generate the associated question. To explicitly incorporate the\ncriteria, we adopt a selective decoding strategy of sampling multiple QUD\ncandidates during inference, followed by selecting the best one with criteria\nscorers. Our method outperforms the state-of-the-art baseline models by 9% in\nhuman evaluation and 4% in automatic evaluation, demonstrating the\neffectiveness of our framework.", "categories": "cs.CL", "created": "2024-08-02", "doi": null, "arxiv_id": "2408.01046"}
{"title": "Unexpected fault activation in underground gas storage. Part II:\n  Definition of safe operational bandwidths", "authors": [], "abstract": "Underground gas storage is a versatile tool for managing energy resources and\naddressing pressing environmental concerns. While natural gas is stored in\ngeological formations since the beginning of the 20th century, hydrogen has\nrecently been considered as a potential candidate toward a more flexible and\nsustainable energy infrastructure. Furthermore, these formations can also be\nused to sequester environmentally harmful gases such as CO2 securely. When such\noperations are implemented in faulted basins, however, safety concerns may\narise due to the possible reactivation of pre-existing faults, which could\nresult in (micro)-seismicity events. In the Netherlands, it has been recently\nnoted that fault reactivation can occur \"unexpectedly\" during the life of an\nunderground gas storage (UGS) site, even when stress conditions are not\nexpected to cause a failure. The present two-part work aims to develop a\nmodeling framework to investigate the physical mechanisms causing such\noccurrences and define a safe operational bandwidth for pore pressure variation\nfor UGS operations in the faulted reservoirs of the Rotliegend formation, the\nNetherlands. In this paper, we investigate in detail the mechanisms and crucial\nfactors that result in fault reactivation at various stages of a UGS project.\nThe mathematical and numerical model described in Part 1 is used, also\naccounting for the effect of geochemical dissolution on reservoir and caprock\nweakening. The study investigates the risks of fault activation caused by the\nstorage of different fluids for various purposes, such as long-term CO2\nsequestration, CH4 and N2 injection and extraction cycles, and N2 permanent\nstorage. The results show how geomechanical properties and reservoir operating\nconditions may increase the risk of fault reactivation at various UGS stages.\nFinally, operational guidelines for improving secure storage operations are\npresented.", "categories": "math.NA cs.NA", "created": "2024-08-02", "doi": null, "arxiv_id": "2408.01049"}
{"title": "The Impact of Hyperparameters on Large Language Model Inference\n  Performance: An Evaluation of vLLM and HuggingFace Pipelines", "authors": [], "abstract": "The recent surge of open-source large language models (LLMs) enables\ndevelopers to create AI-based solutions while maintaining control over aspects\nsuch as privacy and compliance, thereby providing governance and ownership of\nthe model deployment process. To utilize these LLMs, inference engines are\nneeded. These engines load the model's weights onto available resources, such\nas GPUs, and process queries to generate responses. The speed of inference, or\nperformance, of the LLM, is critical for real-time applications, as it computes\nmillions or billions of floating point operations per inference. Recently,\nadvanced inference engines such as vLLM have emerged, incorporating novel\nmechanisms such as efficient memory management to achieve state-of-the-art\nperformance. In this paper, we analyze the performance, particularly the\nthroughput (tokens generated per unit of time), of 20 LLMs using two inference\nlibraries: vLLM and HuggingFace's pipelines. We investigate how various\nhyperparameters, which developers must configure, influence inference\nperformance. Our results reveal that throughput landscapes are irregular, with\ndistinct peaks, highlighting the importance of hyperparameter optimization to\nachieve maximum performance. We also show that applying hyperparameter\noptimization when upgrading or downgrading the GPU model used for inference can\nimprove throughput from HuggingFace pipelines by an average of 9.16% and 13.7%,\nrespectively.", "categories": "cs.SE cs.CL cs.LG", "created": "2024-08-02", "doi": null, "arxiv_id": "2408.01050"}
{"title": "From Stem to Stern: Contestability Along AI Value Chains", "authors": [], "abstract": "This workshop will grow and consolidate a community of interdisciplinary CSCW\nresearchers focusing on the topic of contestable AI. As an outcome of the\nworkshop, we will synthesize the most pressing opportunities and challenges for\ncontestability along AI value chains in the form of a research roadmap. This\nroadmap will help shape and inspire imminent work in this field. Considering\nthe length and depth of AI value chains, it will especially spur discussions\naround the contestability of AI systems along various sites of such chains. The\nworkshop will serve as a platform for dialogue and demonstrations of concrete,\nsuccessful, and unsuccessful examples of AI systems that (could or should) have\nbeen contested, to identify requirements, obstacles, and opportunities for\ndesigning and deploying contestable AI in various contexts. This will be held\nprimarily as an in-person workshop, with some hybrid accommodation. The day\nwill consist of individual presentations and group activities to stimulate\nideation and inspire broad reflections on the field of contestable AI. Our aim\nis to facilitate interdisciplinary dialogue by bringing together researchers,\npractitioners, and stakeholders to foster the design and deployment of\ncontestable AI.", "categories": "cs.AI cs.CY cs.HC", "created": "2024-08-02", "doi": null, "arxiv_id": "2408.01051"}
{"title": "Enhancing the MILP/MIQCP-based Automatic Search for Differential-Linear\n  Distinguishers of Simon-Like Ciphers", "authors": [], "abstract": "In this paper, we propose an improved method based on Mixed-Integer Linear\nProgramming/Mixed-Integer Quadratic Constraint Programming (MILP/MIQCP) to\nautomatically find better differential-linear (DL) distinguishers for the all\nmembers of Simon and Simeck block cipher families. To be specific, we first\ngive the completely precise MILP model to describe the linear part, and explain\nhow to utilize the general expressions of \\textsf{Gurobi} solver to model the\npropagation of continuous difference for the middle part in a quite easy way.\nSecondly, in order to solve the MILP/MIQCP model in a reasonable time, we\npropose two heuristic strategies based on the divide-and-conquer idea to speed\nup the search process. Thirdly, we introduce the transforming technique, which\nexploits the clustering effect on DL trails, to improve the estimated\ncorrelation of the DL approximation.\n  We apply our method to Simon and Simeck block cipher families. Consequently,\nwe find the 14/17/21/26-round theoretical DL distinguishers of\nSimon32/48/64/96, which extend the previous longest ones of Simon32/48/96 by\none round and Simon64 by two rounds, respectively. For Simeck, we do not\nexplore longer distinguishers compared to the currently best results, but\nrefresh all the results of Zhou et al. (the first work to automate finding DL\ndistinguishers for Simon-like ciphers using MILP/MIQCP). Besides, in order to\nvalidate the correctness of these distinguishers, the experimental\nverifications are conducted on Simon32/Simeck32 and Simon48/Simeck48. The\nresults show that our theoretical estimations on correlations are very close to\nthe experimental ones, which can be regarded as a concrete support for the\neffectiveness of our method.", "categories": "cs.CR", "created": "2024-08-02", "doi": null, "arxiv_id": "2408.01052"}
{"title": "Distribution Aggregation via Continuous Thiele's Rules", "authors": [], "abstract": "We introduce the class of \\textit{Continuous Thiele's Rules} that generalize\nthe familiar \\textbf{Thiele's rules} \\cite{janson2018phragmens} of multi-winner\nvoting to distribution aggregation problems. Each rule in that class maximizes\n$\\sum_if(\\pi^i)$ where $\\pi^i$ is an agent $i$'s satisfaction and $f$ could be\nany twice differentiable, increasing and concave real function. Based on a\nsingle quantity we call the \\textit{'Inequality Aversion'} of $f$ (elsewhere\nknown as \"Relative Risk Aversion\"), we derive bounds on the Egalitarian loss,\nwelfare loss and the approximation of \\textit{Average Fair Share}, leading to a\nquantifiable, continuous presentation of their inevitable trade-offs. In\nparticular, we show that the Nash Product Rule satisfies\\textit{ Average Fair\nShare} in our setting.", "categories": "cs.GT", "created": "2024-08-02", "doi": null, "arxiv_id": "2408.01054"}
{"title": "LLM as Runtime Error Handler: A Promising Pathway to Adaptive\n  Self-Healing of Software Systems", "authors": [], "abstract": "Unanticipated runtime errors, lacking predefined handlers, can abruptly\nterminate execution and lead to severe consequences, such as data loss or\nsystem crashes. Despite extensive efforts to identify potential errors during\nthe development phase, such unanticipated errors remain a challenge to to be\nentirely eliminated, making the runtime mitigation measurements still\nindispensable to minimize their impact. Automated self-healing techniques, such\nas reusing existing handlers, have been investigated to reduce the loss coming\nthrough with the execution termination. However, the usability of existing\nmethods is retained by their predefined heuristic rules and they fail to handle\ndiverse runtime errors adaptively. Recently, the advent of Large Language\nModels (LLMs) has opened new avenues for addressing this problem. Inspired by\ntheir remarkable capabilities in understanding and generating code, we propose\nto deal with the runtime errors in a real-time manner using LLMs.\n  Specifically, we propose Healer, the first LLM-assisted self-healing\nframework for handling runtime errors. When an unhandled runtime error occurs,\nHealer will be activated to generate a piece of error-handling code with the\nhelp of its internal LLM and the code will be executed inside the runtime\nenvironment owned by the framework to obtain a rectified program state from\nwhich the program should continue its execution. Our exploratory study\nevaluates the performance of Healer using four different code benchmarks and\nthree state-of-the-art LLMs, GPT-3.5, GPT-4, and CodeQwen-7B. Results show\nthat, without the need for any fine-tuning, GPT-4 can successfully help\nprograms recover from 72.8% of runtime errors, highlighting the potential of\nLLMs in handling runtime errors.", "categories": "cs.SE cs.AI cs.CR", "created": "2024-08-02", "doi": null, "arxiv_id": "2408.01055"}
{"title": "The NING Humanoid: The Concurrent Design and Development of a Dynamic\n  and Agile Platform", "authors": [], "abstract": "The recent surge of interest in agile humanoid robots achieving dynamic tasks\nlike jumping and flipping necessitates the concurrent design of a robot\nplatform that combines exceptional hardware performance with effective control\nalgorithms. This paper introduces the NING Humanoid, an agile and robust\nplatform aimed at achieving human-like athletic capabilities. The NING humanoid\nfeatures high-torque actuators, a resilient mechanical co-design based on the\nCentroidal dynamics, and a whole-body model predictive control (WB-MPC)\nframework. It stands at 1.1 meters tall and weighs 20 kg with 18 degrees of\nfreedom (DOFs). It demonstrates impressive abilities such as walking, push\nrecovery, and stair climbing at a high control bandwidth. Our presentation will\nencompass a hardware co-design, the control framework, as well as simulation\nand real-time experiments.", "categories": "cs.RO", "created": "2024-08-02", "doi": null, "arxiv_id": "2408.01056"}
{"title": "Numerical and Lyapunov-Based Investigation of the Effect of Stenosis on\n  Blood Transport Stability Using a Control-Theoretic PDE Model of\n  Cardiovascular Flow", "authors": [], "abstract": "We perform various numerical tests to study the effect of (boundary) stenosis\non blood flow stability, employing a detailed and accurate, second-order\nfinite-volume scheme for numerically implementing a partial differential\nequation (PDE) model, using clinically realistic values for the artery's\nparameters and the blood inflow. The model consists of a baseline $2\\times 2$\nhetero-directional, nonlinear hyperbolic PDE system, in which, the stenosis'\neffect is described by a pressure drop at the outlet of an arterial segment\nconsidered. We then study the stability properties (observed in our numerical\ntests) of a reference trajectory, corresponding to a given time-varying inflow\n(e.g., a periodic trajectory with period equal to the time interval between two\nconsecutive heartbeats) and stenosis severity, deriving the respective\nlinearized system and constructing a Lyapunov functional. Due to the fact that\nthe linearized system is time varying, with time-varying parameters depending\non the reference trajectories themselves (that, in turn, depend in an implicit\nmanner on the stenosis degree), which cannot be derived analytically, we verify\nthe Lyapunov-based stability conditions obtained, numerically. Both the\nnumerical tests and the Lyapunov-based stability analysis show that a reference\ntrajectory is asymptotically stable with a decay rate that decreases as the\nstenosis severity deteriorates.", "categories": "math.NA cs.NA cs.SY eess.SY", "created": "2024-08-02", "doi": null, "arxiv_id": "2408.01058"}
{"title": "Universality of kernel random matrices and kernel regression in the\n  quadratic regime", "authors": [], "abstract": "Kernel ridge regression (KRR) is a popular class of machine learning models\nthat has become an important tool for understanding deep learning. Much of the\nfocus has been on studying the proportional asymptotic regime, $n \\asymp d$,\nwhere $n$ is the number of training samples and $d$ is the dimension of the\ndataset. In this regime, under certain conditions on the data distribution, the\nkernel random matrix involved in KRR exhibits behavior akin to that of a linear\nkernel. In this work, we extend the study of kernel regression to the quadratic\nasymptotic regime, where $n \\asymp d^2$. In this regime, we demonstrate that a\nbroad class of inner-product kernels exhibit behavior similar to a quadratic\nkernel. Specifically, we establish an operator norm approximation bound for the\ndifference between the original kernel random matrix and a quadratic kernel\nrandom matrix with additional correction terms compared to the Taylor expansion\nof the kernel functions. The approximation works for general data distributions\nunder a Gaussian-moment-matching assumption with a covariance structure. This\nnew approximation is utilized to obtain a limiting spectral distribution of the\noriginal kernel matrix and characterize the precise asymptotic training and\ngeneralization errors for KRR in the quadratic regime when $n/d^2$ converges to\na non-zero constant. The generalization errors are obtained for both\ndeterministic and random teacher models. Our proof techniques combine moment\nmethods, Wick's formula, orthogonal polynomials, and resolvent analysis of\nrandom matrices with correlated entries.", "categories": "stat.ML cs.LG math.PR math.ST stat.TH", "created": "2024-08-02", "doi": null, "arxiv_id": "2408.01062"}
{"title": "Leveraging Large Language Models for Mobile App Review Feature\n  Extraction", "authors": [], "abstract": "Mobile app review analysis presents unique challenges due to the low quality,\nsubjective bias, and noisy content of user-generated documents. Extracting\nfeatures from these reviews is essential for tasks such as feature\nprioritization and sentiment analysis, but it remains a challenging task.\nMeanwhile, encoder-only models based on the Transformer architecture have shown\npromising results for classification and information extraction tasks for\nmultiple software engineering processes. This study explores the hypothesis\nthat encoder-only large language models can enhance feature extraction from\nmobile app reviews. By leveraging crowdsourced annotations from an industrial\ncontext, we redefine feature extraction as a supervised token classification\ntask. Our approach includes extending the pre-training of these models with a\nlarge corpus of user reviews to improve contextual understanding and employing\ninstance selection techniques to optimize model fine-tuning. Empirical\nevaluations demonstrate that this method improves the precision and recall of\nextracted features and enhances performance efficiency. Key contributions\ninclude a novel approach to feature extraction, annotated datasets, extended\npre-trained models, and an instance selection mechanism for cost-effective\nfine-tuning. This research provides practical methods and empirical evidence in\napplying large language models to natural language processing tasks within\nmobile app reviews, offering improved performance in feature extraction.", "categories": "cs.CL cs.SE", "created": "2024-08-02", "doi": null, "arxiv_id": "2408.01063"}
{"title": "Computation of $\\gamma$-linear projected barcodes for multiparameter\n  persistence", "authors": [], "abstract": "The $\\gamma$-linear projected barcode was recently introduced as an\nalternative to the well-known fibered barcode for multiparameter persistence,\nin which restrictions of the modules to lines are replaced by pushforwards of\nthe modules along linear forms in the polar of some fixed cone $\\gamma$. So\nfar, the computation of the $\\gamma$-linear projected barcode has only been\nstudied in the functional setting, in which persistence modules come from the\npersistent cohomology of $\\mathbb{R}^n$-valued functions. Here we develop a\nmethod that works in the algebraic setting directly, for any multiparameter\npersistence module over $\\mathbb{R}^n$ that is given via a finite free\nresolution. Our approach is similar to that of RIVET: first, it pre-processes\nthe resolution to build an arrangement in the dual of $\\mathbb{R}^n$ and a\nbarcode template in each face of the arrangement; second, given any query\nlinear form $u$ in the polar of $\\gamma$, it locates $u$ within the arrangement\nto produce the corresponding barcode efficiently. While our theoretical\ncomplexity bounds are similar to the ones of RIVET, our arrangement turns out\nto be simpler thanks to the linear structure of the space of linear forms. Our\ntheoretical analysis combines sheaf-theoretic and module-theoretic techniques,\nshowing that multiparameter persistence modules can be converted into a special\ntype of complexes of sheaves on vector spaces called conic-complexes, whose\nderived pushforwards by linear forms have predictable barcodes.", "categories": "math.AT cs.CG", "created": "2024-08-02", "doi": null, "arxiv_id": "2408.01065"}
{"title": "Stabilization of synchronous tridiagonal network motion", "authors": [], "abstract": "We consider a network of identical agents, coupled through linear asymmetric\ncoupling. An important case is when each agent has an asymptotically stable\nperiodic orbit, so that the full network inherits a synchronous periodic orbit,\nbut also chaotic trajectories are of interest. In this work, we will restrict\nto \"nearest-neighbor\" type of couplings.\n  The Master Stability Function (MSF) is a powerful tool to establish local\nstability of the synchronous orbit, in particular a negative MSF implies\nasymptotic stability. But not every network structure gives a negative MSF.\nMoreover, there are many situations where in order to obtain a negative MSF,\nsymmetric networks need a coupling strength so large, that the model bears\nlittle physical interest. We make two main contributions: (i) Given a\ntridiagonal nearest neighbor topology, we show how it is possible to choose\nappropriate coupling so that the synchronous orbit is stable, and (ii) we show\nthat this stability comes without the need of a large coupling strength if the\nstructure is not symmetric. Our construction is based on solving inverse\neigenvalue problems. We will see that the coupling of the agents cannot always\nbe chosen to be symmetric so that the underlying graph structure is that of a\ndirected graph with edges having different weights. We provide numerical\nimplementation of our technique on networks of van der Pol and of chaotic\nR\\\"ossler oscillators, where the standard symmetric nearest neighbor coupling\nfails to give stability of the synchronous orbit.", "categories": "math.DS cs.NA math.NA", "created": "2024-08-02", "doi": null, "arxiv_id": "2408.01066"}
{"title": "Amodal Segmentation for Laparoscopic Surgery Video Instruments", "authors": [], "abstract": "Segmentation of surgical instruments is crucial for enhancing surgeon\nperformance and ensuring patient safety. Conventional techniques such as\nbinary, semantic, and instance segmentation share a common drawback: they do\nnot accommodate the parts of instruments obscured by tissues or other\ninstruments. Precisely predicting the full extent of these occluded instruments\ncan significantly improve laparoscopic surgeries by providing critical guidance\nduring operations and assisting in the analysis of potential surgical errors,\nas well as serving educational purposes. In this paper, we introduce Amodal\nSegmentation to the realm of surgical instruments in the medical field. This\ntechnique identifies both the visible and occluded parts of an object. To\nachieve this, we introduce a new Amoal Instruments Segmentation (AIS) dataset,\nwhich was developed by reannotating each instrument with its complete mask,\nutilizing the 2017 MICCAI EndoVis Robotic Instrument Segmentation Challenge\ndataset. Additionally, we evaluate several leading amodal segmentation methods\nto establish a benchmark for this new dataset.", "categories": "cs.CV", "created": "2024-08-02", "doi": null, "arxiv_id": "2408.01067"}
{"title": "A Survey on Self-play Methods in Reinforcement Learning", "authors": [], "abstract": "Self-play, characterized by agents' interactions with copies or past versions\nof itself, has recently gained prominence in reinforcement learning. This paper\nfirst clarifies the preliminaries of self-play, including the multi-agent\nreinforcement learning framework and basic game theory concepts. Then it\nprovides a unified framework and classifies existing self-play algorithms\nwithin this framework. Moreover, the paper bridges the gap between the\nalgorithms and their practical implications by illustrating the role of\nself-play in different scenarios. Finally, the survey highlights open\nchallenges and future research directions in self-play. This paper is an\nessential guide map for understanding the multifaceted landscape of self-play\nin RL.", "categories": "cs.AI", "created": "2024-08-02", "doi": null, "arxiv_id": "2408.01072"}
{"title": "The EAP-AIAS: Adapting the AI Assessment Scale for English for Academic\n  Purposes", "authors": [], "abstract": "The rapid advancement of Generative Artificial Intelligence (GenAI) presents\nboth opportunities and challenges for English for Academic Purposes (EAP)\ninstruction. This paper proposes an adaptation of the AI Assessment Scale\n(AIAS) specifically tailored for EAP contexts, termed the EAP-AIAS.\n  This framework aims to provide a structured approach for integrating GenAI\ntools into EAP assessment practices while maintaining academic integrity and\nsupporting language development. The EAP-AIAS consists of five levels, ranging\nfrom \"No AI\" to \"Full AI\", each delineating appropriate GenAI usage in EAP\ntasks. We discuss the rationale behind this adaptation, considering the unique\nneeds of language learners and the dual focus of EAP on language proficiency\nand academic acculturation.\n  This paper explores potential applications of the EAP-AIAS across various EAP\nassessment types, including writing tasks, presentations, and research\nprojects. By offering a flexible framework, the EAP-AIAS seeks to empower EAP\npractitioners seeking to deal with the complexities of GenAI integration in\neducation and prepare students for an AI-enhanced academic and professional\nfuture. This adaptation represents a step towards addressing the pressing need\nfor ethical and pedagogically sound AI integration in language education.", "categories": "cs.CY cs.AI", "created": "2024-08-02", "doi": null, "arxiv_id": "2408.01075"}
{"title": "Exploiting the Semantic Knowledge of Pre-trained Text-Encoders for\n  Continual Learning", "authors": [], "abstract": "Deep neural networks (DNNs) excel on fixed datasets but struggle with\nincremental and shifting data in real-world scenarios. Continual learning\naddresses this challenge by allowing models to learn from new data while\nretaining previously learned knowledge. Existing methods mainly rely on visual\nfeatures, often neglecting the rich semantic information encoded in text. The\nsemantic knowledge available in the label information of the images, offers\nimportant semantic information that can be related with previously acquired\nknowledge of semantic classes. Consequently, effectively leveraging this\ninformation throughout continual learning is expected to be beneficial. To\naddress this, we propose integrating semantic guidance within and across tasks\nby capturing semantic similarity using text embeddings. We start from a\npre-trained CLIP model, employ the \\emph{Semantically-guided Representation\nLearning (SG-RL)} module for a soft-assignment towards all current task\nclasses, and use the Semantically-guided Knowledge Distillation (SG-KD) module\nfor enhanced knowledge transfer. Experimental results demonstrate the\nsuperiority of our method on general and fine-grained datasets. Our code can be\nfound in\nhttps://github.com/aprilsveryown/semantically-guided-continual-learning.", "categories": "cs.CV", "created": "2024-08-02", "doi": null, "arxiv_id": "2408.01076"}
{"title": "PhysMamba: Leveraging Dual-Stream Cross-Attention SSD for Remote\n  Physiological Measurement", "authors": [], "abstract": "Remote Photoplethysmography (rPPG) is a non-contact technique for extracting\nphysiological signals from facial videos, used in applications like emotion\nmonitoring, medical assistance, and anti-face spoofing. Unlike controlled\nlaboratory settings, real-world environments often contain motion artifacts and\nnoise, affecting the performance of existing methods. To address this, we\npropose PhysMamba, a dual-stream time-frequency interactive model based on\nMamba. PhysMamba integrates the state-of-the-art Mamba-2 model and employs a\ndual-stream architecture to learn diverse rPPG features, enhancing robustness\nin noisy conditions. Additionally, we designed the Cross-Attention State Space\nDuality (CASSD) module to improve information exchange and feature\ncomplementarity between the two streams. We validated PhysMamba using PURE,\nUBFC-rPPG and MMPD. Experimental results show that PhysMamba achieves\nstate-of-the-art performance across various scenarios, particularly in complex\nenvironments, demonstrating its potential in practical remote heart rate\nmonitoring applications.", "categories": "cs.CV", "created": "2024-08-02", "doi": null, "arxiv_id": "2408.01077"}
{"title": "Multibeam Hybrid Transmitarray Based on Polarization Rotating\n  Metasurface With Reconfigurable Bidirectional Radiation", "authors": [], "abstract": "This paper proposes a bidirectional multibeam hybrid transmitarray (HTA)\nemploying a transmission polarization-rotating metasurface (TPRM). A novel\nconfiguration is introduced to facilitate bidirectional beam scanning by\ncombining the transmitarray (TA) and folded-transmitarray (FTA). To accomplish\nthe reconfiguration of both unidirectional and bidirectional radiation states\nin the +z, -z, and +/-z directions, a polarization switchable multi-feed array\n(MFA) is placed at the focal plane between the TA and FTA, radiating\nx-polarization, y-polarization, and 45-degree oblique polarization waves,\nrespectively. Meanwhile, the proposed antenna can achieve multibeam radiation\nin the three aforementioned states by switching the polarization of the MFA. To\ndemonstrate the operating principle, a prototype has been designed, simulated,\nand fabricated. The measured results agree well with the simulated results. The\nsimulated and measured results indicate that the proposed design can generate\nreconfigurable multibeam in both forward and backward directions, either\nseparately or simultaneously. In the unidirectional states, forward and\nbackward beam scanning is achieved within an angular range of +/-30{\\deg} and\n+/-22{\\deg}, respectively, with peak gains of 23.6 dBi and 23.1 dBi. A\nsimultaneous forward and backward beam scanning of +/-40{\\deg} and +/-22{\\deg}\nis achieved in the hybrid radiation state, with peak gains of 19.4 dBi and 19.3\ndBi, respectively. The proposed antenna array design offers several advantages,\nincluding bidirectional low-loss beam scanning, a simple structure, low power\nconsumption, and a low profile.", "categories": "eess.SY cs.SY", "created": "2024-08-02", "doi": "10.1109/TAP.2024.3433567", "arxiv_id": "2408.01078"}
{"title": "FCDFusion: a Fast, Low Color Deviation Method for Fusing Visible and\n  Infrared Image Pairs", "authors": [], "abstract": "Visible and infrared image fusion (VIF) aims to combine information from\nvisible and infrared images into a single fused image. Previous VIF methods\nusually employ a color space transformation to keep the hue and saturation from\nthe original visible image. However, for fast VIF methods, this operation\naccounts for the majority of the calculation and is the bottleneck preventing\nfaster processing. In this paper, we propose a fast fusion method, FCDFusion,\nwith little color deviation. It preserves color information without color space\ntransformations, by directly operating in RGB color space. It incorporates\ngamma correction at little extra cost, allowing color and contrast to be\nrapidly improved. We regard the fusion process as a scaling operation on 3D\ncolor vectors, greatly simplifying the calculations. A theoretical analysis and\nexperiments show that our method can achieve satisfactory results in only 7\nFLOPs per pixel. Compared to state-of-the-art fast, color-preserving methods\nusing HSV color space, our method provides higher contrast at only half of the\ncomputational cost. We further propose a new metric, color deviation, to\nmeasure the ability of a VIF method to preserve color. It is specifically\ndesigned for VIF tasks with color visible-light images, and overcomes\ndeficiencies of existing VIF metrics used for this purpose. Our code is\navailable at https://github.com/HeasonLee/FCDFusion.", "categories": "cs.CV", "created": "2024-08-02", "doi": null, "arxiv_id": "2408.01080"}
{"title": "Lattice Boltzmann for linear elastodynamics: periodic problems and\n  Dirichlet boundary conditions", "authors": [], "abstract": "We propose a new second-order accurate lattice Boltzmann formulation for\nlinear elastodynamics that is stable for arbitrary combinations of material\nparameters under a CFL-like condition. The construction of the numerical scheme\nuses an equivalent first-order hyperbolic system of equations as an\nintermediate step, for which a vectorial lattice Boltzmann formulation is\nintroduced. The only difference to conventional lattice Boltzmann formulations\nis the usage of vector-valued populations, so that all computational benefits\nof the algorithm are preserved. Using the asymptotic expansion technique and\nthe notion of pre-stability structures we further establish second-order\nconsistency as well as analytical stability estimates. Lastly, we introduce a\nsecond-order consistent initialization of the populations as well as a boundary\nformulation for Dirichlet boundary conditions on 2D rectangular domains. All\ntheoretical derivations are numerically verified by convergence studies using\nmanufactured solutions and long-term stability tests.", "categories": "math.NA cs.NA", "created": "2024-08-02", "doi": null, "arxiv_id": "2408.01081"}
{"title": "Adaptive Contrastive Decoding in Retrieval-Augmented Generation for\n  Handling Noisy Contexts", "authors": [], "abstract": "When using large language models (LLMs) in knowledge-intensive tasks, such as\nopen-domain question answering, external context can bridge a gap between\nexternal knowledge and LLM's parametric knowledge. Recent research has been\ndeveloped to amplify contextual knowledge over the parametric knowledge of LLM\nwith contrastive decoding approaches. While these approaches could yield\ntruthful responses when relevant context is provided, they are prone to\nvulnerabilities when faced with noisy contexts. We extend the scope of previous\nstudies to encompass noisy contexts and propose adaptive contrastive decoding\n(ACD) to leverage contextual influence effectively. ACD demonstrates\nimprovements in open-domain question answering tasks compared to baselines,\nespecially in robustness by remaining undistracted by noisy contexts in\nretrieval-augmented generation.", "categories": "cs.CL", "created": "2024-08-02", "doi": null, "arxiv_id": "2408.01084"}
{"title": "Effect of Fog Particle Size Distribution on 3D Object Detection Under\n  Adverse Weather Conditions", "authors": [], "abstract": "LiDAR-based sensors employing optical spectrum signals play a vital role in\nproviding significant information about the target objects in autonomous\ndriving vehicle systems. However, the presence of fog in the atmosphere\nseverely degrades the overall system's performance. This manuscript analyzes\nthe role of fog particle size distributions in 3D object detection under\nadverse weather conditions. We utilise Mie theory and meteorological optical\nrange (MOR) to calculate the attenuation and backscattering coefficient values\nfor point cloud generation and analyze the overall system's accuracy in Car,\nCyclist, and Pedestrian case scenarios under easy, medium and hard detection\ndifficulties. Gamma and Junge (Power-Law) distributions are employed to\nmathematically model the fog particle size distribution under strong and\nmoderate advection fog environments. Subsequently, we modified the KITTI\ndataset based on the backscattering coefficient values and trained it on the\nPV-RCNN++ deep neural network model for Car, Cyclist, and Pedestrian cases\nunder different detection difficulties. The result analysis shows a significant\nvariation in the system's accuracy concerning the changes in target object\ndimensionality, the nature of the fog environment and increasing detection\ndifficulties, with the Car exhibiting the highest accuracy of around 99% and\nthe Pedestrian showing the lowest accuracy of around 73%.", "categories": "cs.CV", "created": "2024-08-02", "doi": null, "arxiv_id": "2408.01085"}
{"title": "Prototypical Partial Optimal Transport for Universal Domain Adaptation", "authors": [], "abstract": "Universal domain adaptation (UniDA) aims to transfer knowledge from a labeled\nsource domain to an unlabeled target domain without requiring the same label\nsets of both domains. The existence of domain and category shift makes the task\nchallenging and requires us to distinguish \"known\" samples (i.e., samples whose\nlabels exist in both domains) and \"unknown\" samples (i.e., samples whose labels\nexist in only one domain) in both domains before reducing the domain gap. In\nthis paper, we consider the problem from the point of view of distribution\nmatching which we only need to align two distributions partially. A novel\napproach, dubbed mini-batch Prototypical Partial Optimal Transport (m-PPOT), is\nproposed to conduct partial distribution alignment for UniDA. In training\nphase, besides minimizing m-PPOT, we also leverage the transport plan of m-PPOT\nto reweight source prototypes and target samples, and design reweighted entropy\nloss and reweighted cross-entropy loss to distinguish \"known\" and \"unknown\"\nsamples. Experiments on four benchmarks show that our method outperforms the\nprevious state-of-the-art UniDA methods.", "categories": "cs.CV", "created": "2024-08-02", "doi": "10.1609/aaai.v37i9.26287", "arxiv_id": "2408.01089"}
{"title": "General-purpose Dataflow Model with Neuromorphic Primitives", "authors": [], "abstract": "Neuromorphic computing exhibits great potential to provide high-performance\nbenefits in various applications beyond neural networks. However, a\ngeneral-purpose program execution model that aligns with the features of\nneuromorphic computing is required to bridge the gap between program\nversatility and neuromorphic hardware efficiency. The dataflow model offers a\npotential solution, but it faces high graph complexity and incompatibility with\nneuromorphic hardware when dealing with control flow programs, which decreases\nthe programmability and performance. Here, we present a dataflow model tailored\nfor neuromorphic hardware, called neuromorphic dataflow, which provides a\ncompact, concise, and neuromorphic-compatible program representation for\ncontrol logic. The neuromorphic dataflow introduces \"when\" and \"where\"\nprimitives, which restructure the view of control. The neuromorphic dataflow\nembeds these primitives in the dataflow schema with the plasticity inherited\nfrom the spiking algorithms. Our method enables the deployment of\ngeneral-purpose programs on neuromorphic hardware with both programmability and\nplasticity, while fully utilizing the hardware's potential.", "categories": "cs.CL cs.AR cs.NE", "created": "2024-08-02", "doi": null, "arxiv_id": "2408.01090"}
{"title": "Dissecting Dissonance: Benchmarking Large Multimodal Models Against\n  Self-Contradictory Instructions", "authors": [], "abstract": "Large multimodal models (LMMs) excel in adhering to human instructions.\nHowever, self-contradictory instructions may arise due to the increasing trend\nof multimodal interaction and context length, which is challenging for language\nbeginners and vulnerable populations. We introduce the Self-Contradictory\nInstructions benchmark to evaluate the capability of LMMs in recognizing\nconflicting commands. It comprises 20,000 conflicts, evenly distributed between\nlanguage and vision paradigms. It is constructed by a novel automatic dataset\ncreation framework, which expedites the process and enables us to encompass a\nwide range of instruction forms. Our comprehensive evaluation reveals current\nLMMs consistently struggle to identify multimodal instruction discordance due\nto a lack of self-awareness. Hence, we propose the Cognitive Awakening\nPrompting to inject cognition from external, largely enhancing dissonance\ndetection. The dataset and code are here: https://selfcontradiction.github.io/.", "categories": "cs.AI", "created": "2024-08-02", "doi": null, "arxiv_id": "2408.01091"}
{"title": "CommonUppRoad: A Framework of Formal Modelling, Verifying, Learning, and\n  Visualisation of Autonomous Vehicles", "authors": [], "abstract": "Combining machine learning and formal methods (FMs) provides a possible\nsolution to overcome the safety issue of autonomous driving (AD) vehicles.\nHowever, there are gaps to be bridged before this combination becomes\npractically applicable and useful. In an attempt to facilitate researchers in\nboth FMs and AD areas, this paper proposes a framework that combines two\nwell-known tools, namely CommonRoad and UPPAAL. On the one hand, CommonRoad can\nbe enhanced by the rigorous semantics of models in UPPAAL, which enables a\nsystematic and comprehensive understanding of the AD system's behaviour and\nthus strengthens the safety of the system. On the other hand, controllers\nsynthesised by UPPAAL can be visualised by CommonRoad in real-world road\nnetworks, which facilitates AD vehicle designers greatly adopting formal models\nin system design. In this framework, we provide automatic model conversions\nbetween CommonRoad and UPPAAL. Therefore, users only need to program in Python\nand the framework takes care of the formal models, learning, and verification\nin the backend. We perform experiments to demonstrate the applicability of our\nframework in various AD scenarios, discuss the advantages of solving motion\nplanning in our framework, and show the scalability limit and possible\nsolutions.", "categories": "cs.MA cs.RO", "created": "2024-08-02", "doi": null, "arxiv_id": "2408.01093"}
{"title": "An Encoding--Searching Separation Perspective on Bi-Encoder Neural\n  Search", "authors": [], "abstract": "This paper reviews, analyzes, and proposes a new perspective on the\nbi-encoder architecture for neural search. While the bi-encoder architecture is\nwidely used due to its simplicity and scalability at test time, it has some\nnotable issues such as low performance on seen datasets and weak zero-shot\nperformance on new datasets. In this paper, we analyze these issues and\nsummarize two main critiques: the encoding information bottleneck problem and\nlimitations of the basic assumption of embedding search. We then construct a\nthought experiment to logically analyze the encoding and searching operations\nand challenge the basic assumption of embedding search. Building on these\nobservations, we propose a new perspective on the bi-encoder architecture\ncalled the \\textit{encoding--searching separation} perspective, which\nconceptually and practically separates the encoding and searching operations.\nThis new perspective is applied to explain the root cause of the identified\nissues and discuss ways to mitigate the problems. Finally, we discuss the\nimplications of the ideas underlying the new perspective, the design surface\nthat it exposes and the potential research directions arising from it.", "categories": "cs.LG cs.IR", "created": "2024-08-02", "doi": null, "arxiv_id": "2408.01094"}
{"title": "Six Dragons Fly Again: Reviving 15th-Century Korean Court Music with\n  Transformers and Novel Encoding", "authors": [], "abstract": "We introduce a project that revives a piece of 15th-century Korean court\nmusic, Chihwapyeong and Chwipunghyeong, composed upon the poem Songs of the\nDragon Flying to Heaven. One of the earliest examples of Jeongganbo, a Korean\nmusical notation system, the remaining version only consists of a rudimentary\nmelody. Our research team, commissioned by the National Gugak (Korean\nTraditional Music) Center, aimed to transform this old melody into a\nperformable arrangement for a six-part ensemble. Using Jeongganbo data acquired\nthrough bespoke optical music recognition, we trained a BERT-like masked\nlanguage model and an encoder-decoder transformer model. We also propose an\nencoding scheme that strictly follows the structure of Jeongganbo and denotes\nnote durations as positions. The resulting machine-transformed version of\nChihwapyeong and Chwipunghyeong were evaluated by experts and performed by the\nCourt Music Orchestra of National Gugak Center. Our work demonstrates that\ngenerative models can successfully be applied to traditional music with limited\ntraining data if combined with careful design.", "categories": "cs.SD cs.AI eess.AS", "created": "2024-08-02", "doi": null, "arxiv_id": "2408.01096"}
{"title": "Uniform approximation of vectors using adaptive randomized information", "authors": [], "abstract": "We study approximation of the embedding $\\ell_p^m \\rightarrow\n\\ell_{\\infty}^m$, $1 \\leq p \\leq 2$, based on randomized adaptive algorithms\nthat use arbitrary linear functionals as information on a problem instance. We\nshow upper bounds for which the complexity $n$ exhibits only a $(\\log\\log\nm)$-dependence. Our results for $p=1$ lead to an example of a gap of order $n$\n(up to logarithmic factors) for the error between best adaptive and\nnon-adaptive Monte Carlo methods. This is the largest possible gap for linear\nproblems.", "categories": "math.NA cs.NA", "created": "2024-08-02", "doi": null, "arxiv_id": "2408.01098"}
{"title": "Contribution-based Low-Rank Adaptation with Pre-training Model for Real\n  Image Restoration", "authors": [], "abstract": "Recently, pre-trained model and efficient parameter tuning have achieved\nremarkable success in natural language processing and high-level computer\nvision with the aid of masked modeling and prompt tuning. In low-level computer\nvision, however, there have been limited investigations on pre-trained models\nand even efficient fine-tuning strategy has not yet been explored despite its\nimportance and benefit in various real-world tasks such as alleviating memory\ninflation issue when integrating new tasks on AI edge devices. Here, we propose\na novel efficient parameter tuning approach dubbed contribution-based low-rank\nadaptation (CoLoRA) for multiple image restorations along with effective\npre-training method with random order degradations (PROD). Unlike prior arts\nthat tune all network parameters, our CoLoRA effectively fine-tunes small\namount of parameters by leveraging LoRA (low-rank adaptation) for each new\nvision task with our contribution-based method to adaptively determine layer by\nlayer capacity for that task to yield comparable performance to full tuning.\nFurthermore, our PROD strategy allows to extend the capability of pre-trained\nmodels with improved performance as well as robustness to bridge synthetic\npre-training and real-world fine-tuning. Our CoLoRA with PROD has demonstrated\nits superior performance in various image restoration tasks across diverse\ndegradation types on both synthetic and real-world datasets for known and novel\ntasks.", "categories": "cs.CV cs.AI", "created": "2024-08-02", "doi": null, "arxiv_id": "2408.01099"}
{"title": "NotePlayer: Engaging Jupyter Notebooks for Dynamic Presentation of\n  Analytical Processes", "authors": [], "abstract": "Diverse presentation formats play a pivotal role in effectively conveying\ncode and analytical processes during data analysis. One increasingly popular\nformat is tutorial videos, particularly those based on Jupyter notebooks, which\noffer an intuitive interpretation of code and vivid explanations of analytical\nprocedures. However, creating such videos requires a diverse skill set and\nsignificant manual effort, posing a barrier for many analysts. To bridge this\ngap, we introduce an innovative tool called NotePlayer, which connects notebook\ncells to video segments and incorporates a computational engine with language\nmodels to streamline video creation and editing. Our aim is to make the process\nmore accessible and efficient for analysts. To inform the design of NotePlayer,\nwe conducted a formative study and performed content analysis on a corpus of 38\nJupyter tutorial videos. This helped us identify key patterns and challenges\nencountered in existing tutorial videos, guiding the development of NotePlayer.\nThrough a combination of a usage scenario and a user study, we validated the\neffectiveness of NotePlayer. The results show that the tool streamlines the\nvideo creation and facilitates the communication process for data analysts.", "categories": "cs.HC", "created": "2024-08-02", "doi": "10.1145/3654777.3676410", "arxiv_id": "2408.01101"}
{"title": "LessonPlanner: Assisting Novice Teachers to Prepare Pedagogy-Driven\n  Lesson Plans with Large Language Models", "authors": [], "abstract": "Preparing a lesson plan, e.g., a detailed road map with strategies and\nmaterials for instructing a 90-minute class, is beneficial yet challenging for\nnovice teachers. Large language models (LLMs) can ease this process by\ngenerating adaptive content for lesson plans, which would otherwise require\nteachers to create from scratch or search existing resources. In this work, we\nfirst conduct a formative study with six novice teachers to understand their\nneeds for support of preparing lesson plans with LLMs. Then, we develop\nLessonPlanner that assists users to interactively construct lesson plans with\nadaptive LLM-generated content based on Gagne's nine events. Our\nwithin-subjects study (N=12) shows that compared to the baseline ChatGPT\ninterface, LessonPlanner can significantly improve the quality of outcome\nlesson plans and ease users' workload in the preparation process. Our expert\ninterviews (N=6) further demonstrate LessonPlanner's usefulness in suggesting\neffective teaching strategies and meaningful educational resources. We discuss\nconcerns on and design considerations for supporting teaching activities with\nLLMs.", "categories": "cs.HC", "created": "2024-08-02", "doi": "10.1145/3654777.3676390", "arxiv_id": "2408.01102"}
{"title": "Validation of an Analysability Model in Hybrid Quantum Software", "authors": [], "abstract": "In the context of quantum-classical hybrid computing, evaluating\nanalysability, which is the ease of understanding and modifying software,\npresents significant challenges due to the complexity and novelty of quantum\nalgorithms. Although advances have been made in quantum software development,\nstandard software quality evaluation methods do not fully address the specifics\nof quantum components, resulting in a gap in the ability to ensure and maintain\nthe quality of hybrid software products. In this registered report proposal, we\nintend to validate a quality model focused on the analysability of hybrid\nsoftware through an international collab orative approach involving academic\ninstitutions from Italy and Spain through a controlled experiment. This\napproach allows for a more detailed analysis and validation methodology and\nestablishes a framework for future research and developments in software\nquality assessment in quantum computing.", "categories": "cs.SE quant-ph", "created": "2024-08-02", "doi": null, "arxiv_id": "2408.01105"}
{"title": "BioRAG: A RAG-LLM Framework for Biological Question Reasoning", "authors": [], "abstract": "The question-answering system for Life science research, which is\ncharacterized by the rapid pace of discovery, evolving insights, and complex\ninteractions among knowledge entities, presents unique challenges in\nmaintaining a comprehensive knowledge warehouse and accurate information\nretrieval. To address these issues, we introduce BioRAG, a novel\nRetrieval-Augmented Generation (RAG) with the Large Language Models (LLMs)\nframework. Our approach starts with parsing, indexing, and segmenting an\nextensive collection of 22 million scientific papers as the basic knowledge,\nfollowed by training a specialized embedding model tailored to this domain.\nAdditionally, we enhance the vector retrieval process by incorporating a\ndomain-specific knowledge hierarchy, which aids in modeling the intricate\ninterrelationships among each query and context. For queries requiring the most\ncurrent information, BioRAG deconstructs the question and employs an iterative\nretrieval process incorporated with the search engine for step-by-step\nreasoning. Rigorous experiments have demonstrated that our model outperforms\nfine-tuned LLM, LLM with search engines, and other scientific RAG frameworks\nacross multiple life science question-answering tasks.", "categories": "cs.CL cs.AI cs.IR", "created": "2024-08-02", "doi": null, "arxiv_id": "2408.01107"}
{"title": "Characterizing Data Dependencies Then and Now", "authors": [], "abstract": "Data dependencies are integrity constraints that the data of interest must\nobey. During the 1980s, Janos Makowsky made a number of contributions to the\nstudy of data dependencies; in particular, he was the first researcher to\ncharacterize data dependencies in terms of their structural properties. The\ngoal of this article is to first present an overview of Makowsky's work on\ncharacterizing certain classes of data dependencies and then discuss recent\ndevelopments concerning characterizations of broader classes of data\ndependencies.", "categories": "cs.LO cs.DB", "created": "2024-08-02", "doi": null, "arxiv_id": "2408.01109"}
{"title": "Agentic LLM Workflows for Generating Patient-Friendly Medical Reports", "authors": [], "abstract": "The application of Large Language Models (LLMs) in healthcare is expanding\nrapidly, with one potential use case being the translation of formal medical\nreports into patient-legible equivalents. Currently, LLM outputs often need to\nbe edited and evaluated by a human to ensure both factual accuracy and\ncomprehensibility, and this is true for the above use case. We aim to minimize\nthis step by proposing an agentic workflow with the Reflexion framework, which\nuses iterative self-reflection to correct outputs from an LLM. This pipeline\nwas tested and compared to zero-shot prompting on 16 randomized radiology\nreports. In our multi-agent approach, reports had an accuracy rate of 94.94%\nwhen looking at verification of ICD-10 codes, compared to zero-shot prompted\nreports, which had an accuracy rate of 68.23%. Additionally, 81.25% of the\nfinal reflected reports required no corrections for accuracy or readability,\nwhile only 25% of zero-shot prompted reports met these criteria without needing\nmodifications. These results indicate that our approach presents a feasible\nmethod for communicating clinical findings to patients in a quick, efficient\nand coherent manner whilst also retaining medical accuracy. The codebase is\navailable for viewing at\nhttp://github.com/malavikhasudarshan/Multi-Agent-Patient-Letter-Generation.", "categories": "cs.MA", "created": "2024-08-02", "doi": null, "arxiv_id": "2408.01112"}
{"title": "Epistemic Ensembles in Semantic and Symbolic Environments (Extended\n  Version with Proofs)", "authors": [], "abstract": "An epistemic ensemble is composed of knowledge-based agents capable of\nretrieving and sharing knowledge and beliefs about themselves and their peers.\nThese agents access a global knowledge state and use actions to communicate and\ncooperate, altering the collective knowledge state. We study two types of\nmathematical semantics for epistemic ensembles based on a common syntactic\noperational ensemble semantics: a semantic environment defined by a class of\nglobal epistemic states, and a symbolic environment consisting of a set of\nepistemic formul{\\ae}. For relating these environments, we use the concept of\n{\\Phi}-equivalence, where a class of epistemic states and a knowledge base are\n{\\Phi}-equivalent, if any formula of {\\Phi} holds in the class of epistemic\nstates if, and only if, it is an element of the knowledge base. Our main\ntheorem shows that {\\Phi}-equivalent configurations simulate each other and\nsatisfy the same dynamic epistemic ensemble formulae.", "categories": "cs.SE", "created": "2024-08-02", "doi": null, "arxiv_id": "2408.01115"}
{"title": "Practical Guidelines for Data-driven Identification of Lifted Linear\n  Predictors for Control", "authors": [], "abstract": "Lifted linear predictor (LLP) is an artificial linear dynamical system\ndesigned to predict trajectories of a generally nonlinear dynamical system\nbased on the current state (or measurements) and the input. The main benefit of\nthe LLP is its potential ability to capture the nonlinear system's dynamics\nwith precision superior to other linearization techniques, such as local\nlinearization about the operation point. The idea of lifting is supported by\nthe theory of Koopman Operators. For LLP identification, we focus on the\ndata-driven method based on the extended dynamic mode decomposition (EDMD)\nalgorithm. However, while the EDMD algorithm presents an extremely simple and\nefficient way to obtain the LLP, it can also yield poor results. In this paper,\nwe present some less intuitive practical guidelines for data-driven\nidentification of the LLPs, aiming at improving usability of LLPs for designing\ncontrol. We support the guidelines with two motivating examples. The\nimplementation of the examples are shared on a public repository.", "categories": "eess.SY cs.SY", "created": "2024-08-02", "doi": null, "arxiv_id": "2408.01116"}
{"title": "IAI Group at CheckThat! 2024: Transformer Models and Data Augmentation\n  for Checkworthy Claim Detection", "authors": [], "abstract": "This paper describes IAI group's participation for automated check-worthiness\nestimation for claims, within the framework of the 2024 CheckThat! Lab \"Task 1:\nCheck-Worthiness Estimation\". The task involves the automated detection of\ncheck-worthy claims in English, Dutch, and Arabic political debates and Twitter\ndata. We utilized various pre-trained generative decoder and encoder\ntransformer models, employing methods such as few-shot chain-of-thought\nreasoning, fine-tuning, data augmentation, and transfer learning from one\nlanguage to another. Despite variable success in terms of performance, our\nmodels achieved notable placements on the organizer's leaderboard: ninth-best\nin English, third-best in Dutch, and the top placement in Arabic, utilizing\nmultilingual datasets for enhancing the generalizability of check-worthiness\ndetection. Despite a significant drop in performance on the unlabeled test\ndataset compared to the development test dataset, our findings contribute to\nthe ongoing efforts in claim detection research, highlighting the challenges\nand potential of language-specific adaptations in claim verification systems.", "categories": "cs.CL", "created": "2024-08-02", "doi": null, "arxiv_id": "2408.01118"}
{"title": "Task Prompt Vectors: Effective Initialization through Multi-Task\n  Soft-Prompt Transfer", "authors": [], "abstract": "Prompt tuning is a modular and efficient solution for training large language\nmodels (LLMs). One of its main advantages is task modularity, making it\nsuitable for multi-task problems. However, current soft-prompt-based methods\noften sacrifice multi-task modularity, requiring the training process to be\nfully or partially repeated for each newly added task. While recent work on\ntask vectors applied arithmetic operations on full model weights to achieve the\ndesired multi-task performance, a similar approach for soft-prompts is still\nmissing. To this end, we introduce Task Prompt Vectors, created by element-wise\ndifference between weights of tuned soft-prompts and their random\ninitialization. Experimental results on 12 NLU datasets show that task prompt\nvectors can be used in low-resource settings to effectively initialize prompt\ntuning on similar tasks. In addition, we show that task prompt vectors are\nindependent of the random initialization of prompt tuning. This allows prompt\narithmetics with the pre-trained vectors from different tasks. In this way, by\narithmetic addition of task prompt vectors from multiple tasks, we are able to\noutperform a state-of-the-art baseline in some cases.", "categories": "cs.CL", "created": "2024-08-02", "doi": null, "arxiv_id": "2408.01119"}
{"title": "An Efficient and Effective Transformer Decoder-Based Framework for\n  Multi-Task Visual Grounding", "authors": [], "abstract": "Most advanced visual grounding methods rely on Transformers for\nvisual-linguistic feature fusion. However, these Transformer-based approaches\nencounter a significant drawback: the computational costs escalate\nquadratically due to the self-attention mechanism in the Transformer Encoder,\nparticularly when dealing with high-resolution images or long context\nsentences. This quadratic increase in computational burden restricts the\napplicability of visual grounding to more intricate scenes, such as\nconversation-based reasoning segmentation, which involves lengthy language\nexpressions. In this paper, we propose an efficient and effective multi-task\nvisual grounding (EEVG) framework based on Transformer Decoder to address this\nissue, which reduces the cost in both language and visual aspects. In the\nlanguage aspect, we employ the Transformer Decoder to fuse visual and\nlinguistic features, where linguistic features are input as memory and visual\nfeatures as queries. This allows fusion to scale linearly with language\nexpression length. In the visual aspect, we introduce a parameter-free approach\nto reduce computation by eliminating background visual tokens based on\nattention scores. We then design a light mask head to directly predict\nsegmentation masks from the remaining sparse feature maps. Extensive results\nand ablation studies on benchmarks demonstrate the efficiency and effectiveness\nof our approach. Code is available in https://github.com/chenwei746/EEVG.", "categories": "cs.CV", "created": "2024-08-02", "doi": null, "arxiv_id": "2408.01120"}
{"title": "Being Accountable is Smart: Navigating the Technical and Regulatory\n  Landscape of AI-based Services for Power Grid", "authors": [], "abstract": "The emergence of artificial intelligence and digitization of the power grid\nintroduced numerous effective application scenarios for AI-based services for\nthe smart grid. Nevertheless, adopting AI in critical infrastructures presents\nchallenges due to unclear regulations and lacking risk quantification\ntechniques. Regulated and accountable approaches for integrating AI-based\nservices into the smart grid could accelerate the adoption of innovative\nmethods in daily practices and address society's general safety concerns. This\npaper contributes to this objective by defining accountability and highlighting\nits importance for AI-based services in the energy sector. It underlines the\ncurrent shortcomings of the AI Act and proposes an approach to address these\nissues in a potential delegated act. The proposed technical approach for\ndeveloping and operating accountable AI-based smart grid services allows for\nassessing different service life cycle phases and identifying related\naccountability risks.", "categories": "cs.AI", "created": "2024-08-02", "doi": "10.1145/3677525.3678651", "arxiv_id": "2408.01121"}
{"title": "CFBench: A Comprehensive Constraints-Following Benchmark for LLMs", "authors": [], "abstract": "The adeptness of Large Language Models (LLMs) in comprehending and following\nnatural language instructions is critical for their deployment in sophisticated\nreal-world applications. Existing evaluations mainly focus on fragmented\nconstraints or narrow scenarios, but they overlook the comprehensiveness and\nauthenticity of constraints from the user's perspective. To bridge this gap, we\npropose CFBench, a large-scale Comprehensive Constraints Following Benchmark\nfor LLMs, featuring 1,000 curated samples that cover more than 200 real-life\nscenarios and over 50 NLP tasks. CFBench meticulously compiles constraints from\nreal-world instructions and constructs an innovative systematic framework for\nconstraint types, which includes 10 primary categories and over 25\nsubcategories, and ensures each constraint is seamlessly integrated within the\ninstructions. To make certain that the evaluation of LLM outputs aligns with\nuser perceptions, we propose an advanced methodology that integrates\nmulti-dimensional assessment criteria with requirement prioritization, covering\nvarious perspectives of constraints, instructions, and requirement fulfillment.\nEvaluating current leading LLMs on CFBench reveals substantial room for\nimprovement in constraints following, and we further investigate influencing\nfactors and enhancement strategies. The data and code are publicly available at\nhttps://github.com/PKU-Baichuan-MLSystemLab/CFBench", "categories": "cs.CL", "created": "2024-08-02", "doi": null, "arxiv_id": "2408.01122"}
{"title": "Relax, Estimate, and Track: a Simple Battery State-of-charge and\n  State-of-health Estimation Method", "authors": [], "abstract": "Battery management stands as a critical component of ubiquitous\nbattery-powered energy systems, in which battery state-of-charge (SOC) and\nstate-of-health (SOH) estimation are of crucial importance. Conventional SOC\nand SOH estimation methods, especially model-based methods, often lack accurate\nmodeling of the open circuit voltage (OCV), have high computational complexity,\nand lack theoretical analysis. In this paper, a simple SOC and SOH estimation\nmethod that overcomes all these weaknesses is introduced. The method is based\non rigorous theoretical analysis, requires no parameter fine-tuning, and has a\nvery low computational complexity, which is hundreds of times faster than\nconventional methods. The method is validated on six batteries at different C\nrates and temperatures, demonstrating a stronger capability to realize fast and\naccurate estimation under various conditions than other methods, with a SOH\nroot mean square error (RMSE) of around 2.5% and a SOC RMSE of around 1.5%.", "categories": "eess.SY cs.SY", "created": "2024-08-02", "doi": null, "arxiv_id": "2408.01127"}
{"title": "A Survey of Mamba", "authors": [], "abstract": "Deep learning, as a vital technique, has sparked a notable revolution in\nartificial intelligence. As the most representative architecture, Transformers\nhave empowered numerous advanced models, especially the large language models\nthat comprise billions of parameters, becoming a cornerstone in deep learning.\nDespite the impressive achievements, Transformers still face inherent\nlimitations, particularly the time-consuming inference resulting from the\nquadratic computation complexity of attention calculation. Recently, a novel\narchitecture named Mamba, drawing inspiration from classical state space\nmodels, has emerged as a promising alternative for building foundation models,\ndelivering comparable modeling abilities to Transformers while preserving\nnear-linear scalability concerning sequence length. This has sparked an\nincreasing number of studies actively exploring Mamba's potential to achieve\nimpressive performance across diverse domains. Given such rapid evolution,\nthere is a critical need for a systematic review that consolidates existing\nMamba-empowered models, offering a comprehensive understanding of this emerging\nmodel architecture. In this survey, we therefore conduct an in-depth\ninvestigation of recent Mamba-associated studies, covering from three main\naspects: the advancements of Mamba-based models, the techniques of adapting\nMamba to diverse data, and the applications where Mamba can excel.\nSpecifically, we first recall the foundational knowledge of various\nrepresentative deep learning models and the details of Mamba as preliminaries.\nThen, to showcase the significance of Mamba, we comprehensively review the\nrelated studies focusing on Mamba models' architecture design, data\nadaptability, and applications. Finally, we present an discussion of current\nlimitations and explore various promising research directions to provide deeper\ninsights for future investigations.", "categories": "cs.LG cs.AI", "created": "2024-08-02", "doi": null, "arxiv_id": "2408.01129"}
{"title": "Closed-loop underwater soft robotic foil shape control using flexible\n  e-skin", "authors": [], "abstract": "The use of soft robotics for real-world underwater applications is limited,\neven more than in terrestrial applications, by the ability to accurately\nmeasure and control the deformation of the soft materials in real time without\nthe need for feedback from an external sensor. Real-time underwater shape\nestimation would allow for accurate closed-loop control of soft propulsors,\nenabling high-performance swimming and manoeuvring. We propose and demonstrate\na method for closed-loop underwater soft robotic foil control based on a\nflexible capacitive e-skin and machine learning which does not necessitate\nfeedback from an external sensor. The underwater e-skin is applied to a highly\nflexible foil undergoing deformations from 2% to 9% of its camber by means of\nsoft hydraulic actuators. Accurate set point regulation of the camber is\nsuccessfully tracked during sinusoidal and triangle actuation routines with an\namplitude of 5% peak-to-peak and 10-second period with a normalised RMS error\nof 0.11, and 2% peak-to-peak amplitude with a period of 5 seconds with a\nnormalised RMS error of 0.03. The tail tip deflection can be measured across a\n30 mm (0.15 chords) range. These results pave the way for using e-skin\ntechnology for underwater soft robotic closed-loop control applications.", "categories": "cs.RO", "created": "2024-08-02", "doi": null, "arxiv_id": "2408.01130"}
{"title": "Spectral methods on a triangle and W-systems", "authors": [], "abstract": "We present an overarching framework for stable spectral methods on a\ntriangle, defined by a multivariate W-system and based on orthogonal\npolynomials on the triangle. Motivated by the Koornwinder orthogonal\npolynomials on the triangle, we introduce a Koornwinder W-system. Once\ndiscretised by this W-system, the resulting spatial differentiation matrix is\nskew symmetric, affording important advantages insofar as stability and\nconservation of structure are concerned. We analyse the construction of the\ndifferentiation matrix and matrix vector multiplication, demonstrating optimal\ncomputational cost. Numerical convergence is illustrated through experiments\nwith different parameter choices. As a result, our method exhibits key\ncharacteristics of a practical spectral method, inclusive of rapid convergence,\nfast computation and the preservation of structure of the underlying partial\ndifferential equation.", "categories": "math.NA cs.NA", "created": "2024-08-02", "doi": null, "arxiv_id": "2408.01132"}
{"title": "The Impact of Program Reduction on Automated Program Repair", "authors": [], "abstract": "Correcting bugs using modern Automated Program Repair (APR) can be both\ntime-consuming and resource-expensive. We describe a program repair approach\nthat aims to improve the scalability of modern APR tools. The approach\nleverages program reduction in the form of program slicing to eliminate code\nirrelevant to fixing the bug, which improves the APR tool's overall\nperformance. We investigate slicing's impact on all three phases of the repair\nprocess: fault localization, patch generation, and patch validation. Our\nempirical exploration finds that the proposed approach, on average, enhances\nthe repair ability of the TBar APR tool, but we also discovered a few cases\nwhere it was less successful. Specifically, on examples from the widely used\nDefects4J dataset, we obtain a substantial reduction in median repair time,\nwhich falls from 80 minutes to just under 18 minutes. We conclude that program\nreduction can improve the performance of APR without degrading repair quality,\nbut this improvement is not universal.\n  A replication package is available via Zenodo at\nhttps://doi.org/10.5281/zenodo.13074333.\n  Keywords: automated program repair, dynamic program slicing, fault\nlocalization, test-suite reduction, hybrid techniques.", "categories": "cs.SE", "created": "2024-08-02", "doi": null, "arxiv_id": "2408.01134"}
{"title": "PGNeXt: High-Resolution Salient Object Detection via Pyramid Grafting\n  Network", "authors": [], "abstract": "We present an advanced study on more challenging high-resolution salient\nobject detection (HRSOD) from both dataset and network framework perspectives.\nTo compensate for the lack of HRSOD dataset, we thoughtfully collect a\nlarge-scale high resolution salient object detection dataset, called UHRSD,\ncontaining 5,920 images from real-world complex scenarios at 4K-8K resolutions.\nAll the images are finely annotated in pixel-level, far exceeding previous\nlow-resolution SOD datasets. Aiming at overcoming the contradiction between the\nsampling depth and the receptive field size in the past methods, we propose a\nnovel one-stage framework for HR-SOD task using pyramid grafting mechanism. In\ngeneral, transformer-based and CNN-based backbones are adopted to extract\nfeatures from different resolution images independently and then these features\nare grafted from transformer branch to CNN branch. An attention-based\nCross-Model Grafting Module (CMGM) is proposed to enable CNN branch to combine\nbroken detailed information more holistically, guided by different source\nfeature during decoding process. Moreover, we design an Attention Guided Loss\n(AGL) to explicitly supervise the attention matrix generated by CMGM to help\nthe network better interact with the attention from different branches.\nComprehensive experiments on UHRSD and widely-used SOD datasets demonstrate\nthat our method can simultaneously locate salient object and preserve rich\ndetails, outperforming state-of-the-art methods. To verify the generalization\nability of the proposed framework, we apply it to the camouflaged object\ndetection (COD) task. Notably, our method performs superior to most\nstate-of-the-art COD methods without bells and whistles.", "categories": "cs.CV", "created": "2024-08-02", "doi": null, "arxiv_id": "2408.01137"}
{"title": "Interpreting Global Perturbation Robustness of Image Models using\n  Axiomatic Spectral Importance Decomposition", "authors": [], "abstract": "Perturbation robustness evaluates the vulnerabilities of models, arising from\na variety of perturbations, such as data corruptions and adversarial attacks.\nUnderstanding the mechanisms of perturbation robustness is critical for global\ninterpretability. We present a model-agnostic, global mechanistic\ninterpretability method to interpret the perturbation robustness of image\nmodels. This research is motivated by two key aspects. First, previous global\ninterpretability works, in tandem with robustness benchmarks, e.g. mean\ncorruption error (mCE), are not designed to directly interpret the mechanisms\nof perturbation robustness within image models. Second, we notice that the\nspectral signal-to-noise ratios (SNR) of perturbed natural images exponentially\ndecay over the frequency. This power-law-like decay implies that: Low-frequency\nsignals are generally more robust than high-frequency signals -- yet high\nclassification accuracy can not be achieved by low-frequency signals alone. By\napplying Shapley value theory, our method axiomatically quantifies the\npredictive powers of robust features and non-robust features within an\ninformation theory framework. Our method, dubbed as \\textbf{I-ASIDE}\n(\\textbf{I}mage \\textbf{A}xiomatic \\textbf{S}pectral \\textbf{I}mportance\n\\textbf{D}ecomposition \\textbf{E}xplanation), provides a unique insight into\nmodel robustness mechanisms. We conduct extensive experiments over a variety of\nvision models pre-trained on ImageNet to show that \\textbf{I-ASIDE} can not\nonly \\textbf{measure} the perturbation robustness but also \\textbf{provide\ninterpretations} of its mechanisms.", "categories": "cs.AI cs.CV", "created": "2024-08-02", "doi": null, "arxiv_id": "2408.01139"}
{"title": "Machine learning topological energy braiding of non-Bloch bands", "authors": [], "abstract": "Machine learning has been used to identify phase transitions in a variety of\nphysical systems. However, there is still a lack of relevant research on\nnon-Bloch energy braiding in non-Hermitian systems. In this work, we study\nnon-Bloch energy braiding in one-dimensional non-Hermitian systems using\nunsupervised and supervised methods. In unsupervised learning, we use diffusion\nmaps to successfully identify non-Bloch energy braiding without any prior\nknowledge and combine it with k-means to cluster different topological elements\ninto clusters, such as Unlink and Hopf link. In supervised learning, we train a\nConvolutional Neural Network (CNN) based on Bloch energy data to predict not\nonly Bloch energy braiding but also non-Bloch energy braiding with an accuracy\napproaching 100%. By analysing the CNN, we can ascertain that the network has\nsuccessfully acquired the ability to recognise the braiding topology of the\nenergy bands. The present study demonstrates the considerable potential of\nmachine learning in the identification of non-Hermitian topological phases and\nenergy braiding.", "categories": "cond-mat.mes-hall cond-mat.dis-nn cs.LG", "created": "2024-08-02", "doi": null, "arxiv_id": "2408.01141"}
{"title": "Enhanced Prediction of Ventilator-Associated Pneumonia in Patients with\n  Traumatic Brain Injury Using Advanced Machine Learning Techniques", "authors": [], "abstract": "Background: Ventilator-associated pneumonia (VAP) in traumatic brain injury\n(TBI) patients poses a significant mortality risk and imposes a considerable\nfinancial burden on patients and healthcare systems. Timely detection and\nprognostication of VAP in TBI patients are crucial to improve patient outcomes\nand alleviate the strain on healthcare resources.\n  Methods: We implemented six machine learning models using the MIMIC-III\ndatabase. Our methodology included preprocessing steps, such as feature\nselection with CatBoost and expert opinion, addressing class imbalance with the\nSynthetic Minority Oversampling Technique (SMOTE), and rigorous model tuning\nthrough 5-fold cross-validation to optimize hyperparameters. Key models\nevaluated included SVM, Logistic Regression, Random Forest, XGBoost, ANN, and\nAdaBoost. Additionally, we conducted SHAP analysis to determine feature\nimportance and performed an ablation study to assess feature impacts on model\nperformance.\n  Results: XGBoost outperformed the baseline models and the best existing\nliterature. We used metrics, including AUC, Accuracy, Specificity, Sensitivity,\nF1 Score, PPV, and NPV. XGBoost demonstrated the highest performance with an\nAUC of 0.940 and an Accuracy of 0.875, which are 23.4% and 23.5% higher than\nthe best results in the existing literature, with an AUC of 0.706 and an\nAccuracy of 0.640, respectively. This enhanced performance underscores the\nmodels' effectiveness in clinical settings.\n  Conclusions: This study enhances the predictive modeling of VAP in TBI\npatients, improving early detection and intervention potential. Refined feature\nselection and advanced ensemble techniques significantly boosted model accuracy\nand reliability, offering promising directions for future clinical applications\nand medical diagnostics research.", "categories": "cs.LG", "created": "2024-08-02", "doi": null, "arxiv_id": "2408.01144"}
{"title": "Actra: Optimized Transformer Architecture for Vision-Language-Action\n  Models in Robot Learning", "authors": [], "abstract": "Vision-language-action models have gained significant attention for their\nability to model trajectories in robot learning. However, most existing models\nrely on Transformer models with vanilla causal attention, which we find\nsuboptimal for processing segmented multi-modal sequences. Additionally, the\nautoregressive generation approach falls short in generating multi-dimensional\nactions. In this paper, we introduce Actra, an optimized Transformer\narchitecture featuring trajectory attention and learnable action queries,\ndesigned for effective encoding and decoding of segmented\nvision-language-action trajectories in robot imitation learning. Furthermore,\nwe devise a multi-modal contrastive learning objective to explicitly align\ndifferent modalities, complementing the primary behavior cloning objective.\nThrough extensive experiments conducted across various environments, Actra\nexhibits substantial performance improvement when compared to state-of-the-art\nmodels in terms of generalizability, dexterity, and precision.", "categories": "cs.RO", "created": "2024-08-02", "doi": null, "arxiv_id": "2408.01147"}
{"title": "A unified concept of the degree of ill-posedness for compact and\n  non-compact linear operators in Hilbert spaces under the auspices of the\n  spectral theorem", "authors": [], "abstract": "Covering ill-posed problems with compact and non-compact operators regarding\nthe degree of ill-posedness is a never ending story written by many authors in\nthe inverse problems literature. This paper tries to add a new narrative and\nsome new facets with respect to this story under the auspices of the spectral\ntheorem. The latter states that any self-adjoint and bounded operator is\nunitarily equivalent to a multiplication operator on some (semi-finite) measure\nspace. We will exploit this fact and derive a distribution function from the\ncorresponding multiplier, the growth behavior of which at zero allows us to\ncharacterize the degree of ill-posedness. We prove that this new concept\ncoincides with the well-known one for compact operators (by means of their\nsingular values), and illustrate the implications along examples including the\nHausdorff moment operator and convolutions.", "categories": "math.NA cs.NA", "created": "2024-08-02", "doi": null, "arxiv_id": "2408.01148"}
{"title": "Vertiport Terminal Scheduling and Throughput Analysis for Multiple\n  Surface Directions", "authors": [], "abstract": "Vertical Take-Off and Landing (VTOL) vehicles have gained immense popularity\nin the delivery drone market and are now being developed for passenger\ntransportation in urban areas to efficiently enable Urban Air Mobility (UAM).\nUAM aims to utilize the urban airspace \\hidetxt{vertical dimension} to address\nthe problem of heavy road congestion in dense urban cities. VTOL vehicles\nrequire vertiport terminals for landing, take-off, passengers boarding or\ndeboarding, refuelling (or charging), and maintenance. An efficient scheduling\nalgorithm is essential to maximize the throughput of the vertiport terminal\n(vertiminal)\\hidetxt{ as well as efficient use of airspace} while maintaining\nsafety protocols to handle the UAM traffic. While traditional departure and\ntaxiing operations can be applied in the context of vertiminal, specific\nalgorithms are required for take-off and landing schedules. Unlike fixed-wing\naircraft that require a runway to take-off and climb in a single direction,\nVTOL vehicles can approach and climb in several directions. We propose a Mixed\nInteger Linear Program (MILP) formulation to schedule flights for taxiing,\nclimbing (or approaching) using multiple directions after take-off (before\nlanding) and turnaround on gates. We also derived equations to thoroughly\nanalyze the throughput capacity of a vertiminal considering all its core\nelements. We have shown that our MILP can achieve the maximum throughput\nobtained through the equations. Given the input parameters, our analysis can be\nused to analyze the capacity of a vertiminal without running any simulation,\nwhile our MILP can be used to get the most efficient schedule.", "categories": "cs.ET cs.SY eess.SY", "created": "2024-08-02", "doi": null, "arxiv_id": "2408.01152"}
{"title": "DERA: Dense Entity Retrieval for Entity Alignment in Knowledge Graphs", "authors": [], "abstract": "Entity Alignment (EA) aims to match equivalent entities in different\nKnowledge Graphs (KGs), which is essential for knowledge fusion and\nintegration. Recently, embedding-based EA has attracted significant attention\nand many approaches have been proposed. Early approaches primarily focus on\nlearning entity embeddings from the structural features of KGs, defined by\nrelation triples. Later methods incorporated entities' names and attributes as\nauxiliary information to enhance embeddings for EA. However, these approaches\noften used different techniques to encode structural and attribute information,\nlimiting their interaction and mutual enhancement. In this work, we propose a\ndense entity retrieval framework for EA, leveraging language models to\nuniformly encode various features of entities and facilitate nearest entity\nsearch across KGs. Alignment candidates are first generated through entity\nretrieval, which are subsequently reranked to determine the final alignments.\nWe conduct comprehensive experiments on both cross-lingual and monolingual EA\ndatasets, demonstrating that our approach achieves state-of-the-art performance\ncompared to existing EA methods.", "categories": "cs.CL cs.AI", "created": "2024-08-02", "doi": null, "arxiv_id": "2408.01154"}
{"title": "TCR-GPT: Integrating Autoregressive Model and Reinforcement Learning for\n  T-Cell Receptor Repertoires Generation", "authors": [], "abstract": "T-cell receptors (TCRs) play a crucial role in the immune system by\nrecognizing and binding to specific antigens presented by infected or cancerous\ncells. Understanding the sequence patterns of TCRs is essential for developing\ntargeted immune therapies and designing effective vaccines. Language models,\nsuch as auto-regressive transformers, offer a powerful solution to this problem\nby learning the probability distributions of TCR repertoires, enabling the\ngeneration of new TCR sequences that inherit the underlying patterns of the\nrepertoire. We introduce TCR-GPT, a probabilistic model built on a decoder-only\ntransformer architecture, designed to uncover and replicate sequence patterns\nin TCR repertoires. TCR-GPT demonstrates an accuracy of 0.953 in inferring\nsequence probability distributions measured by Pearson correlation coefficient.\nFurthermore, by leveraging Reinforcement Learning(RL), we adapted the\ndistribution of TCR sequences to generate TCRs capable of recognizing specific\npeptides, offering significant potential for advancing targeted immune\ntherapies and vaccine development. With the efficacy of RL, fine-tuned\npretrained TCR-GPT models demonstrated the ability to produce TCR repertoires\nlikely to bind specific peptides, illustrating RL's efficiency in enhancing the\nmodel's adaptability to the probability distributions of biologically relevant\nTCR sequences.", "categories": "cs.LG cs.AI", "created": "2024-08-02", "doi": null, "arxiv_id": "2408.01156"}
{"title": "A Note on Computing Betweenness Centrality from the 2-core", "authors": [], "abstract": "A central task in network analysis is to identify important nodes in a graph.\nBetweenness centrality (BC) is a popular centrality measure that captures the\nsignificance of nodes based on the number of shortest paths each node\nintersects with. In this note, we derive a recursive formula to compute the\nbetweenness centralities of a graph from the betweenness centralities of its\n2-core.Furthermore, we analyze mathematically the significant impact of\nremoving degree-one nodes on the estimation of betweenness centrality within\nthe context of the popular pivot sampling scheme for Single-Source Shortest\nPath (SSSP) computations, as described in the Brandes-Pich approach and\nimplemented in widely used software such as NetworkX. We demonstrate both\ntheoretically and empirically that removing degree-1 nodes can reduce the\nsample complexity needed to achieve better accuracy, thereby decreasing the\noverall runtime.", "categories": "cs.SI", "created": "2024-08-02", "doi": null, "arxiv_id": "2408.01157"}
{"title": "Robust Curve Detection in Volumetric Medical Imaging via Attraction\n  Field", "authors": [], "abstract": "Understanding body part geometry is crucial for precise medical diagnostics.\nCurves effectively describe anatomical structures and are widely used in\nmedical imaging applications related to cardiovascular, respiratory, and\nskeletal diseases. Traditional curve detection methods are often task-specific,\nrelying heavily on domain-specific features, limiting their broader\napplicability. This paper introduces a novel approach for detecting\nnon-branching curves, which does not require prior knowledge of the object's\norientation, shape, or position. Our method uses neural networks to predict (1)\nan attraction field, which offers subpixel accuracy, and (2) a closeness map,\nwhich limits the region of interest and essentially eliminates outliers far\nfrom the desired curve. We tested our curve detector on several clinically\nrelevant tasks with diverse morphologies and achieved impressive subpixel-level\naccuracy results that surpass existing methods, highlighting its versatility\nand robustness. Additionally, to support further advancements in this field, we\nprovide our private annotations of aortic centerlines and masks, which can\nserve as a benchmark for future research. The dataset can be found at\nhttps://github.com/neuro-ml/curve-detection.", "categories": "cs.CV", "created": "2024-08-02", "doi": null, "arxiv_id": "2408.01159"}
{"title": "PreMix: Boosting Multiple Instance Learning in Digital Histopathology\n  through Pre-training with Intra-Batch Slide Mixing", "authors": [], "abstract": "The classification of gigapixel-sized whole slide images (WSIs), digital\nrepresentations of histological slides obtained via a high-resolution scanner,\nfaces significant challenges associated with the meticulous and time-consuming\nnature of fine-grained labeling. While weakly-supervised multiple instance\nlearning (MIL) has emerged as a promising approach, current MIL methods are\nconstrained by their limited ability to leverage the wealth of information\nembedded within unlabeled WSIs. This limitation often necessitates training MIL\nfeature aggregators from scratch after the feature extraction process,\nhindering efficiency and accuracy. PreMix extends the general MIL framework by\npre-training the MIL aggregator with an intra-batch slide mixing approach.\nSpecifically, PreMix incorporates Barlow Twins Slide Mixing during\npre-training, enhancing its ability to handle diverse WSI sizes and maximizing\nthe utility of unlabeled WSIs. Combined with Mixup and Manifold Mixup during\nfine-tuning, PreMix achieves a mean of 4.7% performance improvement over the\nbaseline MIL framework, the hierarchical image pyramid transformer (HIPT), on\nthe Camelyon16 dataset. The observed improvement across a range of active\nlearning acquisition functions and WSI-labeled training budgets highlights the\nframework's adaptability to diverse datasets and varying resource constraints.\nUltimately, PreMix paves the way for more efficient and accurate WSI\nclassification under limited WSI-labeled datasets, encouraging the broader\nadoption of unlabeled WSI data in histopathological research. The code is\navailable at https://anonymous.4open.science/r/PreMix", "categories": "cs.CV", "created": "2024-08-02", "doi": null, "arxiv_id": "2408.01162"}
{"title": "Domain Adaptation-Enhanced Searchlight: Enabling brain decoding from\n  visual perception to mental imagery", "authors": [], "abstract": "In cognitive neuroscience and brain-computer interface research, accurately\npredicting imagined stimuli is crucial. This study investigates the\neffectiveness of Domain Adaptation (DA) in enhancing imagery prediction using\nprimarily visual data from fMRI scans of 18 subjects. Initially, we train a\nbaseline model on visual stimuli to predict imagined stimuli, utilizing data\nfrom 14 brain regions. We then develop several models to improve imagery\nprediction, comparing different DA methods. Our results demonstrate that DA\nsignificantly enhances imagery prediction, especially with the Regular Transfer\napproach. We then conduct a DA-enhanced searchlight analysis using Regular\nTransfer, followed by permutation-based statistical tests to identify brain\nregions where imagery decoding is consistently above chance across subjects.\nOur DA-enhanced searchlight predicts imagery contents in a highly distributed\nset of brain regions, including the visual cortex and the frontoparietal\ncortex, thereby outperforming standard cross-domain classification methods. The\ncomplete code and data for this paper have been made openly available for the\nuse of the scientific community.", "categories": "cs.LG q-bio.NC", "created": "2024-08-02", "doi": null, "arxiv_id": "2408.01163"}
{"title": "Continuous-Time Neural Networks Can Stably Memorize Random Spike Trains", "authors": [], "abstract": "The paper explores the capability of continuous-time recurrent neural\nnetworks to store and recall precisely timed spike patterns. We show (by\nnumerical experiments) that this is indeed possible: within some range of\nparameters, any random score of spike trains (for all neurons in the network)\ncan be robustly memorized and autonomously reproduced with stable accurate\nrelative timing of all spikes, with probability close to one. We also\ndemonstrate associative recall under noisy conditions.\n  In these experiments, the required synaptic weights are computed offline, to\nsatisfy a template that encourages temporal stability.", "categories": "cs.NE", "created": "2024-08-02", "doi": null, "arxiv_id": "2408.01166"}
{"title": "Rethinking Pre-trained Feature Extractor Selection in Multiple Instance\n  Learning for Whole Slide Image Classification", "authors": [], "abstract": "Multiple instance learning (MIL) has become a preferred method for\nclassifying gigapixel whole slide images (WSIs), without requiring patch label\nannotation. The focus of the current MIL research stream is on the\nembedding-based MIL approach, which involves extracting feature vectors from\npatches using a pre-trained feature extractor. These feature vectors are then\nfed into an MIL aggregator for slide-level prediction. Despite prior research\nsuggestions on enhancing the most commonly used ResNet50 supervised model\npre-trained on ImageNet-1K, there remains a lack of clear guidance on selecting\nthe optimal feature extractor to maximize WSI performance. This study aims at\naddressing this gap by examining MIL feature extractors across three\ndimensions: pre-training dataset, backbone model, and pre-training method.\nExtensive experiments were carried out on the two public WSI datasets\n(TCGA-NSCLC and Camelyon16) using four SOTA MIL models. The main findings\nindicate the following: 1) Performance significantly improves with larger and\nmore varied pre-training datasets in both CNN and Transformer backbones. 2)\n`Modern and deeper' backbones greatly outperform `standard' backbones (ResNet\nand ViT), with performance improvements more guaranteed in Transformer-based\nbackbones. 3) The choice of self-supervised learning (SSL) method is crucial,\nwith the most significant benefits observed when applied to the Transformer\n(ViT) backbone. The study findings have practical implications, including\ndesigning more effective pathological foundation models. Our code is available\nat: https://anonymous.4open.science/r/MIL-Feature-Extractor-Selection", "categories": "cs.CV", "created": "2024-08-02", "doi": null, "arxiv_id": "2408.01167"}
{"title": "Misinforming LLMs: vulnerabilities, challenges and opportunities", "authors": [], "abstract": "Large Language Models (LLMs) have made significant advances in natural\nlanguage processing, but their underlying mechanisms are often misunderstood.\nDespite exhibiting coherent answers and apparent reasoning behaviors, LLMs rely\non statistical patterns in word embeddings rather than true cognitive\nprocesses. This leads to vulnerabilities such as \"hallucination\" and\nmisinformation. The paper argues that current LLM architectures are inherently\nuntrustworthy due to their reliance on correlations of sequential patterns of\nword embedding vectors. However, ongoing research into combining generative\ntransformer-based models with fact bases and logic programming languages may\nlead to the development of trustworthy LLMs capable of generating statements\nbased on given truth and explaining their self-reasoning process.", "categories": "cs.CL cs.AI", "created": "2024-08-02", "doi": null, "arxiv_id": "2408.01168"}
{"title": "Algorithm, Expert, or Both? Evaluating the Role of Feature Selection\n  Methods on User Preferences and Reliance", "authors": [], "abstract": "The integration of users and experts in machine learning is a widely studied\ntopic in artificial intelligence literature. Similarly, human-computer\ninteraction research extensively explores the factors that influence the\nacceptance of AI as a decision support system. In this experimental study, we\ninvestigate users' preferences regarding the integration of experts in the\ndevelopment of such systems and how this affects their reliance on these\nsystems. Specifically, we focus on the process of feature selection -- an\nelement that is gaining importance due to the growing demand for transparency\nin machine learning models. We differentiate between three feature selection\nmethods: algorithm-based, expert-based, and a combined approach. In the first\ntreatment, we analyze users' preferences for these methods. In the second\ntreatment, we randomly assign users to one of the three methods and analyze\nwhether the method affects advice reliance. Users prefer the combined method,\nfollowed by the expert-based and algorithm-based methods. However, the users in\nthe second treatment rely equally on all methods. Thus, we find a remarkable\ndifference between stated preferences and actual usage. Moreover, allowing the\nusers to choose their preferred method had no effect, and the preferences and\nthe extent of reliance were domain-specific. The findings underscore the\nimportance of understanding cognitive processes in AI-supported decisions and\nthe need for behavioral experiments in human-AI interactions.", "categories": "cs.HC", "created": "2024-08-02", "doi": null, "arxiv_id": "2408.01171"}
{"title": "Sustainable Diffusion-based Incentive Mechanism for Generative AI-driven\n  Digital Twins in Industrial Cyber-Physical Systems", "authors": [], "abstract": "Industrial Cyber-Physical Systems (ICPSs) are an integral component of modern\nmanufacturing and industries. By digitizing data throughout the product life\ncycle, Digital Twins (DTs) in ICPSs enable a shift from current industrial\ninfrastructures to intelligent and adaptive infrastructures. Thanks to data\nprocess capability, Generative Artificial Intelligence (GAI) can drive the\nconstruction and update of DTs to improve predictive accuracy and prepare for\ndiverse smart manufacturing. However, mechanisms that leverage sensing\nIndustrial Internet of Things (IIoT) devices to share data for the construction\nof DTs are susceptible to adverse selection problems. In this paper, we first\ndevelop a GAI-driven DT architecture for ICPSs. To address the adverse\nselection problem caused by information asymmetry, we propose a contract theory\nmodel and develop the sustainable diffusion-based soft actor-critic algorithm\nto identify the optimal feasible contract. Specifically, we leverage the\ndynamic structured pruning technique to reduce parameter numbers of actor\nnetworks, allowing sustainability and efficient implementation of the proposed\nalgorithm. Finally, numerical results demonstrate the effectiveness of the\nproposed scheme.", "categories": "cs.NI cs.LG", "created": "2024-08-02", "doi": null, "arxiv_id": "2408.01173"}
{"title": "Power Aware Container Placement in Cloud Computing with Affinity and\n  Cubic Power Model", "authors": [], "abstract": "Modern data centres are increasingly adopting containers to enhance power and\nperformance efficiency. These data centres consist of multiple heterogeneous\nmachines, each equipped with varying amounts of resources such as CPU, I/O,\nmemory, and network bandwidth. Data centers rent their resources to\napplications, which demand different amounts of resources and execute on\nmachines for extended durations if the machines provide the demanded resources\nto the applications. Certain applications run efficiently on specific machines,\nreferred to as system affinity between applications and machines. In contrast,\nothers are incompatible with specific machines, referred to as anti-affinity\nbetween applications and machines. We consider that there are multiple\napplications, and data centers need to execute as many applications as\npossible. Data centers incur electricity based on CPU usage due to the\nexecution of applications, with the cost being proportional to the cube of the\ntotal CPU usage. It is a challenging problem to place applications on the\nmachines they have an affinity for while keeping the electricity cost in check.\nOur work addresses the placement problem of matching applications to machines\nto minimize overall electricity costs while maximizing the number of affinity\npairs of machines and applications. We propose three solution approaches: (a)\nPower-Aware Placement (PAP): applications are placed on machines where power\nusage is minimized, (b) Affinity-Aware Placement (AAP): applications are placed\non machines where affinity is maximized, (c) Combined Power-Affinity Placement\n(CPAAP): this approach integrates the benefits of both PAP and AAP. Our\nproposed approach improves the affinity satisfaction ratio by up to 4% while\nreducing the total system cost by up to 26% and improving the affinity payoff\nratio by up to 37% compared to state-of-the-art approaches for real-life\ndatasets.", "categories": "cs.DC", "created": "2024-08-02", "doi": null, "arxiv_id": "2408.01176"}
{"title": "EmoBack: Backdoor Attacks Against Speaker Identification Using Emotional\n  Prosody", "authors": [], "abstract": "Speaker identification (SI) determines a speaker's identity based on their\nspoken utterances. Previous work indicates that SI deep neural networks (DNNs)\nare vulnerable to backdoor attacks. Backdoor attacks involve embedding hidden\ntriggers in DNNs' training data, causing the DNN to produce incorrect output\nwhen these triggers are present during inference. This is the first work that\nexplores SI DNNs' vulnerability to backdoor attacks using speakers' emotional\nprosody, resulting in dynamic, inconspicuous triggers. %Such an attack could\nhave real-world implications in forensics, authentication, and surveillance. We\nconducted a parameter study using three different datasets and DNN\narchitectures to determine the impact of emotions as backdoor triggers on the\naccuracy of SI systems. Additionally, we have explored the robustness of our\nattacks by applying defenses like pruning, STRIP-ViTA, and three popular\npreprocessing techniques: quantization, median filtering, and squeezing. Our\nfindings show that the aforementioned models are prone to our attack,\nindicating that emotional triggers (sad and neutral prosody) can be effectively\nused to compromise the integrity of SI systems. However, the results of our\npruning experiments suggest potential solutions for reinforcing the models\nagainst our attacks, decreasing the attack success rate up to 40%.", "categories": "cs.CR", "created": "2024-08-02", "doi": null, "arxiv_id": "2408.01178"}
{"title": "Nested Music Transformer: Sequentially Decoding Compound Tokens in\n  Symbolic Music and Audio Generation", "authors": [], "abstract": "Representing symbolic music with compound tokens, where each token consists\nof several different sub-tokens representing a distinct musical feature or\nattribute, offers the advantage of reducing sequence length. While previous\nresearch has validated the efficacy of compound tokens in music sequence\nmodeling, predicting all sub-tokens simultaneously can lead to suboptimal\nresults as it may not fully capture the interdependencies between them. We\nintroduce the Nested Music Transformer (NMT), an architecture tailored for\ndecoding compound tokens autoregressively, similar to processing flattened\ntokens, but with low memory usage. The NMT consists of two transformers: the\nmain decoder that models a sequence of compound tokens and the sub-decoder for\nmodeling sub-tokens of each compound token. The experiment results showed that\napplying the NMT to compound tokens can enhance the performance in terms of\nbetter perplexity in processing various symbolic music datasets and discrete\naudio tokens from the MAESTRO dataset.", "categories": "cs.SD cs.IR cs.LG eess.AS", "created": "2024-08-02", "doi": null, "arxiv_id": "2408.01180"}
{"title": "VAR-CLIP: Text-to-Image Generator with Visual Auto-Regressive Modeling", "authors": [], "abstract": "VAR is a new generation paradigm that employs 'next-scale prediction' as\nopposed to 'next-token prediction'. This innovative transformation enables\nauto-regressive (AR) transformers to rapidly learn visual distributions and\nachieve robust generalization. However, the original VAR model is constrained\nto class-conditioned synthesis, relying solely on textual captions for\nguidance. In this paper, we introduce VAR-CLIP, a novel text-to-image model\nthat integrates Visual Auto-Regressive techniques with the capabilities of\nCLIP. The VAR-CLIP framework encodes captions into text embeddings, which are\nthen utilized as textual conditions for image generation. To facilitate\ntraining on extensive datasets, such as ImageNet, we have constructed a\nsubstantial image-text dataset leveraging BLIP2. Furthermore, we delve into the\nsignificance of word positioning within CLIP for the purpose of caption\nguidance. Extensive experiments confirm VAR-CLIP's proficiency in generating\nfantasy images with high fidelity, textual congruence, and aesthetic\nexcellence. Our project page are https://github.com/daixiangzi/VAR-CLIP", "categories": "cs.CV", "created": "2024-08-02", "doi": null, "arxiv_id": "2408.01181"}
{"title": "Optimizing Variational Quantum Circuits Using Metaheuristic Strategies\n  in Reinforcement Learning", "authors": [], "abstract": "Quantum Reinforcement Learning (QRL) offers potential advantages over\nclassical Reinforcement Learning, such as compact state space representation\nand faster convergence in certain scenarios. However, practical benefits\nrequire further validation. QRL faces challenges like flat solution landscapes,\nwhere traditional gradient-based methods are inefficient, necessitating the use\nof gradient-free algorithms. This work explores the integration of\nmetaheuristic algorithms -- Particle Swarm Optimization, Ant Colony\nOptimization, Tabu Search, Genetic Algorithm, Simulated Annealing, and Harmony\nSearch -- into QRL. These algorithms provide flexibility and efficiency in\nparameter optimization. Evaluations in $5\\times5$ MiniGrid Reinforcement\nLearning environments show that, all algorithms yield near-optimal results,\nwith Simulated Annealing and Particle Swarm Optimization performing best. In\nthe Cart Pole environment, Simulated Annealing, Genetic Algorithms, and\nParticle Swarm Optimization achieve optimal results, while the others perform\nslightly better than random action selection. These findings demonstrate the\npotential of Particle Swarm Optimization and Simulated Annealing for efficient\nQRL learning, emphasizing the need for careful algorithm selection and\nadaptation.", "categories": "quant-ph cs.AI cs.LG", "created": "2024-08-02", "doi": null, "arxiv_id": "2408.01187"}
{"title": "Multi-Objective Deep Reinforcement Learning for Optimisation in\n  Autonomous Systems", "authors": [], "abstract": "Reinforcement Learning (RL) is used extensively in Autonomous Systems (AS) as\nit enables learning at runtime without the need for a model of the environment\nor predefined actions. However, most applications of RL in AS, such as those\nbased on Q-learning, can only optimize one objective, making it necessary in\nmulti-objective systems to combine multiple objectives in a single objective\nfunction with predefined weights. A number of Multi-Objective Reinforcement\nLearning (MORL) techniques exist but they have mostly been applied in RL\nbenchmarks rather than real-world AS systems. In this work, we use a MORL\ntechnique called Deep W-Learning (DWN) and apply it to the Emergent Web Servers\nexemplar, a self-adaptive server, to find the optimal configuration for runtime\nperformance optimization. We compare DWN to two single-objective optimization\nimplementations: {\\epsilon}-greedy algorithm and Deep Q-Networks. Our initial\nevaluation shows that DWN optimizes multiple objectives simultaneously with\nsimilar results than DQN and {\\epsilon}-greedy approaches, having a better\nperformance for some metrics, and avoids issues associated with combining\nmultiple objectives into a single utility function.", "categories": "cs.AI", "created": "2024-08-02", "doi": null, "arxiv_id": "2408.01188"}
{"title": "A Weakly Supervised and Globally Explainable Learning Framework for\n  Brain Tumor Segmentation", "authors": [], "abstract": "Machine-based brain tumor segmentation can help doctors make better\ndiagnoses. However, the complex structure of brain tumors and expensive\npixel-level annotations present challenges for automatic tumor segmentation. In\nthis paper, we propose a counterfactual generation framework that not only\nachieves exceptional brain tumor segmentation performance without the need for\npixel-level annotations, but also provides explainability. Our framework\neffectively separates class-related features from class-unrelated features of\nthe samples, and generate new samples that preserve identity features while\naltering class attributes by embedding different class-related features. We\nperform topological data analysis on the extracted class-related features and\nobtain a globally explainable manifold, and for each abnormal sample to be\nsegmented, a meaningful normal sample could be effectively generated with the\nguidance of the rule-based paths designed within the manifold for comparison\nfor identifying the tumor regions. We evaluate our proposed method on two\ndatasets, which demonstrates superior performance of brain tumor segmentation.\nThe code is available at https://github.com/xrt11/tumor-segmentation.", "categories": "cs.CV", "created": "2024-08-02", "doi": null, "arxiv_id": "2408.01191"}
{"title": "On Game Based Distributed Decision Approach for Multi-agent Optimal\n  Coverage Problem with Application to Constellations Reconfiguration", "authors": [], "abstract": "This paper focuses on the optimal coverage problem (OCP) for multi-agent\nsystems with decentralized optimization. A game based distributed decision\napproach for the the multi-agent OCP is proposed. The equivalence between the\nequilibrium of the game and the extreme value of the global performance\nobjective is strictly proved. Then, a distributed algorithm only using local\ninformation to obtain the global near-optimal coverage is developed, and its\nconvergence is proved. Finally, the proposed method is applied to maximize the\ncovering time of a satellite constellation for a target. The simulation results\nunder different scenarios show our method costs much less computation time\nunder some level index than traditional centralized optimization.", "categories": "eess.SY cs.SY", "created": "2024-08-02", "doi": null, "arxiv_id": "2408.01193"}
{"title": "Frequency-Explicit Shape Holomorphy in Uncertainty Quantification for\n  Acoustic Scattering", "authors": [], "abstract": "We consider frequency-domain acoustic scattering at a homogeneous star-shaped\npenetrable obstacle, whose shape is uncertain and modelled via a radial\nspectral parameterization with random coefficients. Using recent results on the\nstability of Helmholtz transmission problems with piecewise constant\ncoefficients from [A. Moiola and E. A. Spence, Acoustic transmission problems:\nwavenumber-explicit bounds and resonance-free regions, Mathematical Models and\nMethods in Applied Sciences, 29 (2019), pp. 317-354] we obtain\nfrequency-explicit statements on the holomorphic dependence of the scattered\nfield and the far-field pattern on the stochastic shape parameters. This paves\nthe way for applying general results on the efficient construction of\nhigh-dimensional surrogate models. We also take into account the effect of\ndomain truncation by means of perfectly matched layers (PML). In addition,\nspatial regularity estimates which are explicit in terms of the wavenumber $k$\npermit us to quantify the impact of finite-element Galerkin discretization\nusing high-order Lagrangian finite-element spaces.", "categories": "math.NA cs.NA", "created": "2024-08-02", "doi": null, "arxiv_id": "2408.01194"}
{"title": "Game Theory Based Community-Aware Opinion Dynamics", "authors": [], "abstract": "Examining the mechanisms underlying the formation and evolution of opinions\nwithin real-world social systems, which consist of numerous individuals, can\nprovide valuable insights for effective social functioning and informed\nbusiness decision making. The focus of our study is on the dynamics of opinions\ninside a networked multi-agent system. We provide a novel approach called the\nGame Theory Based Community-Aware Opinion Formation Process (GCAOFP) to\naccurately represent the co-evolutionary dynamics of communities and opinions\nin real-world social systems. The GCAOFP algorithm comprises two distinct steps\nin each iteration. 1) The Community Dynamics Process conceptualizes the process\nof community formation as a non-cooperative game involving a finite number of\nagents. Each individual agent aims to maximize their own utility by adopting a\nresponse that leads to the most favorable update of the community label. 2) The\nOpinion Formation Process involves the updating of an individual agent's\nopinion within a community-aware framework that incorporates bounded\nconfidence. This process takes into account the updated matrix of community\nmembers and ensures that an agent's opinion aligns with the opinions of others\nwithin their community, within certain defined limits. The present study\nprovides a theoretical proof that under any initial conditions, the\naforementioned co-evolutionary dynamics process will ultimately reach an\nequilibrium state. In this state, both the opinion vector and community member\nmatrix will stabilize after a finite number of iterations. In contrast to\nconventional opinion dynamics models, the guaranteed convergence of agent\nopinion within the same community ensures that the convergence of opinions\ntakes place exclusively inside a given community.", "categories": "cs.GT", "created": "2024-08-02", "doi": null, "arxiv_id": "2408.01196"}
{"title": "Certifiably Robust Encoding Schemes", "authors": [], "abstract": "Quantum machine learning uses principles from quantum mechanics to process\ndata, offering potential advances in speed and performance. However, previous\nwork has shown that these models are susceptible to attacks that manipulate\ninput data or exploit noise in quantum circuits. Following this, various\nstudies have explored the robustness of these models. These works focus on the\nrobustness certification of manipulations of the quantum states. We extend this\nline of research by investigating the robustness against perturbations in the\nclassical data for a general class of data encoding schemes. We show that for\nsuch schemes, the addition of suitable noise channels is equivalent to\nevaluating the mean value of the noiseless classifier at the smoothed data,\nakin to Randomized Smoothing from classical machine learning. Using our general\nframework, we show that suitable additions of phase-damping noise channels\nimprove empirical and provable robustness for the considered class of encoding\nschemes.", "categories": "quant-ph cs.LG", "created": "2024-08-02", "doi": null, "arxiv_id": "2408.01200"}
{"title": "Zoomable Level-of-Detail ChartTables for Interpreting Probabilistic\n  Model Outputs for Reactionary Train Delays", "authors": [], "abstract": "\"Reactionary delay\" is a result of the accumulated cascading effects of\nknock-on train delays which is increasing on UK railways due to increasing\nutilisation of the railway infrastructure. The chaotic nature of its effects on\ntrain lateness is notoriously hard to predict. We use a stochastic\nMonte-Carto-style simulation of reactionary delay that produces whole\ndistributions of likely reactionary delay and delays this causes. We\ndemonstrate how Zoomable Level-of-Detail ChartTables - case-by-variable tables\nwhere cases are rows, variables are columns, variables are complex composite\nmetrics that incorporate distributions, and cells contain mini-charts that\ndepict these as different levels of detail through zoom interaction - help\ninterpret whole distributions of model outputs to help understand the causes\nand effects of reactionary delay, how they inform timetable robustness testing,\nand how they could be used in other contexts.", "categories": "cs.HC", "created": "2024-08-02", "doi": null, "arxiv_id": "2408.01203"}
{"title": "From Problem to Solution: Bio-inspired 3D Printing for Bonding Soft and\n  Rigid Materials via Underextrusions", "authors": [], "abstract": "Vertebrate animals benefit from a combination of rigidity for structural\nsupport and softness for adaptation. Similarly, integrating rigidity and\nsoftness can enhance the versatility of soft robotics. However, the challenges\nassociated with creating durable bonding interfaces between soft and rigid\nmaterials have limited the development of hybrid robots. Existing solutions\nrequire specialized machinery, such as polyjet 3D printers, which are not\ncommonly available. In response to these challenges, we have developed a 3D\nprinting technique that can be used with almost all commercially available FDM\nprinters. This technique leverages the common issue of underextrusion to create\na strong bond between soft and rigid materials. Underextrusion generates a\nporous structure, similar to fibrous connective tissues, that provides a robust\ninterface with the rigid part through layer fusion, while the porosity enables\ninterlocking with the soft material. Our experiments demonstrated that this\nmethod outperforms conventional adhesives commonly used in soft robotics,\nachieving nearly 200\\% of the bonding strength in both lap shear and peeling\ntests. Additionally, we investigated how different porosity levels affect\nbonding strength. We tested the technique under pressure scenarios critical to\nsoft and hybrid robots and achieved three times more pressure than the current\nadhesion solution. Finally, we fabricated various hybrid robots using this\ntechnique to demonstrate the wide range of capabilities this approach and\nhybridity can bring to soft robotics. has context menu", "categories": "cs.RO", "created": "2024-08-02", "doi": null, "arxiv_id": "2408.01210"}
{"title": "Markov Decision Processes with Sure Parity and Multiple Reachability\n  Objectives", "authors": [], "abstract": "This paper considers the problem of finding strategies that satisfy a mixture\nof sure and threshold objectives in Markov decision processes. We focus on a\nsingle $\\omega$-regular objective expressed as parity that must be surely met\nwhile satisfying $n$ reachability objectives towards sink states with some\nprobability thresholds too. We consider three variants of the problem: (a)\nstrict and (b) non-strict thresholds on all reachability objectives, and (c)\nmaximizing the thresholds with respect to a lexicographic order. We show that\n(a) and (c) can be reduced to solving parity games, and (b) can be solved in\n$\\sf{EXPTIME}$. Strategy complexities as well as algorithms are provided for\nall cases.", "categories": "cs.GT", "created": "2024-08-02", "doi": null, "arxiv_id": "2408.01212"}
{"title": "High-Throughput Phenotyping of Clinical Text Using Large Language Models", "authors": [], "abstract": "High-throughput phenotyping automates the mapping of patient signs to\nstandardized ontology concepts and is essential for precision medicine. This\nstudy evaluates the automation of phenotyping of clinical summaries from the\nOnline Mendelian Inheritance in Man (OMIM) database using large language\nmodels. Due to their rich phenotype data, these summaries can be surrogates for\nphysician notes. We conduct a performance comparison of GPT-4 and\nGPT-3.5-Turbo. Our results indicate that GPT-4 surpasses GPT-3.5-Turbo in\nidentifying, categorizing, and normalizing signs, achieving concordance with\nmanual annotators comparable to inter-rater agreement. Despite some limitations\nin sign normalization, the extensive pre-training of GPT-4 results in high\nperformance and generalizability across several phenotyping tasks while\nobviating the need for manually annotated training data. Large language models\nare expected to be the dominant method for automating high-throughput\nphenotyping of clinical text.", "categories": "cs.CL cs.AI", "created": "2024-08-02", "doi": null, "arxiv_id": "2408.01214"}
{"title": "ZNorm: Z-Score Gradient Normalization for Accelerating Neural Network\n  Training", "authors": [], "abstract": "The rapid advancements in deep learning necessitate efficient training\nmethods for deep neural networks (DNNs). As models grow in complexity,\nvanishing and exploding gradients impede convergence and performance. We\npropose Z-Score Normalization for Gradient Descent (ZNorm), an innovative\ntechnique that adjusts only the gradients to enhance training efficiency and\nimprove model performance. ZNorm normalizes the overall gradients, providing\nconsistent gradient scaling across layers, thereby reducing the risks of\nvanishing and exploding gradients. Our extensive experiments on CIFAR-10 and\nmedical datasets demonstrate that ZNorm not only accelerates convergence but\nalso enhances performance metrics. ZNorm consistently outperforms existing\nmethods, achieving superior results using the same computational settings. In\nmedical imaging applications, ZNorm improves tumor prediction and segmentation\nperformances, underscoring its practical utility. These findings highlight\nZNorm's potential as a robust and versatile tool for improving the efficiency\nand effectiveness of deep neural network training across a wide range of\narchitectures and applications.", "categories": "cs.LG", "created": "2024-08-02", "doi": null, "arxiv_id": "2408.01215"}
{"title": "S2TD-Face: Reconstruct a Detailed 3D Face with Controllable Texture from\n  a Single Sketch", "authors": [], "abstract": "3D textured face reconstruction from sketches applicable in many scenarios\nsuch as animation, 3D avatars, artistic design, missing people search, etc., is\na highly promising but underdeveloped research topic. On the one hand, the\nstylistic diversity of sketches leads to existing sketch-to-3D-face methods\nonly being able to handle pose-limited and realistically shaded sketches. On\nthe other hand, texture plays a vital role in representing facial appearance,\nyet sketches lack this information, necessitating additional texture control in\nthe reconstruction process. This paper proposes a novel method for\nreconstructing controllable textured and detailed 3D faces from sketches, named\nS2TD-Face. S2TD-Face introduces a two-stage geometry reconstruction framework\nthat directly reconstructs detailed geometry from the input sketch. To keep\ngeometry consistent with the delicate strokes of the sketch, we propose a novel\nsketch-to-geometry loss that ensures the reconstruction accurately fits the\ninput features like dimples and wrinkles. Our training strategies do not rely\non hard-to-obtain 3D face scanning data or labor-intensive hand-drawn sketches.\nFurthermore, S2TD-Face introduces a texture control module utilizing text\nprompts to select the most suitable textures from a library and seamlessly\nintegrate them into the geometry, resulting in a 3D detailed face with\ncontrollable texture. S2TD-Face surpasses existing state-of-the-art methods in\nextensive quantitative and qualitative experiments. Our project is available at\nhttps://github.com/wang-zidu/S2TD-Face .", "categories": "cs.CV", "created": "2024-08-02", "doi": null, "arxiv_id": "2408.01218"}
{"title": "Rubric-based Learner Modelling via Noisy Gates Bayesian Networks for\n  Computational Thinking Skills Assessment", "authors": [], "abstract": "In modern and personalised education, there is a growing interest in\ndeveloping learners' competencies and accurately assessing them. In a previous\nwork, we proposed a procedure for deriving a learner model for automatic skill\nassessment from a task-specific competence rubric, thus simplifying the\nimplementation of automated assessment tools. The previous approach, however,\nsuffered two main limitations: (i) the ordering between competencies defined by\nthe assessment rubric was only indirectly modelled; (ii) supplementary skills,\nnot under assessment but necessary for accomplishing the task, were not\nincluded in the model. In this work, we address issue (i) by introducing dummy\nobserved nodes, strictly enforcing the skills ordering without changing the\nnetwork's structure. In contrast, for point (ii), we design a network with two\nlayers of gates, one performing disjunctive operations by noisy-OR gates and\nthe other conjunctive operations through logical ANDs. Such changes improve the\nmodel outcomes' coherence and the modelling tool's flexibility without\ncompromising the model's compact parametrisation, interpretability and simple\nexperts' elicitation. We used this approach to develop a learner model for\nComputational Thinking (CT) skills assessment. The CT-cube skills assessment\nframework and the Cross Array Task (CAT) are used to exemplify it and\ndemonstrate its feasibility.", "categories": "cs.AI cs.ET", "created": "2024-08-02", "doi": "10.24138/jcomss-2022-0169", "arxiv_id": "2408.01221"}
{"title": "Multi-head Spatial-Spectral Mamba for Hyperspectral Image Classification", "authors": [], "abstract": "Spatial-Spectral Mamba (SSM) improves computational efficiency and captures\nlong-range dependencies, addressing Transformer limitations. However,\ntraditional Mamba models overlook rich spectral information in HSIs and\nstruggle with high dimensionality and sequential data. To address these issues,\nwe propose the SSM with multi-head self-attention and token enhancement\n(MHSSMamba). This model integrates spectral and spatial information by\nenhancing spectral tokens and using multi-head attention to capture complex\nrelationships between spectral bands and spatial locations. It also manages\nlong-range dependencies and the sequential nature of HSI data, preserving\ncontextual information across spectral bands. MHSSMamba achieved remarkable\nclassification accuracies of 97.62\\% on Pavia University, 96.92\\% on the\nUniversity of Houston, 96.85\\% on Salinas, and 99.49\\% on Wuhan-longKou\ndatasets.", "categories": "cs.CV", "created": "2024-08-02", "doi": null, "arxiv_id": "2408.01224"}
{"title": "Reality Fusion: Robust Real-time Immersive Mobile Robot Teleoperation\n  with Volumetric Visual Data Fusion", "authors": [], "abstract": "We introduce Reality Fusion, a novel robot teleoperation system that\nlocalizes, streams, projects, and merges a typical onboard depth sensor with a\nphotorealistic, high resolution, high framerate, and wide field of view (FoV)\nrendering of the complex remote environment represented as 3D Gaussian splats\n(3DGS). Our framework enables robust egocentric and exocentric robot\nteleoperation in immersive VR, with the 3DGS effectively extending spatial\ninformation of a depth sensor with limited FoV and balancing the trade-off\nbetween data streaming costs and data visual quality. We evaluated our\nframework through a user study with 24 participants, which revealed that\nReality Fusion leads to significantly better user performance, situation\nawareness, and user preferences. To support further research and development,\nwe provide an open-source implementation with an easy-to-replicate custom-made\ntelepresence robot, a high-performance virtual reality 3DGS renderer, and an\nimmersive robot control package. (Source code:\nhttps://github.com/uhhhci/RealityFusion)", "categories": "cs.RO", "created": "2024-08-02", "doi": null, "arxiv_id": "2408.01225"}
{"title": "Parametric holomorphy of elliptic eigenvalue problems", "authors": [], "abstract": "The study of parameter-dependent partial differential equations (parametric\nPDEs) with countably many parameters has been actively studied for the last few\ndecades. In particular, it has been well known that a certain type of\nparametric holomorphy of the PDE solutions allows the application of deep\nneural networks without encountering the curse of dimensionality. This paper\naims to propose a general framework for verifying the desired parametric\nholomorphy by utilizing the bounds on parametric derivatives. The framework is\nillustrated with examples of parametric elliptic eigenvalue problems (EVPs),\nencompassing both linear and semilinear cases. As the results, it will be shown\nthat the ground eigenpairs have the desired holomorphy. Furthermore, under the\nsame conditions, improved bounds for the mixed derivatives of the ground\neigenpairs are derived. These bounds are well known to take a crucial role in\nthe error analysis of quasi-Monte Carlo methods.", "categories": "math.NA cs.NA math.AP", "created": "2024-08-02", "doi": null, "arxiv_id": "2408.01227"}
{"title": "The Phantom Menace: Unmasking Privacy Leakages in Vision-Language Models", "authors": [], "abstract": "Vision-Language Models (VLMs) combine visual and textual understanding,\nrendering them well-suited for diverse tasks like generating image captions and\nanswering visual questions across various domains. However, these capabilities\nare built upon training on large amount of uncurated data crawled from the web.\nThe latter may include sensitive information that VLMs could memorize and leak,\nraising significant privacy concerns. In this paper, we assess whether these\nvulnerabilities exist, focusing on identity leakage. Our study leads to three\nkey findings: (i) VLMs leak identity information, even when the vision-language\nalignment and the fine-tuning use anonymized data; (ii) context has little\ninfluence on identity leakage; (iii) simple, widely used anonymization\ntechniques, like blurring, are not sufficient to address the problem. These\nfindings underscore the urgent need for robust privacy protection strategies\nwhen deploying VLMs. Ethical awareness and responsible development practices\nare essential to mitigate these risks.", "categories": "cs.CV", "created": "2024-08-02", "doi": null, "arxiv_id": "2408.01228"}
{"title": "HeteroMorpheus: Universal Control Based on Morphological Heterogeneity\n  Modeling", "authors": [], "abstract": "In the field of robotic control, designing individual controllers for each\nrobot leads to high computational costs. Universal control policies, applicable\nacross diverse robot morphologies, promise to mitigate this challenge.\nPredominantly, models based on Graph Neural Networks (GNN) and Transformers are\nemployed, owing to their effectiveness in capturing relational dynamics across\na robot's limbs. However, these models typically employ homogeneous graph\nstructures that overlook the functional diversity of different limbs. To bridge\nthis gap, we introduce HeteroMorpheus, a novel method based on heterogeneous\ngraph Transformer. This method uniquely addresses limb heterogeneity, fostering\nbetter representation of robot dynamics of various morphologies. Through\nextensive experiments we demonstrate the superiority of HeteroMorpheus against\nstate-of-the-art methods in the capability of policy generalization, including\nzero-shot generalization and sample-efficient transfer to unfamiliar robot\nmorphologies.", "categories": "cs.RO cs.LG", "created": "2024-08-02", "doi": null, "arxiv_id": "2408.01230"}
{"title": "WaveMamba: Spatial-Spectral Wavelet Mamba for Hyperspectral Image\n  Classification", "authors": [], "abstract": "Hyperspectral Imaging (HSI) has proven to be a powerful tool for capturing\ndetailed spectral and spatial information across diverse applications. Despite\nthe advancements in Deep Learning (DL) and Transformer architectures for HSI\nClassification (HSIC), challenges such as computational efficiency and the need\nfor extensive labeled data persist. This paper introduces WaveMamba, a novel\napproach that integrates wavelet transformation with the Spatial-Spectral Mamba\narchitecture to enhance HSIC. WaveMamba captures both local texture patterns\nand global contextual relationships in an end-to-end trainable model. The\nWavelet-based enhanced features are then processed through the state-space\narchitecture to model spatial-spectral relationships and temporal dependencies.\nThe experimental results indicate that WaveMamba surpasses existing models,\nachieving an accuracy improvement of 4.5\\% on the University of Houston dataset\nand a 2.0\\% increase on the Pavia University dataset. These findings validate\nits effectiveness in addressing the complex data interactions inherent in HSIs.", "categories": "cs.CV eess.IV", "created": "2024-08-02", "doi": null, "arxiv_id": "2408.01231"}
{"title": "CLIP4Sketch: Enhancing Sketch to Mugshot Matching through Dataset\n  Augmentation using Diffusion Models", "authors": [], "abstract": "Forensic sketch-to-mugshot matching is a challenging task in face\nrecognition, primarily hindered by the scarcity of annotated forensic sketches\nand the modality gap between sketches and photographs. To address this, we\npropose CLIP4Sketch, a novel approach that leverages diffusion models to\ngenerate a large and diverse set of sketch images, which helps in enhancing the\nperformance of face recognition systems in sketch-to-mugshot matching. Our\nmethod utilizes Denoising Diffusion Probabilistic Models (DDPMs) to generate\nsketches with explicit control over identity and style. We combine CLIP and\nAdaface embeddings of a reference mugshot, along with textual descriptions of\nstyle, as the conditions to the diffusion model. We demonstrate the efficacy of\nour approach by generating a comprehensive dataset of sketches corresponding to\nmugshots and training a face recognition model on our synthetic data. Our\nresults show significant improvements in sketch-to-mugshot matching accuracy\nover training on an existing, limited amount of real face sketch data,\nvalidating the potential of diffusion models in enhancing the performance of\nface recognition systems across modalities. We also compare our dataset with\ndatasets generated using GAN-based methods to show its superiority.", "categories": "cs.CV", "created": "2024-08-02", "doi": null, "arxiv_id": "2408.01233"}
{"title": "Entanglement Routing in Quantum Networks: A Comprehensive Survey", "authors": [], "abstract": "Entanglement routing in near-term quantum networks consists of choosing the\noptimal sequence of short-range entanglements to combine through swapping\noperations to establish end-to-end entanglement between two distant nodes.\nSimilar to traditional routing technologies, a quantum routing protocol uses\nnetwork information to choose the best paths to satisfy a set of end-to-end\nentanglement requests. However, in addition to network state information, a\nquantum routing protocol must also take into account the requested entanglement\nfidelity, the probabilistic nature of swapping operations, and the short\nlifetime of entangled states. In this work, we formulate a practical\nentanglement routing problem and analyze and categorize the main approaches to\naddress it, drawing comparisons to, and inspiration from, classical network\nrouting strategies where applicable. We classify and discuss the studied\nquantum routing schemes into reactive, proactive, opportunistic, and virtual\nrouting", "categories": "cs.ET cs.NI quant-ph", "created": "2024-08-02", "doi": null, "arxiv_id": "2408.01234"}
{"title": "Entropy conservative discretization of compressible Euler equations with\n  an arbitrary equation of state", "authors": [], "abstract": "This study proposes a novel spatial discretization procedure for the\ncompressible Euler equations which guarantees entropy conservation at a\ndiscrete level when an arbitrary equation of state is assumed. The proposed\nmethod, based on a locally-conservative discretization, guarantees also the\nspatial conservation of mass, momentum, and total energy and is kinetic\nenergy-preserving. In order to achieve the entropy-conservation property for an\narbitrary non-ideal gas, a general strategy is adopted based on the\nmanipulation of discrete balance equations through the imposition of global\nentropy conservation and the use of a summation by parts rule. The procedure,\nwhich is extended to an arbitrary order of accuracy, conducts to a general form\nof the internal-energy numerical flux which results in a nonlinear function of\nthermodynamic and dynamic variables and still admits the mass flux as a\nresidual degree of freedom. The effectiveness of the novel entropy-conservative\nformulation is demonstrated through numerical tests making use of some of the\nmost popular cubic equations of state.", "categories": "physics.flu-dyn cs.NA math.NA", "created": "2024-08-02", "doi": null, "arxiv_id": "2408.01235"}
{"title": "Tailoring Graph Neural Network-based Flow-guided Localization to\n  Individual Bloodstreams and Activities", "authors": [], "abstract": "Flow-guided localization using in-body nanodevices in the bloodstream is\nexpected to be beneficial for early disease detection, continuous monitoring of\nbiological conditions, and targeted treatment. The nanodevices face size and\npower constraints that produce erroneous raw data for localization purposes.\nOn-body anchors receive this data, and use it to derive the locations of\ndiagnostic events of interest. Different Machine Learning (ML) approaches have\nbeen recently proposed for this task, yet they are currently restricted to a\nreference bloodstream of a resting patient. As such, they are unable to deal\nwith the physical diversity of patients' bloodstreams and cannot provide\ncontinuous monitoring due to changes in individual patient's activities. Toward\naddressing these issues for the current State-of-the-Art (SotA) flow-guided\nlocalization approach based on Graph Neural Networks (GNNs), we propose a\npipeline for GNN adaptation based on individual physiological indicators\nincluding height, weight, and heart rate. Our results indicate that the\nproposed adaptions are beneficial in reconciling the individual differences\nbetween bloodstreams and activities.", "categories": "cs.LG cs.AI cs.ET cs.NI", "created": "2024-08-02", "doi": null, "arxiv_id": "2408.01239"}
{"title": "Automated Classification of Dry Bean Varieties Using XGBoost and SVM\n  Models", "authors": [], "abstract": "This paper presents a comparative study on the automated classification of\nseven different varieties of dry beans using machine learning models.\nLeveraging a dataset of 12,909 dry bean samples, reduced from an initial 13,611\nthrough outlier removal and feature extraction, we applied Principal Component\nAnalysis (PCA) for dimensionality reduction and trained two multiclass\nclassifiers: XGBoost and Support Vector Machine (SVM). The models were\nevaluated using nested cross-validation to ensure robust performance assessment\nand hyperparameter tuning. The XGBoost and SVM models achieved overall correct\nclassification rates of 94.00% and 94.39%, respectively. The results underscore\nthe efficacy of these machine learning approaches in agricultural applications,\nparticularly in enhancing the uniformity and efficiency of seed classification.\nThis study contributes to the growing body of work on precision agriculture,\ndemonstrating that automated systems can significantly support seed quality\ncontrol and crop yield optimization. Future work will explore incorporating\nmore diverse datasets and advanced algorithms to further improve classification\naccuracy.", "categories": "cs.LG", "created": "2024-08-02", "doi": null, "arxiv_id": "2408.01244"}
{"title": "CHTW-systems with resource-depended parameters. CHTW(R)-systems", "authors": [], "abstract": "In [1] the concept of CHTW-systems as a multidimensional representation of\nPetri nets was proposed based on the assumption of multidimensional\ndistribution of tokens (resources) in positions (branes) and, accordingly,\nmultidimensional representation of transitions and arcs. The extension of Petri\nnets was developed under the assumption of the stationarity of CHTW-system,\nwhen its parameters are constant during the system operation. We consider the\ncase when the main parameters of CHTW-system (threshold functions and rate\nfunctions) change in accordance with the values of the mark-functions\n(multidimensional resource) of some container branes of the same CHTW-system.\nThe modification of the basic CHTW-system was designated as a CHTW(R) system,\nin which (R) means a Resource control of the system parameters.", "categories": "cs.LO", "created": "2024-08-02", "doi": null, "arxiv_id": "2408.01245"}
{"title": "MapComp: A Secure View-based Collaborative Analytics Framework for\n  Join-Group-Aggregation", "authors": [], "abstract": "This paper introduces MapComp, a novel view-based framework to facilitate\njoin-group-aggregation (JGA) queries for collaborative analytics. Through\nspecially crafted materialized view for join and novel design of\ngroup-aggregation (GA) protocols, MapComp removes duplicated join workload and\nexpedites subsequent GA, improving the efficiency of JGA query execution. To\nsupport continuous data updates, our materialized view offers\npayload-independence feature and brings in significant efficiency improvement\nof view refreshing with free MPC overhead. This feature also allows further\nacceleration for GA, where we devised multiple novel protocols that outperform\nprior works. Notably, our work represents the first endeavor to expedite secure\ncollaborative JGA queries using materialized views. Our experiments demonstrate\na significant advantage of MapComp, achieving up to a 2189.9x efficiency\nimprovement compared to the non-view based baseline when executing queries\neight times.", "categories": "cs.CR", "created": "2024-08-02", "doi": null, "arxiv_id": "2408.01246"}
{"title": "Deep progressive reinforcement learning-based flexible resource\n  scheduling framework for IRS and UAV-assisted MEC system", "authors": [], "abstract": "The intelligent reflection surface (IRS) and unmanned aerial vehicle\n(UAV)-assisted mobile edge computing (MEC) system is widely used in temporary\nand emergency scenarios. Our goal is to minimize the energy consumption of the\nMEC system by jointly optimizing UAV locations, IRS phase shift, task\noffloading, and resource allocation with a variable number of UAVs. To this\nend, we propose a Flexible REsource Scheduling (FRES) framework by employing a\nnovel deep progressive reinforcement learning which includes the following\ninnovations: Firstly, a novel multi-task agent is presented to deal with the\nmixed integer nonlinear programming (MINLP) problem. The multi-task agent has\ntwo output heads designed for different tasks, in which a classified head is\nemployed to make offloading decisions with integer variables while a fitting\nhead is applied to solve resource allocation with continuous variables.\nSecondly, a progressive scheduler is introduced to adapt the agent to the\nvarying number of UAVs by progressively adjusting a part of neurons in the\nagent. This structure can naturally accumulate experiences and be immune to\ncatastrophic forgetting. Finally, a light taboo search (LTS) is introduced to\nenhance the global search of the FRES. The numerical results demonstrate the\nsuperiority of the FRES framework which can make real-time and optimal resource\nscheduling even in dynamic MEC systems.", "categories": "cs.LG cs.AI", "created": "2024-08-02", "doi": "10.1109/TNNLS.2023.3341067", "arxiv_id": "2408.01248"}
{"title": "NeRFoot: Robot-Footprint Estimation for Image-Based Visual Servoing", "authors": [], "abstract": "This paper investigates the utility of Neural Radiance Fields (NeRF) models\nin extending the regions of operation of a mobile robot, controlled by\nImage-Based Visual Servoing (IBVS) via static CCTV cameras. Using NeRF as a\n3D-representation prior, the robot's footprint may be extrapolated\ngeometrically and used to train a CNN-based network to extract it online from\nthe robot's appearance alone. The resulting footprint results in a tighter\nbound than a robot-wide bounding box, allowing the robot's controller to\nprescribe more optimal trajectories and expand its safe operational floor area.", "categories": "cs.RO", "created": "2024-08-02", "doi": null, "arxiv_id": "2408.01251"}
{"title": "Metareasoning in uncertain environments: a meta-BAMDP framework", "authors": [], "abstract": "In decision-making scenarios, \\textit{reasoning} can be viewed as an\nalgorithm $P$ that makes a choice of an action $a^* \\in \\mathcal{A}$, aiming to\noptimize some outcome such as maximizing the value function of a Markov\ndecision process (MDP). However, executing $P$ itself may bear some costs\n(time, energy, limited capacity, etc.) and needs to be considered alongside\nexplicit utility obtained by making the choice in the underlying decision\nproblem. Such costs need to be taken into account in order to accurately model\nhuman behavior, as well as optimizing AI planning, as all physical systems are\nbound to face resource constraints. Finding the right $P$ can itself be framed\nas an optimization problem over the space of reasoning processes $P$, generally\nreferred to as \\textit{metareasoning}. Conventionally, human metareasoning\nmodels assume that the agent knows the transition and reward distributions of\nthe underlying MDP. This paper generalizes such models by proposing a meta\nBayes-Adaptive MDP (meta-BAMDP) framework to handle metareasoning in\nenvironments with unknown reward/transition distributions, which encompasses a\nfar larger and more realistic set of planning problems that humans and AI\nsystems face. As a first step, we apply the framework to two-armed Bernoulli\nbandit (TABB) tasks, which have often been used to study human decision making.\nOwing to the meta problem's complexity, our solutions are necessarily\napproximate, but nevertheless robust within a range of assumptions that are\narguably realistic for human decision-making scenarios. These results offer a\nnormative framework for understanding human exploration under cognitive\nconstraints. This integration of Bayesian adaptive strategies with\nmetareasoning enriches both the theoretical landscape of decision-making\nresearch and practical applications in designing AI systems that plan under\nuncertainty and resource constraints.", "categories": "cs.AI cs.SY eess.SY q-bio.NC", "created": "2024-08-02", "doi": null, "arxiv_id": "2408.01253"}
{"title": "TrIM: Triangular Input Movement Systolic Array for Convolutional Neural\n  Networks -- Part I: Dataflow and Analytical Modelling", "authors": [], "abstract": "In order to follow the ever-growing computational complexity and data\nintensity of state-of-the-art AI models, new computing paradigms are being\nproposed. These paradigms aim at achieving high energy efficiency, by\nmitigating the Von Neumann bottleneck that relates to the energy cost of moving\ndata between the processing cores and the memory. Convolutional Neural Networks\n(CNNs) are particularly susceptible to this bottleneck, given the massive data\nthey have to manage. Systolic Arrays (SAs) are promising architectures to\nmitigate the data transmission cost, thanks to high data utilization carried\nout by an array of Processing Elements (PEs). These PEs continuously exchange\nand process data locally based on specific dataflows (like weight stationary\nand row stationary), in turn reducing the number of memory accesses to the main\nmemory. The hardware specialization of SAs can meet different workloads,\nranging from matrix multiplications to multi-dimensional convolutions. In this\npaper, we propose TrIM: a novel dataflow for SAs based on a Triangular Input\nMovement and compatible with CNN computing. When compared to state-of-the-art\nSA dataflows, like weight stationary and row stationary, the high data\nutilization offered by TrIM guarantees ~10x less memory access. Furthermore,\nconsidering that PEs continuously overlap multiplications and accumulations,\nTrIM achieves high throughput (up to 81.8% higher than row stationary), other\nthan requiring a limited number of registers (up to 15.6x fewer registers than\nrow stationary).", "categories": "cs.AI cs.AR", "created": "2024-08-02", "doi": null, "arxiv_id": "2408.01254"}
{"title": "SeCritMass: Threshold Secret Petitions", "authors": [], "abstract": "We introduce the notion of an $n$-threshold secret petition, in which users\nadd encrypted signatures to a petition, and the signatures are decrypted if and\nonly if at least $n$ signatures have been gathered. This solves the\ncoordination problem in which users wish to sign a petition or commit to a\ncause, but do not want to be identified as having signed it before enough\nothers have signed it too. We present an implementation of such a petition\nbased on the ElGamal cryptosystem. Applications include reporting misconduct in\nsituations were complainants hesitate to come forward alone, such as in\nallegations of sexual harassment or police brutality.", "categories": "cs.CR math.NT", "created": "2024-08-02", "doi": null, "arxiv_id": "2408.01255"}
{"title": "Detection and Characterization of Coordinated Online Behavior: A Survey", "authors": [], "abstract": "Coordination is a fundamental aspect of life. The advent of social media has\nmade it integral also to online human interactions, such as those that\ncharacterize thriving online communities and social movements. At the same\ntime, coordination is also core to effective disinformation, manipulation, and\nhate campaigns. This survey collects, categorizes, and critically discusses the\nbody of work produced as a result of the growing interest on coordinated online\nbehavior. We reconcile industry and academic definitions, propose a\ncomprehensive framework to study coordinated online behavior, and review and\ncritically discuss the existing detection and characterization methods. Our\nanalysis identifies open challenges and promising directions of research,\nserving as a guide for scholars, practitioners, and policymakers in\nunderstanding and addressing the complexities inherent to online coordination.", "categories": "cs.SI cs.AI cs.CY cs.HC cs.LG", "created": "2024-08-02", "doi": null, "arxiv_id": "2408.01257"}
{"title": "Jacta: A Versatile Planner for Learning Dexterous and Whole-body\n  Manipulation", "authors": [], "abstract": "Robotic manipulation is challenging due to discontinuous dynamics, as well as\nhigh-dimensional state and action spaces. Data-driven approaches that succeed\nin manipulation tasks require large amounts of data and expert demonstrations,\ntypically from humans. Existing manipulation planners are restricted to\nspecific systems and often depend on specialized algorithms for using\ndemonstration. Therefore, we introduce a flexible motion planner tailored to\ndexterous and whole-body manipulation tasks. Our planner creates readily usable\ndemonstrations for reinforcement learning algorithms, eliminating the need for\nadditional training pipeline complexities. With this approach, we can\nefficiently learn policies for complex manipulation tasks, where traditional\nreinforcement learning alone only makes little progress. Furthermore, we\ndemonstrate that learned policies are transferable to real robotic systems for\nsolving complex dexterous manipulation tasks.", "categories": "cs.RO", "created": "2024-08-02", "doi": null, "arxiv_id": "2408.01258"}
{"title": "RAGEval: Scenario Specific RAG Evaluation Dataset Generation Framework", "authors": [], "abstract": "Retrieval-Augmented Generation (RAG) systems have demonstrated their\nadvantages in alleviating the hallucination of Large Language Models (LLMs).\nExisting RAG benchmarks mainly focus on evaluating whether LLMs can correctly\nanswer the general knowledge. However, they are unable to evaluate the\neffectiveness of the RAG system in dealing with the data from different\nvertical domains. This paper introduces RAGEval, a framework for automatically\ngenerating evaluation datasets to evaluate the knowledge usage ability of\ndifferent LLMs in different scenarios. Specifically, RAGEval summarizes a\nschema from seed documents, applies the configurations to generate diverse\ndocuments, and constructs question-answering pairs according to both articles\nand configurations. We propose three novel metrics, Completeness,\nHallucination, and Irrelevance, to carefully evaluate the responses generated\nby LLMs. By benchmarking RAG models in vertical domains, RAGEval has the\nability to better evaluate the knowledge usage ability of LLMs, which avoids\nthe confusion regarding the source of knowledge in answering question in\nexisting QA datasets--whether it comes from parameterized memory or retrieval.", "categories": "cs.CL cs.IR", "created": "2024-08-02", "doi": null, "arxiv_id": "2408.01262"}
{"title": "The virtual CAT: A tool for algorithmic thinking assessment in Swiss\n  compulsory education", "authors": [], "abstract": "In today's digital era, holding algorithmic thinking (AT) skills is crucial,\nnot only in computer science-related fields. These abilities enable individuals\nto break down complex problems into more manageable steps and create a sequence\nof actions to solve them. To address the increasing demand for AT assessments\nin educational settings and the limitations of current methods, this paper\nintroduces the virtual Cross Array Task (CAT), a digital adaptation of an\nunplugged assessment activity designed to evaluate algorithmic skills in Swiss\ncompulsory education. This tool offers scalable and automated assessment,\nreducing human involvement and mitigating potential data collection errors. The\nplatform features gesture-based and visual block-based programming interfaces,\nensuring its usability for diverse learners, further supported by multilingual\ncapabilities. To evaluate the virtual CAT platform, we conducted a pilot\nevaluation in Switzerland involving a heterogeneous group of students. The\nfindings show the platform's usability, proficiency and suitability for\nassessing AT skills among students of diverse ages, development stages, and\neducational backgrounds, as well as the feasibility of large-scale data\ncollection.", "categories": "cs.HC cs.AI cs.CY", "created": "2024-08-02", "doi": null, "arxiv_id": "2408.01263"}
{"title": "A General Framework to Boost 3D GS Initialization for Text-to-3D\n  Generation by Lexical Richness", "authors": [], "abstract": "Text-to-3D content creation has recently received much attention, especially\nwith the prevalence of 3D Gaussians Splatting. In general, GS-based methods\ncomprise two key stages: initialization and rendering optimization. To achieve\ninitialization, existing works directly apply random sphere initialization or\n3D diffusion models, e.g., Point-E, to derive the initial shapes. However, such\nstrategies suffer from two critical yet challenging problems: 1) the final\nshapes are still similar to the initial ones even after training; 2) shapes can\nbe produced only from simple texts, e.g., \"a dog\", not for lexically richer\ntexts, e.g., \"a dog is sitting on the top of the airplane\". To address these\nproblems, this paper proposes a novel general framework to boost the 3D GS\nInitialization for text-to-3D generation upon the lexical richness. Our key\nidea is to aggregate 3D Gaussians into spatially uniform voxels to represent\ncomplex shapes while enabling the spatial interaction among the 3D Gaussians\nand semantic interaction between Gaussians and texts. Specifically, we first\nconstruct a voxelized representation, where each voxel holds a 3D Gaussian with\nits position, scale, and rotation fixed while setting opacity as the sole\nfactor to determine a position's occupancy. We then design an initialization\nnetwork mainly consisting of two novel components: 1) Global Information\nPerception (GIP) block and 2) Gaussians-Text Fusion (GTF) block. Such a design\nenables each 3D Gaussian to assimilate the spatial information from other areas\nand semantic information from texts. Extensive experiments show the superiority\nof our framework of high-quality 3D GS initialization against the existing\nmethods, e.g., Shap-E, by taking lexically simple, medium, and hard texts.\nAlso, our framework can be seamlessly plugged into SoTA training frameworks,\ne.g., LucidDreamer, for semantically consistent text-to-3D generation.", "categories": "cs.CV", "created": "2024-08-02", "doi": null, "arxiv_id": "2408.01269"}
{"title": "HRFT: Mining High-Frequency Risk Factor Collections End-to-End via\n  Transformer", "authors": [], "abstract": "In quantitative trading, it is common to find patterns in short term volatile\ntrends of the market. These patterns are known as High Frequency (HF) risk\nfactors, serving as key indicators of future stock price volatility.\nTraditionally, these risk factors were generated by financial models relying\nheavily on domain-specific knowledge manually added rather than extensive\nmarket data. Inspired by symbolic regression (SR), which infers mathematical\nlaws from data, we treat the extraction of formulaic risk factors from\nhigh-frequency trading (HFT) market data as an SR task. In this paper, we\nchallenge the manual construction of risk factors and propose an end-to-end\nmethodology, Intraday Risk Factor Transformer (IRFT), to directly predict\ncomplete formulaic factors, including constants. We use a hybrid\nsymbolic-numeric vocabulary where symbolic tokens represent operators/stock\nfeatures and numeric tokens represent constants. We train a Transformer model\non the HFT dataset to generate complete formulaic HF risk factors without\nrelying on a predefined skeleton of operators. It determines the general shape\nof the stock volatility law up to a choice of constants. We refine the\npredicted constants (a, b) using the Broyden Fletcher Goldfarb Shanno algorithm\n(BFGS) to mitigate non-linear issues. Compared to the 10 approaches in SRBench,\na living benchmark for SR, IRFT gains a 30% excess investment return on the\nHS300 and SP500 datasets, with inference times orders of magnitude faster than\ntheirs in HF risk factor mining tasks.", "categories": "cs.CE", "created": "2024-08-02", "doi": null, "arxiv_id": "2408.01271"}
{"title": "Does This Have a Particular Meaning? Interactive Pattern Explanation for\n  Network Visualizations", "authors": [], "abstract": "This paper presents an interactive technique to explain visual patterns in\nnetwork visualizations to analysts who do not understand these visualizations\nand who are learning to read them. Learning a visualization requires mastering\nits visual grammar and decoding information presented through visual marks,\ngraphical encodings, and spatial configurations. To help people learn network\nvisualization designs and extract meaningful information, we introduce the\nconcept of interactive pattern explanation that allows viewers to select an\narbitrary area in a visualization, then automatically mines the underlying data\npatterns, and explains both visual and data patterns present in the viewer's\nselection. In a qualitative and a quantitative user study with a total of 32\nparticipants, we compare interactive pattern explanations to textual-only and\nvisual-only (cheatsheets) explanations. Our results show that interactive\nexplanations increase learning of i) unfamiliar visualizations, ii) patterns in\nnetwork science, and iii) the respective network terminology.", "categories": "cs.HC", "created": "2024-08-02", "doi": null, "arxiv_id": "2408.01272"}
{"title": "Certified Robust Invariant Polytope Training in Neural Controlled ODEs", "authors": [], "abstract": "We consider a nonlinear control system modeled as an ordinary differential\nequation subject to disturbance, with a state feedback controller parameterized\nas a feedforward neural network. We propose a framework for training\ncontrollers with certified robust forward invariant polytopes, where any\ntrajectory initialized inside the polytope remains within the polytope,\nregardless of the disturbance. First, we parameterize a family of lifted\ncontrol systems in a higher dimensional space, where the original neural\ncontrolled system evolves on an invariant subspace of each lifted system. We\nuse interval analysis and neural network verifiers to further construct a\nfamily of lifted embedding systems, carefully capturing the knowledge of this\ninvariant subspace. If the vector field of any lifted embedding system\nsatisfies a sign constraint at a single point, then a certain convex polytope\nof the original system is robustly forward invariant. Treating the neural\nnetwork controller and the lifted system parameters as variables, we propose an\nalgorithm to train controllers with certified forward invariant polytopes in\nthe closed-loop control system. Through two examples, we demonstrate how the\nsimplicity of the sign constraint allows our approach to scale with system\ndimension to over $50$ states, and outperform state-of-the-art Lyapunov-based\nsampling approaches in runtime.", "categories": "cs.LG cs.SY eess.SY math.OC", "created": "2024-08-02", "doi": null, "arxiv_id": "2408.01273"}
{"title": "Wave-Mamba: Wavelet State Space Model for Ultra-High-Definition\n  Low-Light Image Enhancement", "authors": [], "abstract": "Ultra-high-definition (UHD) technology has attracted widespread attention due\nto its exceptional visual quality, but it also poses new challenges for\nlow-light image enhancement (LLIE) techniques. UHD images inherently possess\nhigh computational complexity, leading existing UHD LLIE methods to employ\nhigh-magnification downsampling to reduce computational costs, which in turn\nresults in information loss. The wavelet transform not only allows downsampling\nwithout loss of information, but also separates the image content from the\nnoise. It enables state space models (SSMs) to avoid being affected by noise\nwhen modeling long sequences, thus making full use of the long-sequence\nmodeling capability of SSMs. On this basis, we propose Wave-Mamba, a novel\napproach based on two pivotal insights derived from the wavelet domain: 1) most\nof the content information of an image exists in the low-frequency component,\nless in the high-frequency component. 2) The high-frequency component exerts a\nminimal influence on the outcomes of low-light enhancement. Specifically, to\nefficiently model global content information on UHD images, we proposed a\nlow-frequency state space block (LFSSBlock) by improving SSMs to focus on\nrestoring the information of low-frequency sub-bands. Moreover, we propose a\nhigh-frequency enhance block (HFEBlock) for high-frequency sub-band\ninformation, which uses the enhanced low-frequency information to correct the\nhigh-frequency information and effectively restore the correct high-frequency\ndetails. Through comprehensive evaluation, our method has demonstrated superior\nperformance, significantly outshining current leading techniques while\nmaintaining a more streamlined architecture. The code is available at\nhttps://github.com/AlexZou14/Wave-Mamba.", "categories": "cs.CV", "created": "2024-08-02", "doi": null, "arxiv_id": "2408.01276"}
{"title": "A Tiny Supervised ODL Core with Auto Data Pruning for Human Activity\n  Recognition", "authors": [], "abstract": "In this paper, we introduce a low-cost and low-power tiny supervised\non-device learning (ODL) core that can address the distributional shift of\ninput data for human activity recognition. Although ODL for resource-limited\nedge devices has been studied recently, how exactly to provide the training\nlabels to these devices at runtime remains an open-issue. To address this\nproblem, we propose to combine an automatic data pruning with supervised ODL to\nreduce the number queries needed to acquire predicted labels from a nearby\nteacher device and thus save power consumption during model retraining. The\ndata pruning threshold is automatically tuned, eliminating a manual threshold\ntuning. As a tinyML solution at a few mW for the human activity recognition, we\ndesign a supervised ODL core that supports our automatic data pruning using a\n45nm CMOS process technology. We show that the required memory size for the\ncore is smaller than the same-shaped multilayer perceptron (MLP) and the power\nconsumption is only 3.39mW. Experiments using a human activity recognition\ndataset show that the proposed automatic data pruning reduces the communication\nvolume by 55.7% and power consumption accordingly with only 0.9% accuracy loss.", "categories": "cs.LG cs.AR", "created": "2024-08-02", "doi": null, "arxiv_id": "2408.01283"}
{"title": "Out-Of-Distribution Detection for Audio-visual Generalized Zero-Shot\n  Learning: A General Framework", "authors": [], "abstract": "Generalized Zero-Shot Learning (GZSL) is a challenging task requiring\naccurate classification of both seen and unseen classes. Within this domain,\nAudio-visual GZSL emerges as an extremely exciting yet difficult task, given\nthe inclusion of both visual and acoustic features as multi-modal inputs.\nExisting efforts in this field mostly utilize either embedding-based or\ngenerative-based methods. However, generative training is difficult and\nunstable, while embedding-based methods often encounter domain shift problem.\nThus, we find it promising to integrate both methods into a unified framework\nto leverage their advantages while mitigating their respective disadvantages.\nOur study introduces a general framework employing out-of-distribution (OOD)\ndetection, aiming to harness the strengths of both approaches. We first employ\ngenerative adversarial networks to synthesize unseen features, enabling the\ntraining of an OOD detector alongside classifiers for seen and unseen classes.\nThis detector determines whether a test feature belongs to seen or unseen\nclasses, followed by classification utilizing separate classifiers for each\nfeature type. We test our framework on three popular audio-visual datasets and\nobserve a significant improvement comparing to existing state-of-the-art works.\nCodes can be found in https://github.com/liuyuan-wen/AV-OOD-GZSL.", "categories": "cs.MM cs.CV cs.SD eess.AS eess.IV", "created": "2024-08-02", "doi": null, "arxiv_id": "2408.01284"}
{"title": "The Mismeasure of Man and Models: Evaluating Allocational Harms in Large\n  Language Models", "authors": [], "abstract": "Large language models (LLMs) are now being considered and even deployed for\napplications that support high-stakes decision-making, such as recruitment and\nclinical decisions. While several methods have been proposed for measuring\nbias, there remains a gap between predictions, which are what the proposed\nmethods consider, and how they are used to make decisions. In this work, we\nintroduce Rank-Allocational-Based Bias Index (RABBI), a model-agnostic bias\nmeasure that assesses potential allocational harms arising from biases in LLM\npredictions. We compare RABBI and current bias metrics on two allocation\ndecision tasks. We evaluate their predictive validity across ten LLMs and\nutility for model selection. Our results reveal that commonly-used bias metrics\nbased on average performance gap and distribution distance fail to reliably\ncapture group disparities in allocation outcomes, whereas RABBI exhibits a\nstrong correlation with allocation disparities. Our work highlights the need to\naccount for how models are used in contexts with limited resource constraints.", "categories": "cs.CL cs.CY", "created": "2024-08-02", "doi": null, "arxiv_id": "2408.01285"}
{"title": "Improving Energy Efficiency in Federated Learning Through the\n  Optimization of Communication Resources Scheduling of Wireless IoT Networks", "authors": [], "abstract": "Federated Learning (FL) allows devices to train a global machine learning\nmodel without sharing data. In the context of wireless networks, the inherently\nunreliable nature of the transmission channel introduces delays and errors that\ncompromise the regularity of updating the global model. Furthermore, limited\nresources and energy consumption of devices are factors that affect FL\nperformance. Therefore, this work proposes a new FL algorithm called FL-E2WS\nthat considers both the requirements of federated training and a wireless\nnetwork within the scope of the Internet of Things. To reduce the energy cost\nof devices, FL-E2WS schedules communication resources to allocate the ideal\nbandwidth and power for the transmission of models under certain device\nselection and uplink resource block allocation, meeting delay requirements,\npower consumption, and packet error rate. The simulation results demonstrate\nthat FL-E2WS reduces energy consumption by up to 70.12% and enhances the\naccuracy of the global model by up to 10.21% compared to the FL algorithms that\nlacks transmission channel knowledge. Additionally, when compared to FL\nversions that scale communication resources, FL-E2WS achieves up to a 38.61%\nreduction in energy consumption and improves the accuracy of the global model\nby up to 1.61%.", "categories": "cs.NI", "created": "2024-08-02", "doi": null, "arxiv_id": "2408.01286"}
{"title": "Deep Learning based Visually Rich Document Content Understanding: A\n  Survey", "authors": [], "abstract": "Visually Rich Documents (VRDs) are essential in academia, finance, medical\nfields, and marketing due to their multimodal information content. Traditional\nmethods for extracting information from VRDs depend on expert knowledge and\nmanual labor, making them costly and inefficient. The advent of deep learning\nhas revolutionized this process, introducing models that leverage multimodal\ninformation vision, text, and layout along with pretraining tasks to develop\ncomprehensive document representations. These models have achieved\nstate-of-the-art performance across various downstream tasks, significantly\nenhancing the efficiency and accuracy of information extraction from VRDs. In\nresponse to the growing demands and rapid developments in Visually Rich\nDocument Understanding (VRDU), this paper provides a comprehensive review of\ndeep learning-based VRDU frameworks. We systematically survey and analyze\nexisting methods and benchmark datasets, categorizing them based on adopted\nstrategies and downstream tasks. Furthermore, we compare different techniques\nused in VRDU models, focusing on feature representation and fusion, model\narchitecture, and pretraining methods, while highlighting their strengths,\nlimitations, and appropriate scenarios. Finally, we identify emerging trends\nand challenges in VRDU, offering insights into future research directions and\npractical applications. This survey aims to provide a thorough understanding of\nVRDU advancements, benefiting both academic and industrial sectors.", "categories": "cs.CL cs.CV", "created": "2024-08-02", "doi": null, "arxiv_id": "2408.01287"}
{"title": "TexGen: Text-Guided 3D Texture Generation with Multi-view Sampling and\n  Resampling", "authors": [], "abstract": "Given a 3D mesh, we aim to synthesize 3D textures that correspond to\narbitrary textual descriptions. Current methods for generating and assembling\ntextures from sampled views often result in prominent seams or excessive\nsmoothing. To tackle these issues, we present TexGen, a novel multi-view\nsampling and resampling framework for texture generation leveraging a\npre-trained text-to-image diffusion model. For view consistent sampling, first\nof all we maintain a texture map in RGB space that is parameterized by the\ndenoising step and updated after each sampling step of the diffusion model to\nprogressively reduce the view discrepancy. An attention-guided multi-view\nsampling strategy is exploited to broadcast the appearance information across\nviews. To preserve texture details, we develop a noise resampling technique\nthat aids in the estimation of noise, generating inputs for subsequent\ndenoising steps, as directed by the text prompt and current texture map.\nThrough an extensive amount of qualitative and quantitative evaluations, we\ndemonstrate that our proposed method produces significantly better texture\nquality for diverse 3D objects with a high degree of view consistency and rich\nappearance details, outperforming current state-of-the-art methods.\nFurthermore, our proposed texture generation technique can also be applied to\ntexture editing while preserving the original identity. More experimental\nresults are available at https://dong-huo.github.io/TexGen/", "categories": "cs.CV", "created": "2024-08-02", "doi": null, "arxiv_id": "2408.01291"}
{"title": "3DPX: Progressive 2D-to-3D Oral Image Reconstruction with Hybrid MLP-CNN\n  Networks", "authors": [], "abstract": "Panoramic X-ray (PX) is a prevalent modality in dental practice for its wide\navailability and low cost. However, as a 2D projection image, PX does not\ncontain 3D anatomical information, and therefore has limited use in dental\napplications that can benefit from 3D information, e.g., tooth angular\nmisa-lignment detection and classification. Reconstructing 3D structures\ndirectly from 2D PX has recently been explored to address limitations with\nexisting methods primarily reliant on Convolutional Neural Networks (CNNs) for\ndirect 2D-to-3D mapping. These methods, however, are unable to correctly infer\ndepth-axis spatial information. In addition, they are limited by the in-trinsic\nlocality of convolution operations, as the convolution kernels only capture the\ninformation of immediate neighborhood pixels. In this study, we propose a\nprogressive hybrid Multilayer Perceptron (MLP)-CNN pyra-mid network (3DPX) for\n2D-to-3D oral PX reconstruction. We introduce a progressive reconstruction\nstrategy, where 3D images are progressively re-constructed in the 3DPX with\nguidance imposed on the intermediate recon-struction result at each pyramid\nlevel. Further, motivated by the recent ad-vancement of MLPs that show promise\nin capturing fine-grained long-range dependency, our 3DPX integrates MLPs and\nCNNs to improve the semantic understanding during reconstruction. Extensive\nexperiments on two large datasets involving 464 studies demonstrate that our\n3DPX outperforms state-of-the-art 2D-to-3D oral reconstruction methods,\nincluding standalone MLP and transformers, in reconstruction quality, and also\nim-proves the performance of downstream angular misalignment classification\ntasks.", "categories": "eess.IV cs.AI cs.CV", "created": "2024-08-02", "doi": null, "arxiv_id": "2408.01292"}
{"title": "Underwater Object Detection Enhancement via Channel Stabilization", "authors": [], "abstract": "The complex marine environment exacerbates the challenges of object detection\nmanifold. Marine trash endangers the aquatic ecosystem, presenting a persistent\nchallenge. Accurate detection of marine deposits is crucial for mitigating this\nharm. Our work addresses underwater object detection by enhancing image quality\nand evaluating detection methods. We use Detectron2's backbone with various\nbase models and configurations for this task.\n  We propose a novel channel stabilization technique alongside a simplified\nimage enhancement model to reduce haze and color cast in training images,\nimproving multi-scale object detection. Following image processing, we test\ndifferent Detectron2 backbones for optimal detection accuracy. Additionally, we\napply a sharpening filter with augmentation techniques to highlight object\nprofiles for easier recognition.\n  Results are demonstrated on the TrashCan Dataset, both instance and material\nversions. The best-performing backbone method incorporates our channel\nstabilization and augmentation techniques. We also compare our Detectron2\ndetection results with the Deformable Transformer. In the instance version of\nTrashCan 1.0, our method achieves a 9.53% absolute increase in average\nprecision for small objects and a 7% absolute gain in bounding box detection\ncompared to the baseline. The code will be available on Code:\nhttps://github.com/aliman80/Underwater-\nObject-Detection-via-Channel-Stablization", "categories": "cs.CV", "created": "2024-08-02", "doi": null, "arxiv_id": "2408.01293"}
{"title": "Optimal Mixed Integer Linear Optimization Trained Multivariate\n  Classification Trees", "authors": [], "abstract": "Multivariate decision trees are powerful machine learning tools for\nclassification and regression that attract many researchers and industry\nprofessionals. An optimal binary tree has two types of vertices, (i) branching\nvertices which have exactly two children and where datapoints are assessed on a\nset of discrete features and (ii) leaf vertices at which datapoints are given a\nprediction, and can be obtained by solving a biobjective optimization problem\nthat seeks to (i) maximize the number of correctly classified datapoints and\n(ii) minimize the number of branching vertices. Branching vertices are linear\ncombinations of training features and therefore can be thought of as\nhyperplanes. In this paper, we propose two cut-based mixed integer linear\noptimization (MILO) formulations for designing optimal binary classification\ntrees (leaf vertices assign discrete classes). Our models leverage on-the-fly\nidentification of minimal infeasible subsystems (MISs) from which we derive\ncutting planes that hold the form of packing constraints. We show theoretical\nimprovements on the strongest flow-based MILO formulation currently in the\nliterature and conduct experiments on publicly available datasets to show our\nmodels' ability to scale, strength against traditional branch and bound\napproaches, and robustness in out-of-sample test performance. Our code and data\nare available on GitHub.", "categories": "cs.LG cs.DM math.CO", "created": "2024-08-02", "doi": null, "arxiv_id": "2408.01297"}
{"title": "Assessing Robustness of Machine Learning Models using Covariate\n  Perturbations", "authors": [], "abstract": "As machine learning models become increasingly prevalent in critical\ndecision-making models and systems in fields like finance, healthcare, etc.,\nensuring their robustness against adversarial attacks and changes in the input\ndata is paramount, especially in cases where models potentially overfit. This\npaper proposes a comprehensive framework for assessing the robustness of\nmachine learning models through covariate perturbation techniques. We explore\nvarious perturbation strategies to assess robustness and examine their impact\non model predictions, including separate strategies for numeric and non-numeric\nvariables, summaries of perturbations to assess and compare model robustness\nacross different scenarios, and local robustness diagnosis to identify any\nregions in the data where a model is particularly unstable. Through empirical\nstudies on real world dataset, we demonstrate the effectiveness of our approach\nin comparing robustness across models, identifying the instabilities in the\nmodel, and enhancing model robustness.", "categories": "stat.ML cs.LG", "created": "2024-08-02", "doi": null, "arxiv_id": "2408.01300"}
{"title": "A Decision-driven Methodology for Designing Uncertainty-aware AI\n  Self-Assessment", "authors": [], "abstract": "Artificial intelligence (AI) has revolutionized decision-making processes and\nsystems throughout society and, in particular, has emerged as a significant\ntechnology in high-impact scenarios of national interest. Yet, despite AI's\nimpressive predictive capabilities in controlled settings, it still suffers\nfrom a range of practical setbacks preventing its widespread use in various\ncritical scenarios. In particular, it is generally unclear if a given AI\nsystem's predictions can be trusted by decision-makers in downstream\napplications. To address the need for more transparent, robust, and trustworthy\nAI systems, a suite of tools has been developed to quantify the uncertainty of\nAI predictions and, more generally, enable AI to \"self-assess\" the reliability\nof its predictions. In this manuscript, we categorize methods for AI\nself-assessment along several key dimensions and provide guidelines for\nselecting and designing the appropriate method for a practitioner's needs. In\nparticular, we focus on uncertainty estimation techniques that consider the\nimpact of self-assessment on the choices made by downstream decision-makers and\non the resulting costs and benefits of decision outcomes. To demonstrate the\nutility of our methodology for self-assessment design, we illustrate its use\nfor two realistic national-interest scenarios. This manuscript is a practical\nguide for machine learning engineers and AI system users to select the ideal\nself-assessment techniques for each problem.", "categories": "stat.ML cs.AI cs.LG", "created": "2024-08-02", "doi": null, "arxiv_id": "2408.01301"}
{"title": "A Systematic Mapping Study on SDN Controllers for Enhancing Security in\n  IoT Networks", "authors": [], "abstract": "Context: The increase in Internet of Things (IoT) devices gives rise to an\nincrease in deceptive manipulations by malicious actors. These actors should be\nprevented from targeting the IoT networks. Cybersecurity threats have evolved\nand become dynamically sophisticated, such that they could exploit any\nvulnerability found in IoT networks. However, with the introduction of the\nSoftware Defined Network (SDN) in the IoT networks as the central monitoring\nunit, IoT networks are less vulnerable and less prone to threats. %Although,\nthe SDN itself is vulnerable to several threats.\n  Objective: To present a comprehensive and unbiased overview of the\nstate-of-the-art on IoT networks security enhancement using SDN controllers.\n  Method: We review the current body of knowledge on enhancing the security of\nIoT networks using SDN with a Systematic Mapping Study (SMS) following the\nestablished guidelines.\n  Results: The SMS result comprises 33 primary studies analyzed against four\nmajor research questions. The SMS highlights current research trends and\nidentifies gaps in the SDN-IoT network security.\n  Conclusion: We conclude that the SDN controller architecture commonly used\nfor securing IoT networks is the centralized controller architecture. However,\nthis architecture is not without its limitations. Additionally, the predominant\ntechnique utilized for risk mitigation is machine learning.", "categories": "cs.CR cs.NI cs.SE", "created": "2024-08-02", "doi": null, "arxiv_id": "2408.01303"}
{"title": "Analyzing Quantum Circuit Depth Reduction with Ancilla Qubits in MCX\n  Gates", "authors": [], "abstract": "This paper aims to give readers a high-level overview of the different MCX\ndepth reduction techniques that utilize ancilla qubits. We also exhibit a brief\nanalysis of how they would perform under different quantum topological\nsettings. The techniques examined are recursion and v-chain, as they are the\nmost commonly used techniques in the most popular quantum computing libraries,\nQiskit. The target audience of this paper is people who do not have intricate\nmathematical or physics knowledge related to quantum computing.", "categories": "quant-ph cs.ET", "created": "2024-08-02", "doi": null, "arxiv_id": "2408.01304"}
{"title": "Reconsidering Token Embeddings with the Definitions for Pre-trained\n  Language Models", "authors": [], "abstract": "Learning token embeddings based on token co-occurrence statistics has proven\neffective for both pre-training and fine-tuning in natural language processing.\nHowever, recent studies have pointed out the distribution of learned embeddings\ndegenerates into anisotropy, and even pre-trained language models (PLMs) suffer\nfrom a loss of semantics-related information in embeddings for low-frequency\ntokens. This study first analyzes fine-tuning dynamics of a PLM, BART-large,\nand demonstrates its robustness against degeneration. On the basis of this\nfinding, we propose DefinitionEMB, a method that utilizes definitions to\nconstruct isotropically distributed and semantics-related token embeddings for\nPLMs while maintaining original robustness during fine-tuning. Our experiments\ndemonstrate the effectiveness of leveraging definitions from Wiktionary to\nconstruct such embeddings for RoBERTa-base and BART-large. Furthermore, the\nconstructed embeddings for low-frequency tokens improve the performance of\nthese models across various GLUE and four text summarization datasets.", "categories": "cs.CL", "created": "2024-08-02", "doi": null, "arxiv_id": "2408.01308"}
{"title": "TopoNAS: Boosting Search Efficiency of Gradient-based NAS via\n  Topological Simplification", "authors": [], "abstract": "Improving search efficiency serves as one of the crucial objectives of Neural\nArchitecture Search (NAS). However, many current approaches ignore the\nuniversality of the search strategy and fail to reduce the computational\nredundancy during the search process, especially in one-shot NAS architectures.\nBesides, current NAS methods show invalid reparameterization in non-linear\nsearch space, leading to poor efficiency in common search spaces like DARTS. In\nthis paper, we propose TopoNAS, a model-agnostic approach for gradient-based\none-shot NAS that significantly reduces searching time and memory usage by\ntopological simplification of searchable paths. Firstly, we model the\nnon-linearity in search spaces to reveal the parameterization difficulties. To\nimprove the search efficiency, we present a topological simplification method\nand iteratively apply module-sharing strategies to simplify the topological\nstructure of searchable paths. In addition, a kernel normalization technique is\nalso proposed to preserve the search accuracy. Experimental results on the\nNASBench201 benchmark with various search spaces demonstrate the effectiveness\nof our method. It proves the proposed TopoNAS enhances the performance of\nvarious architectures in terms of search efficiency while maintaining a high\nlevel of accuracy. The project page is available at\nhttps://xdedss.github.io/topo_simplification.", "categories": "cs.CV", "created": "2024-08-02", "doi": null, "arxiv_id": "2408.01311"}
{"title": "Synergistic pathways of modulation enable robust task packing within\n  neural dynamics", "authors": [], "abstract": "Understanding how brain networks learn and manage multiple tasks\nsimultaneously is of interest in both neuroscience and artificial intelligence.\nIn this regard, a recent research thread in theoretical neuroscience has\nfocused on how recurrent neural network models and their internal dynamics\nenact multi-task learning. To manage different tasks requires a mechanism to\nconvey information about task identity or context into the model, which from a\nbiological perspective may involve mechanisms of neuromodulation. In this\nstudy, we use recurrent network models to probe the distinctions between two\nforms of contextual modulation of neural dynamics, at the level of neuronal\nexcitability and at the level of synaptic strength. We characterize these\nmechanisms in terms of their functional outcomes, focusing on their robustness\nto context ambiguity and, relatedly, their efficiency with respect to packing\nmultiple tasks into finite size networks. We also demonstrate distinction\nbetween these mechanisms at the level of the neuronal dynamics they induce.\nTogether, these characterizations indicate complementarity and synergy in how\nthese mechanisms act, potentially over multiple time-scales, toward enhancing\nrobustness of multi-task learning.", "categories": "q-bio.NC cs.AI", "created": "2024-08-02", "doi": null, "arxiv_id": "2408.01316"}
{"title": "Point Prediction for Streaming Data", "authors": [], "abstract": "We present two new approaches for point prediction with streaming data. One\nis based on the Count-Min sketch (CMS) and the other is based on Gaussian\nprocess priors with a random bias. These methods are intended for the most\ngeneral predictive problems where no true model can be usefully formulated for\nthe data stream. In statistical contexts, this is often called the\n$\\mathcal{M}$-open problem class. Under the assumption that the data consists\nof i.i.d samples from a fixed distribution function $F$, we show that the\nCMS-based estimates of the distribution function are consistent.\n  We compare our new methods with two established predictors in terms of\ncumulative $L^1$ error. One is based on the Shtarkov solution (often called the\nnormalized maximum likelihood) in the normal experts setting and the other is\nbased on Dirichlet process priors. These comparisons are for two cases. The\nfirst is one-pass meaning that the updating of the predictors is done using the\nfact that the CMS is a sketch. For predictors that are not one-pass, we use\nstreaming $K$-means to give a representative subset of fixed size that can be\nupdated as data accumulate.\n  Preliminary computational work suggests that the one-pass median version of\nthe CMS method is rarely outperformed by the other methods for sufficiently\ncomplex data. We also find that predictors based on Gaussian process priors\nwith random biases perform well. The Shtarkov predictors we use here did not\nperform as well probably because we were only using the simplest example. The\nother predictors seemed to perform well mainly when the data did not look like\nthey came from an M-open data generator.", "categories": "stat.ML cs.LG", "created": "2024-08-02", "doi": null, "arxiv_id": "2408.01318"}
{"title": "A Comprehensive Review of Multimodal Large Language Models: Performance\n  and Challenges Across Different Tasks", "authors": [], "abstract": "In an era defined by the explosive growth of data and rapid technological\nadvancements, Multimodal Large Language Models (MLLMs) stand at the forefront\nof artificial intelligence (AI) systems. Designed to seamlessly integrate\ndiverse data types-including text, images, videos, audio, and physiological\nsequences-MLLMs address the complexities of real-world applications far beyond\nthe capabilities of single-modality systems. In this paper, we systematically\nsort out the applications of MLLM in multimodal tasks such as natural language,\nvision, and audio. We also provide a comparative analysis of the focus of\ndifferent MLLMs in the tasks, and provide insights into the shortcomings of\ncurrent MLLMs, and suggest potential directions for future research. Through\nthese discussions, this paper hopes to provide valuable insights for the\nfurther development and application of MLLM.", "categories": "cs.AI", "created": "2024-08-02", "doi": null, "arxiv_id": "2408.01319"}
{"title": "Generalized Reduced-WMMSE Approach for Cell-Free Massive MIMO With\n  Per-AP Power Constraints", "authors": [], "abstract": "The optimization of cooperative beamforming vectors in cell-free massive MIMO\n(mMIMO) systems is presented where multi-antenna access points (APs) support\ndownlink data transmission of multiple users. Albeit the successes of the\nweighted minimum mean squared error (WMMSE) algorithm and their variants, they\nlack careful investigations about computational complexity that scales with the\nnumber of antennas and APs. We propose a generalized and reduced WMMSE\n(G-R-WMMSE) approach whose complexity is significantly lower than conventional\nWMMSE. We partition the set of beamforming coefficients into subvectors, with\neach subvector corresponding to a specific AP. Such a partitioning approach\ndecomposes the original WMMSE problem across individual APs. By leveraging the\nLagrange duality analysis, a closed-form solution can be derived for each\nsubproblem, which substantially reduces the computation burden. Additionally,\nwe present a parallel execution of the proposed G-R-WMMSE with adaptive step\nsizes, aiming at further reducing the time complexity. Numerical results\nvalidate that the proposed G-R-WMMSE schemes achieve over 99% complexity\nsavings compared to the conventional WMMSE scheme while maintaining almost the\nsame performance.", "categories": "eess.SP cs.IT math.IT", "created": "2024-08-02", "doi": null, "arxiv_id": "2408.01320"}
{"title": "A Robotics-Inspired Scanpath Model Reveals the Importance of Uncertainty\n  and Semantic Object Cues for Gaze Guidance in Dynamic Scenes", "authors": [], "abstract": "How we perceive objects around us depends on what we actively attend to, yet\nour eye movements depend on the perceived objects. Still, object segmentation\nand gaze behavior are typically treated as two independent processes. Drawing\non an information processing pattern from robotics, we present a mechanistic\nmodel that simulates these processes for dynamic real-world scenes. Our\nimage-computable model uses the current scene segmentation for object-based\nsaccadic decision-making while using the foveated object to refine its scene\nsegmentation recursively. To model this refinement, we use a Bayesian filter,\nwhich also provides an uncertainty estimate for the segmentation that we use to\nguide active scene exploration. We demonstrate that this model closely\nresembles observers' free viewing behavior, measured by scanpath statistics,\nincluding foveation duration and saccade amplitude distributions used for\nparameter fitting and higher-level statistics not used for fitting. These\ninclude how object detections, inspections, and returns are balanced and a\ndelay of returning saccades without an explicit implementation of such temporal\ninhibition of return. Extensive simulations and ablation studies show that\nuncertainty promotes balanced exploration and that semantic object cues are\ncrucial to form the perceptual units used in object-based attention. Moreover,\nwe show how our model's modular design allows for extensions, such as\nincorporating saccadic momentum or pre-saccadic attention, to further align its\noutput with human scanpaths.", "categories": "cs.CV cs.AI q-bio.NC", "created": "2024-08-02", "doi": null, "arxiv_id": "2408.01322"}
{"title": "FANNO: Augmenting High-Quality Instruction Data with Open-Sourced LLMs\n  Only", "authors": [], "abstract": "Instruction fine-tuning stands as a crucial advancement in leveraging large\nlanguage models (LLMs) for enhanced task performance. However, the annotation\nof instruction datasets has traditionally been expensive and laborious, often\nrelying on manual annotations or costly API calls of proprietary LLMs. To\naddress these challenges, we introduce FANNO, a fully autonomous, open-sourced\nframework that revolutionizes the annotation process without the need for\npre-existing annotated data. Utilizing a Mistral-7b-instruct model, FANNO\nefficiently produces diverse and high-quality datasets through a structured\nprocess involving document pre-screening, instruction generation, and response\ngeneration. Experiments on Open LLM Leaderboard and AlpacaEval benchmark show\nthat the FANNO can generate high-quality data with diversity and complexity for\nfree, comparable to human-annotated or cleaned datasets like\nAlpaca-GPT4-Cleaned.", "categories": "cs.CL", "created": "2024-08-02", "doi": null, "arxiv_id": "2408.01323"}
{"title": "Fully Dynamic $k$-Clustering with Fast Update Time and Small Recourse", "authors": [], "abstract": "In the dynamic metric $k$-median problem, we wish to maintain a set of $k$\ncenters $S \\subseteq V$ in an input metric space $(V, d)$ that gets updated via\npoint insertions/deletions, so as to minimize the objective $\\sum_{x \\in V}\n\\min_{y \\in S} d(x, y)$. The quality of a dynamic algorithm is measured in\nterms of its approximation ratio, \"recourse\" (the number of changes in $S$ per\nupdate) and \"update time\" (the time it takes to handle an update). The ultimate\ngoal in this line of research is to obtain a dynamic $O(1)$ approximation\nalgorithm with $\\tilde{O}(1)$ recourse and $\\tilde{O}(k)$ update time.\n  Dynamic $k$-median is a canonical example of a class of problems known as\ndynamic $k$-clustering, that has received significant attention in recent\nyears. To the best of our knowledge, however, previous papers either attempt to\nminimize the algorithm's recourse while ignoring its update time, or minimize\nthe algorithm's update time while ignoring its recourse. For dynamic\n$k$-median, we come arbitrarily close to resolving the main open question on\nthis topic, with the following results.\n  (I) We develop a new framework of randomized local search that is suitable\nfor adaptation in a dynamic setting. For every $\\epsilon > 0$, this gives us a\ndynamic $k$-median algorithm with $O(1/\\epsilon)$ approximation ratio,\n$\\tilde{O}(k^{\\epsilon})$ recourse and $\\tilde{O}(k^{1+\\epsilon})$ update time.\nThis framework also generalizes to dynamic $k$-clustering with $\\ell^p$-norm\nobjectives, giving similar bounds for the dynamic $k$-means and a new trade-off\nfor dynamic $k$-center.\n  (II) If it suffices to maintain only an estimate of the value of the optimal\n$k$-median objective, then we obtain a $O(1)$ approximation algorithm with\n$\\tilde{O}(k)$ update time. We achieve this result via adapting the Lagrangian\nRelaxation framework to the dynamic setting.", "categories": "cs.DS", "created": "2024-08-02", "doi": null, "arxiv_id": "2408.01325"}
{"title": "Modeling Interfering Sources in Shared Queues for Timely Computations in\n  Edge Computing Systems", "authors": [], "abstract": "Most existing stochastic models on age of information (AoI) focus on a single\nshared server serving status update packets from $N>1$ sources where each\npacket update stream is Poisson, i.e., single-hop scenario. In the current\nwork, we study a two-hop edge computing system for which status updates from\nthe information sources are still Poisson but they are not immediately\navailable at the shared edge server, but instead they need to first receive\nservice from a transmission server dedicated to each source. For exponentially\ndistributed and heterogeneous service times for both the dedicated servers and\nthe edge server, and bufferless preemptive resource management, we develop an\nanalytical model using absorbing Markov chains (AMC) for obtaining the\ndistribution of AoI for any source in the system. Moreover, for a given tagged\nsource, the traffic arriving at the shared server from the $N-1$ un-tagged\nsources, namely the interference traffic, is not Poisson any more, but is\ninstead a Markov modulated Poisson process (MMPP) whose state space grows\nexponentially with $N$. Therefore, we propose to employ a model reduction\ntechnique that approximates the behavior of the MMPP interference traffic with\ntwo states only, making it possible to approximately obtain the AoI statistics\neven for a very large number of sources. Numerical examples are presented to\nvalidate the proposed exact and approximate models.", "categories": "cs.IT cs.NI cs.PF math.IT", "created": "2024-08-02", "doi": null, "arxiv_id": "2408.01327"}
{"title": "Coloring bridge-free antiprismatic graphs", "authors": [], "abstract": "The coloring problem is a well-research topic and its complexity is known for\nseveral classes of graphs. However, the question of its complexity remains open\nfor the class of antiprismatic graphs, which are the complement of prismatic\ngraphs and one of the four remaining cases highlighted by Lozin and Malishev.\nIn this article we focus on the equivalent question of the complexity of the\nclique cover problem in prismatic graphs.\n  A graph $G$ is prismatic if for every triangle $T$ of $G$, every vertex of\n$G$ not in $T$ has a unique neighbor in $T$. A graph is co-bridge-free if it\nhas no $C_4+2K_1$ as induced subgraph. We give a polynomial time algorithm that\nsolves the clique cover problem in co-bridge-free prismatic graphs. It relies\non the structural description given by Chudnovsky and Seymour, and on later\nwork of Preissmann, Robin and Trotignon.\n  We show that co-bridge-free prismatic graphs have a bounded number of\ndisjoint triangles and that implies that the algorithm presented by Preissmann\net al. applies.", "categories": "cs.DM math.CO", "created": "2024-08-02", "doi": null, "arxiv_id": "2408.01328"}
{"title": "On the Effect of TSN Forwarding Mechanisms on Best-Effort Traffic", "authors": [], "abstract": "Time-Sensitive Networking (TSN) enables the transmission of multiple traffic\ntypes within a single network. While the performance of high-priority traffic\nhas been extensively studied in recent years, the performance of low-priority\ntraffic varies significantly between different TSN forwarding algorithms. This\npaper provides an overview of existing TSN forwarding algorithms and discusses\ntheir impact on best-effort traffic. The effects are quantified through\nsimulations of synthetic and realistic networks. The considered forwarding\nmechanisms are Strict Priority (SP), Asynchronous Traffic Shaper (ATS),\nCredit-Based Shaper (CBS), Enhanced Transmission Selection (ETS), and\nTime-Aware Shaper (TAS).\n  The findings indicate that ATS, CBS, and ETS can significantly reduce queuing\ndelays and queue lengths for best-effort traffic when compared to SP and TAS.\nThis effect is enhanced when the reserved bandwidth for high priority queues -\nusing CBS, ATS, or ETS - is reduced to the lowest possible value, within the\nreserved rate and latency requirements. Specifically, the simulations\ndemonstrate that the choice of forwarding algorithm can improve the performance\nof low-priority traffic by up to twenty times compared to the least effective\nalgorithm. This study not only provides a comprehensive understanding of the\nvarious TSN forwarding algorithms but can also serve as guidance at networks'\ndesign time to improve the performance for all types of traffic.", "categories": "cs.NI", "created": "2024-08-02", "doi": null, "arxiv_id": "2408.01330"}
{"title": "HMDN: Hierarchical Multi-Distribution Network for Click-Through Rate\n  Prediction", "authors": [], "abstract": "As the recommendation service needs to address increasingly diverse\ndistributions, such as multi-population, multi-scenario, multitarget, and\nmulti-interest, more and more recent works have focused on multi-distribution\nmodeling and achieved great progress. However, most of them only consider\nmodeling in a single multi-distribution manner, ignoring that mixed\nmulti-distributions often coexist and form hierarchical relationships. To\naddress these challenges, we propose a flexible modeling paradigm, named\nHierarchical Multi-Distribution Network (HMDN), which efficiently models these\nhierarchical relationships and can seamlessly integrate with existing\nmulti-distribution methods, such as Mixture of-Experts (MoE) and Dynamic-Weight\n(DW) models. Specifically, we first design a hierarchical multi-distribution\nrepresentation refinement module, employing a multi-level residual quantization\nto obtain fine-grained hierarchical representation. Then, the refined\nhierarchical representation is integrated into the existing single\nmulti-distribution models, seamlessly expanding them into mixed\nmulti-distribution models. Experimental results on both public and industrial\ndatasets validate the effectiveness and flexibility of HMDN.", "categories": "cs.LG", "created": "2024-08-02", "doi": null, "arxiv_id": "2408.01332"}
{"title": "Incorporating Control Inputs in the Estimation of Continuous Mobile\n  Robot Trajectories and Continuum Robot Shapes", "authors": [], "abstract": "Continuous-time batch state estimation using Gaussian processes is an\nefficient approach to estimate the trajectories of robots over time. In the\npast, relatively simple physics-motivated priors have been considered for such\napproaches, using assumptions such as constant velocity or acceleration. This\npaper presents an approach to incorporating exogenous control inputs, such as\nvelocity or acceleration commands, into the continuous Gaussian process\nstate-estimation framework. It is shown that this approach generalizes across\ndifferent domains in robotics, making it applicable to both the estimation of\ncontinuous-time trajectories for mobile robots and continuum-robot shapes.\nResults show that incorporating control inputs leads to more informed priors,\npotentially requiring less measurements and estimation nodes to obtain accurate\nestimates. This makes the approach particularly useful in situations in which\nlimited sensing is available.", "categories": "cs.RO", "created": "2024-08-02", "doi": null, "arxiv_id": "2408.01333"}
{"title": "Sparse Linear Regression when Noises and Covariates are Heavy-Tailed and\n  Contaminated by Outliers", "authors": [], "abstract": "We investigate a problem estimating coefficients of linear regression under\nsparsity assumption when covariates and noises are sampled from heavy tailed\ndistributions. Additionally, we consider the situation where not only\ncovariates and noises are sampled from heavy tailed distributions but also\ncontaminated by outliers. Our estimators can be computed efficiently, and\nexhibit sharp error bounds.", "categories": "stat.ML cs.LG", "created": "2024-08-02", "doi": null, "arxiv_id": "2408.01336"}
{"title": "MuChoMusic: Evaluating Music Understanding in Multimodal Audio-Language\n  Models", "authors": [], "abstract": "Multimodal models that jointly process audio and language hold great promise\nin audio understanding and are increasingly being adopted in the music domain.\nBy allowing users to query via text and obtain information about a given audio\ninput, these models have the potential to enable a variety of music\nunderstanding tasks via language-based interfaces. However, their evaluation\nposes considerable challenges, and it remains unclear how to effectively assess\ntheir ability to correctly interpret music-related inputs with current methods.\nMotivated by this, we introduce MuChoMusic, a benchmark for evaluating music\nunderstanding in multimodal language models focused on audio. MuChoMusic\ncomprises 1,187 multiple-choice questions, all validated by human annotators,\non 644 music tracks sourced from two publicly available music datasets, and\ncovering a wide variety of genres. Questions in the benchmark are crafted to\nassess knowledge and reasoning abilities across several dimensions that cover\nfundamental musical concepts and their relation to cultural and functional\ncontexts. Through the holistic analysis afforded by the benchmark, we evaluate\nfive open-source models and identify several pitfalls, including an\nover-reliance on the language modality, pointing to a need for better\nmultimodal integration. Data and code are open-sourced.", "categories": "cs.SD cs.CL cs.LG cs.MM eess.AS", "created": "2024-08-02", "doi": null, "arxiv_id": "2408.01337"}
{"title": "Leveraging Knowledge Graph Embedding for Effective Conversational\n  Recommendation", "authors": [], "abstract": "Conversational recommender system (CRS), which combines the techniques of\ndialogue system and recommender system, has obtained increasing interest\nrecently. In contrast to traditional recommender system, it learns the user\npreference better through interactions (i.e. conversations), and then further\nboosts the recommendation performance. However, existing studies on CRS ignore\nto address the relationship among attributes, users, and items effectively,\nwhich might lead to inappropriate questions and inaccurate recommendations. In\nthis view, we propose a knowledge graph based conversational recommender system\n(referred as KG-CRS). Specifically, we first integrate the user-item graph and\nitem-attribute graph into a dynamic graph, i.e., dynamically changing during\nthe dialogue process by removing negative items or attributes. We then learn\ninformative embedding of users, items, and attributes by also considering\npropagation through neighbors on the graph. Extensive experiments on three real\ndatasets validate the superiority of our method over the state-of-the-art\napproaches in terms of both the recommendation and conversation tasks.", "categories": "cs.IR cs.AI", "created": "2024-08-02", "doi": null, "arxiv_id": "2408.01342"}
{"title": "StitchFusion: Weaving Any Visual Modalities to Enhance Multimodal\n  Semantic Segmentation", "authors": [], "abstract": "Multimodal semantic segmentation shows significant potential for enhancing\nsegmentation accuracy in complex scenes. However, current methods often\nincorporate specialized feature fusion modules tailored to specific modalities,\nthereby restricting input flexibility and increasing the number of training\nparameters. To address these challenges, we propose StitchFusion, a\nstraightforward yet effective modal fusion framework that integrates\nlarge-scale pre-trained models directly as encoders and feature fusers. This\napproach facilitates comprehensive multi-modal and multi-scale feature fusion,\naccommodating any visual modal inputs. Specifically, Our framework achieves\nmodal integration during encoding by sharing multi-modal visual information. To\nenhance information exchange across modalities, we introduce a\nmulti-directional adapter module (MultiAdapter) to enable cross-modal\ninformation transfer during encoding. By leveraging MultiAdapter to propagate\nmulti-scale information across pre-trained encoders during the encoding\nprocess, StitchFusion achieves multi-modal visual information integration\nduring encoding. Extensive comparative experiments demonstrate that our model\nachieves state-of-the-art performance on four multi-modal segmentation datasets\nwith minimal additional parameters. Furthermore, the experimental integration\nof MultiAdapter with existing Feature Fusion Modules (FFMs) highlights their\ncomplementary nature. Our code is available at StitchFusion_repo.", "categories": "cs.CV cs.AI cs.LG", "created": "2024-08-02", "doi": null, "arxiv_id": "2408.01343"}
{"title": "Prompt Refinement or Fine-tuning? Best Practices for using LLMs in\n  Computational Social Science Tasks", "authors": [], "abstract": "Large Language Models are expressive tools that enable complex tasks of text\nunderstanding within Computational Social Science. Their versatility, while\nbeneficial, poses a barrier for establishing standardized best practices within\nthe field. To bring clarity on the values of different strategies, we present\nan overview of the performance of modern LLM-based classification methods on a\nbenchmark of 23 social knowledge tasks. Our results point to three best\npractices: select models with larger vocabulary and pre-training corpora; avoid\nsimple zero-shot in favor of AI-enhanced prompting; fine-tune on task-specific\ndata, and consider more complex forms instruction-tuning on multiple datasets\nonly when only training data is more abundant.", "categories": "cs.CY cs.CL physics.soc-ph", "created": "2024-08-02", "doi": null, "arxiv_id": "2408.01346"}
{"title": "PC$^2$: Pseudo-Classification Based Pseudo-Captioning for Noisy\n  Correspondence Learning in Cross-Modal Retrieval", "authors": [], "abstract": "In the realm of cross-modal retrieval, seamlessly integrating diverse\nmodalities within multimedia remains a formidable challenge, especially given\nthe complexities introduced by noisy correspondence learning (NCL). Such noise\noften stems from mismatched data pairs, which is a significant obstacle\ndistinct from traditional noisy labels. This paper introduces\nPseudo-Classification based Pseudo-Captioning (PC$^2$) framework to address\nthis challenge. PC$^2$ offers a threefold strategy: firstly, it establishes an\nauxiliary \"pseudo-classification\" task that interprets captions as categorical\nlabels, steering the model to learn image-text semantic similarity through a\nnon-contrastive mechanism. Secondly, unlike prevailing margin-based techniques,\ncapitalizing on PC$^2$'s pseudo-classification capability, we generate\npseudo-captions to provide more informative and tangible supervision for each\nmismatched pair. Thirdly, the oscillation of pseudo-classification is borrowed\nto assistant the correction of correspondence. In addition to technical\ncontributions, we develop a realistic NCL dataset called Noise of Web (NoW),\nwhich could be a new powerful NCL benchmark where noise exists naturally.\nEmpirical evaluations of PC$^2$ showcase marked improvements over existing\nstate-of-the-art robust cross-modal retrieval techniques on both simulated and\nrealistic datasets with various NCL settings. The contributed dataset and\nsource code are released at https://github.com/alipay/PC2-NoiseofWeb.", "categories": "cs.MM cs.AI cs.CV cs.IR cs.LG", "created": "2024-08-02", "doi": "10.1145/3664647.3680860", "arxiv_id": "2408.01349"}
{"title": "MCGMark: An Encodable and Robust Online Watermark for LLM-Generated\n  Malicious Code", "authors": [], "abstract": "With the advent of large language models (LLMs), numerous software service\nproviders (SSPs) are dedicated to developing LLMs customized for code\ngeneration tasks, such as CodeLlama and Copilot. However, these LLMs can be\nleveraged by attackers to create malicious software, which may pose potential\nthreats to the software ecosystem. For example, they can automate the creation\nof advanced phishing malware. To address this issue, we first conduct an\nempirical study and design a prompt dataset, MCGTest, which involves\napproximately 400 person-hours of work and consists of 406 malicious code\ngeneration tasks. Utilizing this dataset, we propose MCGMark, the first robust,\ncode structure-aware, and encodable watermarking approach to trace\nLLM-generated code. We embed encodable information by controlling the token\nselection and ensuring the output quality based on probabilistic outliers.\nAdditionally, we enhance the robustness of the watermark by considering the\nstructural features of malicious code, preventing the embedding of the\nwatermark in easily modified positions, such as comments. We validate the\neffectiveness and robustness of MCGMark on the DeepSeek-Coder. MCGMark achieves\nan embedding success rate of 88.9% within a maximum output limit of 400 tokens.\nFurthermore, it also demonstrates strong robustness and has minimal impact on\nthe quality of the output code. Our approach assists SSPs in tracing and\nholding responsible parties accountable for malicious code generated by LLMs.", "categories": "cs.CR cs.SE", "created": "2024-08-02", "doi": null, "arxiv_id": "2408.01354"}
{"title": "Hallu-PI: Evaluating Hallucination in Multi-modal Large Language Models\n  within Perturbed Inputs", "authors": [], "abstract": "Multi-modal Large Language Models (MLLMs) have demonstrated remarkable\nperformance on various visual-language understanding and generation tasks.\nHowever, MLLMs occasionally generate content inconsistent with the given\nimages, which is known as \"hallucination\". Prior works primarily center on\nevaluating hallucination using standard, unperturbed benchmarks, which overlook\nthe prevalent occurrence of perturbed inputs in real-world scenarios-such as\nimage cropping or blurring-that are critical for a comprehensive assessment of\nMLLMs' hallucination. In this paper, to bridge this gap, we propose Hallu-PI,\nthe first benchmark designed to evaluate Hallucination in MLLMs within\nPerturbed Inputs. Specifically, Hallu-PI consists of seven perturbed scenarios,\ncontaining 1,260 perturbed images from 11 object types. Each image is\naccompanied by detailed annotations, which include fine-grained hallucination\ntypes, such as existence, attribute, and relation. We equip these annotations\nwith a rich set of questions, making Hallu-PI suitable for both discriminative\nand generative tasks. Extensive experiments on 12 mainstream MLLMs, such as\nGPT-4V and Gemini-Pro Vision, demonstrate that these models exhibit significant\nhallucinations on Hallu-PI, which is not observed in unperturbed scenarios.\nFurthermore, our research reveals a severe bias in MLLMs' ability to handle\ndifferent types of hallucinations. We also design two baselines specifically\nfor perturbed scenarios, namely Perturbed-Reminder and Perturbed-ICL. We hope\nthat our study will bring researchers' attention to the limitations of MLLMs\nwhen dealing with perturbed inputs, and spur further investigations to address\nthis issue. Our code and datasets are publicly available at\nhttps://github.com/NJUNLP/Hallu-PI.", "categories": "cs.CV cs.MM", "created": "2024-08-02", "doi": null, "arxiv_id": "2408.01355"}
{"title": "Balanced Residual Distillation Learning for 3D Point Cloud\n  Class-Incremental Semantic Segmentation", "authors": [], "abstract": "Class-incremental learning (CIL) thrives due to its success in processing the\ninflux of information by learning from continuously added new classes while\npreventing catastrophic forgetting about the old ones. It is essential for the\nperformance breakthrough of CIL to effectively refine past knowledge from the\nbase model and balance it with new learning. However, such an issue has not yet\nbeen considered in current research. In this work, we explore the potential of\nCIL from these perspectives and propose a novel balanced residual distillation\nframework (BRD-CIL) to push the performance bar of CIL to a new higher level.\nSpecifically, BRD-CIL designs a residual distillation learning strategy, which\ncan dynamically expand the network structure to capture the residuals between\nthe base and target models, effectively refining the past knowledge.\nFurthermore, BRD-CIL designs a balanced pseudo-label learning strategy by\ngenerating a guidance mask to reduce the preference for old classes, ensuring\nbalanced learning from new and old classes. We apply the proposed BRD-CIL to a\nchallenging 3D point cloud semantic segmentation task where the data are\nunordered and unstructured. Extensive experimental results demonstrate that\nBRD-CIL sets a new benchmark with an outstanding balance capability in\nclass-biased scenarios.", "categories": "cs.CV", "created": "2024-08-02", "doi": null, "arxiv_id": "2408.01356"}
{"title": "Autoencoders in Function Space", "authors": [], "abstract": "Autoencoders have found widespread application, in both their original\ndeterministic form and in their variational formulation (VAEs). In scientific\napplications it is often of interest to consider data that are comprised of\nfunctions; the same perspective is useful in image processing. In practice,\ndiscretisation (of differential equations arising in the sciences) or\npixellation (of images) renders problems finite dimensional, but conceiving\nfirst of algorithms that operate on functions, and only then discretising or\npixellating, leads to better algorithms that smoothly operate between different\nlevels of discretisation or pixellation. In this paper function-space versions\nof the autoencoder (FAE) and variational autoencoder (FVAE) are introduced,\nanalysed, and deployed. Well-definedness of the objective function governing\nVAEs is a subtle issue, even in finite dimension, and more so on function\nspace. The FVAE objective is well defined whenever the data distribution is\ncompatible with the chosen generative model; this happens, for example, when\nthe data arise from a stochastic differential equation. The FAE objective is\nvalid much more broadly, and can be straightforwardly applied to data governed\nby differential equations. Pairing these objectives with neural operator\narchitectures, which can thus be evaluated on any mesh, enables new\napplications of autoencoders to inpainting, superresolution, and generative\nmodelling of scientific data.", "categories": "stat.ML cs.LG", "created": "2024-08-02", "doi": null, "arxiv_id": "2408.01362"}
{"title": "Toward Automatic Relevance Judgment using Vision--Language Models for\n  Image--Text Retrieval Evaluation", "authors": [], "abstract": "Vision--Language Models (VLMs) have demonstrated success across diverse\napplications, yet their potential to assist in relevance judgments remains\nuncertain. This paper assesses the relevance estimation capabilities of VLMs,\nincluding CLIP, LLaVA, and GPT-4V, within a large-scale \\textit{ad hoc}\nretrieval task tailored for multimedia content creation in a zero-shot fashion.\nPreliminary experiments reveal the following: (1) Both LLaVA and GPT-4V,\nencompassing open-source and closed-source visual-instruction-tuned Large\nLanguage Models (LLMs), achieve notable Kendall's $\\tau \\sim 0.4$ when compared\nto human relevance judgments, surpassing the CLIPScore metric. (2) While\nCLIPScore is strongly preferred, LLMs are less biased towards CLIP-based\nretrieval systems. (3) GPT-4V's score distribution aligns more closely with\nhuman judgments than other models, achieving a Cohen's $\\kappa$ value of around\n0.08, which outperforms CLIPScore at approximately -0.096. These findings\nunderscore the potential of LLM-powered VLMs in enhancing relevance judgments.", "categories": "cs.IR cs.CL cs.CV cs.MM", "created": "2024-08-02", "doi": null, "arxiv_id": "2408.01363"}
{"title": "Data Debugging is NP-hard for Classifiers Trained with SGD", "authors": [], "abstract": "Data debugging is to find a subset of the training data such that the model\nobtained by retraining on the subset has a better accuracy. A bunch of\nheuristic approaches are proposed, however, none of them are guaranteed to\nsolve this problem effectively. This leaves an open issue whether there exists\nan efficient algorithm to find the subset such that the model obtained by\nretraining on it has a better accuracy. To answer this open question and\nprovide theoretical basis for further study on developing better algorithms for\ndata debugging, we investigate the computational complexity of the problem\nnamed Debuggable. Given a machine learning model $\\mathcal{M}$ obtained by\ntraining on dataset $D$ and a test instance\n$(\\mathbf{x}_\\text{test},y_\\text{test})$ where\n$\\mathcal{M}(\\mathbf{x}_\\text{test})\\neq y_\\text{test}$, Debuggable is to\ndetermine whether there exists a subset $D^\\prime$ of $D$ such that the model\n$\\mathcal{M}^\\prime$ obtained by retraining on $D^\\prime$ satisfies\n$\\mathcal{M}^\\prime(\\mathbf{x}_\\text{test})=y_\\text{test}$. To cover a wide\nrange of commonly used models, we take SGD-trained linear classifier as the\nmodel and derive the following main results. (1) If the loss function and the\ndimension of the model are not fixed, Debuggable is NP-complete regardless of\nthe training order in which all the training samples are processed during SGD.\n(2) For hinge-like loss functions, a comprehensive analysis on the\ncomputational complexity of Debuggable is provided; (3) If the loss function is\na linear function, Debuggable can be solved in linear time, that is, data\ndebugging can be solved easily in this case. These results not only highlight\nthe limitations of current approaches but also offer new insights into data\ndebugging.", "categories": "cs.CC cs.LG", "created": "2024-08-02", "doi": null, "arxiv_id": "2408.01365"}
{"title": "Play to the Score: Stage-Guided Dynamic Multi-Sensory Fusion for Robotic\n  Manipulation", "authors": [], "abstract": "Humans possess a remarkable talent for flexibly alternating to different\nsenses when interacting with the environment. Picture a chef skillfully gauging\nthe timing of ingredient additions and controlling the heat according to the\ncolors, sounds, and aromas, seamlessly navigating through every stage of the\ncomplex cooking process. This ability is founded upon a thorough comprehension\nof task stages, as achieving the sub-goal within each stage can necessitate the\nutilization of different senses. In order to endow robots with similar ability,\nwe incorporate the task stages divided by sub-goals into the imitation learning\nprocess to accordingly guide dynamic multi-sensory fusion. We propose MS-Bot, a\nstage-guided dynamic multi-sensory fusion method with coarse-to-fine stage\nunderstanding, which dynamically adjusts the priority of modalities based on\nthe fine-grained state within the predicted current stage. We train a robot\nsystem equipped with visual, auditory, and tactile sensors to accomplish\nchallenging robotic manipulation tasks: pouring and peg insertion with keyway.\nExperimental results indicate that our approach enables more effective and\nexplainable dynamic fusion, aligning more closely with the human fusion process\nthan existing methods.", "categories": "cs.RO cs.CV", "created": "2024-08-02", "doi": null, "arxiv_id": "2408.01366"}
{"title": "Transformers are Universal In-context Learners", "authors": [], "abstract": "Transformers are deep architectures that define \"in-context mappings\" which\nenable predicting new tokens based on a given set of tokens (such as a prompt\nin NLP applications or a set of patches for vision transformers). This work\nstudies in particular the ability of these architectures to handle an\narbitrarily large number of context tokens. To mathematically and uniformly\naddress the expressivity of these architectures, we consider the case that the\nmappings are conditioned on a context represented by a probability distribution\nof tokens (discrete for a finite number of tokens). The related notion of\nsmoothness corresponds to continuity in terms of the Wasserstein distance\nbetween these contexts. We demonstrate that deep transformers are universal and\ncan approximate continuous in-context mappings to arbitrary precision,\nuniformly over compact token domains. A key aspect of our results, compared to\nexisting findings, is that for a fixed precision, a single transformer can\noperate on an arbitrary (even infinite) number of tokens. Additionally, it\noperates with a fixed embedding dimension of tokens (this dimension does not\nincrease with precision) and a fixed number of heads (proportional to the\ndimension). The use of MLP layers between multi-head attention layers is also\nexplicitly controlled.", "categories": "cs.CL stat.ML", "created": "2024-08-02", "doi": null, "arxiv_id": "2408.01367"}
{"title": "EVIT: Event-based Visual-Inertial Tracking in Semi-Dense Maps Using\n  Windowed Nonlinear Optimization", "authors": [], "abstract": "Event cameras are an interesting visual exteroceptive sensor that reacts to\nbrightness changes rather than integrating absolute image intensities. Owing to\nthis design, the sensor exhibits strong performance in situations of\nchallenging dynamics and illumination conditions. While event-based\nsimultaneous tracking and mapping remains a challenging problem, a number of\nrecent works have pointed out the sensor's suitability for prior map-based\ntracking. By making use of cross-modal registration paradigms, the camera's\nego-motion can be tracked across a large spectrum of illumination and dynamics\nconditions on top of accurate maps that have been created a priori by more\ntraditional sensors. The present paper follows up on a recently introduced\nevent-based geometric semi-dense tracking paradigm, and proposes the addition\nof inertial signals in order to robustify the estimation. More specifically,\nthe added signals provide strong cues for pose initialization as well as\nregularization during windowed, multi-frame tracking. As a result, the proposed\nframework achieves increased performance under challenging illumination\nconditions as well as a reduction of the rate at which intermediate event\nrepresentations need to be registered in order to maintain stable tracking\nacross highly dynamic sequences. Our evaluation focuses on a diverse set of\nreal world sequences and comprises a comparison of our proposed method against\na purely event-based alternative running at different rates.", "categories": "cs.CV cs.RO", "created": "2024-08-02", "doi": null, "arxiv_id": "2408.01370"}
{"title": "Spatial-Spectral Morphological Mamba for Hyperspectral Image\n  Classification", "authors": [], "abstract": "In recent years, Transformers have garnered significant attention for\nHyperspectral Image Classification (HSIC) due to their self-attention\nmechanism, which provides strong classification performance. However, these\nmodels face major challenges in computational efficiency, as their complexity\nincreases quadratically with the sequence length. The Mamba architecture,\nleveraging a State Space Model, offers a more efficient alternative to\nTransformers. This paper introduces the Spatial-Spectral Morphological Mamba\n(MorpMamba) model. In the MorpMamba model, a token generation module first\nconverts the Hyperspectral Image (HSI) patch into spatial-spectral tokens.\nThese tokens are then processed by a morphology block, which computes\nstructural and shape information using depthwise separable convolutional\noperations. The extracted information is enhanced in a feature enhancement\nmodule that adjusts the spatial and spectral tokens based on the center region\nof the HSI sample, allowing for effective information fusion within each block.\nSubsequently, the tokens are refined in a multi-head self-attention block to\nfurther improve the feature space. Finally, the combined information is fed\ninto the state space block for classification and the creation of the ground\ntruth map. Experiments on widely used Hyperspectral (HS) datasets demonstrate\nthat the MorpMamba model outperforms (parametric efficiency) both CNN and\nTransformer models.", "categories": "cs.CV eess.IV", "created": "2024-08-02", "doi": null, "arxiv_id": "2408.01372"}
{"title": "Hybrid Coordinate Descent for Efficient Neural Network Learning Using\n  Line Search and Gradient Descent", "authors": [], "abstract": "This paper presents a novel coordinate descent algorithm leveraging a\ncombination of one-directional line search and gradient information for\nparameter updates for a squared error loss function. Each parameter undergoes\nupdates determined by either the line search or gradient method, contingent\nupon whether the modulus of the gradient of the loss with respect to that\nparameter surpasses a predefined threshold. Notably, a larger threshold value\nenhances algorithmic efficiency. Despite the potentially slower nature of the\nline search method relative to gradient descent, its parallelizability\nfacilitates computational time reduction. Experimental validation conducted on\na 2-layer Rectified Linear Unit network with synthetic data elucidates the\nimpact of hyperparameters on convergence rates and computational efficiency.", "categories": "cs.LG", "created": "2024-08-02", "doi": null, "arxiv_id": "2408.01374"}
{"title": "Adaptive Recruitment Resource Allocation to Improve Cohort\n  Representativeness in Participatory Biomedical Datasets", "authors": [], "abstract": "Large participatory biomedical studies, studies that recruit individuals to\njoin a dataset, are gaining popularity and investment, especially for analysis\nby modern AI methods. Because they purposively recruit participants, these\nstudies are uniquely able to address a lack of historical representation, an\nissue that has affected many biomedical datasets. In this work, we define\nrepresentativeness as the similarity to a target population distribution of a\nset of attributes and our goal is to mirror the U.S. population across\ndistributions of age, gender, race, and ethnicity. Many participatory studies\nrecruit at several institutions, so we introduce a computational approach to\nadaptively allocate recruitment resources among sites to improve\nrepresentativeness. In simulated recruitment of 10,000-participant cohorts from\nmedical centers in the STAR Clinical Research Network, we show that our\napproach yields a more representative cohort than existing baselines. Thus, we\nhighlight the value of computational modeling in guiding recruitment efforts.", "categories": "cs.LG cs.CY", "created": "2024-08-02", "doi": null, "arxiv_id": "2408.01375"}
{"title": "Resampling and averaging coordinates on data", "authors": [], "abstract": "We introduce algorithms for robustly computing intrinsic coordinates on point\nclouds. Our approach relies on generating many candidate coordinates by\nsubsampling the data and varying hyperparameters of the embedding algorithm\n(e.g., manifold learning). We then identify a subset of representative\nembeddings by clustering the collection of candidate coordinates and using\nshape descriptors from topological data analysis. The final output is the\nembedding obtained as an average of the representative embeddings using\ngeneralized Procrustes analysis. We validate our algorithm on both synthetic\ndata and experimental measurements from genomics, demonstrating robustness to\nnoise and outliers.", "categories": "stat.ML cs.CG cs.LG", "created": "2024-08-02", "doi": null, "arxiv_id": "2408.01379"}
{"title": "Coalitions of Large Language Models Increase the Robustness of AI Agents", "authors": [], "abstract": "The emergence of Large Language Models (LLMs) have fundamentally altered the\nway we interact with digital systems and have led to the pursuit of LLM powered\nAI agents to assist in daily workflows. LLMs, whilst powerful and capable of\ndemonstrating some emergent properties, are not logical reasoners and often\nstruggle to perform well at all sub-tasks carried out by an AI agent to plan\nand execute a workflow. While existing studies tackle this lack of proficiency\nby generalised pretraining at a huge scale or by specialised fine-tuning for\ntool use, we assess if a system comprising of a coalition of pretrained LLMs,\neach exhibiting specialised performance at individual sub-tasks, can match the\nperformance of single model agents. The coalition of models approach showcases\nits potential for building robustness and reducing the operational costs of\nthese AI agents by leveraging traits exhibited by specific models. Our findings\ndemonstrate that fine-tuning can be mitigated by considering a coalition of\npretrained models and believe that this approach can be applied to other\nnon-agentic systems which utilise LLMs.", "categories": "cs.CL", "created": "2024-08-02", "doi": null, "arxiv_id": "2408.01380"}
{"title": "Explaining a probabilistic prediction on the simplex with Shapley\n  compositions", "authors": [], "abstract": "Originating in game theory, Shapley values are widely used for explaining a\nmachine learning model's prediction by quantifying the contribution of each\nfeature's value to the prediction. This requires a scalar prediction as in\nbinary classification, whereas a multiclass probabilistic prediction is a\ndiscrete probability distribution, living on a multidimensional simplex. In\nsuch a multiclass setting the Shapley values are typically computed separately\non each class in a one-vs-rest manner, ignoring the compositional nature of the\noutput distribution. In this paper, we introduce Shapley compositions as a\nwell-founded way to properly explain a multiclass probabilistic prediction,\nusing the Aitchison geometry from compositional data analysis. We prove that\nthe Shapley composition is the unique quantity satisfying linearity, symmetry\nand efficiency on the Aitchison simplex, extending the corresponding axiomatic\nproperties of the standard Shapley value. We demonstrate this proper multiclass\ntreatment in a range of scenarios.", "categories": "cs.LG cs.GT", "created": "2024-08-02", "doi": null, "arxiv_id": "2408.01382"}
{"title": "NOLO: Navigate Only Look Once", "authors": [], "abstract": "The in-context learning ability of Transformer models has brought new\npossibilities to visual navigation. In this paper, we focus on the video\nnavigation setting, where an in-context navigation policy needs to be learned\npurely from videos in an offline manner, without access to the actual\nenvironment. For this setting, we propose Navigate Only Look Once (NOLO), a\nmethod for learning a navigation policy that possesses the in-context ability\nand adapts to new scenes by taking corresponding context videos as input\nwithout finetuning or re-training. To enable learning from videos, we first\npropose a pseudo action labeling procedure using optical flow to recover the\naction label from egocentric videos. Then, offline reinforcement learning is\napplied to learn the navigation policy. Through extensive experiments on\ndifferent scenes, we show that our algorithm outperforms baselines by a large\nmargin, which demonstrates the in-context learning ability of the learned\npolicy.", "categories": "cs.CV", "created": "2024-08-02", "doi": null, "arxiv_id": "2408.01384"}
{"title": "NeuralBeta: Estimating Beta Using Deep Learning", "authors": [], "abstract": "Traditional approaches to estimating beta in finance often involve rigid\nassumptions and fail to adequately capture beta dynamics, limiting their\neffectiveness in use cases like hedging. To address these limitations, we have\ndeveloped a novel method using neural networks called NeuralBeta, which is\ncapable of handling both univariate and multivariate scenarios and tracking the\ndynamic behavior of beta. To address the issue of interpretability, we\nintroduce a new output layer inspired by regularized weighted linear\nregression, which provides transparency into the model's decision-making\nprocess. We conducted extensive experiments on both synthetic and market data,\ndemonstrating NeuralBeta's superior performance compared to benchmark methods\nacross various scenarios, especially instances where beta is highly\ntime-varying, e.g., during regime shifts in the market. This model not only\nrepresents an advancement in the field of beta estimation, but also shows\npotential for applications in other financial contexts that assume linear\nrelationships.", "categories": "q-fin.ST cs.LG", "created": "2024-08-02", "doi": null, "arxiv_id": "2408.01387"}
{"title": "Improving Multilingual Neural Machine Translation by Utilizing Semantic\n  and Linguistic Features", "authors": [], "abstract": "The many-to-many multilingual neural machine translation can be regarded as\nthe process of integrating semantic features from the source sentences and\nlinguistic features from the target sentences. To enhance zero-shot\ntranslation, models need to share knowledge across languages, which can be\nachieved through auxiliary tasks for learning a universal representation or\ncross-lingual mapping. To this end, we propose to exploit both semantic and\nlinguistic features between multiple languages to enhance multilingual\ntranslation. On the encoder side, we introduce a disentangling learning task\nthat aligns encoder representations by disentangling semantic and linguistic\nfeatures, thus facilitating knowledge transfer while preserving complete\ninformation. On the decoder side, we leverage a linguistic encoder to integrate\nlow-level linguistic features to assist in the target language generation.\nExperimental results on multilingual datasets demonstrate significant\nimprovement in zero-shot translation compared to the baseline system, while\nmaintaining performance in supervised translation. Further analysis validates\nthe effectiveness of our method in leveraging both semantic and linguistic\nfeatures. The code is available at https://github.com/ictnlp/SemLing-MNMT.", "categories": "cs.CL", "created": "2024-08-02", "doi": null, "arxiv_id": "2408.01394"}
{"title": "Error analysis of DGTD for linear Maxwell equations with inhomogeneous\n  interface conditions", "authors": [], "abstract": "In the present paper we consider linear and isotropic Maxwell equations with\ninhomogeneous interface conditions. We discretize the problem with the\ndiscontinuous Galerkin method in space and with the leapfrog scheme in time. An\nanalytical setting is provided in which we show wellposedness of the problem,\nderive stability estimates, and exploit this in the error analysis to prove\nrigorous error bounds for both the spatial and full discretization. The\ntheoretical findings are confirmed with numerical experiments.", "categories": "math.NA cs.NA physics.comp-ph", "created": "2024-08-02", "doi": null, "arxiv_id": "2408.01398"}
{"title": "Pre-trained Language Models Improve the Few-shot Prompt Ability of\n  Decision Transformer", "authors": [], "abstract": "Decision Transformer (DT) has emerged as a promising class of algorithms in\noffline reinforcement learning (RL) tasks, leveraging pre-collected datasets\nand Transformer's capability to model long sequences. Recent works have\ndemonstrated that using parts of trajectories from training tasks as prompts in\nDT enhances its performance on unseen tasks, giving rise to Prompt-DT methods.\nHowever, collecting data from specific environments can be both costly and\nunsafe in many scenarios, leading to suboptimal performance and limited\nfew-shot prompt abilities due to the data-hungry nature of Transformer-based\nmodels. Additionally, the limited datasets used in pre-training make it\nchallenging for Prompt-DT type of methods to distinguish between various RL\ntasks through prompts alone. To address these challenges, we introduce the\nLanguage model-initialized Prompt Decision Transformer (LPDT), which leverages\npre-trained language models for meta-RL tasks and fine-tunes the model using\nLow-rank Adaptation (LoRA). We further incorporate prompt regularization to\neffectively differentiate between tasks based on prompt feature\nrepresentations. Our approach integrates pre-trained language model and RL\ntasks seamlessly. Extensive empirical studies demonstrate that initializing\nwith a pre-trained language model significantly enhances the performance of\nPrompt-DT on unseen tasks compared to baseline methods.", "categories": "cs.LG cs.AI cs.CL", "created": "2024-08-02", "doi": null, "arxiv_id": "2408.01402"}
{"title": "Derivation of Back-propagation for Graph Convolutional Networks using\n  Matrix Calculus and its Application to Explainable Artificial Intelligence", "authors": [], "abstract": "This paper provides a comprehensive and detailed derivation of the\nbackpropagation algorithm for graph convolutional neural networks using matrix\ncalculus. The derivation is extended to include arbitrary element-wise\nactivation functions and an arbitrary number of layers. The study addresses two\nfundamental problems, namely node classification and link prediction. To\nvalidate our method, we compare it with reverse-mode automatic differentiation.\nThe experimental results demonstrate that the median sum of squared errors of\nthe updated weight matrices, when comparing our method to the approach using\nreverse-mode automatic differentiation, falls within the range of $10^{-18}$ to\n$10^{-14}$. These outcomes are obtained from conducting experiments on a\nfive-layer graph convolutional network, applied to a node classification\nproblem on Zachary's karate club social network and a link prediction problem\non a drug-drug interaction network. Finally, we show how the derived\nclosed-form solution can facilitate the development of explainable AI and\nsensitivity analysis.", "categories": "cs.LG", "created": "2024-08-02", "doi": null, "arxiv_id": "2408.01408"}
{"title": "The random timestep Euler method and its continuous dynamics", "authors": [], "abstract": "ODE solvers with randomly sampled timestep sizes appear in the context of\nchaotic dynamical systems, differential equations with low regularity, and,\nimplicitly, in stochastic optimisation. In this work, we propose and study the\nstochastic Euler dynamics - a continuous-time Markov process that is equivalent\nto a linear spline interpolation of a random timestep (forward) Euler method.\nWe understand the stochastic Euler dynamics as a path-valued ansatz for the ODE\nsolution that shall be approximated. We first obtain qualitative insights by\nstudying deterministic Euler dynamics which we derive through a first order\napproximation to the infinitesimal generator of the stochastic Euler dynamics.\nThen we show convergence of the stochastic Euler dynamics to the ODE solution\nby studying the associated infinitesimal generators and by a novel local\ntruncation error analysis. Next we prove stability by an immediate analysis of\nthe random timestep Euler method and by deriving Foster-Lyapunov criteria for\nthe stochastic Euler dynamics; the latter also yield bounds on the speed of\nconvergence to stationarity. The paper ends with a discussion of second-order\nstochastic Euler dynamics and a series of numerical experiments that appear to\nverify our analytical results.", "categories": "math.NA cs.NA math.PR", "created": "2024-08-02", "doi": null, "arxiv_id": "2408.01409"}
{"title": "A Game Theoretic Analysis of High Occupancy Toll Lane Design", "authors": [], "abstract": "In this article, we study the optimal design of High Occupancy Toll (HOT)\nlanes. The traffic authority determines the road capacity allocation between\nHOT lanes and ordinary lanes, as well as the toll price charged for travelers\nusing HOT lanes who do not meet the high-occupancy eligibility criteria. We\ndevelop a game-theoretic model to analyze the decisions of travelers with\nheterogeneous preference parameters in values of time and carpool disutilities.\nThese travelers choose between paying or forming carpools to use the HOT lanes,\nor taking the ordinary lanes. Travelers' welfare depends on the congestion cost\nof the lane they use, the toll payment, and the carpool disutilities. For\nhighways with a single entrance and exit node, we provide a complete\ncharacterization of equilibrium strategies and a comparative statics analysis\nof how the equilibrium vehicle flow and travel time change with HOT capacity\nand toll price. We then extend the single segment model to highways with\nmultiple entrance and exit nodes. We extend the equilibrium concept and propose\nvarious design objectives considering traffic congestion, toll revenue, and\nsocial welfare. Using the data collected from the HOT lane of the California\nInterstate Highway 880 (I-880), we formulate a convex program to estimate the\ntravel demand and approximate the distribution of travelers' preference\nparameters. We then compute the optimal toll design of five segments for I-880\nfor achieve each one of the four objectives, and compare the optimal solution\nwith the current toll pricing.", "categories": "cs.GT", "created": "2024-08-02", "doi": null, "arxiv_id": "2408.01413"}
{"title": "Conditional LoRA Parameter Generation", "authors": [], "abstract": "Generative models have achieved remarkable success in image, video, and text\ndomains. Inspired by this, researchers have explored utilizing generative\nmodels to generate neural network parameters. However, these efforts have been\nlimited by the parameter size and the practicality of generating\nhigh-performance parameters. In this paper, we propose COND P-DIFF, a novel\napproach that demonstrates the feasibility of controllable high-performance\nparameter generation, particularly for LoRA (Low-Rank Adaptation) weights,\nduring the fine-tuning process. Specifically, we employ an autoencoder to\nextract efficient latent representations for parameters. We then train a\nconditional latent diffusion model to synthesize high-performing model\nparameters from random noise based on specific task conditions. Experimental\nresults in both computer vision and natural language processing domains\nconsistently demonstrate that COND P-DIFF can generate high-performance\nparameters conditioned on the given task. Moreover, we observe that the\nparameter distribution generated by COND P-DIFF exhibits differences compared\nto the distribution obtained through normal optimization methods, indicating a\ncertain level of generalization capability. Our work paves the way for further\nexploration of condition-driven parameter generation, offering a promising\ndirection for task-specific adaptation of neural networks.", "categories": "cs.AI cs.LG", "created": "2024-08-02", "doi": null, "arxiv_id": "2408.01415"}
{"title": "The Quest for the Right Mediator: A History, Survey, and Theoretical\n  Grounding of Causal Interpretability", "authors": [], "abstract": "Interpretability provides a toolset for understanding how and why neural\nnetworks behave in certain ways. However, there is little unity in the field:\nmost studies employ ad-hoc evaluations and do not share theoretical\nfoundations, making it difficult to measure progress and compare the pros and\ncons of different techniques. Furthermore, while mechanistic understanding is\nfrequently discussed, the basic causal units underlying these mechanisms are\noften not explicitly defined. In this paper, we propose a perspective on\ninterpretability research grounded in causal mediation analysis. Specifically,\nwe describe the history and current state of interpretability taxonomized\naccording to the types of causal units (mediators) employed, as well as methods\nused to search over mediators. We discuss the pros and cons of each mediator,\nproviding insights as to when particular kinds of mediators and search methods\nare most appropriate depending on the goals of a given study. We argue that\nthis framing yields a more cohesive narrative of the field, as well as\nactionable insights for future work. Specifically, we recommend a focus on\ndiscovering new mediators with better trade-offs between human-interpretability\nand compute-efficiency, and which can uncover more sophisticated abstractions\nfrom neural networks than the primarily linear mediators employed in current\nwork. We also argue for more standardized evaluations that enable principled\ncomparisons across mediator types, such that we can better understand when\nparticular causal units are better suited to particular use cases.", "categories": "cs.LG cs.AI", "created": "2024-08-02", "doi": null, "arxiv_id": "2408.01416"}
{"title": "Talk Less, Interact Better: Evaluating In-context Conversational\n  Adaptation in Multimodal LLMs", "authors": [], "abstract": "Humans spontaneously use increasingly efficient language as interactions\nprogress, by adapting and forming ad-hoc conventions. This phenomenon has been\nstudied extensively using reference games, showing properties of human language\nthat go beyond relaying intents. It remains unexplored whether multimodal large\nlanguage models (MLLMs) similarly increase communication efficiency during\ninteractions, and what mechanisms they may adopt for this purpose. We introduce\nICCA, an automated framework to evaluate such conversational adaptation as an\nin-context behavior in MLLMs. We evaluate several state-of-the-art MLLMs, and\nobserve that while they may understand the increasingly efficient language of\ntheir interlocutor, they do not spontaneously make their own language more\nefficient over time. This latter ability can only be elicited in some models\n(e.g., GPT-4) with heavy-handed prompting. This shows that this property of\nlinguistic interaction does not arise from current training regimes, even\nthough it is a common hallmark of human language. ICCA is available at\nhttps://github.com/lil-lab/ICCA.", "categories": "cs.CL cs.AI cs.CV cs.LG", "created": "2024-08-02", "doi": null, "arxiv_id": "2408.01417"}
{"title": "DebateQA: Evaluating Question Answering on Debatable Knowledge", "authors": [], "abstract": "The rise of large language models (LLMs) has enabled us to seek answers to\ninherently debatable questions on LLM chatbots, necessitating a reliable way to\nevaluate their ability. However, traditional QA benchmarks assume fixed answers\nare inadequate for this purpose. To address this, we introduce DebateQA, a\ndataset of 2,941 debatable questions, each accompanied by multiple\nhuman-annotated partial answers that capture a variety of perspectives. We\ndevelop two metrics: Perspective Diversity, which evaluates the\ncomprehensiveness of perspectives, and Dispute Awareness, which assesses if the\nLLM acknowledges the question's debatable nature. Experiments demonstrate that\nboth metrics align with human preferences and are stable across different\nunderlying models. Using DebateQA with two metrics, we assess 12 popular LLMs\nand retrieval-augmented generation methods. Our findings reveal that while LLMs\ngenerally excel at recognizing debatable issues, their ability to provide\ncomprehensive answers encompassing diverse perspectives varies considerably.", "categories": "cs.CL", "created": "2024-08-02", "doi": null, "arxiv_id": "2408.01419"}
{"title": "Mission Impossible: A Statistical Perspective on Jailbreaking LLMs", "authors": [], "abstract": "Large language models (LLMs) are trained on a deluge of text data with\nlimited quality control. As a result, LLMs can exhibit unintended or even\nharmful behaviours, such as leaking information, fake news or hate speech.\nCountermeasures, commonly referred to as preference alignment, include\nfine-tuning the pretrained LLMs with carefully crafted text examples of desired\nbehaviour. Even then, empirical evidence shows preference aligned LLMs can be\nenticed to harmful behaviour. This so called jailbreaking of LLMs is typically\nachieved by adversarially modifying the input prompt to the LLM. Our paper\nprovides theoretical insights into the phenomenon of preference alignment and\njailbreaking from a statistical perspective. Under our framework, we first show\nthat pretrained LLMs will mimic harmful behaviour if present in the training\ncorpus. Under that same framework, we then introduce a statistical notion of\nalignment, and lower-bound the jailbreaking probability, showing that it is\nunpreventable under reasonable assumptions. Based on our insights, we propose\nan alteration to the currently prevalent alignment strategy RLHF. Specifically,\nwe introduce a simple modification to the RLHF objective, we call E-RLHF, that\naims to increase the likelihood of safe responses. E-RLHF brings no additional\ntraining cost, and is compatible with other methods. Empirically, we\ndemonstrate that E-RLHF outperforms RLHF on all alignment problems put forward\nby the AdvBench and HarmBench project without sacrificing model performance as\nmeasured by the MT-Bench project.", "categories": "cs.LG cs.AI cs.CL", "created": "2024-08-02", "doi": null, "arxiv_id": "2408.01420"}
{"title": "Prompt Recursive Search: A Living Framework with Adaptive Growth in LLM\n  Auto-Prompting", "authors": [], "abstract": "Large Language Models (LLMs) exhibit remarkable proficiency in addressing a\ndiverse array of tasks within the Natural Language Processing (NLP) domain,\nwith various prompt design strategies significantly augmenting their\ncapabilities. However, these prompts, while beneficial, each possess inherent\nlimitations. The primary prompt design methodologies are twofold: The first,\nexemplified by the Chain of Thought (CoT), involves manually crafting prompts\nspecific to individual datasets, hence termed Expert-Designed Prompts (EDPs).\nOnce these prompts are established, they are unalterable, and their\neffectiveness is capped by the expertise of the human designers. When applied\nto LLMs, the static nature of EDPs results in a uniform approach to both simple\nand complex problems within the same dataset, leading to the inefficient use of\ntokens for straightforward issues. The second method involves prompts\nautonomously generated by the LLM, known as LLM-Derived Prompts (LDPs), which\nprovide tailored solutions to specific problems, mitigating the limitations of\nEDPs. However, LDPs may encounter a decline in performance when tackling\ncomplex problems due to the potential for error accumulation during the\nsolution planning process. To address these challenges, we have conceived a\nnovel Prompt Recursive Search (PRS) framework that leverages the LLM to\ngenerate solutions specific to the problem, thereby conserving tokens. The\nframework incorporates an assessment of problem complexity and an adjustable\nstructure, ensuring a reduction in the likelihood of errors. We have\nsubstantiated the efficacy of PRS framework through extensive experiments using\nLLMs with different numbers of parameters across a spectrum of datasets in\nvarious domains. Compared to the CoT method, the PRS method has increased the\naccuracy on the BBH dataset by 8% using Llama3-7B model, achieving a 22%\nimprovement.", "categories": "cs.CL cs.AI", "created": "2024-08-02", "doi": null, "arxiv_id": "2408.01423"}
{"title": "Using a CNN Model to Assess Visual Artwork's Creativity", "authors": [], "abstract": "Assessing artistic creativity has long challenged researchers, with\ntraditional methods proving time-consuming. Recent studies have applied machine\nlearning to evaluate creativity in drawings, but not paintings. Our research\naddresses this gap by developing a CNN model to automatically assess the\ncreativity of students' paintings. Using a dataset of 600 paintings by\nprofessionals and children, our model achieved 90% accuracy and faster\nevaluation times than human raters. This approach demonstrates the potential of\nmachine learning in advancing artistic creativity assessment, offering a more\nefficient alternative to traditional methods.", "categories": "cs.CV cs.HC cs.LG", "created": "2024-08-02", "doi": null, "arxiv_id": "2408.01481"}
{"title": "NeuralFactors: A Novel Factor Learning Approach to Generative Modeling\n  of Equities", "authors": [], "abstract": "The use of machine learning for statistical modeling (and thus, generative\nmodeling) has grown in popularity with the proliferation of time series models,\ntext-to-image models, and especially large language models. Fundamentally, the\ngoal of classical factor modeling is statistical modeling of stock returns, and\nin this work, we explore using deep generative modeling to enhance classical\nfactor models. Prior work has explored the use of deep generative models in\norder to model hundreds of stocks, leading to accurate risk forecasting and\nalpha portfolio construction; however, that specific model does not allow for\neasy factor modeling interpretation in that the factor exposures cannot be\ndeduced. In this work, we introduce NeuralFactors, a novel machine-learning\nbased approach to factor analysis where a neural network outputs factor\nexposures and factor returns, trained using the same methodology as variational\nautoencoders. We show that this model outperforms prior approaches both in\nterms of log-likelihood performance and computational efficiency. Further, we\nshow that this method is competitive to prior work in generating realistic\nsynthetic data, covariance estimation, risk analysis (e.g., value at risk, or\nVaR, of portfolios), and portfolio optimization. Finally, due to the connection\nto classical factor analysis, we analyze how the factors our model learns\ncluster together and show that the factor exposures could be used for embedding\nstocks.", "categories": "q-fin.ST cs.LG", "created": "2024-08-02", "doi": null, "arxiv_id": "2408.01499"}
{"title": "Efficient Graph Coloring with Neural Networks: A Physics-Inspired\n  Approach for Large Graphs", "authors": [], "abstract": "The graph coloring problem is an optimization problem involving the\nassignment of one of q colors to each vertex of a graph such that no two\nadjacent vertices share the same color. This problem is NP-hard and arises in\nvarious practical applications. In this work, we present a novel algorithm that\nleverages graph neural networks to tackle the problem efficiently, particularly\nfor large graphs. We propose a physics-inspired approach that leverages tools\nused in statistical mechanics to improve the training and performance of the\nalgorithm. The scaling of our method is evaluated for different connectivities\nand graph sizes. Finally, we demonstrate the effectiveness of our method on a\ndataset of Erdos-Renyi graphs, showing its applicability also in hard-to-solve\nconnectivity regions where traditional methods struggle.", "categories": "cs.LG", "created": "2024-08-02", "doi": null, "arxiv_id": "2408.01503"}
{"title": "MoDE: Effective Multi-task Parameter Efficient Fine-Tuning with a\n  Mixture of Dyadic Experts", "authors": [], "abstract": "Parameter-efficient fine-tuning techniques like Low-Rank Adaptation (LoRA)\nhave revolutionized the adaptation of large language models (LLMs) to diverse\ntasks. Recent efforts have explored mixtures of LoRA modules for multi-task\nsettings. However, our analysis reveals redundancy in the down-projection\nmatrices of these architectures. This observation motivates our proposed\nmethod, Mixture of Dyadic Experts (MoDE), which introduces a novel design for\nefficient multi-task adaptation. This is done by sharing the down-projection\nmatrix across tasks and employing atomic rank-one adapters, coupled with\nrouters that allow more sophisticated task-level specialization. Our design\nallows for more fine-grained mixing, thereby increasing the model's ability to\njointly handle multiple tasks. We evaluate MoDE on the Supernatural\nInstructions (SNI) benchmark consisting of a diverse set of 700+ tasks and\ndemonstrate that it outperforms state-of-the-art multi-task parameter-efficient\nfine-tuning (PEFT) methods, without introducing additional parameters. Our\nfindings contribute to a deeper understanding of parameter efficiency in\nmulti-task LLM adaptation and provide a practical solution for deploying\nhigh-performing, lightweight models.", "categories": "cs.CL", "created": "2024-08-02", "doi": null, "arxiv_id": "2408.01505"}
{"title": "Blockchain Economic Denial of Sustainability Attack: Exploiting Latency\n  Optimization in Ethereum Transaction Forwarding", "authors": [], "abstract": "Strategies related to the blockchain concept of Extractable Value (MEV/BEV),\nsuch as arbitrage, front- or back-running create an economic incentive for\nnetwork nodes to reduce latency, including minimizing transaction validation\ntime -- a core feature to secure blockchain networks. A modified node, that\nneglects to filter invalid transactions in the Ethereum P2P network, introduces\nnovel attack vectors. In this work, we formalize and evaluate a Blockchain\nEconomic Denial of Sustainability (EDoS) attack, which can cause financial\nlosses in traffic costs for operators of modified nodes. We 1) mathematically\ndefine the attack model, 2) identify thousands of empirical instances of this\nsimilar attack in the wild, 3) empirically measure the model parameters from\nour two monitoring nodes, and 4) conduct attack simulations on the local\nnetwork to compare its performance with existing Denial-of-Service attacks. We\nshow that an attacker can amplify network traffic at modified nodes by a factor\nof 3,600, and cause economic damages 13,800 times greater than the amount\nneeded to carry out the attack. Despite these risks, aggressive latency\nreduction may still be profitable enough to justify the existence of modified\nnodes. To assess this trade-off, we 1) simulate the transaction validation\nprocess in the local network and 2) empirically measure the latency reduction\nby deploying our modified node in the Ethereum testnet. We conclude with a\ncost-benefit analysis of skipping validation and provide mitigation strategies\nagainst this attack.", "categories": "cs.CR", "created": "2024-08-02", "doi": null, "arxiv_id": "2408.01508"}
{"title": "Adaptive Planning with Generative Models under Uncertainty", "authors": [], "abstract": "Planning with generative models has emerged as an effective decision-making\nparadigm across a wide range of domains, including reinforcement learning and\nautonomous navigation. While continuous replanning at each timestep might seem\nintuitive because it allows decisions to be made based on the most recent\nenvironmental observations, it results in substantial computational challenges,\nprimarily due to the complexity of the generative model's underlying deep\nlearning architecture. Our work addresses this challenge by introducing a\nsimple adaptive planning policy that leverages the generative model's ability\nto predict long-horizon state trajectories, enabling the execution of multiple\nactions consecutively without the need for immediate replanning. We propose to\nuse the predictive uncertainty derived from a Deep Ensemble of inverse dynamics\nmodels to dynamically adjust the intervals between planning sessions. In our\nexperiments conducted on locomotion tasks within the OpenAI Gym framework, we\ndemonstrate that our adaptive planning policy allows for a reduction in\nreplanning frequency to only about 10% of the steps without compromising the\nperformance. Our results underscore the potential of generative modeling as an\nefficient and effective tool for decision-making.", "categories": "cs.RO cs.LG", "created": "2024-08-02", "doi": null, "arxiv_id": "2408.01510"}
{"title": "From Program Logics to Language Logics", "authors": [], "abstract": "Program logics are a powerful formal method in the context of program\nverification. Can we develop a counterpart of program logics in the context of\nlanguage verification? This paper proposes language logics, which allow for\nstatements of the form $\\{P\\}\\ \\mathcal{X}\\ \\{Q\\}$ where $\\mathcal{X}$, the\nsubject of analysis, can be a language component such as a piece of grammar, a\ntyping rule, a reduction rule or other parts of a language definition. To\ndemonstrate our approach, we develop $\\mathbb{L}$, a language logic that can be\nused to analyze language definitions on various aspects of language design. We\nillustrate $\\mathbb{L}$ to the analysis of some selected aspects of a\nprogramming language. We have also implemented an automated prover for\n$\\mathbb{L}$, and we confirm that the tool repeats these analyses. Ultimately,\n$\\mathbb{L}$ cannot verify languages. Nonetheless, we believe that this paper\nprovides a strong first step towards adopting the methods of program logics for\nthe analysis of languages.", "categories": "cs.PL", "created": "2024-08-02", "doi": null, "arxiv_id": "2408.01515"}
{"title": "Gradient flow in parameter space is equivalent to linear interpolation\n  in output space", "authors": [], "abstract": "We prove that the usual gradient flow in parameter space that underlies many\ntraining algorithms for neural networks in deep learning can be continuously\ndeformed into an adapted gradient flow which yields (constrained) Euclidean\ngradient flow in output space. Moreover, if the Jacobian of the outputs with\nrespect to the parameters is full rank (for fixed training data), then the time\nvariable can be reparametrized so that the resulting flow is simply linear\ninterpolation, and a global minimum can be achieved.", "categories": "cs.LG cs.AI math-ph math.MP math.OC stat.ML", "created": "2024-08-02", "doi": null, "arxiv_id": "2408.01517"}
{"title": "Multi-Unit Floor Plan Recognition and Reconstruction Using Improved\n  Semantic Segmentation of Raster-Wise Floor Plans", "authors": [], "abstract": "Digital twins have a major potential to form a significant part of urban\nmanagement in emergency planning, as they allow more efficient designing of the\nescape routes, better orientation in exceptional situations, and faster rescue\nintervention. Nevertheless, creating the twins still remains a largely manual\neffort, due to a lack of 3D-representations, which are available only in\nlimited amounts for some new buildings. Thus, in this paper we aim to\nsynthesize 3D information from commonly available 2D architectural floor plans.\nWe propose two novel pixel-wise segmentation methods based on the MDA-Unet and\nMACU-Net architectures with improved skip connections, an attention mechanism,\nand a training objective together with a reconstruction part of the pipeline,\nwhich vectorizes the segmented plans to create a 3D model. The proposed methods\nare compared with two other state-of-the-art techniques and several benchmark\ndatasets. On the commonly used CubiCasa benchmark dataset, our methods have\nachieved the mean F1 score of 0.86 over five examined classes, outperforming\nthe other pixel-wise approaches tested. We have also made our code publicly\navailable to support research in the field.", "categories": "cs.CV", "created": "2024-08-02", "doi": null, "arxiv_id": "2408.01526"}
{"title": "Analyzing LLMs' Capabilities to Establish Implicit User Sentiment of\n  Software Desirability", "authors": [], "abstract": "This study explores the use of several LLMs for providing quantitative\nzero-shot sentiment analysis of implicit software desirability expressed by\nusers. The study provides scaled numerical sentiment analysis unlike other\nmethods that simply classify sentiment as positive, neutral, or negative.\nNumerical analysis provides deeper insights into the magnitude of sentiment, to\ndrive better decisions regarding product desirability.\n  Data is collected through the use of the Microsoft Product Desirability\nToolkit (PDT), a well-known qualitative user experience analysis tool. For\ninitial exploration, the PDT metric was given to users of ZORQ, a gamification\nsystem used in undergraduate computer science education. The PDT data collected\nwas fed through several LLMs (Claude Sonnet 3 and 3.5, GPT4, and GPT4o) and\nthrough a leading transfer learning technique, Twitter-Roberta-Base-Sentiment\n(TRBS), and through Vader, a leading sentiment analysis tool, for quantitative\nsentiment analysis. Each system was asked to evaluate the data in two ways,\nfirst by looking at the sentiment expressed in the PDT word/explanation pairs;\nand by looking at the sentiment expressed by the users in their grouped\nselection of five words and explanations, as a whole. Each LLM was also asked\nto provide its confidence (low, medium, high) in its sentiment score, along\nwith an explanation of why it selected the sentiment value.\n  All LLMs tested were able to statistically detect user sentiment from the\nusers' grouped data, whereas TRBS and Vader were not. The confidence and\nexplanation of confidence provided by the LLMs assisted in understanding the\nuser sentiment. This study adds to a deeper understanding of evaluating user\nexperiences, toward the goal of creating a universal tool that quantifies\nimplicit sentiment expressed.", "categories": "cs.CL cs.AI cs.HC cs.LG cs.SE", "created": "2024-08-02", "doi": null, "arxiv_id": "2408.01527"}
{"title": "Can multivariate Granger causality detect directed connectivity of a\n  multistable and dynamic biological decision network model?", "authors": [], "abstract": "Extracting causal connections can advance interpretable AI and machine\nlearning. Granger causality (GC) is a robust statistical method for estimating\ndirected influences (DC) between signals. While GC has been widely applied to\nanalysing neuronal signals in biological neural networks and other domains, its\napplication to complex, nonlinear, and multistable neural networks is less\nexplored. In this study, we applied time-domain multi-variate Granger causality\n(MVGC) to the time series neural activity of all nodes in a trained multistable\nbiologically based decision neural network model with real-time decision\nuncertainty monitoring. Our analysis demonstrated that challenging two-choice\ndecisions, where input signals could be closely matched, and the appropriate\napplication of fine-grained sliding time windows, could readily reveal the\noriginal model's DC. Furthermore, the identified DC varied based on whether the\nnetwork had correct or error decisions. Integrating the identified DC from\ndifferent decision outcomes recovered most of the original model's\narchitecture, despite some spurious and missing connectivity. This approach\ncould be used as an initial exploration to enhance the interpretability and\ntransparency of dynamic multistable and nonlinear biological or AI systems by\nrevealing causal connections throughout different phases of neural network\ndynamics and outcomes.", "categories": "q-bio.NC cs.LG cs.NE math.DS", "created": "2024-08-02", "doi": null, "arxiv_id": "2408.01528"}
{"title": "A Structured Framework for Predicting Sustainable Aviation Fuel\n  Properties using Liquid-Phase FTIR and Machine Learning", "authors": [], "abstract": "Sustainable aviation fuels have the potential for reducing emissions and\nenvironmental impact. To help identify viable sustainable aviation fuels and\naccelerate research, several machine learning models have been developed to\npredict relevant physiochemical properties. However, many of the models have\nlimited applicability, leverage data from complex analytical techniques with\nconfined spectral ranges, or use feature decomposition methods that have\nlimited interpretability. Using liquid-phase Fourier Transform Infrared (FTIR)\nspectra, this study presents a structured method for creating accurate and\ninterpretable property prediction models for neat molecules, aviation fuels,\nand blends. Liquid-phase FTIR spectra measurements can be collected quickly and\nconsistently, offering high reliability, sensitivity, and component specificity\nusing less than 2 mL of sample. The method first decomposes FTIR spectra into\nfundamental building blocks using Non-negative Matrix Factorization (NMF) to\nenable scientific analysis of FTIR spectra attributes and fuel properties. The\nNMF features are then used to create five ensemble models for predicting final\nboiling point, flash point, freezing point, density at 15C, and kinematic\nviscosity at -20C. All models were trained using experimental property data\nfrom neat molecules, aviation fuels, and blends. The models accurately predict\nproperties while enabling interpretation of relationships between compositional\nelements of a fuel, such as functional groups or chemical classes, and its\nproperties. To support sustainable aviation fuel research and development, the\nmodels and data are available on an interactive web tool.", "categories": "physics.chem-ph cs.LG", "created": "2024-08-02", "doi": null, "arxiv_id": "2408.01530"}
{"title": "An Adaptive Tensor-Train Decomposition Approach for Efficient Deep\n  Neural Network Compression", "authors": [], "abstract": "In the field of model compression, choosing an appropriate rank for tensor\ndecomposition is pivotal for balancing model compression rate and efficiency.\nHowever, this selection, whether done manually or through optimization-based\nautomatic methods, often increases computational complexity. Manual rank\nselection lacks efficiency and scalability, often requiring extensive\ntrial-and-error, while optimization-based automatic methods significantly\nincrease the computational burden. To address this, we introduce a novel,\nautomatic, and budget-aware rank selection method for efficient model\ncompression, which employs Layer-Wise Imprinting Quantitation (LWIQ). LWIQ\nquantifies each layer's significance within a neural network by integrating a\nproxy classifier. This classifier assesses the layer's impact on overall model\nperformance, allowing for a more informed adjustment of tensor rank.\nFurthermore, our approach includes a scaling factor to cater to varying\ncomputational budget constraints. This budget awareness eliminates the need for\nrepetitive rank recalculations for different budget scenarios. Experimental\nresults on the CIFAR-10 dataset show that our LWIQ improved by 63.2$\\%$ in rank\nsearch efficiency, and the accuracy only dropped by 0.86$\\%$ with 3.2x less\nmodel size on the ResNet-56 model as compared to the state-of-the-art\nproxy-based automatic tensor rank selection method.", "categories": "cs.LG", "created": "2024-08-02", "doi": null, "arxiv_id": "2408.01534"}
{"title": "Active Learning for Neural PDE Solvers", "authors": [], "abstract": "Solving partial differential equations (PDEs) is a fundamental problem in\nengineering and science. While neural PDE solvers can be more efficient than\nestablished numerical solvers, they often require large amounts of training\ndata that is costly to obtain. Active Learning (AL) could help surrogate models\nreach the same accuracy with smaller training sets by querying classical\nsolvers with more informative initial conditions and PDE parameters. While AL\nis more common in other domains, it has yet to be studied extensively for\nneural PDE solvers. To bridge this gap, we introduce AL4PDE, a modular and\nextensible active learning benchmark. It provides multiple parametric PDEs and\nstate-of-the-art surrogate models for the solver-in-the-loop setting, enabling\nthe evaluation of existing and the development of new AL methods for PDE\nsolving. We use the benchmark to evaluate batch active learning algorithms such\nas uncertainty- and feature-based methods. We show that AL reduces the average\nerror by up to 71% compared to random sampling and significantly reduces\nworst-case errors. Moreover, AL generates similar datasets across repeated\nruns, with consistent distributions over the PDE parameters and initial\nconditions. The acquired datasets are reusable, providing benefits for\nsurrogate models not involved in the data generation.", "categories": "cs.LG cs.AI cs.CE cs.NE", "created": "2024-08-02", "doi": null, "arxiv_id": "2408.01536"}
{"title": "SceneMotion: From Agent-Centric Embeddings to Scene-Wide Forecasts", "authors": [], "abstract": "Self-driving vehicles rely on multimodal motion forecasts to effectively\ninteract with their environment and plan safe maneuvers. We introduce\nSceneMotion, an attention-based model for forecasting scene-wide motion modes\nof multiple traffic agents. Our model transforms local agent-centric embeddings\ninto scene-wide forecasts using a novel latent context module. This module\nlearns a scene-wide latent space from multiple agent-centric embeddings,\nenabling joint forecasting and interaction modeling. The competitive\nperformance in the Waymo Open Interaction Prediction Challenge demonstrates the\neffectiveness of our approach. Moreover, we cluster future waypoints in time\nand space to quantify the interaction between agents. We merge all modes and\nanalyze each mode independently to determine which clusters are resolved\nthrough interaction or result in conflict. Our implementation is available at:\nhttps://github.com/kit-mrt/future-motion", "categories": "cs.CV cs.RO", "created": "2024-08-02", "doi": null, "arxiv_id": "2408.01537"}
{"title": "Delay Conditioned Generative Modelling of Resistive Drift in Memristors", "authors": [], "abstract": "The modelling of memristive devices is an essential part of the development\nof novel in-memory computing systems. Models are needed to enable the accurate\nand efficient simulation of memristor device characteristics, for purposes of\ntesting the performance of the devices or the feasibility of their use in\nfuture neuromorphic and in-memory computing architectures. The consideration of\nmemristor non-idealities is an essential part of any modelling approach. The\nnature of the deviation of memristive devices from their initial state,\nparticularly at ambient temperature and in the absence of a stimulating\nvoltage, is of key interest, as it dictates their reliability as information\nstorage media - a property that is of importance for both traditional storage\nand neuromorphic applications. In this paper, we investigate the use of a\ngenerative modelling approach for the simulation of the delay and initial\nresistance-conditioned resistive drift distribution of memristive devices. We\nintroduce a data normalisation scheme and a novel training technique to enable\nthe generative model to be conditioned on the continuous inputs. The proposed\ngenerative modelling approach is suited for use in end-to-end training and\ndevice modelling scenarios, including learned data storage applications, due to\nits simulation efficiency and differentiability.", "categories": "cs.ET eess.SP", "created": "2024-08-02", "doi": null, "arxiv_id": "2408.01539"}
{"title": "Guardians of Image Quality: Benchmarking Defenses Against Adversarial\n  Attacks on Image Quality Metrics", "authors": [], "abstract": "In the field of Image Quality Assessment (IQA), the adversarial robustness of\nthe metrics poses a critical concern. This paper presents a comprehensive\nbenchmarking study of various defense mechanisms in response to the rise in\nadversarial attacks on IQA. We systematically evaluate 25 defense strategies,\nincluding adversarial purification, adversarial training, and certified\nrobustness methods. We applied 14 adversarial attack algorithms of various\ntypes in both non-adaptive and adaptive settings and tested these defenses\nagainst them. We analyze the differences between defenses and their\napplicability to IQA tasks, considering that they should preserve IQA scores\nand image quality. The proposed benchmark aims to guide future developments and\naccepts submissions of new methods, with the latest results available online:\nhttps://videoprocessing.ai/benchmarks/iqa-defenses.html.", "categories": "cs.CV eess.IV", "created": "2024-08-02", "doi": null, "arxiv_id": "2408.01541"}
{"title": "Non-linear Analysis Based ECG Classification of Cardiovascular Disorders", "authors": [], "abstract": "Multi-channel ECG-based cardiac disorders detection has an impact on cardiac\ncare and treatment. Limitations of existing methods included variation in ECG\nwaveforms due to the location of electrodes, high non-linearity in the signal,\nand amplitude measurement in millivolts. The present study reports a non-linear\nanalysis-based methodology that utilizes Recurrence plot visualization. The\npatterned occurrence of well-defined structures, such as the QRS complex, can\nbe exploited effectively using Recurrence plots. This Recurrence-based method\nis applied to the publicly available Physikalisch-Technische Bundesanstalt\n(PTB) dataset from PhysioNet database, where we studied four classes of\ndifferent cardiac disorders (Myocardial infarction, Bundle branch blocks,\nCardiomyopathy, and Dysrhythmia) and healthy controls, achieving an impressive\nclassification accuracy of 100%. Additionally, t-SNE plot visualizations of the\nlatent space embeddings derived from Recurrence plots and Recurrence\nQuantification Analysis features reveal a clear demarcation between the\nconsidered cardiac disorders and healthy individuals, demonstrating the\npotential of this approach.", "categories": "cs.CV", "created": "2024-08-02", "doi": null, "arxiv_id": "2408.01542"}
{"title": "A Decomposition of Interaction Force for Multi-Agent Co-Manipulation", "authors": [], "abstract": "Multi-agent human-robot co-manipulation is a poorly understood process with\nmany inputs that potentially affect agent behavior. This paper explores one\nsuch input known as interaction force. Interaction force is potentially a\nprimary component in communication that occurs during co-manipulation. There\nare, however, many different perspectives and definitions of interaction force\nin the literature. Therefore, a decomposition of interaction force is proposed\nthat provides a consistent way of ascertaining the state of an agent relative\nto the group for multi-agent co-manipulation. This proposed method extends a\ncurrent definition from one to four degrees of freedom, does not rely on a\npredefined object path, and is independent of the number of agents acting on\nthe system and their locations and input wrenches (forces and torques). In\naddition, all of the necessary measures can be obtained by a self-contained\nrobotic system, allowing for a more flexible and adaptive approach for future\nco-manipulation robot controllers.", "categories": "cs.RO eess.SP", "created": "2024-08-02", "doi": null, "arxiv_id": "2408.01543"}
{"title": "Momentum Capture and Prediction System Based on Wimbledon Open2023\n  Tournament Data", "authors": [], "abstract": "There is a hidden energy in tennis, which cannot be seen or touched. It is\nthe force that controls the flow of the game and is present in all types of\nmatches. This mysterious force is Momentum. This study introduces an evaluation\nmodel that synergizes the Entropy Weight Method (EWM) and Gray Relation\nAnalysis (GRA) to quantify momentum's impact on match outcomes. Empirical\nvalidation was conducted through Mann-Whitney U and Kolmogorov-Smirnov tests,\nwhich yielded p values of 0.0043 and 0.00128,respectively. These results\nunderscore the non-random association between momentum shifts and match\noutcomes, highlighting the critical role of momentum in tennis. Otherwise, our\ninvestigation foucus is the creation of a predictive model that combines the\nadvanced machine learning algorithm XGBoost with the SHAP framework. This model\nenables precise predictions of match swings with exceptional accuracy (0.999013\nfor multiple matches and 0.992738 for finals). The model's ability to identify\nthe influence of specific factors on match dynamics,such as bilateral distance\nrun during points, demonstrates its prowess.The model's generalizability was\nthoroughly evaluated using datasets from the four Grand Slam tournaments. The\nresults demonstrate its remarkable adaptability to different match\nscenarios,despite minor variations in predictive accuracy. It offers strategic\ninsights that can help players effectively respond to opponents' shifts in\nmomentum,enhancing their competitive edge.", "categories": "cs.LG stat.AP", "created": "2024-08-02", "doi": null, "arxiv_id": "2408.01544"}
{"title": "Trainable Pointwise Decoder Module for Point Cloud Segmentation", "authors": [], "abstract": "Point cloud segmentation (PCS) aims to make per-point predictions and enables\nrobots and autonomous driving cars to understand the environment. The range\nimage is a dense representation of a large-scale outdoor point cloud, and\nsegmentation models built upon the image commonly execute efficiently. However,\nthe projection of the point cloud onto the range image inevitably leads to\ndropping points because, at each image coordinate, only one point is kept\ndespite multiple points being projected onto the same location. More\nimportantly, it is challenging to assign correct predictions to the dropped\npoints that belong to the classes different from the kept point class. Besides,\nexisting post-processing methods, such as K-nearest neighbor (KNN) search and\nkernel point convolution (KPConv), cannot be trained with the models in an\nend-to-end manner or cannot process varying-density outdoor point clouds well,\nthereby enabling the models to achieve sub-optimal performance. To alleviate\nthis problem, we propose a trainable pointwise decoder module (PDM) as the\npost-processing approach, which gathers weighted features from the neighbors\nand then makes the final prediction for the query point. In addition, we\nintroduce a virtual range image-guided copy-rotate-paste (VRCrop) strategy in\ndata augmentation. VRCrop constrains the total number of points and eliminates\nundesirable artifacts in the augmented point cloud. With PDM and VRCrop,\nexisting range image-based segmentation models consistently perform better than\ntheir counterparts on the SemanticKITTI, SemanticPOSS, and nuScenes datasets.", "categories": "cs.CV", "created": "2024-08-02", "doi": null, "arxiv_id": "2408.01548"}
{"title": "Reducing COVID-19 Misinformation Spread by Introducing Information\n  Diffusion Delay Using Agent-based Modeling", "authors": [], "abstract": "With the explosive growth of the Coronavirus Pandemic (COVID-19),\nmisinformation on social media has developed into a global phenomenon with\nwidespread and detrimental societal effects. Despite recent progress and\nefforts in detecting COVID-19 misinformation on social media networks, this\ntask remains challenging due to the complexity, diversity, multi-modality, and\nhigh costs of fact-checking or annotation. In this research, we introduce a\nsystematic and multidisciplinary agent-based modeling approach to limit the\nspread of COVID-19 misinformation and interpret the dynamic actions of users\nand communities in evolutionary online (or offline) social media networks. Our\nmodel was applied to a Twitter network associated with an armed protest\ndemonstration against the COVID-19 lockdown in Michigan state in May, 2020. We\nimplemented a one-median problem to categorize the Twitter network into six key\ncommunities (nodes) and identified information exchange (links) within the\nnetwork. We measured the response time to COVID-19 misinformation spread in the\nnetwork and employed a cybernetic organizational method to monitor the Twitter\nnetwork. The overall misinformation mitigation strategy was evaluated, and\nagents were allocated to interact with the network based on the measured\nresponse time and feedback. The proposed model prioritized the communities\nbased on the agents response times at the operational level. It then optimized\nagent allocation to limit the spread of COVID19 related misinformation from\ndifferent communities, improved the information diffusion delay threshold to up\nto 3 minutes, and ultimately enhanced the mitigation process to reduce\nmisinformation spread across the entire network.", "categories": "cs.SI physics.soc-ph", "created": "2024-08-02", "doi": null, "arxiv_id": "2408.01549"}
{"title": "PiCoGen2: Piano cover generation with transfer learning approach and\n  weakly aligned data", "authors": [], "abstract": "Piano cover generation aims to create a piano cover from a pop song. Existing\napproaches mainly employ supervised learning and the training demands\nstrongly-aligned and paired song-to-piano data, which is built by remapping\npiano notes to song audio. This would, however, result in the loss of piano\ninformation and accordingly cause inconsistencies between the original and\nremapped piano versions. To overcome this limitation, we propose a transfer\nlearning approach that pre-trains our model on piano-only data and fine-tunes\nit on weakly-aligned paired data constructed without note remapping. During\npre-training, to guide the model to learn piano composition concepts instead of\nmerely transcribing audio, we use an existing lead sheet transcription model as\nthe encoder to extract high-level features from the piano recordings. The\npre-trained model is then fine-tuned on the paired song-piano data to transfer\nthe learned composition knowledge to the pop song domain. Our evaluation shows\nthat this training strategy enables our model, named PiCoGen2, to attain\nhigh-quality results, outperforming baselines on both objective and subjective\nmetrics across five pop genres.", "categories": "cs.SD eess.AS", "created": "2024-08-02", "doi": null, "arxiv_id": "2408.01551"}
{"title": "Exploring the Frontiers of Energy Efficiency using Power Management at\n  System Scale", "authors": [], "abstract": "In the face of surging power demands for exascale HPC systems, this work\ntackles the critical challenge of understanding the impact of software-driven\npower management techniques like Dynamic Voltage and Frequency Scaling (DVFS)\nand Power Capping. These techniques have been actively developed over the past\nfew decades. By combining insights from GPU benchmarking to understand\napplication power profiles, we present a telemetry data-driven approach for\nderiving energy savings projections. This approach has been demonstrably\napplied to the Frontier supercomputer at scale. Our findings based on three\nmonths of telemetry data indicate that, for certain resource-constrained jobs,\nsignificant energy savings (up to 8.5%) can be achieved without compromising\nperformance. This translates to a substantial cost reduction, equivalent to\n1438 MWh of energy saved. The key contribution of this work lies in the\nmethodology for establishing an upper limit for these best-case scenarios and\nits successful application. This work sheds light on potential energy savings\nand empowers HPC professionals to optimize the power-performance trade-off\nwithin constrained power budgets, not only for the exascale era but also\nbeyond.", "categories": "cs.DC", "created": "2024-08-02", "doi": null, "arxiv_id": "2408.01552"}
{"title": "Multi-task SAR Image Processing via GAN-based Unsupervised Manipulation", "authors": [], "abstract": "Generative Adversarial Networks (GANs) have shown tremendous potential in\nsynthesizing a large number of realistic SAR images by learning patterns in the\ndata distribution. Some GANs can achieve image editing by introducing latent\ncodes, demonstrating significant promise in SAR image processing. Compared to\ntraditional SAR image processing methods, editing based on GAN latent space\ncontrol is entirely unsupervised, allowing image processing to be conducted\nwithout any labeled data. Additionally, the information extracted from the data\nis more interpretable. This paper proposes a novel SAR image processing\nframework called GAN-based Unsupervised Editing (GUE), aiming to address the\nfollowing two issues: (1) disentangling semantic directions in the GAN latent\nspace and finding meaningful directions; (2) establishing a comprehensive SAR\nimage processing framework while achieving multiple image processing functions.\nIn the implementation of GUE, we decompose the entangled semantic directions in\nthe GAN latent space by training a carefully designed network. Moreover, we can\naccomplish multiple SAR image processing tasks (including despeckling,\nlocalization, auxiliary identification, and rotation editing) in a single\ntraining process without any form of supervision. Extensive experiments\nvalidate the effectiveness of the proposed method.", "categories": "cs.CV eess.IV", "created": "2024-08-02", "doi": null, "arxiv_id": "2408.01553"}
{"title": "Robot-Enabled Machine Learning-Based Diagnosis of Gastric Cancer Polyps\n  Using Partial Surface Tactile Imaging", "authors": [], "abstract": "In this paper, to collectively address the existing limitations on endoscopic\ndiagnosis of Advanced Gastric Cancer (AGC) Tumors, for the first time, we\npropose (i) utilization and evaluation of our recently developed Vision-based\nTactile Sensor (VTS), and (ii) a complementary Machine Learning (ML) algorithm\nfor classifying tumors using their textural features. Leveraging a seven DoF\nrobotic manipulator and unique custom-designed and additively-manufactured\nrealistic AGC tumor phantoms, we demonstrated the advantages of automated data\ncollection using the VTS addressing the problem of data scarcity and biases\nencountered in traditional ML-based approaches. Our synthetic-data-trained ML\nmodel was successfully evaluated and compared with traditional ML models\nutilizing various statistical metrics even under mixed morphological\ncharacteristics and partial sensor contact.", "categories": "cs.RO cs.AI cs.CV cs.LG", "created": "2024-08-02", "doi": null, "arxiv_id": "2408.01554"}
{"title": "pathfinder: A Semantic Framework for Literature Review and Knowledge\n  Discovery in Astronomy", "authors": [], "abstract": "The exponential growth of astronomical literature poses significant\nchallenges for researchers navigating and synthesizing general insights or even\ndomain-specific knowledge. We present Pathfinder, a machine learning framework\ndesigned to enable literature review and knowledge discovery in astronomy,\nfocusing on semantic searching with natural language instead of syntactic\nsearches with keywords. Utilizing state-of-the-art large language models (LLMs)\nand a corpus of 350,000 peer-reviewed papers from the Astrophysics Data System\n(ADS), Pathfinder offers an innovative approach to scientific inquiry and\nliterature exploration. Our framework couples advanced retrieval techniques\nwith LLM-based synthesis to search astronomical literature by semantic context\nas a complement to currently existing methods that use keywords or citation\ngraphs. It addresses complexities of jargon, named entities, and temporal\naspects through time-based and citation-based weighting schemes. We demonstrate\nthe tool's versatility through case studies, showcasing its application in\nvarious research scenarios. The system's performance is evaluated using custom\nbenchmarks, including single-paper and multi-paper tasks. Beyond literature\nreview, Pathfinder offers unique capabilities for reformatting answers in ways\nthat are accessible to various audiences (e.g. in a different language or as\nsimplified text), visualizing research landscapes, and tracking the impact of\nobservatories and methodologies. This tool represents a significant advancement\nin applying AI to astronomical research, aiding researchers at all career\nstages in navigating modern astronomy literature.", "categories": "astro-ph.IM cs.DL cs.IR", "created": "2024-08-02", "doi": null, "arxiv_id": "2408.01556"}
{"title": "Enhanced Knee Kinematics: Leveraging Deep Learning and Morphing\n  Algorithms for 3D Implant Modeling", "authors": [], "abstract": "Accurate reconstruction of implanted knee models is crucial in orthopedic\nsurgery and biomedical engineering, enhancing preoperative planning, optimizing\nimplant design, and improving surgical outcomes. Traditional methods rely on\nlabor-intensive and error-prone manual segmentation. This study proposes a\nnovel approach using machine learning (ML) algorithms and morphing techniques\nfor precise 3D reconstruction of implanted knee models.\n  The methodology begins with acquiring preoperative imaging data, such as\nfluoroscopy or X-ray images of the patient's knee joint. A convolutional neural\nnetwork (CNN) is then trained to automatically segment the femur contour of the\nimplanted components, significantly reducing manual effort and ensuring high\naccuracy.\n  Following segmentation, a morphing algorithm generates a personalized 3D\nmodel of the implanted knee joint, using the segmented data and biomechanical\nprinciples. This algorithm considers implant position, size, and orientation to\nsimulate the knee joint's shape. By integrating morphological data with\nimplant-specific parameters, the reconstructed models accurately reflect the\npatient's implant anatomy and configuration.\n  The approach's effectiveness is demonstrated through quantitative\nevaluations, including comparisons with ground truth data and existing\ntechniques. In 19 test cases involving various implant types, the ML-based\nsegmentation method showed superior accuracy and consistency compared to manual\nsegmentation, with an average RMS error of 0.58 +/- 0.14 mm.\n  This research advances orthopedic surgery by providing a robust framework for\nthe automated reconstruction of implanted knee models. Leveraging ML and\nmorphing algorithms, clinicians and researchers gain valuable insights into\npatient-specific knee anatomy, implant biomechanics, and surgical planning,\nleading to improved patient outcomes and enhanced quality of care.", "categories": "eess.IV cs.CV", "created": "2024-08-02", "doi": null, "arxiv_id": "2408.01557"}
{"title": "Accelerating Domain-Aware Electron Microscopy Analysis Using Deep\n  Learning Models with Synthetic Data and Image-Wide Confidence Scoring", "authors": [], "abstract": "The integration of machine learning (ML) models enhances the efficiency,\naffordability, and reliability of feature detection in microscopy, yet their\ndevelopment and applicability are hindered by the dependency on scarce and\noften flawed manually labeled datasets and a lack of domain awareness. We\naddressed these challenges by creating a physics-based synthetic image and data\ngenerator, resulting in a machine learning model that achieves comparable\nprecision (0.86), recall (0.63), F1 scores (0.71), and engineering property\npredictions (R2=0.82) to a model trained on human-labeled data. We enhanced\nboth models by using feature prediction confidence scores to derive an\nimage-wide confidence metric, enabling simple thresholding to eliminate\nambiguous and out-of-domain images resulting in performance boosts of 5-30%\nwith a filtering-out rate of 25%. Our study demonstrates that synthetic data\ncan eliminate human reliance in ML and provides a means for domain awareness in\ncases where many feature detections per image are needed.", "categories": "cs.CV cond-mat.mtrl-sci", "created": "2024-08-02", "doi": null, "arxiv_id": "2408.01558"}
{"title": "Welfare, sustainability, and equity evaluation of the New York City\n  Interborough Express using spatially heterogeneous mode choice models", "authors": [], "abstract": "The Metropolitan Transit Authority (MTA) proposed building a new light rail\nroute called the Interborough Express (IBX) to provide a direct, fast transit\nlinkage between Queens and Brooklyn. An open-access synthetic citywide trip\nagenda dataset and a block-group-level mode choice model are used to assess the\npotential impact IBX could bring to New York City (NYC). IBX could save 28.1\nminutes to potential riders across the city. For travelers either going to or\ndeparting from areas close to IBX, the average time saving is projected to be\n29.7 minutes. IBX is projected to have more than 254 thousand daily ridership\nafter its completion (69% higher than reported in the official IBX proposal).\nAmong those riders, more than 78 thousand people (30.8%) would come from\nlow-income households while 165 thousand people (64.7%) would start or end\nalong the IBX corridor. The addition of IBX would attract more than 50 thousand\nadditional daily trips to transit mode, among which more than 16 thousand would\nbe switched from using private vehicles, reducing potential greenhouse gas\n(GHG) emissions by 29.28 metric tons per day. IBX can also bring significant\nconsumer surplus benefits to the communities, which are estimated to be $1.25\nUSD per trip, or as high as $1.64 per trip made by a low-income traveler. While\nbenefits are proportionately higher for lower-income users, the service does\nnot appear to significantly reduce the proportion of travelers whose consumer\nsurpluses fall below 10% of the population average (already quite low).", "categories": "cs.CY", "created": "2024-08-02", "doi": null, "arxiv_id": "2408.01562"}
{"title": "Self-Supervised Depth Estimation Based on Camera Models", "authors": [], "abstract": "Depth estimationn is a critical topic for robotics and vision-related tasks.\nIn monocular depth estimation, in comparison with supervised learning that\nrequires expensive ground truth labeling, self-supervised methods possess great\npotential due to no labeling cost. However, self-supervised learning still has\na large gap with supervised learning in depth estimation performance.\nMeanwhile, scaling is also a major issue for monocular unsupervised depth\nestimation, which commonly still needs ground truth scale from GPS, LiDAR, or\nexisting maps to correct. In deep learning era, while existing methods mainly\nrely on the exploration of image relationships to train the unsupervised neural\nnetworks, fundamental information provided by the camera itself has been\ngenerally ignored, which can provide extensive supervision information for\nfree, without the need for any extra equipment to provide supervision signals.\nUtilizing the camera itself's intrinsics and extrinsics, depth information can\nbe calculated for ground regions and regions connecting ground based on\nphysical principles, providing free supervision information without any other\nsensors. The method is easy to realize and can be a component to enhance the\neffects of all the unsupervised methods.", "categories": "cs.CV", "created": "2024-08-02", "doi": null, "arxiv_id": "2408.01565"}
{"title": "Full-range Head Pose Geometric Data Augmentations", "authors": [], "abstract": "Many head pose estimation (HPE) methods promise the ability to create\nfull-range datasets, theoretically allowing the estimation of the rotation and\npositioning of the head from various angles. However, these methods are only\naccurate within a range of head angles; exceeding this specific range led to\nsignificant inaccuracies. This is dominantly explained by unclear specificity\nof the coordinate systems and Euler Angles used in the foundational rotation\nmatrix calculations. Here, we addressed these limitations by presenting (1)\nmethods that accurately infer the correct coordinate system and Euler angles in\nthe correct axis-sequence, (2) novel formulae for 2D geometric augmentations of\nthe rotation matrices under the (SPECIFIC) coordinate system, (3) derivations\nfor the correct drawing routines for rotation matrices and poses, and (4)\nmathematical experimentation and verification that allow proper pitch-yaw\ncoverage for full-range head pose dataset generation. Performing our\naugmentation techniques to existing head pose estimation methods demonstrated a\nsignificant improvement to the model performance. Code will be released upon\npaper acceptance.", "categories": "cs.CV", "created": "2024-08-02", "doi": null, "arxiv_id": "2408.01566"}
{"title": "TURTLMap: Real-time Localization and Dense Mapping of Low-texture\n  Underwater Environments with a Low-cost Unmanned Underwater Vehicle", "authors": [], "abstract": "Significant work has been done on advancing localization and mapping in\nunderwater environments. Still, state-of-the-art methods are challenged by\nlow-texture environments, which is common for underwater settings. This makes\nit difficult to use existing methods in diverse, real-world scenes. In this\npaper, we present TURTLMap, a novel solution that focuses on textureless\nunderwater environments through a real-time localization and mapping method. We\nshow that this method is low-cost, and capable of tracking the robot\naccurately, while constructing a dense map of a low-textured environment in\nreal-time. We evaluate the proposed method using real-world data collected in\nan indoor water tank with a motion capture system and ground truth reference\nmap. Qualitative and quantitative results validate the proposed system achieves\naccurate and robust localization and precise dense mapping, even when subject\nto wave conditions. The project page for TURTLMap is\nhttps://umfieldrobotics.github.io/TURTLMap.", "categories": "cs.RO", "created": "2024-08-02", "doi": null, "arxiv_id": "2408.01569"}
{"title": "On Validation of Search & Retrieval of Tissue Images in Digital\n  Pathology", "authors": [], "abstract": "Medical images play a crucial role in modern healthcare by providing vital\ninformation for diagnosis, treatment planning, and disease monitoring. Fields\nsuch as radiology and pathology rely heavily on accurate image interpretation,\nwith radiologists examining X-rays, CT scans, and MRIs to diagnose conditions\nfrom fractures to cancer, while pathologists use microscopy and digital images\nto detect cellular abnormalities for diagnosing cancers and infections. The\ntechnological advancements have exponentially increased the volume and\ncomplexity of medical images, necessitating efficient tools for management and\nretrieval. Content-Based Image Retrieval (CBIR) systems address this need by\nsearching and retrieving images based on visual content, enhancing diagnostic\naccuracy by allowing clinicians to find similar cases and compare pathological\npatterns. Comprehensive validation of image search engines in medical\napplications involves evaluating performance metrics like accuracy, indexing,\nand search times, and storage overhead, ensuring reliable and efficient\nretrieval of accurate results, as demonstrated by recent validations in\nhistopathology.", "categories": "eess.IV cs.CV cs.IR", "created": "2024-08-02", "doi": null, "arxiv_id": "2408.01570"}
{"title": "Counterfactual Explanations for Medical Image Classification and\n  Regression using Diffusion Autoencoder", "authors": [], "abstract": "Counterfactual explanations (CEs) aim to enhance the interpretability of\nmachine learning models by illustrating how alterations in input features would\naffect the resulting predictions. Common CE approaches require an additional\nmodel and are typically constrained to binary counterfactuals. In contrast, we\npropose a novel method that operates directly on the latent space of a\ngenerative model, specifically a Diffusion Autoencoder (DAE). This approach\noffers inherent interpretability by enabling the generation of CEs and the\ncontinuous visualization of the model's internal representation across decision\nboundaries.\n  Our method leverages the DAE's ability to encode images into a semantically\nrich latent space in an unsupervised manner, eliminating the need for labeled\ndata or separate feature extraction models. We show that these latent\nrepresentations are helpful for medical condition classification and the\nordinal regression of severity pathologies, such as vertebral compression\nfractures (VCF) and diabetic retinopathy (DR). Beyond binary CEs, our method\nsupports the visualization of ordinal CEs using a linear model, providing\ndeeper insights into the model's decision-making process and enhancing\ninterpretability.\n  Experiments across various medical imaging datasets demonstrate the method's\nadvantages in interpretability and versatility. The linear manifold of the\nDAE's latent space allows for meaningful interpolation and manipulation, making\nit a powerful tool for exploring medical image properties. Our code is\navailable at https://github.com/matanat/dae_counterfactual.", "categories": "cs.CV cs.LG", "created": "2024-08-02", "doi": null, "arxiv_id": "2408.01571"}
{"title": "Advancing Mixed Reality Game Development: An Evaluation of a Visual Game\n  Analytics Tool in Action-Adventure and FPS Genres", "authors": [], "abstract": "In response to the unique challenges of Mixed Reality (MR) game development,\nwe developed GAMR, an analytics tool specifically designed for MR games. GAMR\naims to assist developers in identifying and resolving gameplay issues\neffectively. It features reconstructed gameplay sessions, heatmaps for data\nvisualization, a comprehensive annotation system, and advanced tracking for\nhands, camera, input, and audio, providing in-depth insights for nuanced game\nanalysis.\n  To evaluate GAMR's effectiveness, we conducted an experimental study with\ngame development students across two game genres: action-adventure and\nfirst-person shooter (FPS). The participants used GAMR and provided feedback on\nits utility. The results showed a significant positive impact of GAMR in both\ngenres, particularly in action-adventure games. This study demonstrates GAMR's\neffectiveness in MR game development and suggests its potential to influence\nfuture MR game analytics, addressing the specific needs of developers in this\nevolving area.", "categories": "cs.HC", "created": "2024-08-02", "doi": "10.1145/3677055", "arxiv_id": "2408.01573"}
{"title": "Deep Learning Framework for History Matching CO2 Storage with 4D Seismic\n  and Monitoring Well Data", "authors": [], "abstract": "Geological carbon storage entails the injection of megatonnes of\nsupercritical CO2 into subsurface formations. The properties of these\nformations are usually highly uncertain, which makes design and optimization of\nlarge-scale storage operations challenging. In this paper we introduce a\nhistory matching strategy that enables the calibration of formation properties\nbased on early-time observations. Early-time assessments are essential to\nassure the operation is performing as planned. Our framework involves two\nfit-for-purpose deep learning surrogate models that provide predictions for\nin-situ monitoring well data and interpreted time-lapse (4D) seismic saturation\ndata. These two types of data are at very different scales of resolution, so it\nis appropriate to construct separate, specialized deep learning networks for\ntheir prediction. This approach results in a workflow that is more\nstraightforward to design and more efficient to train than a single surrogate\nthat provides global high-fidelity predictions. The deep learning models are\nintegrated into a hierarchical Markov chain Monte Carlo (MCMC) history matching\nprocedure. History matching is performed on a synthetic case with and without\n4D seismic data, which allows us to quantify the impact of 4D seismic on\nuncertainty reduction. The use of both data types is shown to provide\nsubstantial uncertainty reduction in key geomodel parameters and to enable\naccurate predictions of CO2 plume dynamics. The overall history matching\nframework developed in this study represents an efficient way to integrate\nmultiple data types and to assess the impact of each on uncertainty reduction\nand performance predictions.", "categories": "cs.LG physics.geo-ph stat.ML", "created": "2024-08-02", "doi": null, "arxiv_id": "2408.01575"}
{"title": "Autonomous Integration of Bench-Top Wet Lab Equipment", "authors": [], "abstract": "Laboratory automation is an expensive and complicated endeavor with limited\ninflexible options for small-scale labs. We develop a prototype system for\ntending to a bench-top centrifuge using computer vision methods for color\ndetection and circular Hough Transforms to detect and localize centrifuge\nbuckets. Initial results show that the prototype is capable of automating the\nusage of regular bench-top lab equipment.", "categories": "cs.RO", "created": "2024-08-02", "doi": null, "arxiv_id": "2408.01576"}
{"title": "MAC Address De-Randomization Using Multi-Channel Sniffers and Two-Stage\n  Clustering", "authors": [], "abstract": "MAC randomization is a widely used technique implemented on most modern\nsmartphones to protect user's privacy against tracking based on Probe Request\nframes capture. However, there exist weaknesses in such a methodology which may\nstill expose distinctive information, allowing to track the device generating\nthe Probe Requests. Such techniques, known as MAC de-randomization algorithms,\ngenerally exploit Information Elements (IEs) contained in the Probe Requests\nand use clustering methodologies to group together frames belonging to the same\ndevice. While effective on heterogeneous device types, such techniques are not\nable to differentiate among devices of identical type and running the same\nOperating System (OS). In this paper, we propose a MAC de-randomization\ntechnique able to overcome such a weakness. First, we propose a new dataset of\nProbe Requests captured from devices sharing the same characteristics.\nSecondly, we observe that the time-frequency pattern of Probe Request emission\nis unique among devices and can therefore be used as a discriminative feature.\nWe embed such a feature in a two-stage clustering methodology and show through\nexperiments its effectiveness compared to state-of-the-art techniques based\nsolely on IEs fingerprinting. The original dataset used in this work is made\npublicly available for reproducible research.", "categories": "cs.NI", "created": "2024-08-02", "doi": null, "arxiv_id": "2408.01578"}
{"title": "THOR2: Leveraging Topological Soft Clustering of Color Space for\n  Human-Inspired Object Recognition in Unseen Environments", "authors": [], "abstract": "Visual object recognition in unseen and cluttered indoor environments is a\nchallenging problem for mobile robots. This study presents a 3D shape and\ncolor-based descriptor, TOPS2, for point clouds generated from RGB-D images and\nan accompanying recognition framework, THOR2. The TOPS2 descriptor embodies\nobject unity, a human cognition mechanism, by retaining the slicing-based\ntopological representation of 3D shape from the TOPS descriptor while capturing\nobject color information through slicing-based color embeddings computed using\na network of coarse color regions. These color regions, analogous to the\nMacAdam ellipses identified in human color perception, are obtained using the\nMapper algorithm, a topological soft-clustering technique. THOR2, trained using\nsynthetic data, demonstrates markedly improved recognition accuracy compared to\nTHOR, its 3D shape-based predecessor, on two benchmark real-world datasets: the\nOCID dataset capturing cluttered scenes from different viewpoints and the UW-IS\nOccluded dataset reflecting different environmental conditions and degrees of\nobject occlusion recorded using commodity hardware. THOR2 also outperforms\nbaseline deep learning networks, and a widely-used ViT adapted for RGB-D inputs\non both the datasets. Therefore, THOR2 is a promising step toward achieving\nrobust recognition in low-cost robots.", "categories": "cs.CV", "created": "2024-08-02", "doi": null, "arxiv_id": "2408.01579"}
{"title": "Controlling Dataflows with a Bolt-on Data Escrow", "authors": [], "abstract": "The data-driven economy has created tremendous value in our society.\nIndividuals share their data with platforms in exchange for services such as\nsearch, social networks, and health recommendations. Platforms use the data to\nprovide those services and create other revenue-generating opportunities, e.g.,\nselling the data to data brokers. With the ever-expanding data economy comes\nthe growing concern about potential data misuse. While most platforms give\nindividuals certain control over their data (i.e., what data is being shared),\nindividuals do not know how the data will be used once shared; they cannot\ncontrol the purpose.\n  In this paper, we introduce a data escrow design that permits individuals to\nobserve all dataflows - not just what is shared but for what purpose. Rather\nthan data flowing to the platform, the platform delegates their computation to\nthe escrow, where individuals can observe and manage their data. To make the\ndata escrow practical, we design and implement a prototype that works alongside\nthe Apple ecosystem; specifically, we retrofit the Apple SDKs with a\nprogramming interface to enable delegated computation. Our solution does not\ndepend on Apple's software and can be applied to other platforms, but building\nfor Apple lets us study the main hypothesis of our work: whether such a data\nescrow solution is a feasible alternative to today's data governance. We show\nthat our escrow prototype implementation is efficient, and we analyze the\ndataflows in real-world apps and show that the escrow's programming interface\nsupports implementing a wide range of dataflows.", "categories": "cs.DB", "created": "2024-08-02", "doi": null, "arxiv_id": "2408.01580"}
{"title": "Huge Ensembles Part II: Properties of a Huge Ensemble of Hindcasts\n  Generated with Spherical Fourier Neural Operators", "authors": [], "abstract": "In Part I, we created an ensemble based on Spherical Fourier Neural\nOperators. As initial condition perturbations, we used bred vectors, and as\nmodel perturbations, we used multiple checkpoints trained independently from\nscratch. Based on diagnostics that assess the ensemble's physical fidelity, our\nensemble has comparable performance to operational weather forecasting systems.\nHowever, it requires several orders of magnitude fewer computational resources.\nHere in Part II, we generate a huge ensemble (HENS), with 7,424 members\ninitialized each day of summer 2023. We enumerate the technical requirements\nfor running huge ensembles at this scale. HENS precisely samples the tails of\nthe forecast distribution and presents a detailed sampling of internal\nvariability. For extreme climate statistics, HENS samples events 4$\\sigma$ away\nfrom the ensemble mean. At each grid cell, HENS improves the skill of the most\naccurate ensemble member and enhances coverage of possible future trajectories.\nAs a weather forecasting model, HENS issues extreme weather forecasts with\nbetter uncertainty quantification. It also reduces the probability of outlier\nevents, in which the verification value lies outside the ensemble forecast\ndistribution.", "categories": "cs.LG physics.ao-ph", "created": "2024-08-02", "doi": null, "arxiv_id": "2408.01581"}
{"title": "Conformal Diffusion Models for Individual Treatment Effect Estimation\n  and Inference", "authors": [], "abstract": "Estimating treatment effects from observational data is of central interest\nacross numerous application domains. Individual treatment effect offers the\nmost granular measure of treatment effect on an individual level, and is the\nmost useful to facilitate personalized care. However, its estimation and\ninference remain underdeveloped due to several challenges. In this article, we\npropose a novel conformal diffusion model-based approach that addresses those\nintricate challenges. We integrate the highly flexible diffusion modeling, the\nmodel-free statistical inference paradigm of conformal inference, along with\npropensity score and covariate local approximation that tackle distributional\nshifts. We unbiasedly estimate the distributions of potential outcomes for\nindividual treatment effect, construct an informative confidence interval, and\nestablish rigorous theoretical guarantees. We demonstrate the competitive\nperformance of the proposed method over existing solutions through extensive\nnumerical studies.", "categories": "stat.ML cs.AI cs.LG stat.ME", "created": "2024-08-02", "doi": null, "arxiv_id": "2408.01582"}
{"title": "GPUDrive: Data-driven, multi-agent driving simulation at 1 million FPS", "authors": [], "abstract": "Multi-agent learning algorithms have been successful at generating superhuman\nplanning in a wide variety of games but have had little impact on the design of\ndeployed multi-agent planners. A key bottleneck in applying these techniques to\nmulti-agent planning is that they require billions of steps of experience. To\nenable the study of multi-agent planning at this scale, we present GPUDrive, a\nGPU-accelerated, multi-agent simulator built on top of the Madrona Game Engine\nthat can generate over a million steps of experience per second. Observation,\nreward, and dynamics functions are written directly in C++, allowing users to\ndefine complex, heterogeneous agent behaviors that are lowered to\nhigh-performance CUDA. We show that using GPUDrive we are able to effectively\ntrain reinforcement learning agents over many scenes in the Waymo Motion\ndataset, yielding highly effective goal-reaching agents in minutes for\nindividual scenes and generally capable agents in a few hours. We ship these\ntrained agents as part of the code base at\nhttps://github.com/Emerge-Lab/gpudrive.", "categories": "cs.AI cs.AR cs.GR cs.PF", "created": "2024-08-02", "doi": null, "arxiv_id": "2408.01584"}
{"title": "OpenLogParser: Unsupervised Parsing with Open-Source Large Language\n  Models", "authors": [], "abstract": "Log parsing is a critical step that transforms unstructured log data into\nstructured formats, facilitating subsequent log-based analysis. Traditional\nsyntax-based log parsers are efficient and effective, but they often experience\ndecreased accuracy when processing logs that deviate from the predefined rules.\nRecently, large language models (LLM) based log parsers have shown superior\nparsing accuracy. However, existing LLM-based parsers face three main\nchallenges: 1)time-consuming and labor-intensive manual labeling for\nfine-tuning or in-context learning, 2)increased parsing costs due to the vast\nvolume of log data and limited context size of LLMs, and 3)privacy risks from\nusing commercial models like ChatGPT with sensitive log information. To\novercome these limitations, this paper introduces OpenLogParser, an\nunsupervised log parsing approach that leverages open-source LLMs (i.e.,\nLlama3-8B) to enhance privacy and reduce operational costs while achieving\nstate-of-the-art parsing accuracy. OpenLogParser first groups logs with similar\nstatic text but varying dynamic variables using a fixed-depth grouping tree. It\nthen parses logs within these groups using three components: i)similarity\nscoring-based retrieval augmented generation: selects diverse logs within each\ngroup based on Jaccard similarity, helping the LLM distinguish between static\ntext and dynamic variables; ii)self-reflection: iteratively query LLMs to\nrefine log templates to improve parsing accuracy; and iii) log template memory:\nstores parsed templates to reduce LLM queries for improved parsing efficiency.\nOur evaluation on LogHub-2.0 shows that OpenLogParser achieves 25% higher\nparsing accuracy and processes logs 2.7 times faster compared to\nstate-of-the-art LLM-based parsers. In short, OpenLogParser addresses privacy\nand cost concerns of using commercial LLMs while achieving state-of-the-arts\nparsing efficiency and accuracy.", "categories": "cs.SE cs.AI", "created": "2024-08-02", "doi": null, "arxiv_id": "2408.01585"}
{"title": "Deep Learning Approach for Ear Recognition and Longitudinal Evaluation\n  in Children", "authors": [], "abstract": "Ear recognition as a biometric modality is becoming increasingly popular,\nwith promising broader application areas. While current applications involve\nadults, one of the challenges in ear recognition for children is the rapid\nstructural changes in the ear as they age. This work introduces a foundational\nlongitudinal dataset collected from children aged 4 to 14 years over a 2.5-year\nperiod and evaluates ear recognition performance in this demographic. We\npresent a deep learning based approach for ear recognition, using an ensemble\nof VGG16 and MobileNet, focusing on both adult and child datasets, with an\nemphasis on longitudinal evaluation for children.", "categories": "cs.CV", "created": "2024-08-02", "doi": null, "arxiv_id": "2408.01588"}
{"title": "Soil Sample Search in Partially Observable Environments", "authors": [], "abstract": "To work in unknown outdoor environments, autonomous sampling machines need\nthe ability to target samples despite limited visibility and robotic arm reach\ndistance. We design a heuristic guided search method to speed up the search\nprocess and more efficiently localize the approximate center of soil regions.\nThrough simulation experiments, we assess the effectiveness of the proposed\nalgorithm and discover superior performance in terms of speed, distance\ntraveled, and success rate compared to naive baselines.", "categories": "cs.RO", "created": "2024-08-02", "doi": null, "arxiv_id": "2408.01589"}
{"title": "Interpretations, Representations, and Stereotypes of Caste within\n  Text-to-Image Generators", "authors": [], "abstract": "The surge in the popularity of text-to-image generators (T2Is) has been\nmatched by extensive research into ensuring fairness and equitable outcomes,\nwith a focus on how they impact society. However, such work has typically\nfocused on globally-experienced identities or centered Western contexts. In\nthis paper, we address interpretations, representations, and stereotypes\nsurrounding a tragically underexplored context in T2I research: caste. We\nexamine how the T2I Stable Diffusion displays people of various castes, and\nwhat professions they are depicted as performing. Generating 100 images per\nprompt, we perform CLIP-cosine similarity comparisons with default depictions\nof an 'Indian person' by Stable Diffusion, and explore patterns of similarity.\nOur findings reveal how Stable Diffusion outputs perpetuate systems of\n'castelessness', equating Indianness with high-castes and depicting\ncaste-oppressed identities with markers of poverty. In particular, we note the\nstereotyping and representational harm towards the historically-marginalized\nDalits, prominently depicted as living in rural areas and always at protests.\nOur findings underscore a need for a caste-aware approach towards T2I design,\nand we conclude with design recommendations.", "categories": "cs.CY", "created": "2024-08-02", "doi": null, "arxiv_id": "2408.01590"}
{"title": "\"I don't see myself represented here at all\": User Experiences of Stable\n  Diffusion Outputs Containing Representational Harms across Gender Identities\n  and Nationalities", "authors": [], "abstract": "Though research into text-to-image generators (T2Is) such as Stable Diffusion\nhas demonstrated their amplification of societal biases and potentials to cause\nharm, such research has primarily relied on computational methods instead of\nseeking information from real users who experience harm, which is a significant\nknowledge gap. In this paper, we conduct the largest human subjects study of\nStable Diffusion, with a combination of crowdsourced data from 133 crowdworkers\nand 14 semi-structured interviews across diverse countries and genders. Through\na mixed-methods approach of intra-set cosine similarity hierarchies (i.e.,\ncomparing multiple Stable Diffusion outputs for the same prompt with each other\nto examine which result is 'closest' to the prompt) and qualitative thematic\nanalysis, we first demonstrate a large disconnect between user expectations for\nStable Diffusion outputs with those generated, evidenced by a set of Stable\nDiffusion renditions of `a Person' providing images far away from such\nexpectations. We then extend this finding of general dissatisfaction into\nhighlighting representational harms caused by Stable Diffusion upon our\nsubjects, especially those with traditionally marginalized identities,\nsubjecting them to incorrect and often dehumanizing stereotypes about their\nidentities. We provide recommendations for a harm-aware approach to (re)design\nfuture versions of Stable Diffusion and other T2Is.", "categories": "cs.CY cs.SI", "created": "2024-08-02", "doi": null, "arxiv_id": "2408.01594"}
{"title": "Trustworthy Machine Learning under Social and Adversarial Data Sources", "authors": [], "abstract": "Machine learning has witnessed remarkable breakthroughs in recent years. As\nmachine learning permeates various aspects of daily life, individuals and\norganizations increasingly interact with these systems, exhibiting a wide range\nof social and adversarial behaviors. These behaviors may have a notable impact\non the behavior and performance of machine learning systems. Specifically,\nduring these interactions, data may be generated by strategic individuals,\ncollected by self-interested data collectors, possibly poisoned by adversarial\nattackers, and used to create predictors, models, and policies satisfying\nmultiple objectives. As a result, the machine learning systems' outputs might\ndegrade, such as the susceptibility of deep neural networks to adversarial\nexamples (Shafahi et al., 2018; Szegedy et al., 2013) and the diminished\nperformance of classic algorithms in the presence of strategic individuals\n(Ahmadi et al., 2021). Addressing these challenges is imperative for the\nsuccess of machine learning in societal settings.", "categories": "cs.LG cs.AI cs.GT", "created": "2024-08-02", "doi": null, "arxiv_id": "2408.01596"}
{"title": "Physics-Informed Geometry-Aware Neural Operator", "authors": [], "abstract": "Engineering design problems often involve solving parametric Partial\nDifferential Equations (PDEs) under variable PDE parameters and domain\ngeometry. Recently, neural operators have shown promise in learning PDE\noperators and quickly predicting the PDE solutions. However, training these\nneural operators typically requires large datasets, the acquisition of which\ncan be prohibitively expensive. To overcome this, physics-informed training\noffers an alternative way of building neural operators, eliminating the high\ncomputational costs associated with Finite Element generation of training data.\nNevertheless, current physics-informed neural operators struggle with\nlimitations, either in handling varying domain geometries or varying PDE\nparameters. In this research, we introduce a novel method, the Physics-Informed\nGeometry-Aware Neural Operator (PI-GANO), designed to simultaneously generalize\nacross both PDE parameters and domain geometries. We adopt a geometry encoder\nto capture the domain geometry features, and design a novel pipeline to\nintegrate this component within the existing DCON architecture. Numerical\nresults demonstrate the accuracy and efficiency of the proposed method.", "categories": "cs.LG cs.NA math.NA", "created": "2024-08-02", "doi": null, "arxiv_id": "2408.01600"}
{"title": "FIVB ranking: Misstep in the right direction", "authors": [], "abstract": "This work uses a statistical framework to present and evaluate the ranking\nalgorithm that has been used by F\\'ed\\'eration Internationale de Volleyball\n(FIVB) since 2020. The salient feature of the FIVB ranking is the use of the\nprobabilistic model, which explicitly calculates the probabilities of the games\nto come. This explicit modeling is new in the context of official ranking, and\nwe study the optimality of its parameters as well as its relationship with the\nranking algorithm as such. The analysis is carried out using both analytical\nand numerical methods. We conclude that, from the modeling perspective, the use\nof the home-field advantage (HFA) would be beneficial and that the weighting of\nthe game results is counterproductive. Regarding the algorithm itself, we\nexplain the rationale beyond the approximations currently used and explain how\nto find new parameters which improve the performance. Finally, we propose a new\nmodel that drastically simplifies both the implementation and interpretation of\nthe resulting algorithm.", "categories": "cs.LG", "created": "2024-08-02", "doi": null, "arxiv_id": "2408.01603"}
{"title": "Efficient Data-driven Joint-level Calibration of Cable-driven Surgical\n  Robots", "authors": [], "abstract": "Knowing accurate joint positions is crucial for safe and precise control of\nlaparoscopic surgical robots, especially for the automation of surgical\nsub-tasks. These robots have often been designed with cable-driven arms and\ntools because cables allow for larger motors to be placed at the base of the\nrobot, further from the operating area where space is at a premium. However, by\nconnecting the joint to its motor with a cable, any stretch in the cable can\nlead to errors in kinematic estimation from encoders at the motor, which can\nresult in difficulties for accurate control of the surgical tool. In this work,\nwe propose an efficient data-driven calibration of positioning joints of such\nrobots, in this case the RAVEN-II surgical robotics research platform. While\nthe calibration takes only 8-21 minutes, the accuracy of the calibrated joints\nremains high during a 6-hour heavily loaded operation, suggesting desirable\nfeasibility in real practice. The calibration models take original robot states\nas input and are trained using zig-zag trajectories within a desired sparsity,\nrequiring no additional sensors after training. Compared to fixed offset\ncompensation, the Deep Neural Network calibration model can further reduce 76\npercent of error and achieve accuracy of 0.104 deg, 0.120 deg, and 0.118 mm in\njoints 1, 2, and 3, respectively. In contrast to end-to-end models, experiments\nsuggest that the DNN model achieves better accuracy and faster convergence when\noutputting the error to correct original inaccurate joint positions.\nFurthermore, a linear regression model is shown to have 160 times faster\ninference speed than DNN models for application within the 1000 Hz servo\ncontrol loop, with slightly compromised accuracy.", "categories": "cs.RO cs.SY eess.SY", "created": "2024-08-02", "doi": null, "arxiv_id": "2408.01604"}
{"title": "CYBERSECEVAL 3: Advancing the Evaluation of Cybersecurity Risks and\n  Capabilities in Large Language Models", "authors": [], "abstract": "We are releasing a new suite of security benchmarks for LLMs, CYBERSECEVAL 3,\nto continue the conversation on empirically measuring LLM cybersecurity risks\nand capabilities. CYBERSECEVAL 3 assesses 8 different risks across two broad\ncategories: risk to third parties, and risk to application developers and end\nusers. Compared to previous work, we add new areas focused on offensive\nsecurity capabilities: automated social engineering, scaling manual offensive\ncyber operations, and autonomous offensive cyber operations. In this paper we\ndiscuss applying these benchmarks to the Llama 3 models and a suite of\ncontemporaneous state-of-the-art LLMs, enabling us to contextualize risks both\nwith and without mitigations in place.", "categories": "cs.CR cs.LG", "created": "2024-08-02", "doi": null, "arxiv_id": "2408.01605"}
{"title": "Deep Learning Meets OBIA: Tasks, Challenges, Strategies, and\n  Perspectives", "authors": [], "abstract": "Deep learning has gained significant attention in remote sensing, especially\nin pixel- or patch-level applications. Despite initial attempts to integrate\ndeep learning into object-based image analysis (OBIA), its full potential\nremains largely unexplored. In this article, as OBIA usage becomes more\nwidespread, we conducted a comprehensive review and expansion of its task\nsubdomains, with or without the integration of deep learning. Furthermore, we\nhave identified and summarized five prevailing strategies to address the\nchallenge of deep learning's limitations in directly processing unstructured\nobject data within OBIA, and this review also recommends some important future\nresearch directions. Our goal with these endeavors is to inspire more\nexploration in this fascinating yet overlooked area and facilitate the\nintegration of deep learning into OBIA processing workflows.", "categories": "cs.CV cs.LG", "created": "2024-08-02", "doi": null, "arxiv_id": "2408.01607"}
{"title": "Fed-RD: Privacy-Preserving Federated Learning for Financial Crime\n  Detection", "authors": [], "abstract": "We introduce Federated Learning for Relational Data (Fed-RD), a novel\nprivacy-preserving federated learning algorithm specifically developed for\nfinancial transaction datasets partitioned vertically and horizontally across\nparties. Fed-RD strategically employs differential privacy and secure\nmultiparty computation to guarantee the privacy of training data. We provide\ntheoretical analysis of the end-to-end privacy of the training algorithm and\npresent experimental results on realistic synthetic datasets. Our results\ndemonstrate that Fed-RD achieves high model accuracy with minimal degradation\nas privacy increases, while consistently surpassing benchmark results.", "categories": "cs.CE", "created": "2024-08-02", "doi": null, "arxiv_id": "2408.01609"}
{"title": "Data-Driven Machine Learning Approaches for Predicting In-Hospital\n  Sepsis Mortality", "authors": [], "abstract": "Background: Sepsis is a severe condition responsible for many deaths\nworldwide. Accurate prediction of sepsis outcomes is crucial for timely and\neffective treatment. Although previous studies have used ML to forecast\noutcomes, they faced limitations in feature selection and model\ncomprehensibility, resulting in less effective predictions. Thus, this research\naims to develop an interpretable and accurate ML model to help clinical\nprofessionals predict in-hospital mortality.\n  Methods: We analyzed ICU patient records from the MIMIC-III database based on\nspecific criteria and extracted relevant data. Our feature selection process\nincluded a literature review, clinical input refinement, and using Random\nForest to select the top 35 features. We performed data preprocessing,\nincluding cleaning, imputation, standardization, and applied SMOTE for\noversampling to address imbalance, resulting in 4,683 patients, with admission\ncounts of 17,429. We compared the performance of Random Forest, Gradient\nBoosting, Logistic Regression, SVM, and KNN models.\n  Results: The Random Forest model was the most effective in predicting\nsepsis-related in-hospital mortality. It outperformed other models, achieving\nan accuracy of 0.90 and an AUROC of 0.97, significantly better than the\nexisting literature. Our meticulous feature selection contributed to the\nmodel's precision and identified critical determinants of sepsis mortality.\nThese results underscore the pivotal role of data-driven ML in healthcare,\nespecially for predicting in-hospital mortality due to sepsis.\n  Conclusion: This study represents a significant advancement in predicting\nin-hospital sepsis mortality, highlighting the potential of ML in healthcare.\nThe implications are profound, offering a data-driven approach that enhances\ndecision-making in patient care and reduces in-hospital mortality.", "categories": "cs.LG", "created": "2024-08-02", "doi": null, "arxiv_id": "2408.01612"}
{"title": "Advancing Mental Health Pre-Screening: A New Custom GPT for\n  Psychological Distress Assessment", "authors": [], "abstract": "This study introduces 'Psycho Analyst', a custom GPT model based on OpenAI's\nGPT-4, optimized for pre-screening mental health disorders. Enhanced with\nDSM-5, PHQ-8, detailed data descriptions, and extensive training data, the\nmodel adeptly decodes nuanced linguistic indicators of mental health disorders.\nIt utilizes a dual-task framework that includes binary classification and a\nthree-stage PHQ-8 score computation involving initial assessment, detailed\nbreakdown, and independent assessment, showcasing refined analytic\ncapabilities. Validation with the DAIC-WOZ dataset reveals F1 and Macro-F1\nscores of 0.929 and 0.949, respectively, along with the lowest MAE and RMSE of\n2.89 and 3.69 in PHQ-8 scoring. These results highlight the model's precision\nand transformative potential in enhancing public mental health support,\nimproving accessibility, cost-effectiveness, and serving as a second opinion\nfor professionals.", "categories": "cs.CY cs.AI", "created": "2024-08-02", "doi": null, "arxiv_id": "2408.01614"}
{"title": "A conservative, implicit solver for 0D-2V multi-species nonlinear\n  Fokker-Planck collision equations", "authors": [], "abstract": "In this study, we present an optimal implicit algorithm designed to\naccurately solve the multi-species nonlinear 0D-2V axisymmetric\nFokker-Planck-Rosenbluth (FRP) collision equation while preserving mass,\nmomentum, and energy. We rely on the nonlinear Shkarofsky's formula of FRP\n(FRPS) collision operator in terms of Legendre polynomial expansions. The key\nto our meshfree approach is the adoption of the Legendre polynomial expansion\nfor the angular direction and King function (Eq.\\EQ{King}) expansion for the\nvelocity axis direction. The Legendre polynomial expansion will converge\nexponentially and the King method, a moment convergence algorithm, could ensure\nthe conservation with high precision in discrete form. Additionally, a\npost-step projection to manifolds is employed to exactly enforce symmetries of\nthe collision operators. Through solving several typical problems across\nvarious nonequilibrium configurations, we demonstrate the superior performance\nand high accuracy of our algorithm.", "categories": "math.NA cs.NA physics.plasm-ph", "created": "2024-08-02", "doi": null, "arxiv_id": "2408.01616"}
{"title": "MedUHIP: Towards Human-In-the-Loop Medical Segmentation", "authors": [], "abstract": "Although segmenting natural images has shown impressive performance, these\ntechniques cannot be directly applied to medical image segmentation. Medical\nimage segmentation is particularly complicated by inherent uncertainties. For\ninstance, the ambiguous boundaries of tissues can lead to diverse but plausible\nannotations from different clinicians. These uncertainties cause significant\ndiscrepancies in clinical interpretations and impact subsequent medical\ninterventions. Therefore, achieving quantitative segmentations from uncertain\nmedical images becomes crucial in clinical practice. To address this, we\npropose a novel approach that integrates an \\textbf{uncertainty-aware model}\nwith \\textbf{human-in-the-loop interaction}. The uncertainty-aware model\nproposes several plausible segmentations to address the uncertainties inherent\nin medical images, while the human-in-the-loop interaction iteratively modifies\nthe segmentation under clinician supervision. This collaborative model ensures\nthat segmentation is not solely dependent on automated techniques but is also\nrefined through clinician expertise. As a result, our approach represents a\nsignificant advancement in the field which enhances the safety of medical image\nsegmentation. It not only offers a comprehensive solution to produce\nquantitative segmentation from inherent uncertain medical images, but also\nestablishes a synergistic balance between algorithmic precision and clincian\nknowledge. We evaluated our method on various publicly available\nmulti-clinician annotated datasets: REFUGE2, LIDC-IDRI and QUBIQ. Our method\nshowcases superior segmentation capabilities, outperforming a wide range of\ndeterministic and uncertainty-aware models. We also demonstrated that our model\nproduced significantly better results with fewer interactions compared to\nprevious interactive models. We will release the code to foster further\nresearch in this area.", "categories": "eess.IV cs.CV", "created": "2024-08-02", "doi": null, "arxiv_id": "2408.01620"}
{"title": "Managing Human-Centric Software Defects: Insights from GitHub and\n  Practitioners' Perspectives", "authors": [], "abstract": "Context: Human-centric defects (HCDs) are nuanced and subjective defects that\noften occur due to end-user perceptions or differences, such as their genders,\nages, cultures, languages, disabilities, socioeconomic status, and educational\nbackgrounds. Development teams have a limited understanding of these issues,\nwhich leads to the neglect of these defects. Defect reporting tools do not\nadequately handle the capture and fixing of HCDs.\n  Objective: This research aims to understand the current defect reporting\nprocess and tools for managing defects. Our study aims to capture process flaws\nand create a preliminary defect categorisation and practices of a\ndefect-reporting tool that can improve the reporting and fixing of HCDs in\nsoftware engineering.\n  Method: We first manually classified 1,100 open-source issues from the GitHub\ndefect reporting tool to identify human-centric defects and to understand the\ncategories of such reported defects. We then interviewed software engineering\npractitioners to elicit feedback on our findings from the GitHub defects\nanalysis and gauge their knowledge and experience of the defect-reporting\nprocess and tools for managing human-centric defects.\n  Results: We identified 176 HCDs from 1,100 open-source issues across six\ndomains: IT-Healthcare, IT-Web, IT-Spatial, IT-Manufacturing, IT-Finance, and\nIT-Gaming. Additionally, we interviewed 15 software practitioners to identify\nshortcomings in the current defect reporting process and determine practices\nfor addressing these weaknesses.\n  Conclusion: HCDs present in open-source repositories are fairly technical,\nand due to the lack of awareness and improper defect reports, they present a\nmajor challenge to software practitioners. However, the management of HCDs can\nbe enhanced by implementing the practices for an ideal defect reporting tool\ndeveloped as part of this study.", "categories": "cs.SE", "created": "2024-08-02", "doi": null, "arxiv_id": "2408.01621"}
{"title": "Positive-Unlabeled Constraint Learning (PUCL) for Inferring Nonlinear\n  Continuous Constraints Functions from Expert Demonstrations", "authors": [], "abstract": "Planning for a wide range of real-world robotic tasks necessitates to know\nand write all constraints. However, instances exist where these constraints are\neither unknown or challenging to specify accurately. A possible solution is to\ninfer the unknown constraints from expert demonstration. This paper presents a\nnovel Positive-Unlabeled Constraint Learning (PUCL) algorithm to infer a\ncontinuous arbitrary constraint function from demonstration, without requiring\nprior knowledge of the true constraint parameterization or environmental model\nas existing works. Within our framework, we treat all data in demonstrations as\npositive (feasible) data, and learn a control policy to generate potentially\ninfeasible trajectories, which serve as unlabeled data. In each iteration, we\nfirst update the policy and then a two-step positive-unlabeled learning\nprocedure is applied, where it first identifies reliable infeasible data using\na distance metric, and secondly learns a binary feasibility classifier (i.e.,\nconstraint function) from the feasible demonstrations and reliable infeasible\ndata. The proposed framework is flexible to learn complex-shaped constraint\nboundary and will not mistakenly classify demonstrations as infeasible as\nprevious methods. The effectiveness of the proposed method is verified in three\nrobotic tasks, using a networked policy or a dynamical system policy. It\nsuccessfully infers and transfers the continuous nonlinear constraints and\noutperforms other baseline methods in terms of constraint accuracy and policy\nsafety.", "categories": "cs.RO cs.AI cs.LG", "created": "2024-08-02", "doi": null, "arxiv_id": "2408.01622"}
{"title": "Dialog Flow Induction for Constrainable LLM-Based Chatbots", "authors": [], "abstract": "LLM-driven dialog systems are used in a diverse set of applications, ranging\nfrom healthcare to customer service. However, given their generalization\ncapability, it is difficult to ensure that these chatbots stay within the\nboundaries of the specialized domains, potentially resulting in inaccurate\ninformation and irrelevant responses. This paper introduces an unsupervised\napproach for automatically inducing domain-specific dialog flows that can be\nused to constrain LLM-based chatbots. We introduce two variants of dialog flow\nbased on the availability of in-domain conversation instances. Through human\nand automatic evaluation over various dialog domains, we demonstrate that our\nhigh-quality data-guided dialog flows achieve better domain coverage, thereby\novercoming the need for extensive manual crafting of such flows.", "categories": "cs.CL", "created": "2024-08-02", "doi": null, "arxiv_id": "2408.01623"}
{"title": "Fair Risk Minimization under Causal Path-Specific Effect Constraints", "authors": [], "abstract": "This paper introduces a framework for estimating fair optimal predictions\nusing machine learning where the notion of fairness can be quantified using\npath-specific causal effects. We use a recently developed approach based on\nLagrange multipliers for infinite-dimensional functional estimation to derive\nclosed-form solutions for constrained optimization based on mean squared error\nand cross-entropy risk criteria. The theoretical forms of the solutions are\nanalyzed in detail and described as nuanced adjustments to the unconstrained\nminimizer. This analysis highlights important trade-offs between risk\nminimization and achieving fairnes. The theoretical solutions are also used as\nthe basis for construction of flexible semiparametric estimation strategies for\nthese nuisance components. We describe the robustness properties of our\nestimators in terms of achieving the optimal constrained risk, as well as in\nterms of controlling the value of the constraint. We study via simulation the\nimpact of using robust estimators of pathway-specific effects to validate our\ntheory. This work advances the discourse on algorithmic fairness by integrating\ncomplex causal considerations into model training, thus providing strategies\nfor implementing fair models in real-world applications.", "categories": "cs.LG stat.ML", "created": "2024-08-02", "doi": null, "arxiv_id": "2408.01630"}
{"title": "A Comparative Analysis of Wealth Index Predictions in Africa between\n  three Multi-Source Inference Models", "authors": [], "abstract": "Poverty map inference is a critical area of research, with growing interest\nin both traditional and modern techniques, ranging from regression models to\nconvolutional neural networks applied to tabular data, images, and networks.\nDespite extensive focus on the validation of training phases, the scrutiny of\nfinal predictions remains limited. Here, we compare the Relative Wealth Index\n(RWI) inferred by Chi et al. (2021) with the International Wealth Index (IWI)\ninferred by Lee and Braithwaite (2022) and Esp\\'in-Noboa et al. (2023) across\nsix Sub-Saharan African countries. Our analysis focuses on identifying trends\nand discrepancies in wealth predictions over time. Our results show that the\npredictions by Chi et al. and Esp\\'in-Noboa et al. align with general GDP\ntrends, with differences expected due to the distinct time-frames of the\ntraining sets. However, predictions by Lee and Braithwaite diverge\nsignificantly, indicating potential issues with the validity of the model.\nThese discrepancies highlight the need for policymakers and stakeholders in\nAfrica to rigorously audit models that predict wealth, especially those used\nfor decision-making on the ground. These and other techniques require\ncontinuous verification and refinement to enhance their reliability and ensure\nthat poverty alleviation strategies are well-founded.", "categories": "physics.soc-ph cs.CY cs.LG", "created": "2024-08-02", "doi": null, "arxiv_id": "2408.01631"}
{"title": "Self-Emotion Blended Dialogue Generation in Social Simulation Agents", "authors": [], "abstract": "When engaging in conversations, dialogue agents in a virtual simulation\nenvironment may exhibit their own emotional states that are unrelated to the\nimmediate conversational context, a phenomenon known as self-emotion. This\nstudy explores how such self-emotion affects the agents' behaviors in dialogue\nstrategies and decision-making within a large language model (LLM)-driven\nsimulation framework. In a dialogue strategy prediction experiment, we analyze\nthe dialogue strategy choices employed by agents both with and without\nself-emotion, comparing them to those of humans. The results show that\nincorporating self-emotion helps agents exhibit more human-like dialogue\nstrategies. In an independent experiment comparing the performance of models\nfine-tuned on GPT-4 generated dialogue datasets, we demonstrate that\nself-emotion can lead to better overall naturalness and humanness. Finally, in\na virtual simulation environment where agents have discussions on multiple\ntopics, we show that self-emotion of agents can significantly influence the\ndecision-making process of the agents, leading to approximately a 50% change in\ndecisions.", "categories": "cs.MA cs.AI cs.CL cs.CY", "created": "2024-08-02", "doi": null, "arxiv_id": "2408.01633"}
{"title": "KTWIN: A Serverless Kubernetes-based Digital Twin Platform", "authors": [], "abstract": "Digital Twins (DTs) systems are virtual representations of physical assets\nallowing organizations to gain insights and improve existing processes. In\npractice, DTs require proper modeling, coherent development and seamless\ndeployment along cloud and edge landscapes relying on established patterns to\nreduce operational costs. In this work, we propose KTWIN a Kubernetes-based\nServerless Platform for Digital Twins. KTWIN was developed using the\nstate-of-the-art open-source Cloud Native tools, allowing DT operators to\neasily define models through open standards and configure details of the\nunderlying services and infrastructure. The experiments carried out with the\ndeveloped prototype show that KTWIN can provide a higher level of abstraction\nto model and deploy a Digital Twin use case without compromising the solution\nscalability. The tests performed also show cost savings ranging between 60% and\n80% compared to overprovisioned scenarios.", "categories": "cs.NI", "created": "2024-08-02", "doi": null, "arxiv_id": "2408.01635"}
{"title": "Transforming Slot Schema Induction with Generative Dialogue State\n  Inference", "authors": [], "abstract": "The challenge of defining a slot schema to represent the state of a\ntask-oriented dialogue system is addressed by Slot Schema Induction (SSI),\nwhich aims to automatically induce slots from unlabeled dialogue data. Whereas\nprevious approaches induce slots by clustering value spans extracted directly\nfrom the dialogue text, we demonstrate the power of discovering slots using a\ngenerative approach. By training a model to generate slot names and values that\nsummarize key dialogue information with no prior task knowledge, our SSI method\ndiscovers high-quality candidate information for representing dialogue state.\nThese discovered slot-value candidates can be easily clustered into unified\nslot schemas that align well with human-authored schemas. Experimental\ncomparisons on the MultiWOZ and SGD datasets demonstrate that Generative\nDialogue State Inference (GenDSI) outperforms the previous state-of-the-art on\nmultiple aspects of the SSI task.", "categories": "cs.CL", "created": "2024-08-02", "doi": null, "arxiv_id": "2408.01638"}
{"title": "Coordinating Planning and Tracking in Layered Control Policies via\n  Actor-Critic Learning", "authors": [], "abstract": "We propose a reinforcement learning (RL)-based algorithm to jointly train (1)\na trajectory planner and (2) a tracking controller in a layered control\narchitecture. Our algorithm arises naturally from a rewrite of the underlying\noptimal control problem that lends itself to an actor-critic learning approach.\nBy explicitly learning a \\textit{dual} network to coordinate the interaction\nbetween the planning and tracking layers, we demonstrate the ability to achieve\nan effective consensus between the two components, leading to an interpretable\npolicy. We theoretically prove that our algorithm converges to the optimal dual\nnetwork in the Linear Quadratic Regulator (LQR) setting and empirically\nvalidate its applicability to nonlinear systems through simulation experiments\non a unicycle model.", "categories": "eess.SY cs.LG cs.SY", "created": "2024-08-02", "doi": null, "arxiv_id": "2408.01639"}
{"title": "Leveraging GNSS and Onboard Visual Data from Consumer Vehicles for\n  Robust Road Network Estimation", "authors": [], "abstract": "Maps are essential for diverse applications, such as vehicle navigation and\nautonomous robotics. Both require spatial models for effective route planning\nand localization. This paper addresses the challenge of road graph construction\nfor autonomous vehicles. Despite recent advances, creating a road graph remains\nlabor-intensive and has yet to achieve full automation. The goal of this paper\nis to generate such graphs automatically and accurately. Modern cars are\nequipped with onboard sensors used for today's advanced driver assistance\nsystems like lane keeping. We propose using global navigation satellite system\n(GNSS) traces and basic image data acquired from these standard sensors in\nconsumer vehicles to estimate road-level maps with minimal effort. We exploit\nthe spatial information in the data by framing the problem as a road centerline\nsemantic segmentation task using a convolutional neural network. We also\nutilize the data's time series nature to refine the neural network's output by\nusing map matching. We implemented and evaluated our method using a fleet of\nreal consumer vehicles, only using the deployed onboard sensors. Our evaluation\ndemonstrates that our approach not only matches existing methods on simpler\nroad configurations but also significantly outperforms them on more complex\nroad geometries and topologies. This work received the 2023 Woven by Toyota\nInvention Award.", "categories": "cs.CV cs.RO", "created": "2024-08-02", "doi": null, "arxiv_id": "2408.01640"}
{"title": "Zero-Shot Surgical Tool Segmentation in Monocular Video Using Segment\n  Anything Model 2", "authors": [], "abstract": "The Segment Anything Model 2 (SAM 2) is the latest generation foundation\nmodel for image and video segmentation. Trained on the expansive Segment\nAnything Video (SA-V) dataset, which comprises 35.5 million masks across 50.9K\nvideos, SAM 2 advances its predecessor's capabilities by supporting zero-shot\nsegmentation through various prompts (e.g., points, boxes, and masks). Its\nrobust zero-shot performance and efficient memory usage make SAM 2 particularly\nappealing for surgical tool segmentation in videos, especially given the\nscarcity of labeled data and the diversity of surgical procedures. In this\nstudy, we evaluate the zero-shot video segmentation performance of the SAM 2\nmodel across different types of surgeries, including endoscopy and microscopy.\nWe also assess its performance on videos featuring single and multiple tools of\nvarying lengths to demonstrate SAM 2's applicability and effectiveness in the\nsurgical domain. We found that: 1) SAM 2 demonstrates a strong capability for\nsegmenting various surgical videos; 2) When new tools enter the scene,\nadditional prompts are necessary to maintain segmentation accuracy; and 3)\nSpecific challenges inherent to surgical videos can impact the robustness of\nSAM 2.", "categories": "eess.IV cs.CV", "created": "2024-08-02", "doi": null, "arxiv_id": "2408.01648"}
{"title": "LF-3PM: a LiDAR-based Framework for Perception-aware Planning with\n  Perturbation-induced Metric", "authors": [], "abstract": "Just as humans can become disoriented in featureless deserts or thick fogs,\nnot all environments are conducive to the Localization Accuracy and Stability\n(LAS) of autonomous robots. This paper introduces an efficient framework\ndesigned to enhance LiDAR-based LAS through strategic trajectory generation,\nknown as Perception-aware Planning. Unlike vision-based frameworks, the\nLiDAR-based requires different considerations due to unique sensor attributes.\nOur approach focuses on two main aspects: firstly, assessing the impact of\nLiDAR observations on LAS. We introduce a perturbation-induced metric to\nprovide a comprehensive and reliable evaluation of LiDAR observations.\nSecondly, we aim to improve motion planning efficiency. By creating a Static\nObservation Loss Map (SOLM) as an intermediary, we logically separate the\ntime-intensive evaluation and motion planning phases, significantly boosting\nthe planning process. In the experimental section, we demonstrate the\neffectiveness of the proposed metrics across various scenes and the feature of\ntrajectories guided by different metrics. Ultimately, our framework is tested\nin a real-world scenario, enabling the robot to actively choose topologies and\norientations preferable for localization. The source code is accessible at\nhttps://github.com/ZJU-FAST-Lab/LF-3PM.", "categories": "cs.RO", "created": "2024-08-02", "doi": null, "arxiv_id": "2408.01649"}
{"title": "Music2P: A Multi-Modal AI-Driven Tool for Simplifying Album Cover Design", "authors": [], "abstract": "In today's music industry, album cover design is as crucial as the music\nitself, reflecting the artist's vision and brand. However, many AI-driven album\ncover services require subscriptions or technical expertise, limiting\naccessibility. To address these challenges, we developed Music2P, an\nopen-source, multi-modal AI-driven tool that streamlines album cover creation,\nmaking it efficient, accessible, and cost-effective through Ngrok. Music2P\nautomates the design process using techniques such as Bootstrapping Language\nImage Pre-training (BLIP), music-to-text conversion (LP-music-caps), image\nsegmentation (LoRA), and album cover and QR code generation (ControlNet). This\npaper demonstrates the Music2P interface, details our application of these\ntechnologies, and outlines future improvements. Our ultimate goal is to provide\na tool that empowers musicians and producers, especially those with limited\nresources or expertise, to create compelling album covers.", "categories": "cs.MM cs.AI cs.HC", "created": "2024-08-02", "doi": null, "arxiv_id": "2408.01651"}
{"title": "Complex event recognition meets hierarchical conjunctive queries", "authors": [], "abstract": "Hierarchical conjunctive queries (HCQ) are a subclass of conjunctive queries\n(CQ) with robust algorithmic properties. Among others, Berkholz, Keppeler, and\nSchweikardt have shown that HCQ is the subclass of CQ (without projection) that\nadmits dynamic query evaluation with constant update time and constant delay\nenumeration. On a different but related setting stands Complex Event\nRecognition (CER), a prominent technology for evaluating sequence patterns over\nstreams. Since one can interpret a data stream as an unbounded sequence of\ninserts in dynamic query evaluation, it is natural to ask to which extent CER\ncan take advantage of HCQ to find a robust class of queries that can be\nevaluated efficiently.\n  In this paper, we search to combine HCQ with sequence patterns to find a\nclass of CER queries that can get the best of both worlds. To reach this goal,\nwe propose a class of complex event automata model called Parallelized Complex\nEvent Automata (PCEA) for evaluating CER queries with correlation (i.e., joins)\nover streams. This model allows us to express sequence patterns and compare\nvalues among tuples, but it also allows us to express conjunctions by\nincorporating a novel form of non-determinism that we call parallelization. We\nshow that for every HCQ (under bag semantics), we can construct an equivalent\nPCEA. Further, we show that HCQ is the biggest class of acyclic CQ that this\nautomata model can define. Then, PCEA stands as a sweet spot that precisely\nexpresses HCQ (i.e., among acyclic CQ) and extends them with sequence patterns.\nFinally, we show that PCEA also inherits the good algorithmic properties of HCQ\nby presenting a streaming evaluation algorithm under sliding windows with\nlogarithmic update time and output-linear delay for the class of PCEA with\nequality predicates.", "categories": "cs.DB cs.DS cs.FL", "created": "2024-08-02", "doi": null, "arxiv_id": "2408.01652"}
{"title": "MCPDepth: Omnidirectional Depth Estimation via Stereo Matching from\n  Multi-Cylindrical Panoramas", "authors": [], "abstract": "We introduce Multi-Cylindrical Panoramic Depth Estimation (MCPDepth), a\ntwo-stage framework for omnidirectional depth estimation via stereo matching\nbetween multiple cylindrical panoramas. MCPDepth uses cylindrical panoramas for\ninitial stereo matching and then fuses the resulting depth maps across views. A\ncircular attention module is employed to overcome the distortion along the\nvertical axis. MCPDepth exclusively utilizes standard network components,\nsimplifying deployment to embedded devices and outperforming previous methods\nthat require custom kernels. We theoretically and experimentally compare\nspherical and cylindrical projections for stereo matching, highlighting the\nadvantages of the cylindrical projection. MCPDepth achieves state-of-the-art\nperformance with an 18.8% reduction in mean absolute error (MAE) for depth on\nthe outdoor synthetic dataset Deep360 and a 19.9% reduction on the indoor\nreal-scene dataset 3D60.", "categories": "cs.CV", "created": "2024-08-02", "doi": null, "arxiv_id": "2408.01653"}
{"title": "Deep Patch Visual SLAM", "authors": [], "abstract": "Recent work in visual SLAM has shown the effectiveness of using deep network\nbackbones. Despite excellent accuracy, however, such approaches are often\nexpensive to run or do not generalize well zero-shot. Their runtime can also\nfluctuate wildly while their frontend and backend fight for access to GPU\nresources. To address these problems, we introduce Deep Patch Visual (DPV)\nSLAM, a method for monocular visual SLAM on a single GPU. DPV-SLAM maintains a\nhigh minimum framerate and small memory overhead (5-7G) compared to existing\ndeep SLAM systems. On real-world datasets, DPV-SLAM runs at 1x-4x real-time\nframerates. We achieve comparable accuracy to DROID-SLAM on EuRoC and TartanAir\nwhile running 2.5x faster using a fraction of the memory. DPV-SLAM is an\nextension to the DPVO visual odometry system; its code can be found in the same\nrepository: https://github.com/princeton-vl/DPVO", "categories": "cs.CV", "created": "2024-08-02", "doi": null, "arxiv_id": "2408.01654"}
{"title": "Stimulating Imagination: Towards General-purpose Object Rearrangement", "authors": [], "abstract": "General-purpose object placement is a fundamental capability of an\nintelligent generalist robot, i.e., being capable of rearranging objects\nfollowing human instructions even in novel environments. To achieve this, we\nbreak the rearrangement down into three parts, including object localization,\ngoal imagination and robot control, and propose a framework named SPORT. SPORT\nleverages pre-trained large vision models for broad semantic reasoning about\nobjects, and learns a diffusion-based 3D pose estimator to ensure\nphysically-realistic results. Only object types (to be moved or reference) are\ncommunicated between these two parts, which brings two benefits. One is that we\ncan fully leverage the powerful ability of open-set object localization and\nrecognition since no specific fine-tuning is needed for robotic scenarios.\nFurthermore, the diffusion-based estimator only need to \"imagine\" the poses of\nthe moving and reference objects after the placement, while no necessity for\ntheir semantic information. Thus the training burden is greatly reduced and no\nmassive training is required. The training data for goal pose estimation is\ncollected in simulation and annotated with GPT-4. A set of simulation and\nreal-world experiments demonstrate the potential of our approach to accomplish\ngeneral-purpose object rearrangement, placing various objects following precise\ninstructions.", "categories": "cs.RO cs.AI", "created": "2024-08-02", "doi": null, "arxiv_id": "2408.01655"}
{"title": "Deep Reinforcement Learning for Dynamic Order Picking in Warehouse\n  Operations", "authors": [], "abstract": "Order picking is a crucial operation in warehouses that significantly impacts\noverall efficiency and profitability. This study addresses the dynamic order\npicking problem, a significant concern in modern warehouse management where\nreal-time adaptation to fluctuating order arrivals and efficient picker routing\nare crucial. Traditional methods, often assuming fixed order sets, fall short\nin this dynamic environment. We utilize Deep Reinforcement Learning (DRL) as a\nsolution methodology to handle the inherent uncertainties in customer demands.\nWe focus on a single-block warehouse with an autonomous picking device,\neliminating human behavioral factors. Our DRL framework enables the dynamic\noptimization of picker routes, significantly reducing order throughput times,\nespecially under high order arrival rates. Experiments demonstrate a\nsubstantial decrease in order throughput time and unfulfilled orders compared\nto benchmark algorithms. We further investigate integrating a hyperparameter in\nthe reward function that allows for flexible balancing between distance\ntraveled and order completion time. Finally, we demonstrate the robustness of\nour DRL model for out-of-sample test instances.", "categories": "math.OC cs.LG", "created": "2024-08-02", "doi": null, "arxiv_id": "2408.01656"}
{"title": "Towards Tractability of the Diversity of Query Answers: Ultrametrics to\n  the Rescue", "authors": [], "abstract": "The set of answers to a query may be very large, potentially overwhelming\nusers when presented with the entire set. In such cases, presenting only a\nsmall subset of the answers to the user may be preferable. A natural\nrequirement for this subset is that it should be as diverse as possible to\nreflect the variety of the entire population. To achieve this, the diversity of\na subset is measured using a metric that determines how different two solutions\nare and a diversity function that extends this metric from pairs to sets. In\nthe past, several studies have shown that finding a diverse subset from an\nexplicitly given set is intractable even for simple metrics (like Hamming\ndistance) and simple diversity functions (like summing all pairwise distances).\nThis complexity barrier becomes even more challenging when trying to output a\ndiverse subset from a set that is only implicitly given such as the query\nanswers of a query and a database. Until now, tractable cases have been found\nonly for restricted problems and particular diversity functions.\n  To overcome these limitations, we focus on the notion of ultrametrics, which\nhave been widely studied and used in many applications. Starting from any\nultrametric $d$ and a diversity function $\\delta$ extending $d$, we provide\nsufficient conditions over $\\delta$ for having polynomial-time algorithms to\nconstruct diverse answers. To the best of our knowledge, these conditions are\nsatisfied by all diversity functions considered in the literature. Moreover, we\ncomplement these results with lower bounds that show specific cases when these\nconditions are not satisfied and finding diverse subsets becomes intractable.\nWe conclude by applying these results to the evaluation of conjunctive queries,\ndemonstrating efficient algorithms for finding a diverse subset of solutions\nfor acyclic conjunctive queries when the attribute order is used to measure\ndiversity.", "categories": "cs.DB cs.DS", "created": "2024-08-02", "doi": null, "arxiv_id": "2408.01657"}
{"title": "Degrade to Function: Towards Eco-friendly Morphing Devices that Function\n  Through Programmed Sequential Degradation", "authors": [], "abstract": "While it seems counterintuitive to think of degradation within an operating\ndevice as beneficial, one may argue that when rationally designed, the\ncontrolled breakdown of materials can be harnessed for specific functions. To\napply this principle to the design of morphing devices, we introduce the\nconcept of Degrade to Function (DtF). This concept aims to create eco-friendly\nand self-contained morphing devices that operate through a sequence of\nenvironmentally-triggered degradations. We explore its design considerations\nand implementation techniques by identifying environmental conditions and\ndegradation types that can be exploited, evaluating potential materials capable\nof controlled degradation, suggesting designs for structures that can leverage\ndegradation to achieve various transformations and functions, and developing\nsequential control approaches that integrate degradation triggers. To\ndemonstrate the viability and versatility of this design strategy, we showcase\nseveral application examples across a range of environmental conditions.", "categories": "cs.HC", "created": "2024-08-03", "doi": "10.1145/3654777.3676464", "arxiv_id": "2408.01660"}
{"title": "Mitigating the Impact of Malware Evolution on API Sequence-based Windows\n  Malware Detector", "authors": [], "abstract": "In dynamic Windows malware detection, deep learning models are extensively\ndeployed to analyze API sequences. Methods based on API sequences play a\ncrucial role in malware prevention. However, due to the continuous updates of\nAPIs and the changes in API sequence calls leading to the constant evolution of\nmalware variants, the detection capability of API sequence-based malware\ndetection models significantly diminishes over time. We observe that the API\nsequences of malware samples before and after evolution usually have similar\nmalicious semantics. Specifically, compared to the original samples, evolved\nmalware samples often use the API sequences of the pre-evolution samples to\nachieve similar malicious behaviors. For instance, they access similar\nsensitive system resources and extend new malicious functions based on the\noriginal functionalities. In this paper, we propose a frame(MME), a framework\nthat can enhance existing API sequence-based malware detectors and mitigate the\nadverse effects of malware evolution. To help detection models capture the\nsimilar semantics of these post-evolution API sequences, our framework\nrepresents API sequences using API knowledge graphs and system resource\nencodings and applies contrastive learning to enhance the model's encoder.\nResults indicate that, compared to Regular Text-CNN, our framework can\nsignificantly reduce the false positive rate by 13.10% and improve the F1-Score\nby 8.47% on five years of data, achieving the best experimental results.\nAdditionally, evaluations show that our framework can save on the human costs\nrequired for model maintenance. We only need 1% of the budget per month to\nreduce the false positive rate by 11.16% and improve the F1-Score by 6.44%.", "categories": "cs.CR", "created": "2024-08-03", "doi": null, "arxiv_id": "2408.01661"}
{"title": "SAT3D: Image-driven Semantic Attribute Transfer in 3D", "authors": [], "abstract": "GAN-based image editing task aims at manipulating image attributes in the\nlatent space of generative models. Most of the previous 2D and 3D-aware\napproaches mainly focus on editing attributes in images with ambiguous\nsemantics or regions from a reference image, which fail to achieve photographic\nsemantic attribute transfer, such as the beard from a photo of a man. In this\npaper, we propose an image-driven Semantic Attribute Transfer method in 3D\n(SAT3D) by editing semantic attributes from a reference image. For the proposed\nmethod, the exploration is conducted in the style space of a pre-trained\n3D-aware StyleGAN-based generator by learning the correlations between semantic\nattributes and style code channels. For guidance, we associate each attribute\nwith a set of phrase-based descriptor groups, and develop a Quantitative\nMeasurement Module (QMM) to quantitatively describe the attribute\ncharacteristics in images based on descriptor groups, which leverages the\nimage-text comprehension capability of CLIP. During the training process, the\nQMM is incorporated into attribute losses to calculate attribute similarity\nbetween images, guiding target semantic transferring and irrelevant semantics\npreserving. We present our 3D-aware attribute transfer results across multiple\ndomains and also conduct comparisons with classical 2D image editing methods,\ndemonstrating the effectiveness and customizability of our SAT3D.", "categories": "cs.CV cs.AI", "created": "2024-08-03", "doi": "10.1145/3664647.3681035", "arxiv_id": "2408.01664"}
{"title": "Automated Phishing Detection Using URLs and Webpages", "authors": [], "abstract": "Phishing detection is a critical cybersecurity task that involves the\nidentification and neutralization of fraudulent attempts to obtain sensitive\ninformation, thereby safeguarding individuals and organizations from data\nbreaches and financial loss. In this project, we address the constraints of\ntraditional reference-based phishing detection by developing an LLM agent\nframework. This agent harnesses Large Language Models to actively fetch and\nutilize online information, thus providing a dynamic reference system for more\naccurate phishing detection. This innovation circumvents the need for a static\nknowledge base, offering a significant enhancement in adaptability and\nefficiency for automated security measures.\n  The project report includes an initial study and problem analysis of existing\nsolutions, which motivated us to develop a new framework. We demonstrate the\nframework with LLMs simulated as agents and detail the techniques required for\nconstruction, followed by a complete implementation with a proof-of-concept as\nwell as experiments to evaluate our solution's performance against other\nsimilar solutions. The results show that our approach has achieved with\naccuracy of 0.945, significantly outperforms the existing solution(DynaPhish)\nby 0.445. Furthermore, we discuss the limitations of our approach and suggest\nimprovements that could make it more effective.\n  Overall, the proposed framework has the potential to enhance the\neffectiveness of current reference-based phishing detection approaches and\ncould be adapted for real-world applications.", "categories": "cs.CR", "created": "2024-08-03", "doi": null, "arxiv_id": "2408.01667"}
{"title": "Multiple Contexts and Frequencies Aggregation Network forDeepfake\n  Detection", "authors": [], "abstract": "Deepfake detection faces increasing challenges since the fast growth of\ngenerative models in developing massive and diverse Deepfake technologies.\nRecent advances rely on introducing heuristic features from spatial or\nfrequency domains rather than modeling general forgery features within\nbackbones. To address this issue, we turn to the backbone design with two\nintuitive priors from spatial and frequency detectors, \\textit{i.e.,} learning\nrobust spatial attributes and frequency distributions that are discriminative\nfor real and fake samples. To this end, we propose an efficient network for\nface forgery detection named MkfaNet, which consists of two core modules. For\nspatial contexts, we design a Multi-Kernel Aggregator that adaptively selects\norgan features extracted by multiple convolutions for modeling subtle facial\ndifferences between real and fake faces. For the frequency components, we\npropose a Multi-Frequency Aggregator to process different bands of frequency\ncomponents by adaptively reweighing high-frequency and low-frequency features.\nComprehensive experiments on seven popular deepfake detection benchmarks\ndemonstrate that our proposed MkfaNet variants achieve superior performances in\nboth within-domain and across-domain evaluations with impressive efficiency of\nparameter usage.", "categories": "cs.CV cs.MM", "created": "2024-08-03", "doi": null, "arxiv_id": "2408.01668"}
{"title": "radarODE: An ODE-Embedded Deep Learning Model for Contactless ECG\n  Reconstruction from Millimeter-Wave Radar", "authors": [], "abstract": "Radar-based contactless cardiac monitoring has become a popular research\ndirection recently, but the fine-grained electrocardiogram (ECG) signal is\nstill hard to reconstruct from millimeter-wave radar signal. The key obstacle\nis to decouple the cardiac activities in the electrical domain (i.e., ECG) from\nthat in the mechanical domain (i.e., heartbeat), and most existing research\nonly uses pure data-driven methods to map such domain transformation as a black\nbox. Therefore, this work first proposes a signal model for domain\ntransformation, and then a novel deep learning framework called radarODE is\ndesigned to fuse the temporal and morphological features extracted from radar\nsignals and generate ECG. In addition, ordinary differential equations are\nembedded in radarODE as a decoder to provide morphological prior, helping the\nconvergence of the model training and improving the robustness under body\nmovements. After being validated on the dataset, the proposed radarODE achieves\nbetter performance compared with the benchmark in terms of missed detection\nrate, root mean square error, Pearson correlation coefficient with the\nimprovement of 9%, 16% and 19%, respectively. The validation results imply that\nradarODE is capable of recovering ECG signals from radar signals with high\nfidelity and can be potentially implemented in real-life scenarios.", "categories": "eess.SP cs.AI", "created": "2024-08-03", "doi": null, "arxiv_id": "2408.01672"}
{"title": "Prototyping of a multirotor UAV for precision landing under rotor\n  failures", "authors": [], "abstract": "This work presents a prototype of a multirotor aerial vehicle capable of\nprecision landing, even under the effects of rotor failures. The manuscript\npresents the fault-tolerant techniques and mechanical designs to achieve a\nfault-tolerant multirotor, and a vision-based navigation system required to\nachieve a precision landing. Preliminary experimental results will be shown, to\nvalidate on one hand the fault-tolerant control vehicle and, on the other hand,\nthe autonomous landing algorithm. Also, a prototype of the fault-tolerant UAV\nis presented, capable of precise autonomous landing, which will be used in\nfuture experiments.", "categories": "cs.RO", "created": "2024-08-03", "doi": null, "arxiv_id": "2408.01676"}
{"title": "HIVE: HIerarchical Volume Encoding for Neural Implicit Surface\n  Reconstruction", "authors": [], "abstract": "Neural implicit surface reconstruction has become a new trend in\nreconstructing a detailed 3D shape from images. In previous methods, however,\nthe 3D scene is only encoded by the MLPs which do not have an explicit 3D\nstructure. To better represent 3D shapes, we introduce a volume encoding to\nexplicitly encode the spatial information. We further design hierarchical\nvolumes to encode the scene structures in multiple scales. The high-resolution\nvolumes capture the high-frequency geometry details since spatially varying\nfeatures could be learned from different 3D points, while the low-resolution\nvolumes enforce the spatial consistency to keep the shape smooth since adjacent\nlocations possess the same low-resolution feature. In addition, we adopt a\nsparse structure to reduce the memory consumption at high-resolution volumes,\nand two regularization terms to enhance results smoothness. This hierarchical\nvolume encoding could be appended to any implicit surface reconstruction method\nas a plug-and-play module, and can generate a smooth and clean reconstruction\nwith more details. Superior performance is demonstrated in DTU, EPFL, and\nBlendedMVS datasets with significant improvement on the standard metrics.", "categories": "cs.CV", "created": "2024-08-03", "doi": null, "arxiv_id": "2408.01677"}
{"title": "iControl3D: An Interactive System for Controllable 3D Scene Generation", "authors": [], "abstract": "3D content creation has long been a complex and time-consuming process, often\nrequiring specialized skills and resources. While recent advancements have\nallowed for text-guided 3D object and scene generation, they still fall short\nof providing sufficient control over the generation process, leading to a gap\nbetween the user's creative vision and the generated results. In this paper, we\npresent iControl3D, a novel interactive system that empowers users to generate\nand render customizable 3D scenes with precise control. To this end, a 3D\ncreator interface has been developed to provide users with fine-grained control\nover the creation process. Technically, we leverage 3D meshes as an\nintermediary proxy to iteratively merge individual 2D diffusion-generated\nimages into a cohesive and unified 3D scene representation. To ensure seamless\nintegration of 3D meshes, we propose to perform boundary-aware depth alignment\nbefore fusing the newly generated mesh with the existing one in 3D space.\nAdditionally, to effectively manage depth discrepancies between remote content\nand foreground, we propose to model remote content separately with an\nenvironment map instead of 3D meshes. Finally, our neural rendering interface\nenables users to build a radiance field of their scene online and navigate the\nentire scene. Extensive experiments have been conducted to demonstrate the\neffectiveness of our system. The code will be made available at\nhttps://github.com/xingyi-li/iControl3D.", "categories": "cs.CV", "created": "2024-08-03", "doi": null, "arxiv_id": "2408.01678"}
{"title": "MMPKUBase: A Comprehensive and High-quality Chinese Multi-modal\n  Knowledge Graph", "authors": [], "abstract": "Multi-modal knowledge graphs have emerged as a powerful approach for\ninformation representation, combining data from different modalities such as\ntext, images, and videos. While several such graphs have been constructed and\nhave played important roles in applications like visual question answering and\nrecommendation systems, challenges persist in their development. These include\nthe scarcity of high-quality Chinese knowledge graphs and limited domain\ncoverage in existing multi-modal knowledge graphs. This paper introduces\nMMPKUBase, a robust and extensive Chinese multi-modal knowledge graph that\ncovers diverse domains, including birds, mammals, ferns, and more, comprising\nover 50,000 entities and over 1 million filtered images. To ensure data\nquality, we employ Prototypical Contrastive Learning and the Isolation Forest\nalgorithm to refine the image data. Additionally, we have developed a\nuser-friendly platform to facilitate image attribute exploration.", "categories": "cs.CL cs.MM", "created": "2024-08-03", "doi": null, "arxiv_id": "2408.01679"}
{"title": "Service Placement and Trajectory Design for Heterogeneous Tasks in\n  Multi-UAV Cooperative Computing Networks", "authors": [], "abstract": "In this paper, we consider deploying multiple Unmanned Aerial Vehicles (UAVs)\nto enhance the computation service of Mobile Edge Computing (MEC) through\ncollaborative computation among UAVs. In particular, the tasks of different\ntypes and service requirements in MEC network are offloaded from one UAV to\nanother. To pursue the goal of low-carbon edge computing, we study the problem\nof minimizing system energy consumption by jointly optimizing computation\nresource allocation, task scheduling, service placement, and UAV trajectories.\nConsidering the inherent unpredictability associated with task generation and\nthe dynamic nature of wireless fading channels, addressing this problem\npresents a significant challenge. To overcome this issue, we reformulate the\ncomplicated non-convex problem as a Markov decision process and propose a soft\nactor-critic-based trajectory optimization and resource allocation algorithm to\nimplement a flexible learning strategy. Numerical results illustrate that\nwithin a multi-UAV-enabled MEC network, the proposed algorithm effectively\nreduces the system energy consumption in heterogeneous tasks and services\nscenarios compared to other baseline solutions.", "categories": "cs.IT math.IT", "created": "2024-08-03", "doi": null, "arxiv_id": "2408.01680"}
{"title": "Multi-Frame Vision-Language Model for Long-form Reasoning in Driver\n  Behavior Analysis", "authors": [], "abstract": "Identifying risky driving behavior in real-world situations is essential for\nthe safety of both drivers and pedestrians. However, integrating natural\nlanguage models in this field remains relatively untapped. To address this, we\ncreated a novel multi-modal instruction tuning dataset and driver coaching\ninference system. Our primary use case is dashcam-based coaching for commercial\ndrivers. The North American Dashcam Market is expected to register a CAGR of\n15.4 percent from 2022 to 2027. Our dataset enables language models to learn\nvisual instructions across various risky driving scenarios, emphasizing\ndetailed reasoning crucial for effective driver coaching and managerial\ncomprehension. Our model is trained on road-facing and driver-facing RGB camera\nfootage, capturing the comprehensive scope of driving behavior in vehicles\nequipped with dashcams.", "categories": "cs.CL cs.CV", "created": "2024-08-03", "doi": null, "arxiv_id": "2408.01682"}
{"title": "Near-Field Beamforming for Stacked Intelligent Metasurfaces-assisted\n  MIMO Networks", "authors": [], "abstract": "Stacked intelligent metasurfaces (SIMs) have recently gained significant\ninterest since they enable precoding in the wave domain that comes with\nincreased processing capability and reduced energy consumption. The study of\nSIMs and high frequency propagation make the study of the performance in the\nnear field of crucial importance. Hence, in this work, we focus on SIM-assisted\nmultiuser multiple-input multiple-output (MIMO) systems operating in the near\nfield region. To this end, we formulate the weighted sum rate maximisation\nproblem in terms of the transmit power and the phase shifts of the SIM. By\napplying a block coordinate descent (BCD)-relied algorithm, numerical results\nshow the enhanced performance of the SIM in the near field with respect to the\nfar field.", "categories": "cs.IT eess.SP math.IT", "created": "2024-08-03", "doi": null, "arxiv_id": "2408.01684"}
{"title": "Voices from the Frontier: A Comprehensive Analysis of the OpenAI\n  Developer Forum", "authors": [], "abstract": "OpenAI's advanced large language models (LLMs) have revolutionized natural\nlanguage processing and enabled developers to create innovative applications.\nAs adoption grows, understanding the experiences and challenges of developers\nworking with these technologies is crucial. This paper presents a comprehensive\nanalysis of the OpenAI Developer Forum, focusing on (1) popularity trends and\nuser engagement patterns, and (2) a taxonomy of challenges and concerns faced\nby developers. We first employ a quantitative analysis of the metadata from\n29,576 forum topics, investigating temporal trends in topic creation, the\npopularity of topics across different categories, and user contributions at\nvarious trust levels. We then qualitatively analyze content from 9,301 recently\nactive topics on developer concerns. From a sample of 886 topics, we construct\na taxonomy of concerns in the OpenAI Developer Forum. Our findings uncover\ncritical concerns raised by developers in creating AI-powered applications and\noffer targeted recommendations to address them. This work not only advances\nAI-assisted software engineering but also empowers developer communities to\nshape the responsible evolution and integration of AI technology in society.", "categories": "cs.SE", "created": "2024-08-03", "doi": null, "arxiv_id": "2408.01687"}
{"title": "SiamMo: Siamese Motion-Centric 3D Object Tracking", "authors": [], "abstract": "Current 3D single object tracking methods primarily rely on the Siamese\nmatching-based paradigm, which struggles with textureless and incomplete LiDAR\npoint clouds. Conversely, the motion-centric paradigm avoids appearance\nmatching, thus overcoming these issues. However, its complex multi-stage\npipeline and the limited temporal modeling capability of a single-stream\narchitecture constrain its potential. In this paper, we introduce SiamMo, a\nnovel and simple Siamese motion-centric tracking approach. Unlike the\ntraditional single-stream architecture, we employ Siamese feature extraction\nfor motion-centric tracking. This decouples feature extraction from temporal\nfusion, significantly enhancing tracking performance. Additionally, we design a\nSpatio-Temporal Feature Aggregation module to integrate Siamese features at\nmultiple scales, capturing motion information effectively. We also introduce a\nBox-aware Feature Encoding module to encode object size priors into motion\nestimation. SiamMo is a purely motion-centric tracker that eliminates the need\nfor additional processes like segmentation and box refinement. Without whistles\nand bells, SiamMo not only surpasses state-of-the-art methods across multiple\nbenchmarks but also demonstrates exceptional robustness in challenging\nscenarios. SiamMo sets a new record on the KITTI tracking benchmark with 90.1\\%\nprecision while maintaining a high inference speed of 108 FPS. The code will be\nreleased at https://github.com/HDU-VRLab/SiamMo.", "categories": "cs.CV", "created": "2024-08-03", "doi": null, "arxiv_id": "2408.01688"}
{"title": "Controllable Unlearning for Image-to-Image Generative Models via\n  $\\varepsilon$-Constrained Optimization", "authors": [], "abstract": "While generative models have made significant advancements in recent years,\nthey also raise concerns such as privacy breaches and biases. Machine\nunlearning has emerged as a viable solution, aiming to remove specific training\ndata, e.g., containing private information and bias, from models. In this\npaper, we study the machine unlearning problem in Image-to-Image (I2I)\ngenerative models. Previous studies mainly treat it as a single objective\noptimization problem, offering a solitary solution, thereby neglecting the\nvaried user expectations towards the trade-off between complete unlearning and\nmodel utility. To address this issue, we propose a controllable unlearning\nframework that uses a control coefficient $\\varepsilon$ to control the\ntrade-off. We reformulate the I2I generative model unlearning problem into a\n$\\varepsilon$-constrained optimization problem and solve it with a\ngradient-based method to find optimal solutions for unlearning boundaries.\nThese boundaries define the valid range for the control coefficient. Within\nthis range, every yielded solution is theoretically guaranteed with Pareto\noptimality. We also analyze the convergence rate of our framework under various\ncontrol functions. Extensive experiments on two benchmark datasets across three\nmainstream I2I models demonstrate the effectiveness of our controllable\nunlearning framework.", "categories": "cs.LG cs.AI cs.CV", "created": "2024-08-03", "doi": null, "arxiv_id": "2408.01689"}
{"title": "IDNet: A Novel Dataset for Identity Document Analysis and Fraud\n  Detection", "authors": [], "abstract": "Effective fraud detection and analysis of government-issued identity\ndocuments, such as passports, driver's licenses, and identity cards, are\nessential in thwarting identity theft and bolstering security on online\nplatforms. The training of accurate fraud detection and analysis tools depends\non the availability of extensive identity document datasets. However, current\npublicly available benchmark datasets for identity document analysis, including\nMIDV-500, MIDV-2020, and FMIDV, fall short in several respects: they offer a\nlimited number of samples, cover insufficient varieties of fraud patterns, and\nseldom include alterations in critical personal identifying fields like\nportrait images, limiting their utility in training models capable of detecting\nrealistic frauds while preserving privacy.\n  In response to these shortcomings, our research introduces a new benchmark\ndataset, IDNet, designed to advance privacy-preserving fraud detection efforts.\nThe IDNet dataset comprises 837,060 images of synthetically generated identity\ndocuments, totaling approximately 490 gigabytes, categorized into 20 types from\n$10$ U.S. states and 10 European countries. We evaluate the utility and present\nuse cases of the dataset, illustrating how it can aid in training\nprivacy-preserving fraud detection methods, facilitating the generation of\ncamera and video capturing of identity documents, and testing schema\nunification and other identity document management functionalities.", "categories": "cs.CV cs.AI cs.MM", "created": "2024-08-03", "doi": null, "arxiv_id": "2408.01690"}
{"title": "TreeCSS: An Efficient Framework for Vertical Federated Learning", "authors": [], "abstract": "Vertical federated learning (VFL) considers the case that the features of\ndata samples are partitioned over different participants. VFL consists of two\nmain steps, i.e., identify the common data samples for all participants\n(alignment) and train model using the aligned data samples (training). However,\nwhen there are many participants and data samples, both alignment and training\nbecome slow. As such, we propose TreeCSS as an efficient VFL framework that\naccelerates the two main steps. In particular, for sample alignment, we design\nan efficient multi-party private set intersection (MPSI) protocol called\nTree-MPSI, which adopts a tree-based structure and a data-volume-aware\nscheduling strategy to parallelize alignment among the participants. As model\ntraining time scales with the number of data samples, we conduct coreset\nselection (CSS) to choose some representative data samples for training. Our\nCCS method adopts a clustering-based scheme for security and generality, which\nfirst clusters the features locally on each participant and then merges the\nlocal clustering results to select representative samples. In addition, we\nweight the samples according to their distances to the centroids to reflect\ntheir importance to model training. We evaluate the effectiveness and\nefficiency of our TreeCSS framework on various datasets and models. The results\nshow that compared with vanilla VFL, TreeCSS accelerates training by up to\n2.93x and achieves comparable model accuracy.", "categories": "cs.LG cs.AI", "created": "2024-08-03", "doi": null, "arxiv_id": "2408.01691"}
{"title": "A Comparative Analysis of CNN-based Deep Learning Models for Landslide\n  Detection", "authors": [], "abstract": "Landslides inflict substantial societal and economic damage, underscoring\ntheir global significance as recurrent and destructive natural disasters.\nRecent landslides in northern parts of India and Nepal have caused significant\ndisruption, damaging infrastructure and posing threats to local communities.\nConvolutional Neural Networks (CNNs), a type of deep learning technique, have\nshown remarkable success in image processing. Because of their sophisticated\narchitectures, advanced CNN-based models perform better in landslide detection\nthan conventional algorithms. The purpose of this work is to investigate CNNs'\npotential in more detail, with an emphasis on comparison of CNN based models\nfor better landslide detection. We compared four traditional semantic\nsegmentation models (U-Net, LinkNet, PSPNet, and FPN) and utilized the ResNet50\nbackbone encoder to implement them. Moreover, we have experimented with the\nhyperparameters such as learning rates, batch sizes, and regularization\ntechniques to fine-tune the models. We have computed the confusion matrix for\neach model and used performance metrics including precision, recall and\nf1-score to evaluate and compare the deep learning models. According to the\nexperimental results, LinkNet gave the best results among the four models\nhaving an Accuracy of 97.49% and a F1-score of 85.7% (with 84.49% precision,\n87.07% recall). We have also presented a comprehensive comparison of all\npixel-wise confusion matrix results and the time taken to train each model.", "categories": "cs.CV", "created": "2024-08-03", "doi": null, "arxiv_id": "2408.01692"}
{"title": "Bayesian Active Learning for Semantic Segmentation", "authors": [], "abstract": "Fully supervised training of semantic segmentation models is costly and\nchallenging because each pixel within an image needs to be labeled. Therefore,\nthe sparse pixel-level annotation methods have been introduced to train models\nwith a subset of pixels within each image. We introduce a Bayesian active\nlearning framework based on sparse pixel-level annotation that utilizes a\npixel-level Bayesian uncertainty measure based on Balanced Entropy (BalEnt)\n[84]. BalEnt captures the information between the models' predicted\nmarginalized probability distribution and the pixel labels. BalEnt has linear\nscalability with a closed analytical form and can be calculated independently\nper pixel without relational computations with other pixels. We train our\nproposed active learning framework for Cityscapes, Camvid, ADE20K and VOC2012\nbenchmark datasets and show that it reaches supervised levels of mIoU using\nonly a fraction of labeled pixels while outperforming the previous\nstate-of-the-art active learning models with a large margin.", "categories": "cs.CV", "created": "2024-08-03", "doi": null, "arxiv_id": "2408.01694"}
{"title": "Generating High-quality Symbolic Music Using Fine-grained Discriminators", "authors": [], "abstract": "Existing symbolic music generation methods usually utilize discriminator to\nimprove the quality of generated music via global perception of music. However,\nconsidering the complexity of information in music, such as rhythm and melody,\na single discriminator cannot fully reflect the differences in these two\nprimary dimensions of music. In this work, we propose to decouple the melody\nand rhythm from music, and design corresponding fine-grained discriminators to\ntackle the aforementioned issues. Specifically, equipped with a pitch\naugmentation strategy, the melody discriminator discerns the melody variations\npresented by the generated samples. By contrast, the rhythm discriminator,\nenhanced with bar-level relative positional encoding, focuses on the velocity\nof generated notes. Such a design allows the generator to be more explicitly\naware of which aspects should be adjusted in the generated music, making it\neasier to mimic human-composed music. Experimental results on the POP909\nbenchmark demonstrate the favorable performance of the proposed method compared\nto several state-of-the-art methods in terms of both objective and subjective\nmetrics.", "categories": "cs.SD cs.AI eess.AS", "created": "2024-08-03", "doi": null, "arxiv_id": "2408.01696"}
{"title": "Invariant Graph Learning Meets Information Bottleneck for\n  Out-of-Distribution Generalization", "authors": [], "abstract": "Graph out-of-distribution (OOD) generalization remains a major challenge in\ngraph learning since graph neural networks (GNNs) often suffer from severe\nperformance degradation under distribution shifts. Invariant learning, aiming\nto extract invariant features across varied distributions, has recently emerged\nas a promising approach for OOD generation. Despite the great success of\ninvariant learning in OOD problems for Euclidean data (i.e., images), the\nexploration within graph data remains constrained by the complex nature of\ngraphs. Existing studies, such as data augmentation or causal intervention,\neither suffer from disruptions to invariance during the graph manipulation\nprocess or face reliability issues due to a lack of supervised signals for\ncausal parts. In this work, we propose a novel framework, called Invariant\nGraph Learning based on Information bottleneck theory (InfoIGL), to extract the\ninvariant features of graphs and enhance models' generalization ability to\nunseen distributions. Specifically, InfoIGL introduces a redundancy filter to\ncompress task-irrelevant information related to environmental factors.\nCooperating with our designed multi-level contrastive learning, we maximize the\nmutual information among graphs of the same class in the downstream\nclassification tasks, preserving invariant features for prediction to a great\nextent. An appealing feature of InfoIGL is its strong generalization ability\nwithout depending on supervised signal of invariance. Experiments on both\nsynthetic and real-world datasets demonstrate that our method achieves\nstate-of-the-art performance under OOD generalization for graph classification\ntasks. The source code is available at https://github.com/maowenyu-11/InfoIGL.", "categories": "cs.LG cs.AI stat.ML", "created": "2024-08-03", "doi": null, "arxiv_id": "2408.01697"}
{"title": "Integrating Large Language Models and Knowledge Graphs for Extraction\n  and Validation of Textual Test Data", "authors": [], "abstract": "Aerospace manufacturing companies, such as Thales Alenia Space, design,\ndevelop, integrate, verify, and validate products characterized by high\ncomplexity and low volume. They carefully document all phases for each product\nbut analyses across products are challenging due to the heterogeneity and\nunstructured nature of the data in documents. In this paper, we propose a\nhybrid methodology that leverages Knowledge Graphs (KGs) in conjunction with\nLarge Language Models (LLMs) to extract and validate data contained in these\ndocuments. We consider a case study focused on test data related to electronic\nboards for satellites. To do so, we extend the Semantic Sensor Network\nontology. We store the metadata of the reports in a KG, while the actual test\nresults are stored in parquet accessible via a Virtual Knowledge Graph. The\nvalidation process is managed using an LLM-based approach. We also conduct a\nbenchmarking study to evaluate the performance of state-of-the-art LLMs in\nexecuting this task. Finally, we analyze the costs and benefits of automating\npreexisting processes of manual data extraction and validation for subsequent\ncross-report analyses.", "categories": "cs.AI cs.CL", "created": "2024-08-03", "doi": null, "arxiv_id": "2408.01700"}
{"title": "Signal-SGN: A Spiking Graph Convolutional Network for Skeletal Action\n  Recognition via Learning Temporal-Frequency Dynamics", "authors": [], "abstract": "In skeletal-based action recognition, Graph Convolutional Networks (GCNs)\nbased methods face limitations due to their complexity and high energy\nconsumption. Spiking Neural Networks (SNNs) have gained attention in recent\nyears for their low energy consumption, but existing methods combining GCNs and\nSNNs fail to fully utilize the temporal characteristics of skeletal sequences,\nleading to increased storage and computational costs. To address this issue, we\npropose a Signal-SGN(Spiking Graph Convolutional Network), which leverages the\ntemporal dimension of skeletal sequences as the spiking timestep and treats\nfeatures as discrete stochastic signals. The core of the network consists of a\n1D Spiking Graph Convolutional Network (1D-SGN) and a Frequency Spiking\nConvolutional Network (FSN). The SGN performs graph convolution on single\nframes and incorporates spiking network characteristics to capture inter-frame\ntemporal relationships, while the FSN uses Fast Fourier Transform (FFT) and\ncomplex convolution to extract temporal-frequency features. We also introduce a\nmulti-scale wavelet transform feature fusion module(MWTF) to capture spectral\nfeatures of temporal signals, enhancing the model's classification capability.\nWe propose a pluggable temporal-frequency spatial semantic feature extraction\nmodule(TFSM) to enhance the model's ability to distinguish features without\nincreasing inference-phase consumption. Our numerous experiments on the NTU\nRGB+D, NTU RGB+D 120, and NW-UCLA datasets demonstrate that the proposed models\nnot only surpass existing SNN-based methods in accuracy but also reduce\ncomputational and storage costs during training. Furthermore, they achieve\ncompetitive accuracy compared to corresponding GCN-based methods, which is\nquite remarkable.", "categories": "cs.CV", "created": "2024-08-03", "doi": null, "arxiv_id": "2408.01701"}
{"title": "Beamforming for PIN Diode-Based IRS-Assisted Systems Under a Phase\n  Shift-Dependent Power Consumption Model", "authors": [], "abstract": "Intelligent reflecting surfaces (IRSs) have been regarded as a promising\nenabler for future wireless communication systems. In the literature, IRSs have\nbeen considered power-free or assumed to have constant power consumption.\nHowever, recent experimental results have shown that for\npositive-intrinsic-negative (PIN) diode-based IRSs, the power consumption\ndynamically changes with the phase shift configuration. This phase\nshift-dependent power consumption (PS-DPC) introduces a challenging power\nallocation problem between base station (BS) and IRS. To tackle this issue, in\nthis paper, we investigate a rate maximization problem for IRS-assisted systems\nunder a practical PS-DPC model. For the single-user case, we propose a\ngeneralized Benders decomposition-based beamforming method to maximize the\nachievable rate while satisfying a total system power consumption constraint.\nMoreover, we propose a low-complexity beamforming design, where the powers\nallocated to BS and IRS are optimized offline based on statistical channel\nstate information. Furthermore, for the multi-user case, we solve an equivalent\nweighted mean square error minimization problem with two different joint power\nallocation and phase shift optimization methods. Simulation results indicate\nthat compared to baseline schemes, our proposed methods can flexibly optimize\nthe power allocation between BS and IRS, thus achieving better performance. The\noptimized power allocation strategy strongly depends on the system power\nbudget. When the system power budget is high, the PS-DPC is not the dominant\nfactor in the system power consumption, allowing the IRS to turn on as many PIN\ndiodes as needed to achieve high beamforming quality. When the system power\nbudget is limited, however, more power tends to be allocated to the BS to\nenhance the transmit power, resulting in a lower beamforming quality at the IRS\ndue to the reduced PS-DPC budget.", "categories": "cs.IT eess.SP math.IT", "created": "2024-08-03", "doi": null, "arxiv_id": "2408.01702"}
{"title": "WaitGPT: Monitoring and Steering Conversational LLM Agent in Data\n  Analysis with On-the-Fly Code Visualization", "authors": [], "abstract": "Large language models (LLMs) support data analysis through conversational\nuser interfaces, as exemplified in OpenAI's ChatGPT (formally known as Advanced\nData Analysis or Code Interpreter). Essentially, LLMs produce code for\naccomplishing diverse analysis tasks. However, presenting raw code can obscure\nthe logic and hinder user verification. To empower users with enhanced\ncomprehension and augmented control over analysis conducted by LLMs, we propose\na novel approach to transform LLM-generated code into an interactive visual\nrepresentation. In the approach, users are provided with a clear, step-by-step\nvisualization of the LLM-generated code in real time, allowing them to\nunderstand, verify, and modify individual data operations in the analysis. Our\ndesign decisions are informed by a formative study (N=8) probing into user\npractice and challenges. We further developed a prototype named WaitGPT and\nconducted a user study (N=12) to evaluate its usability and effectiveness. The\nfindings from the user study reveal that WaitGPT facilitates monitoring and\nsteering of data analysis performed by LLMs, enabling participants to enhance\nerror detection and increase their overall confidence in the results.", "categories": "cs.HC", "created": "2024-08-03", "doi": "10.1145/3654777.3676374", "arxiv_id": "2408.01703"}
{"title": "Downstream Transfer Attack: Adversarial Attacks on Downstream Models\n  with Pre-trained Vision Transformers", "authors": [], "abstract": "With the advancement of vision transformers (ViTs) and self-supervised\nlearning (SSL) techniques, pre-trained large ViTs have become the new\nfoundation models for computer vision applications. However, studies have shown\nthat, like convolutional neural networks (CNNs), ViTs are also susceptible to\nadversarial attacks, where subtle perturbations in the input can fool the model\ninto making false predictions. This paper studies the transferability of such\nan adversarial vulnerability from a pre-trained ViT model to downstream tasks.\nWe focus on \\emph{sample-wise} transfer attacks and propose a novel attack\nmethod termed \\emph{Downstream Transfer Attack (DTA)}. For a given test image,\nDTA leverages a pre-trained ViT model to craft the adversarial example and then\napplies the adversarial example to attack a fine-tuned version of the model on\na downstream dataset. During the attack, DTA identifies and exploits the most\nvulnerable layers of the pre-trained model guided by a cosine similarity loss\nto craft highly transferable attacks. Through extensive experiments with\npre-trained ViTs by 3 distinct pre-training methods, 3 fine-tuning schemes, and\nacross 10 diverse downstream datasets, we show that DTA achieves an average\nattack success rate (ASR) exceeding 90\\%, surpassing existing methods by a huge\nmargin. When used with adversarial training, the adversarial examples generated\nby our DTA can significantly improve the model's robustness to different\ndownstream transfer attacks.", "categories": "cs.CV cs.AI", "created": "2024-08-03", "doi": null, "arxiv_id": "2408.01705"}
{"title": "AVESFormer: Efficient Transformer Design for Real-Time Audio-Visual\n  Segmentation", "authors": [], "abstract": "Recently, transformer-based models have demonstrated remarkable performance\non audio-visual segmentation (AVS) tasks. However, their expensive\ncomputational cost makes real-time inference impractical. By characterizing\nattention maps of the network, we identify two key obstacles in AVS models: 1)\nattention dissipation, corresponding to the over-concentrated attention weights\nby Softmax within restricted frames, and 2) inefficient, burdensome transformer\ndecoder, caused by narrow focus patterns in early stages. In this paper, we\nintroduce AVESFormer, the first real-time Audio-Visual Efficient Segmentation\ntransformer that achieves fast, efficient and light-weight simultaneously. Our\nmodel leverages an efficient prompt query generator to correct the behaviour of\ncross-attention. Additionally, we propose ELF decoder to bring greater\nefficiency by facilitating convolutions suitable for local features to reduce\ncomputational burdens. Extensive experiments demonstrate that our AVESFormer\nsignificantly enhances model performance, achieving 79.9% on S4, 57.9% on MS3\nand 31.2% on AVSS, outperforming previous state-of-the-art and achieving an\nexcellent trade-off between performance and speed. Code can be found at\nhttps://github.com/MarkXCloud/AVESFormer.git.", "categories": "cs.CV", "created": "2024-08-03", "doi": null, "arxiv_id": "2408.01708"}
{"title": "A General Ambiguity Model for Binary Edge Images with Edge Tracing and\n  its Implementation", "authors": [], "abstract": "We present a general and intuitive ambiguity model for intersections,\njunctions and other structures in binary edge images. The model is combined\nwith edge tracing, where edges are ordered sequences of connected pixels. The\nobjective is to provide a versatile preprocessing method for tasks such as\nfigure-ground segmentation, object recognition, topological analysis, etc. By\nusing only a small set of straightforward principles, the results are intuitive\nto describe. This helps to implement subsequent processing steps, such as\nresolving ambiguous edge connections at junctions. By using an augmented edge\nmap, neighboring edges can be directly accessed using quick local search\noperations. The edge tracing uses recursion, which leads to compact programming\ncode. We explain our algorithm using pseudocode, compare it with related\nmethods, and show how simple modular postprocessing steps can be used to\noptimize the results. The complete algorithm, including all data structures,\nrequires less than 50 lines of pseudocode. We also provide a C++ implementation\nof our method.", "categories": "cs.CV", "created": "2024-08-03", "doi": null, "arxiv_id": "2408.01712"}
{"title": "Intuitionistic Fuzzy Generalized Eigenvalue Proximal Support Vector\n  Machine", "authors": [], "abstract": "Generalized eigenvalue proximal support vector machine (GEPSVM) has attracted\nwidespread attention due to its simple architecture, rapid execution, and\ncommendable performance. GEPSVM gives equal significance to all samples,\nthereby diminishing its robustness and efficacy when confronted with real-world\ndatasets containing noise and outliers. In order to reduce the impact of noises\nand outliers, we propose a novel intuitionistic fuzzy generalized eigenvalue\nproximal support vector machine (IF-GEPSVM). The proposed IF-GEPSVM assigns the\nintuitionistic fuzzy score to each training sample based on its location and\nsurroundings in the high-dimensional feature space by using a kernel function.\nThe solution of the IF-GEPSVM optimization problem is obtained by solving a\ngeneralized eigenvalue problem. Further, we propose an intuitionistic fuzzy\nimproved GEPSVM (IF-IGEPSVM) by solving the standard eigenvalue decomposition\nresulting in simpler optimization problems with less computation cost which\nleads to an efficient intuitionistic fuzzy-based model. We conduct a\ncomprehensive evaluation of the proposed IF-GEPSVM and IF-IGEPSVM models on UCI\nand KEEL datasets. Moreover, to evaluate the robustness of the proposed\nIF-GEPSVM and IF-IGEPSVM models, label noise is introduced into some UCI and\nKEEL datasets. The experimental findings showcase the superior generalization\nperformance of the proposed models when compared to the existing baseline\nmodels, both with and without label noise. Our experimental results, supported\nby rigorous statistical analyses, confirm the superior generalization abilities\nof the proposed IF-GEPSVM and IF-IGEPSVM models over the baseline models.\nFurthermore, we implement the proposed IF-GEPSVM and IF-IGEPSVM models on the\nUSPS recognition dataset, yielding promising results that underscore the\nmodels' effectiveness in practical and real-world applications.", "categories": "cs.LG", "created": "2024-08-03", "doi": "10.1016/j.neucom.2024.128258", "arxiv_id": "2408.01713"}
{"title": "Joint Universal Adversarial Perturbations with Interpretations", "authors": [], "abstract": "Deep neural networks (DNNs) have significantly boosted the performance of\nmany challenging tasks. Despite the great development, DNNs have also exposed\ntheir vulnerability. Recent studies have shown that adversaries can manipulate\nthe predictions of DNNs by adding a universal adversarial perturbation (UAP) to\nbenign samples. On the other hand, increasing efforts have been made to help\nusers understand and explain the inner working of DNNs by highlighting the most\ninformative parts (i.e., attribution maps) of samples with respect to their\npredictions. Moreover, we first empirically find that such attribution maps\nbetween benign and adversarial examples have a significant discrepancy, which\nhas the potential to detect universal adversarial perturbations for defending\nagainst adversarial attacks. This finding motivates us to further investigate a\nnew research problem: whether there exist universal adversarial perturbations\nthat are able to jointly attack DNNs classifier and its interpretation with\nmalicious desires. It is challenging to give an explicit answer since these two\nobjectives are seemingly conflicting. In this paper, we propose a novel\nattacking framework to generate joint universal adversarial perturbations\n(JUAP), which can fool the DNNs model and misguide the inspection from\ninterpreters simultaneously. Comprehensive experiments on various datasets\ndemonstrate the effectiveness of the proposed method JUAP for joint attacks. To\nthe best of our knowledge, this is the first effort to study UAP for jointly\nattacking both DNNs and interpretations.", "categories": "cs.CR cs.AI", "created": "2024-08-03", "doi": null, "arxiv_id": "2408.01715"}
{"title": "Visual-Inertial SLAM for Agricultural Robotics: Benchmarking the\n  Benefits and Computational Costs of Loop Closing", "authors": [], "abstract": "Simultaneous Localization and Mapping (SLAM) is essential for mobile\nrobotics, enabling autonomous navigation in dynamic, unstructured outdoor\nenvironments without relying on external positioning systems. In agricultural\napplications, where environmental conditions can be particularly challenging\ndue to variable lighting or weather conditions, Visual-Inertial SLAM has\nemerged as a potential solution. This paper benchmarks several open-source\nVisual-Inertial SLAM systems, including ORB-SLAM3, VINS-Fusion, OpenVINS,\nKimera, and SVO Pro, to evaluate their performance in agricultural settings. We\nfocus on the impact of loop closing on localization accuracy and computational\ndemands, providing a comprehensive analysis of these systems' effectiveness in\nreal-world environments and especially their application to embedded systems in\nagricultural robotics. Our contributions further include an assessment of\nvarying frame rates on localization accuracy and computational load. The\nfindings highlight the importance of loop closing in improving localization\naccuracy while managing computational resources efficiently, offering valuable\ninsights for optimizing Visual-Inertial SLAM systems for practical outdoor\napplications in mobile robotics.", "categories": "cs.RO cs.CV", "created": "2024-08-03", "doi": null, "arxiv_id": "2408.01716"}
{"title": "MoleNetwork: A tool for the generation of synthetic optical network\n  topologies", "authors": [], "abstract": "Model networks and their underlying topologies have been used as a reference\nfor techno-economic studies for several decades. Existing reference topologies\nfor optical networks may cover different network segments such as backbone,\nmetro core, metro aggregation, access and/or data center. While telco operators\nwork on the optimization of their own existing deployed optical networks, the\navailability of different topologies is useful for researchers and technology\ndevelopers to test their solutions in a variety of scenarios and validate the\nperformance in terms of energy efficiency or cost reduction. This paper\npresents an open-source tool, MoleNetwork, to generate graphs inspired by real\nnetwork topologies of telecommunication operators that can be used as\nbenchmarks for techno-economic studies.", "categories": "cs.NI", "created": "2024-08-03", "doi": null, "arxiv_id": "2408.01721"}
{"title": "A Novel Evaluation Framework for Image2Text Generation", "authors": [], "abstract": "Evaluating the quality of automatically generated image descriptions is\nchallenging, requiring metrics that capture various aspects such as\ngrammaticality, coverage, correctness, and truthfulness. While human evaluation\noffers valuable insights, its cost and time-consuming nature pose limitations.\nExisting automated metrics like BLEU, ROUGE, METEOR, and CIDEr aim to bridge\nthis gap but often show weak correlations with human judgment. We address this\nchallenge by introducing a novel evaluation framework rooted in a modern large\nlanguage model (LLM), such as GPT-4 or Gemini, capable of image generation. In\nour proposed framework, we begin by feeding an input image into a designated\nimage captioning model, chosen for evaluation, to generate a textual\ndescription. Using this description, an LLM then creates a new image. By\nextracting features from both the original and LLM-created images, we measure\ntheir similarity using a designated similarity metric. A high similarity score\nsuggests that the image captioning model has accurately generated textual\ndescriptions, while a low similarity score indicates discrepancies, revealing\npotential shortcomings in the model's performance. Human-annotated reference\ncaptions are not required in our proposed evaluation framework, which serves as\na valuable tool for evaluating the effectiveness of image captioning models.\nIts efficacy is confirmed through human evaluation.", "categories": "cs.CV cs.IR", "created": "2024-08-03", "doi": null, "arxiv_id": "2408.01723"}
{"title": "The Drama Machine: Simulating Character Development with LLM Agents", "authors": [], "abstract": "This paper explores use of multiple large language model (LLM) agents to\nsimulate complex, dynamic characters in dramatic scenarios. We introduce a\n`drama machine' framework that coordinates interactions between LLM agents\nplaying different `Ego' and `Superego' psychological roles. In roleplay\nsimulations, this design allows intersubjective dialogue and intra-subjective\ninternal monologue to develop in parallel. We apply this framework to two\ndramatic scenarios - an interview and a detective story - and compare character\ndevelopment with and without the Superego's influence. Though exploratory,\nresults suggest this multi-agent approach can produce more nuanced, adaptive\nnarratives that evolve over a sequence of dialogical turns. We discuss\ndifferent modalities of LLM-based roleplay and character development, along\nwith what this might mean for conceptualization of AI subjectivity. The paper\nconcludes by considering how this approach opens possibilities for thinking of\nthe roles of internal conflict and social performativity in AI-based\nsimulation.", "categories": "cs.CY", "created": "2024-08-03", "doi": null, "arxiv_id": "2408.01725"}
{"title": "Survey on Emotion Recognition through Posture Detection and the\n  possibility of its application in Virtual Reality", "authors": [], "abstract": "A survey is presented focused on using pose estimation techniques in\nEmotional recognition using various technologies normal cameras, and depth\ncameras for real-time, and the potential use of VR and inputs including images,\nvideos, and 3-dimensional poses described in vector space. We discussed 19\nresearch papers collected from selected journals and databases highlighting\ntheir methodology, classification algorithm, and the used datasets that relate\nto emotion recognition and pose estimation. A benchmark has been made according\nto their accuracy as it was the most common performance measurement metric\nused. We concluded that the multimodal Approaches overall made the best\naccuracy and then we mentioned futuristic concerns that can improve the\ndevelopment of this research topic.", "categories": "cs.CV cs.AI", "created": "2024-08-03", "doi": null, "arxiv_id": "2408.01728"}
{"title": "A Survey on Robotic Prosthetics: Neuroprosthetics, Soft Actuators, and\n  Control Strategies", "authors": [], "abstract": "The field of robotics is a quickly evolving feat of technology that accepts\ncontributions from various genres of science. Neuroscience, Physiology,\nChemistry, Material science, Computer science, and the wide umbrella of\nmechatronics have all simultaneously contributed to many innovations in the\nprosthetic applications of robotics. This review begins with a discussion of\nthe scope of the term robotic prosthetics and discusses the evolving domain of\nNeuroprosthetics. The discussion is then constrained to focus on various\nactuation and control strategies for robotic prosthetic limbs. This review\ndiscusses various soft robotic actuators such as EAP, SMA, FFA, etc., and the\nmerits of such actuators over conventional hard robotic actuators. Options in\ncontrol strategies for robotic prosthetics, that are in various states of\nresearch and development, are reviewed. This paper concludes the discussion\nwith an analysis regarding the prospective direction in which this field of\nrobotic prosthetics is evolving in terms of actuation, control, and other\nfeatures relevant to artificial limbs. This paper intends to review some of the\nemerging research and development trends in the field of robotic prosthetics\nand summarize many tangents that are represented under this broad domain in an\napproachable manner.", "categories": "cs.RO cs.SY eess.SY", "created": "2024-08-03", "doi": "10.1145/3648355", "arxiv_id": "2408.01729"}
{"title": "Real-time Hybrid System Identification with Online Deterministic\n  Annealing", "authors": [], "abstract": "We introduce a real-time identification method for discrete-time\nstate-dependent switching systems in both the input--output and state-space\ndomains. In particular, we design a system of adaptive algorithms running in\ntwo timescales; a stochastic approximation algorithm implements an online\ndeterministic annealing scheme at a slow timescale and estimates the\nmode-switching signal, and an recursive identification algorithm runs at a\nfaster timescale and updates the parameters of the local models based on the\nestimate of the switching signal. We first focus on piece-wise affine systems\nand discuss identifiability conditions and convergence properties based on the\ntheory of two-timescale stochastic approximation. In contrast to standard\nidentification algorithms for switched systems, the proposed approach gradually\nestimates the number of modes and is appropriate for real-time system\nidentification using sequential data acquisition. The progressive nature of the\nalgorithm improves computational efficiency and provides real-time control over\nthe performance-complexity trade-off. Finally, we address specific challenges\nthat arise in the application of the proposed methodology in identification of\nmore general switching systems. Simulation results validate the efficacy of the\nproposed methodology.", "categories": "eess.SY cs.LG cs.SY", "created": "2024-08-03", "doi": null, "arxiv_id": "2408.01730"}
{"title": "Landmark-guided Diffusion Model for High-fidelity and Temporally\n  Coherent Talking Head Generation", "authors": [], "abstract": "Audio-driven talking head generation is a significant and challenging task\napplicable to various fields such as virtual avatars, film production, and\nonline conferences. However, the existing GAN-based models emphasize generating\nwell-synchronized lip shapes but overlook the visual quality of generated\nframes, while diffusion-based models prioritize generating high-quality frames\nbut neglect lip shape matching, resulting in jittery mouth movements. To\naddress the aforementioned problems, we introduce a two-stage diffusion-based\nmodel. The first stage involves generating synchronized facial landmarks based\non the given speech. In the second stage, these generated landmarks serve as a\ncondition in the denoising process, aiming to optimize mouth jitter issues and\ngenerate high-fidelity, well-synchronized, and temporally coherent talking head\nvideos. Extensive experiments demonstrate that our model yields the best\nperformance.", "categories": "cs.CV cs.AI", "created": "2024-08-03", "doi": null, "arxiv_id": "2408.01732"}
{"title": "CoEdPilot: Recommending Code Edits with Learned Prior Edit Relevance,\n  Project-wise Awareness, and Interactive Nature", "authors": [], "abstract": "Recent years have seen the development of LLM-based code generation. Compared\nto generating code in a software project, incremental code edits are\nempirically observed to be more frequent. The emerging code editing approaches\nusually formulate the problem as generating an edit based on known relevant\nprior edits and context. However, practical code edits can be more complicated.\nFirst, an editing session can include multiple (ir)relevant edits to the code\nunder edit. Second, the inference of the subsequent edits is non-trivial as the\nscope of its ripple effect can be the whole project. In this work, we propose\nCoEdPilot, an LLM-driven solution to recommend code edits by discriminating the\nrelevant edits, exploring their interactive natures, and estimating its ripple\neffect in the project. Specifically, CoEdPilot orchestrates multiple neural\ntransformers to identify what and how to edit in the project regarding both\nedit location and edit content. When a user accomplishes an edit with an\noptional editing description, a Subsequent Edit Analysis first reports the most\nrelevant files in the project with what types of edits (e.g., keep, insert, and\nreplace) can happen for each line of their code. Next, an Edit-content\nGenerator generates concrete edit options for the lines of code, regarding its\nrelevant prior changes reported by an Edit-dependency Analyzer. Lastly, both\nthe Subsequent Edit Analysis and the Edit-content Generator capture relevant\nprior edits as feedback to readjust their recommendations. We train our models\nby collecting over 180K commits from 471 open-source projects in 5 programming\nlanguages. Our extensive experiments show that CoEdPilot can well predict the\nedits (i.e., predicting edit location with an accuracy of 70.8%-85.3%, and the\nedit content with an exact match rate of 41.8% and BLEU4 score of 60.7)...", "categories": "cs.SE", "created": "2024-08-03", "doi": "10.1145/3650212.3652142", "arxiv_id": "2408.01733"}
{"title": "Can LLMs predict the convergence of Stochastic Gradient Descent?", "authors": [], "abstract": "Large-language models are notoriously famous for their impressive performance\nacross a wide range of tasks. One surprising example of such impressive\nperformance is a recently identified capacity of LLMs to understand the\ngoverning principles of dynamical systems satisfying the Markovian property. In\nthis paper, we seek to explore this direction further by studying the dynamics\nof stochastic gradient descent in convex and non-convex optimization. By\nleveraging the theoretical link between the SGD and Markov chains, we show a\nremarkable zero-shot performance of LLMs in predicting the local minima to\nwhich SGD converges for previously unseen starting points. On a more general\nlevel, we inquire about the possibility of using LLMs to perform zero-shot\nrandomized trials for larger deep learning models used in practice.", "categories": "cs.LG cs.AI stat.ML", "created": "2024-08-03", "doi": null, "arxiv_id": "2408.01736"}
{"title": "Real-time Localization and Mapping in Architectural Plans with\n  Deviations", "authors": [], "abstract": "Having prior knowledge of an environment boosts the localization and mapping\naccuracy of robots. Several approaches in the literature have utilized\narchitectural plans in this regard. However, almost all of them overlook the\ndeviations between actual as-built environments and as-planned architectural\ndesigns, introducing bias in the estimations. To address this issue, we present\na novel localization and mapping method denoted as deviations-informed\nSituational Graphs or diS-Graphs that integrates prior knowledge from\narchitectural plans even in the presence of deviations. It is based on\nSituational Graphs (S-Graphs) that merge geometric models of the environment\nwith 3D scene graphs into a multi-layered jointly optimizable factor graph. Our\ndiS-Graph extracts information from architectural plans by first modeling them\nas a hierarchical factor graph, which we will call an Architectural Graph\n(A-Graph). While the robot explores the real environment, it estimates an\nS-Graph from its onboard sensors. We then use a novel matching algorithm to\nregister the A-Graph and S-Graph in the same reference, and merge both of them\nwith an explicit model of deviations. Finally, an alternating graph\noptimization strategy allows simultaneous global localization and mapping, as\nwell as deviation estimation between both the A-Graph and the S-Graph. We\nperform several experiments in simulated and real datasets in the presence of\ndeviations. On average, our diS-Graphs outperforms the baselines by a margin of\napproximately 43% in simulated environments and by 7% in real environments,\nwhile being able to estimate deviations up to 35 cm and 15 degrees.", "categories": "cs.RO", "created": "2024-08-03", "doi": null, "arxiv_id": "2408.01737"}
{"title": "Adaptive Safety with Control BarrierFunctions and Triggered Batch\n  Least-Squares Identifier", "authors": [], "abstract": "In this paper, a triggered Batch Least-Squares Identifier (BaLSI) based\nadaptive safety control scheme is proposed for uncertain systems with\npotentially conflicting control objectives and safety constraints. A relaxation\nterm is added to the Quadratic Programs (QP) combining the transformed Control\nLyapunov Functions (CLFs) and Control Barrier Functions (CBFs), to mediate the\npotential conflict. The existing Lyapunov-based adaptive schemes designed to\nguarantee specific properties of the Lyapunov functions, may grow unboundedly\nunder the effects of the relaxation term. The adaptive law is designed by\nprocessing system inputs and outputs, to avoid unbounded estimates and\noverparameterization problems in the existing results. A safetytriggered\ncondition is presented, based on which the forward invariant property of the\nsafe set is shown and Zeno behavior can be excluded. Simulation results are\npresented to demonstrate the effectiveness of the proposed adaptive control\nscheme.", "categories": "eess.SY cs.SY", "created": "2024-08-03", "doi": null, "arxiv_id": "2408.01738"}
{"title": "LAM3D: Leveraging Attention for Monocular 3D Object Detection", "authors": [], "abstract": "Since the introduction of the self-attention mechanism and the adoption of\nthe Transformer architecture for Computer Vision tasks, the Vision\nTransformer-based architectures gained a lot of popularity in the field, being\nused for tasks such as image classification, object detection and image\nsegmentation. However, efficiently leveraging the attention mechanism in vision\ntransformers for the Monocular 3D Object Detection task remains an open\nquestion. In this paper, we present LAM3D, a framework that Leverages\nself-Attention mechanism for Monocular 3D object Detection. To do so, the\nproposed method is built upon a Pyramid Vision Transformer v2 (PVTv2) as\nfeature extraction backbone and 2D/3D detection machinery. We evaluate the\nproposed method on the KITTI 3D Object Detection Benchmark, proving the\napplicability of the proposed solution in the autonomous driving domain and\noutperforming reference methods. Moreover, due to the usage of self-attention,\nLAM3D is able to systematically outperform the equivalent architecture that\ndoes not employ self-attention.", "categories": "cs.CV cs.AI", "created": "2024-08-03", "doi": null, "arxiv_id": "2408.01739"}
{"title": "Summarization of Investment Reports Using Pre-trained Model", "authors": [], "abstract": "In this paper, we attempt to summarize monthly reports as investment reports.\nFund managers have a wide range of tasks, one of which is the preparation of\ninvestment reports. In addition to preparing monthly reports on fund\nmanagement, fund managers prepare management reports that summarize these\nmonthly reports every six months or once a year. The preparation of fund\nreports is a labor-intensive and time-consuming task. Therefore, in this paper,\nwe tackle investment summarization from monthly reports using transformer-based\nmodels. There are two main types of summarization methods: extractive\nsummarization and abstractive summarization, and this study constructs both\nmethods and examines which is more useful in summarizing investment reports.", "categories": "cs.CL", "created": "2024-08-03", "doi": "10.1109/IIAI-AAI59060.2023.00111", "arxiv_id": "2408.01744"}
{"title": "Indexing and Visualization of Climate Change Narratives Using BERT and\n  Causal Extraction", "authors": [], "abstract": "In this study, we propose a methodology to extract, index, and visualize\n``climate change narratives'' (stories about the connection between causal and\nconsequential events related to climate change). We use two natural language\nprocessing methods, BERT (Bidirectional Encoder Representations from\nTransformers) and causal extraction, to textually analyze newspaper articles on\nclimate change to extract ``climate change narratives.'' The novelty of the\nmethodology could extract and quantify the causal relationships assumed by the\nnewspaper's writers. Looking at the extracted climate change narratives over\ntime, we find that since 2018, an increasing number of narratives suggest the\nimpact of the development of climate change policy discussion and the\nimplementation of climate change-related policies on corporate behaviors,\nmacroeconomics, and price dynamics. We also observed the recent emergence of\nnarratives focusing on the linkages between climate change-related policies and\nmonetary policy. Furthermore, there is a growing awareness of the negative\nimpacts of natural disasters (e.g., abnormal weather and severe floods) related\nto climate change on economic activities, and this issue might be perceived as\na new challenge for companies and governments. The methodology of this study is\nexpected to be applied to a wide range of fields, as it can analyze causal\nrelationships among various economic topics, including analysis of inflation\nexpectation or monetary policy communication strategy.", "categories": "cs.CL", "created": "2024-08-03", "doi": "10.1109/BigData59044.2023.10386320", "arxiv_id": "2408.01745"}
{"title": "Domain penalisation for improved Out-of-Distribution Generalisation", "authors": [], "abstract": "In the field of object detection, domain generalisation (DG) aims to ensure\nrobust performance across diverse and unseen target domains by learning the\nrobust domain-invariant features corresponding to the objects of interest\nacross multiple source domains. While there are many approaches established for\nperforming DG for the task of classification, there has been a very little\nfocus on object detection. In this paper, we propose a domain penalisation (DP)\nframework for the task of object detection, where the data is assumed to be\nsampled from multiple source domains and tested on completely unseen test\ndomains. We assign penalisation weights to each domain, with the values updated\nbased on the detection networks performance on the respective source domains.\nBy prioritising the domains that needs more attention, our approach effectively\nbalances the training process. We evaluate our solution on the GWHD 2021\ndataset, a component of the WiLDS benchmark and we compare against ERM and\nGroupDRO as these are primarily loss function based. Our extensive experimental\nresults reveals that the proposed approach improves the accuracy by 0.3 percent\nand 0.5 percent on validation and test out-of-distribution (OOD) sets,\nrespectively for FasterRCNN. We also compare the performance of our approach on\nFCOS detector and show that our approach improves the baseline OOD performance\nover the existing approaches by 1.3 percent and 1.4 percent on validation and\ntest sets, respectively. This study underscores the potential of performance\nbased domain penalisation in enhancing the generalisation ability of object\ndetection models across diverse environments.", "categories": "cs.CV", "created": "2024-08-03", "doi": null, "arxiv_id": "2408.01746"}
{"title": "Classical Machine Learning: Seventy Years of Algorithmic Learning\n  Evolution", "authors": [], "abstract": "Machine learning (ML) has transformed numerous fields, but understanding its\nfoundational research is crucial for its continued progress. This paper\npresents an overview of the significant classical ML algorithms and examines\nthe state-of-the-art publications spanning twelve decades through an extensive\nbibliometric analysis study. We analyzed a dataset of highly cited papers from\nprominent ML conferences and journals, employing citation and keyword analyses\nto uncover critical insights. The study further identifies the most influential\npapers and authors, reveals the evolving collaborative networks within the ML\ncommunity, and pinpoints prevailing research themes and emerging focus areas.\nAdditionally, we examine the geographic distribution of highly cited\npublications, highlighting the leading countries in ML research. This study\nprovides a comprehensive overview of the evolution of traditional learning\nalgorithms and their impacts. It discusses challenges and opportunities for\nfuture development, focusing on the Global South. The findings from this paper\noffer valuable insights for both ML experts and the broader research community,\nenhancing understanding of the field's trajectory and its significant influence\non recent advances in learning algorithms.", "categories": "cs.LG", "created": "2024-08-03", "doi": null, "arxiv_id": "2408.01747"}
{"title": "Discovery of Rare Causal Knowledge from Financial Statement Summaries", "authors": [], "abstract": "What would happen if temperatures were subdued and result in a cool summer?\nOne can easily imagine that air conditioner, ice cream or beer sales would be\nsuppressed as a result of this. Less obvious is that agricultural shipments\nmight be delayed, or that sound proofing material sales might decrease. The\nability to extract such causal knowledge is important, but it is also important\nto distinguish between cause-effect pairs that are known and those that are\nlikely to be unknown, or rare. Therefore, in this paper, we propose a method\nfor extracting rare causal knowledge from Japanese financial statement\nsummaries produced by companies. Our method consists of three steps. First, it\nextracts sentences that include causal knowledge from the summaries using a\nmachine learning method based on an extended language ontology. Second, it\nobtains causal knowledge from the extracted sentences using syntactic patterns.\nFinally, it extracts the rarest causal knowledge from the knowledge it has\nobtained.", "categories": "cs.CL", "created": "2024-08-03", "doi": "10.1109/SSCI.2017.8285265", "arxiv_id": "2408.01748"}
{"title": "On the Rationale and Use of Assertion Messages in Test Code: Insights\n  from Software Practitioners", "authors": [], "abstract": "Unit testing is an important practice that helps ensure the quality of a\nsoftware system by validating its behavior through a series of test cases. Core\nto these test cases are assertion statements, which enable software\npractitioners to validate the correctness of the system's behavior. To aid with\nunderstanding and troubleshooting test case failures, practitioners can include\na message (i.e., assertion message) within the assertion statement. While prior\nstudies have examined the frequency and structure of assertion messages by\nmining software repositories, they do not determine their types or purposes or\nhow practitioners perceive the need for or the usage of various types of\nassertion messages.\n  In this paper, we survey 138 professional software practitioners to gather\ninsights into their experience and views regarding assertion messages. Our\nfindings reveal that a majority of survey respondents find assertion messages\nvaluable for troubleshooting failures, improving test understandability, and\nserving as documentation. However, not all respondents consistently include\nmessages in their assertion methods. We also identified common considerations\nfor constructing effective assertion messages, challenges in crafting them,\nmaintenance techniques, and their integration into debugging processes.\n  Our results contribute to the understanding of current practices and provide\nguidelines for authoring high-quality assertion messages, serving as a\nfoundation for best practices and coding standards. Furthermore, the insights\ncan guide the improvement of automated unit testing tools by incorporating\nchecks for the presence and quality of assertion messages and providing\nreal-time feedback to practitioners.", "categories": "cs.SE", "created": "2024-08-03", "doi": null, "arxiv_id": "2408.01751"}
{"title": "Advancing Green AI: Efficient and Accurate Lightweight CNNs for Rice\n  Leaf Disease Identification", "authors": [], "abstract": "Rice plays a vital role as a primary food source for over half of the world's\npopulation, and its production is critical for global food security.\nNevertheless, rice cultivation is frequently affected by various diseases that\ncan severely decrease yield and quality. Therefore, early and accurate\ndetection of rice diseases is necessary to prevent their spread and minimize\ncrop losses. In this research, we explore three mobile-compatible CNN\narchitectures, namely ShuffleNet, MobileNetV2, and EfficientNet-B0, for rice\nleaf disease classification. These models are selected due to their\ncompatibility with mobile devices, as they demand less computational power and\nmemory compared to other CNN models. To enhance the performance of the three\nmodels, we added two fully connected layers separated by a dropout layer. We\nused early stop creation to prevent the model from being overfiting. The\nresults of the study showed that the best performance was achieved by the\nEfficientNet-B0 model with an accuracy of 99.8%. Meanwhile, MobileNetV2 and\nShuffleNet only achieved accuracies of 84.21% and 66.51%, respectively. This\nstudy shows that EfficientNet-B0 when combined with the proposed layer and\nearly stop, can produce a high-accuracy model.\n  Keywords: rice leaf detection; green AI; smart agriculture; EfficientNet;", "categories": "cs.CV cs.AI", "created": "2024-08-03", "doi": null, "arxiv_id": "2408.01752"}
{"title": "Opinion Dynamics with Set-Based Confidence: Convergence Criteria and\n  Periodic Solutions", "authors": [], "abstract": "This paper introduces a new multidimensional extension of the\nHegselmann-Krause (HK) opinion dynamics model, where opinion proximity is not\ndetermined by a norm or metric. Instead, each agent trusts opinions within the\nMinkowski sum $\\xi+\\mathcal{O}$, where $\\xi$ is the agent's current opinion and\n$\\mathcal{O}$ is the confidence set defining acceptable deviations. During each\niteration, agents update their opinions by simultaneously averaging the trusted\nopinions. Unlike traditional HK systems, where $\\mathcal{O}$ is a ball in some\nnorm, our model allows the confidence set to be non-convex and even unbounded.\n  We demonstrate that the new model, referred to as SCOD (Set-based Confidence\nOpinion Dynamics), can exhibit properties absent in the conventional HK model.\nSome solutions may converge to non-equilibrium points in the state space, while\nothers oscillate periodically. These ``pathologies'' disappear if the set\n$\\mathcal{O}$ is symmetric and contains zero in its interior: similar to the\nusual HK model, SCOD then converges in a finite number of iterations to one of\nthe equilibrium points. The latter property is also preserved if one agent is\n\"stubborn\" and resists changing their opinion, yet still influences the others;\nhowever, two stubborn agents can lead to oscillations.", "categories": "cs.MA cs.SY eess.SY math.DS math.OC nlin.AO", "created": "2024-08-03", "doi": null, "arxiv_id": "2408.01753"}
{"title": "Large Language Models for Equivalent Mutant Detection: How Far Are We?", "authors": [], "abstract": "Mutation testing is vital for ensuring software quality. However, the\npresence of equivalent mutants is known to introduce redundant cost and bias\nissues, hindering the effectiveness of mutation testing in practical use.\nAlthough numerous equivalent mutant detection (EMD) techniques have been\nproposed, they exhibit limitations due to the scarcity of training data and\nchallenges in generalizing to unseen mutants. Recently, large language models\n(LLMs) have been extensively adopted in various code-related tasks and have\nshown superior performance by more accurately capturing program semantics. Yet\nthe performance of LLMs in equivalent mutant detection remains largely unclear.\nIn this paper, we conduct an empirical study on 3,302 method-level Java mutant\npairs to comprehensively investigate the effectiveness and efficiency of LLMs\nfor equivalent mutant detection. Specifically, we assess the performance of\nLLMs compared to existing EMD techniques, examine the various strategies of\nLLMs, evaluate the orthogonality between EMD techniques, and measure the time\noverhead of training and inference. Our findings demonstrate that LLM-based\ntechniques significantly outperform existing techniques (i.e., the average\nimprovement of 35.69% in terms of F1-score), with the fine-tuned code embedding\nstrategy being the most effective. Moreover, LLM-based techniques offer an\nexcellent balance between cost (relatively low training and inference time) and\neffectiveness. Based on our findings, we further discuss the impact of model\nsize and embedding quality, and provide several promising directions for future\nresearch. This work is the first to examine LLMs in equivalent mutant\ndetection, affirming their effectiveness and efficiency.", "categories": "cs.SE", "created": "2024-08-03", "doi": null, "arxiv_id": "2408.01760"}
{"title": "Joint Model Pruning and Resource Allocation for Wireless Time-triggered\n  Federated Learning", "authors": [], "abstract": "Time-triggered federated learning, in contrast to conventional event-based\nfederated learning, organizes users into tiers based on fixed time intervals.\nHowever, this network still faces challenges due to a growing number of devices\nand limited wireless bandwidth, increasing issues like stragglers and\ncommunication overhead. In this paper, we apply model pruning to wireless\nTime-triggered systems and jointly study the problem of optimizing the pruning\nratio and bandwidth allocation to minimize training loss under communication\nlatency constraints. To solve this joint optimization problem, we perform a\nconvergence analysis on the gradient $l_2$-norm of the asynchronous multi-tier\nfederated learning (FL) model with adaptive model pruning. The convergence\nupper bound is derived and a joint optimization problem of pruning ratio and\nwireless bandwidth is defined to minimize the model training loss under a given\ncommunication latency constraint. The closed-form solutions for wireless\nbandwidth and pruning ratio by using KKT conditions are then formulated. As\nindicated in the simulation experiments, our proposed TT-Prune demonstrates a\n40% reduction in communication cost, compared with the asynchronous multi-tier\nFL without model pruning, while maintaining the model convergence at the same\nlevel.", "categories": "cs.LG cs.IT math.IT", "created": "2024-08-03", "doi": null, "arxiv_id": "2408.01765"}
{"title": "MultiFuser: Multimodal Fusion Transformer for Enhanced Driver Action\n  Recognition", "authors": [], "abstract": "Driver action recognition, aiming to accurately identify drivers' behaviours,\nis crucial for enhancing driver-vehicle interactions and ensuring driving\nsafety. Unlike general action recognition, drivers' environments are often\nchallenging, being gloomy and dark, and with the development of sensors,\nvarious cameras such as IR and depth cameras have emerged for analyzing\ndrivers' behaviors. Therefore, in this paper, we propose a novel multimodal\nfusion transformer, named MultiFuser, which identifies cross-modal\ninterrelations and interactions among multimodal car cabin videos and\nadaptively integrates different modalities for improved representations.\nSpecifically, MultiFuser comprises layers of Bi-decomposed Modules to model\nspatiotemporal features, with a modality synthesizer for multimodal features\nintegration. Each Bi-decomposed Module includes a Modal Expertise ViT block for\nextracting modality-specific features and a Patch-wise Adaptive Fusion block\nfor efficient cross-modal fusion. Extensive experiments are conducted on\nDrive&Act dataset and the results demonstrate the efficacy of our proposed\napproach.", "categories": "cs.CV", "created": "2024-08-03", "doi": null, "arxiv_id": "2408.01766"}
{"title": "Comparison of Embedded Spaces for Deep Learning Classification", "authors": [], "abstract": "Embedded spaces are a key feature in deep learning. Good embedded spaces\nrepresent the data well to support classification and advanced techniques such\nas open-set recognition, few-short learning and explainability. This paper\npresents a compact overview of different techniques to design embedded spaces\nfor classification. It compares different loss functions and constraints on the\nnetwork parameters with respect to the achievable geometric structure of the\nembedded space. The techniques are demonstrated with two and three-dimensional\nembeddings for the MNIST, Fashion MNIST and CIFAR-10 datasets, allowing visual\ninspection of the embedded spaces.", "categories": "cs.LG cs.CV eess.IV eess.SP", "created": "2024-08-03", "doi": null, "arxiv_id": "2408.01767"}
{"title": "Building Living Software Systems with Generative & Agentic AI", "authors": [], "abstract": "This paper is an opinion paper that looks at the future of computing in the\nage of Generative \\& Agentic AI. Current software systems are static and\ninflexible, leading to significant challenges in translating human goals into\ncomputational actions. \"Living software systems\" powered by generative AI offer\na solution to this fundamental problem in computing. Traditional software\ndevelopment involves multiple layers of imperfect translation, from business\nrequirements to code, resulting in rigid systems that struggle to adapt to\nchanging user needs and contexts. Generative AI, particularly large language\nmodels, can serve as a universal translator between human intent and computer\noperations. This approach enables the creation of more flexible, context-aware\nsystems that can dynamically evolve to meet user goals. Two pathways for\nimplementing living software systems are explored: using generative AI to\naccelerate traditional software development, and leveraging agentic AI to\ncreate truly adaptive systems. New skills like Prompt Engineering are\nnecessary. By reimagining software as a living, adaptable entity, we can create\ncomputing interfaces that are more intuitive, powerful, and responsive to human\nneeds.", "categories": "cs.SE", "created": "2024-08-03", "doi": null, "arxiv_id": "2408.01768"}
{"title": "STDA: Spatio-Temporal Dual-Encoder Network Incorporating Driver\n  Attention to Predict Driver Behaviors Under Safety-Critical Scenarios", "authors": [], "abstract": "Accurate behavior prediction for vehicles is essential but challenging for\nautonomous driving. Most existing studies show satisfying performance under\nregular scenarios, but most neglected safety-critical scenarios. In this study,\na spatio-temporal dual-encoder network named STDA for safety-critical scenarios\nwas developed. Considering the exceptional capabilities of human drivers in\nterms of situational awareness and comprehending risks, driver attention was\nincorporated into STDA to facilitate swift identification of the critical\nregions, which is expected to improve both performance and interpretability.\nSTDA contains four parts: the driver attention prediction module, which\npredicts driver attention; the fusion module designed to fuse the features\nbetween driver attention and raw images; the temporary encoder module used to\nenhance the capability to interpret dynamic scenes; and the behavior prediction\nmodule to predict the behavior. The experiment data are used to train and\nvalidate the model. The results show that STDA improves the G-mean from 0.659\nto 0.719 when incorporating driver attention and adopting a temporal encoder\nmodule. In addition, extensive experimentation has been conducted to validate\nthat the proposed module exhibits robust generalization capabilities and can be\nseamlessly integrated into other mainstream models.", "categories": "cs.CV cs.AI cs.LG", "created": "2024-08-03", "doi": null, "arxiv_id": "2408.01774"}
{"title": "3DStoryline: Immersive Visual Storytelling", "authors": [], "abstract": "Storyline visualization has emerged as an innovative method for illustrating\nthe development and changes in stories across various domains. Traditional\napproaches typically represent stories with one line per character, progressing\nfrom left to right. While effective for simpler narratives, this method faces\nsignificant challenges when dealing with complex stories involving multiple\ncharacters, as well as temporal and spatial dynamics. In this study, we\ninvestigate the potential of immersive environments for enhancing storyline\nvisualizations. We begin by summarizing the key design considerations for\neffective storyline visualization in virtual reality (VR). Guided by these\nprinciples, we develop 3DStoryline, a system that allows users to view and\ninteract with 3D immersive storyline visualizations. To evaluate the\neffectiveness of 3DStoryline, we conduct a task-based user study, revealing\nthat the system significantly enhances users' comprehension of complex\nnarratives.", "categories": "cs.HC", "created": "2024-08-03", "doi": null, "arxiv_id": "2408.01775"}
{"title": "MathLearner: A Large Language Model Agent Framework for Learning to\n  Solve Mathematical Problems", "authors": [], "abstract": "With the development of artificial intelligence (AI), large language models\n(LLM) are widely used in many fields. However, the reasoning ability of LLM is\nstill very limited when it comes to mathematical reasoning. Mathematics plays\nan important role in all aspects of human society and is a technical guarantee\nin the fields of healthcare, transport and aerospace, for this reason, the\ndevelopment of AI big language models in the field of mathematics has great\npotential significance. To improve the mathematical reasoning ability of large\nlanguage models, we proposed an agent framework for learning to solve\nmathematical problems based on inductive reasoning. By emulating the human\nlearning process of generalization of learned information and effective\napplication of previous knowledge in new reasoning tasks, this framework has\ngreat performance in the mathematical reasoning process. It improves global\naccuracy over the baseline method (chain-of-thought) by 20.96% and solves\n17.54% of the mathematical problems that the baseline cannot solve. Benefiting\nfrom the efficient RETRIEVAL method, our model improves the ability of large\nlanguage models to efficiently use external knowledge, i.e., the mathematical\ncomputation of the model can be based on written procedures. In education, our\nmodel can be used as a personalised learning aid, thus reducing the inequality\nof educational resources.", "categories": "cs.CL", "created": "2024-08-03", "doi": null, "arxiv_id": "2408.01779"}
{"title": "Graph Stochastic Neural Process for Inductive Few-shot Knowledge Graph\n  Completion", "authors": [], "abstract": "Knowledge graphs (KGs) store enormous facts as relationships between\nentities. Due to the long-tailed distribution of relations and the\nincompleteness of KGs, there is growing interest in few-shot knowledge graph\ncompletion (FKGC). Existing FKGC methods often assume the existence of all\nentities in KGs, which may not be practical since new relations and entities\ncan emerge over time. Therefore, we focus on a more challenging task called\ninductive few-shot knowledge graph completion (I-FKGC), where both relations\nand entities during the test phase are unknown before. Inspired by the idea of\ninductive reasoning, we cast I-FKGC as an inductive reasoning problem.\nSpecifically, we propose a novel Graph Stochastic Neural Process approach\n(GS-NP), which consists of two major modules. In the first module, to obtain a\ngeneralized hypothesis (e.g., shared subgraph), we present a neural\nprocess-based hypothesis extractor that models the joint distribution of\nhypothesis, from which we can sample a hypothesis for predictions. In the\nsecond module, based on the hypothesis, we propose a graph stochastic\nattention-based predictor to test if the triple in the query set aligns with\nthe extracted hypothesis. Meanwhile, the predictor can generate an explanatory\nsubgraph identified by the hypothesis. Finally, the training of these two\nmodules is seamlessly combined into a unified objective function, of which the\neffectiveness is verified by theoretical analyses as well as empirical studies.\nExtensive experiments on three public datasets demonstrate that our method\noutperforms existing methods and derives new state-of-the-art performance.", "categories": "cs.IR", "created": "2024-08-03", "doi": null, "arxiv_id": "2408.01784"}
{"title": "Towards an ontology of state actors in cyberspace", "authors": [], "abstract": "To improve cyber threat analysis practices in cybersecurity, I present a plan\nto build a formal ontological representation of state actors in cyberspace and\nof cyber operations. I argue that modelling these phenomena via ontologies\nallows for coherent integration of data coming from diverse sources, automated\nreasoning over such data, as well as intelligence extraction and reuse from and\nof them. Existing ontological tools in cybersecurity can be ameliorated by\nconnecting them to neighboring domains such as law, regulations, governmental\ninstitutions, and documents. In this paper, I propose metrics to evaluate\ncurrently existing ontological tools to create formal representations in the\ncybersecurity domain, and I provide a plan to develop and extend them when they\nare lacking.", "categories": "cs.CR cs.AI cs.LO", "created": "2024-08-03", "doi": null, "arxiv_id": "2408.01787"}
{"title": "Adaptic: A Shape Changing Prop with Haptic Retargeting", "authors": [], "abstract": "We present Adaptic, a novel \"hybrid\" active/passive haptic device that can\nchange shape to act as a proxy for a range of virtual objects in VR. We use\nAdaptic with haptic retargeting to redirect the user's hand to provide haptic\nfeedback for several virtual objects in arm's reach using only a single prop.\nTo evaluate the effectiveness of Adaptic with haptic retargeting, we conducted\na within-subjects experiment employing a docking task to compare Adaptic to\nnon-matching proxy objects (i.e., Styrofoam balls) and matching shape props. In\nour study, Adaptic sat on a desk in front of the user and changed shapes\nbetween grasps, to provide matching tactile feedback for various virtual\nobjects placed in different virtual locations. Results indicate that the\nillusion was convincing: users felt they were manipulating several virtual\nobjects in different virtual locations with a single Adaptic device. Docking\nperformance (completion time and accuracy) with Adaptic was comparable to props\nwithout haptic retargeting.", "categories": "cs.HC", "created": "2024-08-03", "doi": "10.1145/3485279.3485293", "arxiv_id": "2408.01789"}
{"title": "Implementing NAT Hole Punching with QUIC", "authors": [], "abstract": "The widespread adoption of Network Address Translation (NAT) technology has\nled to a significant number of network end nodes being located in private\nnetworks behind NAT devices, impeding direct communication between these nodes.\nTo solve this problem, a technique known as \"hole punching\" has been devised\nfor NAT traversal to facilitate peer-to-peer communication among end nodes\nlocated in distinct private networks. However, as the increasing demands for\nspeed and security in networks, TCP-based hole punching schemes gradually show\nperformance drawbacks. Therefore, we present a QUIC-based hole punching scheme\nfor NAT traversal. Through a comparative analysis of the hole punching time\nbetween QUIC-based and TCP based protocols, we find that the QUIC-based scheme\neffectively reduces the hole punching time, exhibiting a pronounced advantage\nin weak network environments. Furthermore, in scenarios where the hole punched\nconnection is disrupted due to factors such as network transitions or NAT\ntimeouts, this paper evaluates two schemes for restoring the connection: QUIC\nconnection migration and re-punching. Our results show that QUIC connection\nmigration for connection restoration saves 2 RTTs compared to QUIC re-punching,\nand 3 RTTs compared to TCP re-punching, effectively reducing the computational\nresources consumption for re-punching.", "categories": "cs.NI", "created": "2024-08-03", "doi": null, "arxiv_id": "2408.01791"}
{"title": "Optimizing Intrusion Detection System Performance Through Synergistic\n  Hyperparameter Tuning and Advanced Data Processing", "authors": [], "abstract": "Intrusion detection is vital for securing computer networks against malicious\nactivities. Traditional methods struggle to detect complex patterns and\nanomalies in network traffic effectively. To address this issue, we propose a\nsystem combining deep learning, data balancing (K-means + SMOTE),\nhigh-dimensional reduction (PCA and FCBF), and hyperparameter optimization\n(Extra Trees and BO-TPE) to enhance intrusion detection performance. By\ntraining on extensive datasets like CIC IDS 2018 and CIC IDS 2017, our models\ndemonstrate robust performance and generalization. Notably, the ensemble model\n\"VGG19\" consistently achieves remarkable accuracy (99.26% on CIC-IDS2017 and\n99.22% on CSE-CIC-IDS2018), outperforming other models.", "categories": "cs.CR", "created": "2024-08-03", "doi": null, "arxiv_id": "2408.01792"}
{"title": "Efficient generation of odd order de Bruijn sequence with the same\n  complement and reverse sequences", "authors": [], "abstract": "Experimental results show that, when the order $n$ is odd, there are de\nBruijn sequences such that the corresponding complement sequence and the\nreverse sequence are the same. In this paper, we propose one efficient method\nto generate such de Bruijn sequences. This solves an open problem asked by\nFredricksen forty years ago for showing the existence of such de Bruijn\nsequences when the odd order $n >1$. Moreover, we refine a characterization of\nde Bruijn sequences with the same complement and reverse sequences and study\nthe number of these de Bruijn sequences, as well as the distribution of de\nBruijn sequences of the maximum linear complexity.", "categories": "cs.IT math.CO math.IT", "created": "2024-08-03", "doi": null, "arxiv_id": "2408.01794"}
{"title": "Review of Cloud Service Composition for Intelligent Manufacturing", "authors": [], "abstract": "Intelligent manufacturing is a new model that uses advanced technologies such\nas the Internet of Things, big data, and artificial intelligence to improve the\nefficiency and quality of manufacturing production. As an important support to\npromote the transformation and upgrading of the manufacturing industry, cloud\nservice optimization has received the attention of researchers. In recent\nyears, remarkable research results have been achieved in this field. For the\nsustainability of intelligent manufacturing platforms, in this paper we\nsummarize the process of cloud service optimization for intelligent\nmanufacturing. Further, to address the problems of dispersed optimization\nindicators and nonuniform/unstandardized definitions in the existing research,\n11 optimization indicators that take into account three-party participant\nsubjects are defined from the urgent requirements of the sustainable\ndevelopment of intelligent manufacturing platforms. Next, service optimization\nalgorithms are classified into two categories, heuristic and reinforcement\nlearning. After comparing the two categories, the current key techniques of\nservice optimization are targeted. Finally, research hotspots and future\nresearch trends of service optimization are summarized.", "categories": "cs.AI", "created": "2024-08-03", "doi": null, "arxiv_id": "2408.01795"}
{"title": "Understanding the Challenges of OpenSCAD Users for 3D Printing", "authors": [], "abstract": "Direct manipulation has been established as the main interaction paradigm for\nComputer-Aided Design (CAD) for decades. It provides fast, incremental, and\nreversible actions that allow for an iterative process on a visual\nrepresentation of the result. Despite its numerous advantages, some users\nprefer a programming-based approach where they describe the 3D model they\ndesign with a specific programming language, such as OpenSCAD. It allows users\nto create complex structured geometries and facilitates abstraction.\nUnfortunately, most current knowledge about CAD practices only focuses on\ndirect manipulation programs. In this study, we interviewed 20\nprogramming-based CAD users to understand their motivations and challenges. Our\nfindings reveal that this programming-oriented population presents difficulties\nin the design process in tasks such as 3D spatial understanding, validation and\ncode debugging, creation of organic shapes, and code-view navigation.", "categories": "cs.HC", "created": "2024-08-03", "doi": "10.1145/3613904.3642566", "arxiv_id": "2408.01796"}
{"title": "Differentially Private Gomory-Hu Trees", "authors": [], "abstract": "Given an undirected, weighted $n$-vertex graph $G = (V, E, w)$, a Gomory-Hu\ntree $T$ is a weighted tree on $V$ such that for any pair of distinct vertices\n$s, t \\in V$, the Min-$s$-$t$-Cut on $T$ is also a Min-$s$-$t$-Cut on $G$.\nComputing a Gomory-Hu tree is a well-studied problem in graph algorithms and\nhas received considerable attention. In particular, a long line of work\nrecently culminated in constructing a Gomory-Hu tree in almost linear time\n[Abboud, Li, Panigrahi and Saranurak, FOCS 2023].\n  We design a differentially private (DP) algorithm that computes an\napproximate Gomory-Hu tree. Our algorithm is $\\varepsilon$-DP, runs in\npolynomial time, and can be used to compute $s$-$t$ cuts that are\n$\\tilde{O}(n/\\varepsilon)$-additive approximations of the Min-$s$-$t$-Cuts in\n$G$ for all distinct $s, t \\in V$ with high probability. Our error bound is\nessentially optimal, as [Dalirrooyfard, Mitrovi\\'c and Nevmyvaka, NeurIPS 2023]\nshowed that privately outputting a single Min-$s$-$t$-Cut requires $\\Omega(n)$\nadditive error even with $(1, 0.1)$-DP and allowing for a multiplicative error\nterm. Prior to our work, the best additive error bounds for approximate\nall-pairs Min-$s$-$t$-Cuts were $O(n^{3/2}/\\varepsilon)$ for $\\varepsilon$-DP\n[Gupta, Roth and Ullman, TCC 2012] and $O(\\sqrt{mn} \\cdot\n\\text{polylog}(n/\\delta) / \\varepsilon)$ for $(\\varepsilon, \\delta)$-DP [Liu,\nUpadhyay and Zou, SODA 2024], both of which are implied by differential private\nalgorithms that preserve all cuts in the graph. An important technical\ningredient of our main result is an $\\varepsilon$-DP algorithm for computing\nminimum Isolating Cuts with $\\tilde{O}(n / \\varepsilon)$ additive error, which\nmay be of independent interest.", "categories": "cs.DS cs.CR", "created": "2024-08-03", "doi": null, "arxiv_id": "2408.01798"}
{"title": "MiniCPM-V: A GPT-4V Level MLLM on Your Phone", "authors": [], "abstract": "The recent surge of Multimodal Large Language Models (MLLMs) has\nfundamentally reshaped the landscape of AI research and industry, shedding\nlight on a promising path toward the next AI milestone. However, significant\nchallenges remain preventing MLLMs from being practical in real-world\napplications. The most notable challenge comes from the huge cost of running an\nMLLM with a massive number of parameters and extensive computation. As a\nresult, most MLLMs need to be deployed on high-performing cloud servers, which\ngreatly limits their application scopes such as mobile, offline,\nenergy-sensitive, and privacy-protective scenarios. In this work, we present\nMiniCPM-V, a series of efficient MLLMs deployable on end-side devices. By\nintegrating the latest MLLM techniques in architecture, pretraining and\nalignment, the latest MiniCPM-Llama3-V 2.5 has several notable features: (1)\nStrong performance, outperforming GPT-4V-1106, Gemini Pro and Claude 3 on\nOpenCompass, a comprehensive evaluation over 11 popular benchmarks, (2) strong\nOCR capability and 1.8M pixel high-resolution image perception at any aspect\nratio, (3) trustworthy behavior with low hallucination rates, (4) multilingual\nsupport for 30+ languages, and (5) efficient deployment on mobile phones. More\nimportantly, MiniCPM-V can be viewed as a representative example of a promising\ntrend: The model sizes for achieving usable (e.g., GPT-4V) level performance\nare rapidly decreasing, along with the fast growth of end-side computation\ncapacity. This jointly shows that GPT-4V level MLLMs deployed on end devices\nare becoming increasingly possible, unlocking a wider spectrum of real-world AI\napplications in the near future.", "categories": "cs.CV", "created": "2024-08-03", "doi": null, "arxiv_id": "2408.01800"}
{"title": "Introducing Bidirectional Programming in Constructive Solid\n  Geometry-Based CAD", "authors": [], "abstract": "3D Computer-Aided Design (CAD) users need to overcome several obstacles to\nbenefit from the flexibility of programmatic interface tools. Besides the\nbarriers of any programming language, users face challenges inherent to 3D\nspatial interaction. Scripting simple operations, such as moving an element in\n3D space, can be significantly more challenging than performing the same task\nusing direct manipulation. We introduce the concept of bidirectional\nprogramming for Constructive Solid Geometry (CSG) CAD tools, informed by\ninterviews we performed with programmatic interface users. We describe how\nusers can navigate and edit the 3D model using direct manipulation in the view\nor code editing while the system ensures consistency between both spaces. We\nalso detail a proof-of-concept implementation using a modified version of\nOpenSCAD.", "categories": "cs.HC", "created": "2024-08-03", "doi": "10.1145/3607822.3614521", "arxiv_id": "2408.01801"}
{"title": "STBLLM: Breaking the 1-Bit Barrier with Structured Binary LLMs", "authors": [], "abstract": "In this paper, we present STBLLM, the first structural binarization framework\nfor compressing Large Language Models (LLMs) to less than 1-bit precision. LLMs\nhave achieved remarkable performance, but their heavy memory requirements have\nhindered widespread adoption, particularly on resource-constrained devices.\nBinarization, which quantifies weights to a mere 1-bit, achieves a milestone in\nincreasing computational efficiency. However, we observe that some weights in\nbinarized LLMs can be randomly flipped without significant performance\ndegradation, indicating the potential for further compression. To exploit this,\nour STBLLM employs an N:M sparsity to perform structural binarization of the\nweights. First, we introduce a new Standardized Importance (SI) metric that\nconsiders weight magnitude and input feature norm to better evaluate weight\nsignificance. Then, we propose a layer-wise approach where different layers of\nthe LLM can be sparsified with varying N:M ratios, balancing compression and\naccuracy. Finally, we use residual approximation with double binarization to\npreserve information for salient weights. In addition, we utilize a\nfine-grained grouping strategy for less important weights that applies\ndifferent quantization schemes to sparse, intermediate, and dense regions. We\nconduct extensive experiments on various language models, including the\nLLaMA-1/2/3, OPT family, and Mistral, to evaluate the effectiveness of STBLLM.\nThe results demonstrate that our approach performs better than other compressed\nbinarization LLM methods while significantly reducing memory requirements.", "categories": "cs.LG cs.CL", "created": "2024-08-03", "doi": null, "arxiv_id": "2408.01803"}
{"title": "Billion-files File Systems (BfFS): A Comparison", "authors": [], "abstract": "As the volume of data being produced is increasing at an exponential rate\nthat needs to be processed quickly, it is reasonable that the data needs to be\navailable very close to the compute devices to reduce transfer latency. Due to\nthis need, local filesystems are getting close attention to understand their\ninner workings, performance, and more importantly their limitations. This study\nanalyzes few popular Linux filesystems: EXT4, XFS, BtrFS, ZFS, and F2FS by\ncreating, storing, and then reading back one billion files from the local\nfilesystem. The study also captured and analyzed read/write throughput, storage\nblocks usage, disk space utilization and overheads, and other metrics useful\nfor system designers and integrators. Furthermore, the study explored other\nside effects such as filesystem performance degradation during and after these\nlarge numbers of files and folders are created.", "categories": "cs.PF", "created": "2024-08-03", "doi": null, "arxiv_id": "2408.01805"}
{"title": "Algebraic Geometry Codes for Distributed Matrix Multiplication Using\n  Local Expansions", "authors": [], "abstract": "Code-based Distributed Matrix Multiplication (DMM) has been extensively\nstudied in distributed computing for efficiently performing large-scale matrix\nmultiplication using coding theoretic techniques. The communication cost and\nrecovery threshold (i.e., the least number of successful worker nodes required\nto recover the product of two matrices) are two major challenges in coded DMM\nresearch. Several constructions based on Reed-Solomon (RS) codes are known,\nincluding Polynomial codes, MatDot codes, and PolyDot codes. However, these\nRS-based schemes are not efficient for small finite fields because the\ndistributed order (i.e., the total number of worker nodes) is limited by the\nsize of the underlying finite field. Algebraic geometry (AG) codes can have a\ncode length exceeding the size of the finite field, which helps solve this\nproblem. Some work has been done to generalize Polynomial and MatDot codes to\nAG codes, but the generalization of PolyDot codes to AGcodes still remains an\nopen problem as far as we know. This is because functions of an algebraic curve\ndo not behave as nicely as polynomials.\n  In this work, by using local expansions of functions, we are able to\ngeneralize the three DMM schemes based on RS codes to AG codes. Specifically,\nwe provide a construction of AG-based PolyDot codes for the first time. In\naddition, our AG-based Polynomial and MatDot codes achieve better recovery\nthresholds compared to previous AG-based DMM schemes while maintaining similar\ncommunication costs. Our constructions are based on a novel basis of the\nRiemann-Roch space using local expansions, which naturally generalizes the\nstandard monomial basis of the univariate polynomial space in RS codes. In\ncontrast, previous work used the non-gap numbers to construct a basis of the\nRiemann-Roch space, which can cause cancellation problems that prevent the\nconditions of PolyDot codes from being satisfied.", "categories": "cs.IT cs.DC math.IT", "created": "2024-08-03", "doi": null, "arxiv_id": "2408.01806"}
{"title": "ALIF: Low-Cost Adversarial Audio Attacks on Black-Box Speech Platforms\n  using Linguistic Features", "authors": [], "abstract": "Extensive research has revealed that adversarial examples (AE) pose a\nsignificant threat to voice-controllable smart devices. Recent studies have\nproposed black-box adversarial attacks that require only the final\ntranscription from an automatic speech recognition (ASR) system. However, these\nattacks typically involve many queries to the ASR, resulting in substantial\ncosts. Moreover, AE-based adversarial audio samples are susceptible to ASR\nupdates. In this paper, we identify the root cause of these limitations, namely\nthe inability to construct AE attack samples directly around the decision\nboundary of deep learning (DL) models. Building on this observation, we propose\nALIF, the first black-box adversarial linguistic feature-based attack pipeline.\nWe leverage the reciprocal process of text-to-speech (TTS) and ASR models to\ngenerate perturbations in the linguistic embedding space where the decision\nboundary resides. Based on the ALIF pipeline, we present the ALIF-OTL and\nALIF-OTA schemes for launching attacks in both the digital domain and the\nphysical playback environment on four commercial ASRs and voice assistants.\nExtensive evaluations demonstrate that ALIF-OTL and -OTA significantly improve\nquery efficiency by 97.7% and 73.3%, respectively, while achieving competitive\nperformance compared to existing methods. Notably, ALIF-OTL can generate an\nattack sample with only one query. Furthermore, our test-of-time experiment\nvalidates the robustness of our approach against ASR updates.", "categories": "cs.CR cs.AI cs.SD eess.AS", "created": "2024-08-03", "doi": null, "arxiv_id": "2408.01808"}
{"title": "Demystifying Device-specific Compatibility Issues in Android Apps", "authors": [], "abstract": "The Android ecosystem is profoundly fragmented due to the frequent updates of\nthe Android system and the prevalent customizations by mobile device\nmanufacturers. Previous research primarily focused on identifying and repairing\nevolution-induced API compatibility issues, with limited consideration of\ndevices-specific compatibility issues (DSC issues). To fill this gap, we\nconduct an empirical study of 197 DSC issues collected from 94 open-source\nrepositories on GitHub. We introduce a new perspective for comprehending these\nissues by categorizing them into two principal groups, Functionality Breaks,\nand OEM Features, based on their manifestations and root causes. The\nfunctionality break issues disrupt standard Android system behaviors, lead to\ncrashes or unexpected behaviors on specific devices, and require developers to\nimplement workarounds to preserve the original functionality. The OEM feature\nissues involve the introduction of device-specific functionalities or features\nbeyond the basic Android system. The different nature of functionality break\nissues and OEM feature issues lead to unique challenges in addressing them.\nCommon solutions for functionality break issues involve calling additional\nAPIs, substituting problematic ones, or using specific parameters, while\nresolving OEM feature issues often relies on Android inter-component\ncommunication methods and reflection, with additional unconventional\nstrategies. Such observations highlight the distinctive challenges in\naddressing DSC issues in Android apps and will facilitate the future\ndevelopment of testing and analysis tools targeting these issues. Our study\ndemonstrates that Functionality break and OEM feature issues have different\ncharacteristics, and future research may need to investigate them separately.", "categories": "cs.SE", "created": "2024-08-03", "doi": null, "arxiv_id": "2408.01810"}
{"title": "SkyDiffusion: Street-to-Satellite Image Synthesis with Diffusion Models\n  and BEV Paradigm", "authors": [], "abstract": "Street-to-satellite image synthesis focuses on generating realistic satellite\nimages from corresponding ground street-view images while maintaining a\nconsistent content layout, similar to looking down from the sky. The\nsignificant differences in perspectives create a substantial domain gap between\nthe views, making this cross-view generation task particularly challenging. In\nthis paper, we introduce SkyDiffusion, a novel cross-view generation method for\nsynthesizing satellite images from street-view images, leveraging diffusion\nmodels and Bird's Eye View (BEV) paradigm. First, we design a Curved-BEV method\nto transform street-view images to the satellite view, reformulating the\nchallenging cross-domain image synthesis task into a conditional generation\nproblem. Curved-BEV also includes a \"Multi-to-One\" mapping strategy for\ncombining multiple street-view images within the same satellite coverage area,\neffectively solving the occlusion issues in dense urban scenes. Next, we design\na BEV-controlled diffusion model to generate satellite images consistent with\nthe street-view content, which also incorporates a light manipulation module to\noptimize the lighting condition of the synthesized image using a reference\nsatellite. Experimental results demonstrate that SkyDiffusion outperforms\nstate-of-the-art methods on both suburban (CVUSA & CVACT) and urban\n(VIGOR-Chicago) cross-view datasets, with an average SSIM increase of 14.5% and\na FID reduction of 29.6%, achieving realistic and content-consistent satellite\nimage generation. The code and models of this work will be released at\nhttps://opendatalab.github.io/skydiffusion/.", "categories": "cs.CV", "created": "2024-08-03", "doi": null, "arxiv_id": "2408.01812"}
{"title": "Workshop on Information Theory and Related Fields -- In Memory of Ning\n  Cai", "authors": [], "abstract": "Sadly, our esteemed colleague and friend Ning Cai passed away on 25th May,\n2023. In his memory, Ingo Alth\\\"ofer, Holger Boche, Christian Deppe, Jens\nStoye, Ulrich Tamm, Andreas Winter, and Raymond Yeung have organized the\n\"Workshop on Information Theory and Related Fields\" at the Bielefeld ZiF\n(Center for Interdisciplinary Research). This special event will be held from\n24th November to 26th November, 2023. The workshop aims to celebrate Ning Cai's\nremarkable contributions to the field of information theory and to provide a\nplatform for discussing current research in related areas. Ning Cai's work has\nhad a significant impact on many domains, and this gathering will bring\ntogether colleagues, collaborators, and young researchers who have been\ninfluenced by his pioneering efforts.", "categories": "cs.IT math.IT", "created": "2024-08-03", "doi": null, "arxiv_id": "2408.01813"}
{"title": "Facilitating the Parametric Definition of Geometric Properties in\n  Programming-Based CAD", "authors": [], "abstract": "Parametric Computer-aided design (CAD) enables the creation of reusable\nmodels by integrating variables into geometric properties, facilitating\ncustomization without a complete redesign. However, creating parametric designs\nin programming-based CAD presents significant challenges. Users define models\nin a code editor using a programming language, with the application generating\na visual representation in a viewport. This process involves complex\nprogramming and arithmetic expressions to describe geometric properties,\nlinking various object properties to create parametric designs. Unfortunately,\nthese applications lack assistance, making the process unnecessarily demanding.\nWe propose a solution that allows users to retrieve parametric expressions from\nthe visual representation for reuse in the code, streamlining the design\nprocess. We demonstrated this concept through a proof-of-concept implemented in\nthe programming-based CAD application, OpenSCAD, and conducted an experiment\nwith 11 users. Our findings suggest that this solution could significantly\nreduce design errors, improve interactivity and engagement in the design\nprocess, and lower the entry barrier for newcomers by reducing the mathematical\nskills typically required in programming-based CAD applications", "categories": "cs.HC", "created": "2024-08-03", "doi": "10.1145/3654777.3676417", "arxiv_id": "2408.01815"}
{"title": "GLDiTalker: Speech-Driven 3D Facial Animation with Graph Latent\n  Diffusion Transformer", "authors": [], "abstract": "3D speech-driven facial animation generation has received much attention in\nboth industrial applications and academic research. Since the non-verbal facial\ncues that exist across the face in reality are non-deterministic, the generated\nresults should be diverse. However, most recent methods are deterministic\nmodels that cannot learn a many-to-many mapping between audio and facial motion\nto generate diverse facial animations. To address this problem, we propose\nGLDiTalker, which introduces a motion prior along with some stochasticity to\nreduce the uncertainty of cross-modal mapping while increasing non-determinacy\nof the non-verbal facial cues that reside throughout the face. Particularly,\nGLDiTalker uses VQ-VAE to map facial motion mesh sequences into latent space in\nthe first stage, and then iteratively adds and removes noise to the latent\nfacial motion features in the second stage. In order to integrate different\nlevels of spatial information, the Spatial Pyramidal SpiralConv Encoder is also\ndesigned to extract multi-scale features. Extensive qualitative and\nquantitative experiments demonstrate that our method achieves the\nstate-of-the-art performance.", "categories": "cs.CV", "created": "2024-08-03", "doi": null, "arxiv_id": "2408.01826"}
{"title": "ST-SACLF: Style Transfer Informed Self-Attention Classifier for\n  Bias-Aware Painting Classification", "authors": [], "abstract": "Painting classification plays a vital role in organizing, finding, and\nsuggesting artwork for digital and classic art galleries. Existing methods\nstruggle with adapting knowledge from the real world to artistic images during\ntraining, leading to poor performance when dealing with different datasets. Our\ninnovation lies in addressing these challenges through a two-step process.\nFirst, we generate more data using Style Transfer with Adaptive Instance\nNormalization (AdaIN), bridging the gap between diverse styles. Then, our\nclassifier gains a boost with feature-map adaptive spatial attention modules,\nimproving its understanding of artistic details. Moreover, we tackle the\nproblem of imbalanced class representation by dynamically adjusting augmented\nsamples. Through a dual-stage process involving careful hyperparameter search\nand model fine-tuning, we achieve an impressive 87.24\\% accuracy using the\nResNet-50 backbone over 40 training epochs. Our study explores quantitative\nanalyses that compare different pretrained backbones, investigates model\noptimization through ablation studies, and examines how varying augmentation\nlevels affect model performance. Complementing this, our qualitative\nexperiments offer valuable insights into the model's decision-making process\nusing spatial attention and its ability to differentiate between easy and\nchallenging samples based on confidence ranking.", "categories": "cs.CV cs.AI", "created": "2024-08-03", "doi": null, "arxiv_id": "2408.01827"}
{"title": "A Deep CNN Model for Ringing Effect Attenuation of Vibroseis Data", "authors": [], "abstract": "In the field of exploration geophysics, seismic vibrator is one of the widely\nused seismic sources to acquire seismic data, which is usually named vibroseis.\n\"Ringing effect\" is a common problem in vibroseis data processing due to the\nlimited frequency bandwidth of the vibrator, which degrades the performance of\nfirst-break picking. In this paper, we proposed a novel deringing model for\nvibroseis data using deep convolutional neural network (CNN). In this model we\nuse end-to-end training strategy to obtain the deringed data directly, and skip\nconnections to improve model training process and preserve the details of\nvibroseis data. For real vibroseis deringing task we synthesize training data\nand corresponding labels from real vibroseis data and utilize them to train the\ndeep CNN model. Experiments are conducted both on synthetic data and real\nvibroseis data. The experiment results show that deep CNN model can attenuate\nthe ringing effect effectively and expand the bandwidth of vibroseis data. The\nSTA/LTA ratio method for first-break picking also shows improvement on deringed\nvibroseis data using deep CNN model.", "categories": "cs.CV physics.geo-ph", "created": "2024-08-03", "doi": null, "arxiv_id": "2408.01831"}
{"title": "TS-SAM: Fine-Tuning Segment-Anything Model for Downstream Tasks", "authors": [], "abstract": "Adapter based fine-tuning has been studied for improving the performance of\nSAM on downstream tasks. However, there is still a significant performance gap\nbetween fine-tuned SAMs and domain-specific models. To reduce the gap, we\npropose Two-Stream SAM (TS-SAM). On the one hand, inspired by the side network\nin Parameter-Efficient Fine-Tuning (PEFT), we designed a lightweight\nConvolutional Side Adapter (CSA), which integrates the powerful features from\nSAM into side network training for comprehensive feature fusion. On the other\nhand, in line with the characteristics of segmentation tasks, we designed\nMulti-scale Refinement Module (MRM) and Feature Fusion Decoder (FFD) to keep\nboth the detailed and semantic features. Extensive experiments on ten public\ndatasets from three tasks demonstrate that TS-SAM not only significantly\noutperforms the recently proposed SAM-Adapter and SSOM, but achieves\ncompetitive performance with the SOTA domain-specific models. Our code is\navailable at: https://github.com/maoyangou147/TS-SAM.", "categories": "cs.CV", "created": "2024-08-03", "doi": null, "arxiv_id": "2408.01835"}
{"title": "Tracking Emotional Dynamics in Chat Conversations: A Hybrid Approach\n  using DistilBERT and Emoji Sentiment Analysis", "authors": [], "abstract": "Computer-mediated communication has become more important than face-to-face\ncommunication in many contexts. Tracking emotional dynamics in chat\nconversations can enhance communication, improve services, and support\nwell-being in various contexts. This paper explores a hybrid approach to\ntracking emotional dynamics in chat conversations by combining DistilBERT-based\ntext emotion detection and emoji sentiment analysis. A Twitter dataset was\nanalyzed using various machine learning algorithms, including SVM, Random\nForest, and AdaBoost. We contrasted their performance with DistilBERT. Results\nreveal DistilBERT's superior performance in emotion recognition. Our approach\naccounts for emotive expressions conveyed through emojis to better understand\nparticipants' emotions during chats. We demonstrate how this approach can\neffectively capture and analyze emotional shifts in real-time conversations.\nOur findings show that integrating text and emoji analysis is an effective way\nof tracking chat emotion, with possible applications in customer service, work\nchats, and social media interactions.", "categories": "cs.CL", "created": "2024-08-03", "doi": null, "arxiv_id": "2408.01838"}
{"title": "Complexity of Minimizing Projected-Gradient-Dominated Functions with\n  Stochastic First-order Oracles", "authors": [], "abstract": "This work investigates the performance limits of projected stochastic\nfirst-order methods for minimizing functions under the\n$(\\alpha,\\tau,\\mathcal{X})$-projected-gradient-dominance property, that asserts\nthe sub-optimality gap $F(\\mathbf{x})-\\min_{\\mathbf{x}'\\in\n\\mathcal{X}}F(\\mathbf{x}')$ is upper-bounded by\n$\\tau\\cdot\\|\\mathcal{G}_{\\eta,\\mathcal{X}}(\\mathbf{x})\\|^{\\alpha}$ for some\n$\\alpha\\in[1,2)$ and $\\tau>0$ and $\\mathcal{G}_{\\eta,\\mathcal{X}}(\\mathbf{x})$\nis the projected-gradient mapping with $\\eta>0$ as a parameter. For non-convex\nfunctions, we show that the complexity lower bound of querying a batch smooth\nfirst-order stochastic oracle to obtain an $\\epsilon$-global-optimum point is\n$\\Omega(\\epsilon^{-{2}/{\\alpha}})$. Furthermore, we show that a projected\nvariance-reduced first-order algorithm can obtain the upper complexity bound of\n$\\mathcal{O}(\\epsilon^{-{2}/{\\alpha}})$, matching the lower bound. For convex\nfunctions, we establish a complexity lower bound of\n$\\Omega(\\log(1/\\epsilon)\\cdot\\epsilon^{-{2}/{\\alpha}})$ for minimizing\nfunctions under a local version of gradient-dominance property, which also\nmatches the upper complexity bound of accelerated stochastic subgradient\nmethods.", "categories": "math.OC cs.LG", "created": "2024-08-03", "doi": null, "arxiv_id": "2408.01839"}
{"title": "E$^3$NeRF: Efficient Event-Enhanced Neural Radiance Fields from Blurry\n  Images", "authors": [], "abstract": "Neural Radiance Fields (NeRF) achieve impressive rendering performance by\nlearning volumetric 3D representation from several images of different views.\nHowever, it is difficult to reconstruct a sharp NeRF from blurry input as it\noften occurs in the wild. To solve this problem, we propose a novel Efficient\nEvent-Enhanced NeRF (E$^3$NeRF) by utilizing the combination of RGB images and\nevent streams. To effectively introduce event streams into the neural\nvolumetric representation learning process, we propose an event-enhanced blur\nrendering loss and an event rendering loss, which guide the network via\nmodeling the real blur process and event generation process, respectively.\nSpecifically, we leverage spatial-temporal information from the event stream to\nevenly distribute learning attention over temporal blur while simultaneously\nfocusing on blurry texture through the spatial attention. Moreover, a camera\npose estimation framework for real-world data is built with the guidance of the\nevents to generalize the method to practical applications. Compared to previous\nimage-based or event-based NeRF, our framework makes more profound use of the\ninternal relationship between events and images. Extensive experiments on both\nsynthetic data and real-world data demonstrate that E$^3$NeRF can effectively\nlearn a sharp NeRF from blurry images, especially in non-uniform motion and\nlow-light scenes.", "categories": "cs.CV", "created": "2024-08-03", "doi": null, "arxiv_id": "2408.01840"}
{"title": "Supervised Image Translation from Visible to Infrared Domain for Object\n  Detection", "authors": [], "abstract": "This study aims to learn a translation from visible to infrared imagery,\nbridging the domain gap between the two modalities so as to improve accuracy on\ndownstream tasks including object detection. Previous approaches attempt to\nperform bi-domain feature fusion through iterative optimization or end-to-end\ndeep convolutional networks. However, we pose the problem as similar to that of\nimage translation, adopting a two-stage training strategy with a Generative\nAdversarial Network and an object detection model. The translation model learns\na conversion that preserves the structural detail of visible images while\npreserving the texture and other characteristics of infrared images. Images so\ngenerated are used to train standard object detection frameworks including\nYolov5, Mask and Faster RCNN. We also investigate the usefulness of integrating\na super-resolution step into our pipeline to further improve model accuracy,\nand achieve an improvement of as high as 5.3% mAP.", "categories": "cs.CV", "created": "2024-08-03", "doi": null, "arxiv_id": "2408.01843"}
{"title": "MotionTrace: IMU-based Field of View Prediction for Smartphone AR\n  Interactions", "authors": [], "abstract": "For handheld smartphone AR interactions, bandwidth is a critical constraint.\nStreaming techniques have been developed to provide a seamless and high-quality\nuser experience despite these challenges. To optimize streaming performance in\nsmartphone-based AR, accurate prediction of the user's field of view is\nessential. This prediction allows the system to prioritize loading digital\ncontent that the user is likely to engage with, enhancing the overall\ninteractivity and immersion of the AR experience. In this paper, we present\nMotionTrace, a method for predicting the user's field of view using a\nsmartphone's inertial sensor. This method continuously estimates the user's\nhand position in 3D-space to localize the phone position. We evaluated\nMotionTrace over future hand positions at 50, 100, 200, 400, and 800ms time\nhorizons using the large motion capture (AMASS) and smartphone-based full-body\npose estimation (Pose-on-the-Go) datasets. We found that our method can\nestimate the future phone position of the user with an average MSE between 0.11\n- 143.62 mm across different time horizons.", "categories": "cs.HC", "created": "2024-08-03", "doi": null, "arxiv_id": "2408.01850"}
{"title": "Cost-constrained multi-label group feature selection using shadow\n  features", "authors": [], "abstract": "We consider the problem of feature selection in multi-label classification,\nconsidering the costs assigned to groups of features. In this task, the goal is\nto select a subset of features that will be useful for predicting the label\nvector, but at the same time, the cost associated with the selected features\nwill not exceed the assumed budget. Solving the problem is of great importance\nin medicine, where we may be interested in predicting various diseases based on\ngroups of features. The groups may be associated with parameters obtained from\na certain diagnostic test, such as a blood test. Because diagnostic test costs\ncan be very high, considering cost information when selecting relevant features\nbecomes crucial to reducing the cost of making predictions. We focus on the\nfeature selection method based on information theory. The proposed method\nconsists of two steps. First, we select features sequentially while maximizing\nconditional mutual information until the budget is exhausted. In the second\nstep, we select additional cost-free features, i.e., those coming from groups\nthat have already been used in previous steps. Limiting the number of added\nfeatures is possible using the stop rule based on the concept of so-called\nshadow features, which are randomized counterparts of the original ones. In\ncontrast to existing approaches based on penalized criteria, in our method, we\navoid the need for computationally demanding optimization of the penalty\nparameter. Experiments conducted on the MIMIC medical database show the\neffectiveness of the method, especially when the assumed budget is limited.", "categories": "stat.ML cs.LG", "created": "2024-08-03", "doi": null, "arxiv_id": "2408.01851"}
{"title": "Effect of Uniform and Non-uniform wall heating on Three-Dimensional\n  Magneto-Hydrodynamics Natural Convection and Entropy Generation: A\n  computational study using New Higher Order Super Compact Scheme", "authors": [], "abstract": "Current research work deals with the effect of uniform and non-uniform wall\nheating on magnetohydrodynamic (MHD) natural convection within a\nthree-dimensional (3D) cavity filled with molten lithium. A new Higher-Order\nSuper Compact (HOSC) finite difference scheme is used to analyze the thermal\nbehavior under both heating scenarios. After the quantitative and qualitative\nvalidations, the computed results are analyzed for a range of Hartman number\n($Ha = 25, 50, 100, 150$) and Rayleigh number ($Ra = 10^3, 10^4, 10^5$) with\nfixed $Pr=0.065$ (molten lithium). Three distinct heating scenarios, i.e.,\nuniform heating ($T_h = 1$), $y$-dependent non-uniform heating ($T_h = sin(\\pi\ny$)), and a combination of $y$ and $z$-dependent non-uniform heating ($T_h =\nsin(\\pi y)sin(\\pi z)$) are investigated on the left wall ($x=0$) of the cubic\ncavity. It is found that variations in the $Ha$ and $Ra$, along with distinct\nthermal boundary conditions, exert significant effects on both the temperature\ndistribution and flow field inside the 3D cubical cavity. Specifically, an\nincrease in $Ra$ corresponds to enhanced heat transfer, highlighting the\ndominance of convection. Conversely, an increase in $Ha$ leads to a reduction\nin heat transfer due to the deceleration of fluid velocity. The scenario in\nwhich walls are uniformly heated exhibits the most significant total entropy\ngeneration. It is observed that with an increase in the $Ra$, the Bejan number\n($Be$) decreases, which ultimately leads to an increase in total entropy\ngeneration. The implementation of the new HOSC scheme in this analysis\nshowcases its effectiveness in capturing the complexities of 3D MHD-driven\nnatural convection and entropy generation. This study offers significant\ninformation that might help improve the optimization and design of relevant\nengineering systems. Thus, our work stands out as genuinely novel and\npioneering in its approach.", "categories": "physics.flu-dyn cs.NA math.NA", "created": "2024-08-03", "doi": null, "arxiv_id": "2408.01853"}
{"title": "MoodPupilar: Predicting Mood Through Smartphone Detected Pupillary\n  Responses in Naturalistic Settings", "authors": [], "abstract": "MoodPupilar introduces a novel method for mood evaluation using pupillary\nresponse captured by a smartphone's front-facing camera during daily use. Over\na four-week period, data was gathered from 25 participants to develop models\ncapable of predicting daily mood averages. Utilizing the GLOBEM behavior\nmodeling platform, we benchmarked the utility of pupillary response as a\npredictor for mood. Our proposed model demonstrated a Matthew's Correlation\nCoefficient (MCC) score of 0.15 for Valence and 0.12 for Arousal, which is on\npar with or exceeds those achieved by existing behavioral modeling algorithms\nsupported by GLOBEM. This capability to accurately predict mood trends\nunderscores the effectiveness of pupillary response data in providing crucial\ninsights for timely mental health interventions and resource allocation. The\noutcomes are encouraging, demonstrating the potential of real-time and\npredictive mood analysis to support mental health interventions.", "categories": "cs.HC", "created": "2024-08-03", "doi": null, "arxiv_id": "2408.01855"}
{"title": "Using Linearized Optimal Transport to Predict the Evolution of\n  Stochastic Particle Systems", "authors": [], "abstract": "We develop an algorithm to approximate the time evolution of a probability\nmeasure without explicitly learning an operator that governs the evolution. A\nparticular application of interest is discrete measures $\\mu_t^N$ that arise\nfrom particle systems. In many such situations, the individual particles move\nchaotically on short time scales, making it difficult to learn the dynamics of\na governing operator, but the bulk distribution $\\mu_t^N$ approximates an\nabsolutely continuous measure $\\mu_t$ that evolves ``smoothly.'' If $\\mu_t$ is\nknown on some time interval, then linearized optimal transport theory provides\nan Euler-like scheme for approximating the evolution of $\\mu_t$ using its\n``tangent vector field'' (represented as a time-dependent vector field on\n$\\mathbb R^d$), which can be computed as a limit of optimal transport maps. We\npropose an analog of this Euler approximation to predict the evolution of the\ndiscrete measure $\\mu_t^N$ (without knowing $\\mu_t$). To approximate the\nanalogous tangent vector field, we use a finite difference over a time step\nthat sits between the two time scales of the system -- long enough for the\nlarge-$N$ evolution ($\\mu_t$) to emerge but short enough to satisfactorily\napproximate the derivative object used in the Euler scheme. By allowing the\nlimiting behavior to emerge, the optimal transport maps closely approximate the\nvector field describing the bulk distribution's smooth evolution instead of the\nindividual particles' more chaotic movements. We demonstrate the efficacy of\nthis approach with two illustrative examples, Gaussian diffusion and a cell\nchemotaxis model, and show that our method succeeds in predicting the bulk\nbehavior over relatively large steps.", "categories": "math.NA cs.LG cs.NA math.OC", "created": "2024-08-03", "doi": null, "arxiv_id": "2408.01857"}
{"title": "Graph Unfolding and Sampling for Transitory Video Summarization via\n  Gershgorin Disc Alignment", "authors": [], "abstract": "User-generated videos (UGVs) uploaded from mobile phones to social media\nsites like YouTube and TikTok are short and non-repetitive. We summarize a\ntransitory UGV into several keyframes in linear time via fast graph sampling\nbased on Gershgorin disc alignment (GDA). Specifically, we first model a\nsequence of $N$ frames in a UGV as an $M$-hop path graph $\\mathcal{G}^o$ for $M\n\\ll N$, where the similarity between two frames within $M$ time instants is\nencoded as a positive edge based on feature similarity. Towards efficient\nsampling, we then \"unfold\" $\\mathcal{G}^o$ to a $1$-hop path graph\n$\\mathcal{G}$, specified by a generalized graph Laplacian matrix $\\mathcal{L}$,\nvia one of two graph unfolding procedures with provable performance bounds. We\nshow that maximizing the smallest eigenvalue $\\lambda_{\\min}(\\mathbf{B})$ of a\ncoefficient matrix $\\mathbf{B} = \\textit{diag}\\left(\\mathbf{h}\\right) + \\mu\n\\mathcal{L}$, where $\\mathbf{h}$ is the binary keyframe selection vector, is\nequivalent to minimizing a worst-case signal reconstruction error. We maximize\ninstead the Gershgorin circle theorem (GCT) lower bound\n$\\lambda^-_{\\min}(\\mathbf{B})$ by choosing $\\mathbf{h}$ via a new fast graph\nsampling algorithm that iteratively aligns left-ends of Gershgorin discs for\nall graph nodes (frames). Extensive experiments on multiple short video\ndatasets show that our algorithm achieves comparable or better video\nsummarization performance compared to state-of-the-art methods, at a\nsubstantially reduced complexity.", "categories": "cs.CV eess.IV eess.SP", "created": "2024-08-03", "doi": null, "arxiv_id": "2408.01859"}
{"title": "Batch Active Learning in Gaussian Process Regression using Derivatives", "authors": [], "abstract": "We investigate the use of derivative information for Batch Active Learning in\nGaussian Process regression models. The proposed approach employs the\npredictive covariance matrix for selection of data batches to exploit full\ncorrelation of samples. We theoretically analyse our proposed algorithm taking\ndifferent optimality criteria into consideration and provide empirical\ncomparisons highlighting the advantage of incorporating derivatives\ninformation. Our results show the effectiveness of our approach across diverse\napplications.", "categories": "cs.LG stat.ML", "created": "2024-08-03", "doi": null, "arxiv_id": "2408.01861"}
{"title": "Efficient Solutions For An Intriguing Failure of LLMs: Long Context\n  Window Does Not Mean LLMs Can Analyze Long Sequences Flawlessly", "authors": [], "abstract": "Large Language Models (LLMs) have demonstrated remarkable capabilities in\ncomprehending and analyzing lengthy sequential inputs, owing to their extensive\ncontext windows that allow processing millions of tokens in a single forward\npass. However, this paper uncovers a surprising limitation: LLMs fall short\nwhen handling long input sequences. We investigate this issue using three\ndatasets and two tasks (sentiment analysis and news categorization) across\nvarious LLMs, including Claude 3, Gemini Pro, GPT 3.5 Turbo, Llama 3 Instruct,\nand Mistral Instruct models. To address this limitation, we propose and\nevaluate ad-hoc solutions that substantially enhance LLMs' performance on long\ninput sequences by up to 50%, while reducing API cost and latency by up to 93%\nand 50%, respectively.", "categories": "cs.CL cs.LG", "created": "2024-08-03", "doi": null, "arxiv_id": "2408.01866"}
{"title": "TrustNavGPT: Modeling Uncertainty to Improve Trustworthiness of\n  Audio-Guided LLM-Based Robot Navigation", "authors": [], "abstract": "While LLMs are proficient at processing text in human conversations, they\noften encounter difficulties with the nuances of verbal instructions and, thus,\nremain prone to hallucinate trust in human command. In this work, we present\nTrustNavGPT, an LLM based audio guided navigation agent that uses affective\ncues in spoken communication elements such as tone and inflection that convey\nmeaning beyond words, allowing it to assess the trustworthiness of human\ncommands and make effective, safe decisions. Our approach provides a\nlightweight yet effective approach that extends existing LLMs to model audio\nvocal features embedded in the voice command and model uncertainty for safe\nrobotic navigation.", "categories": "cs.RO", "created": "2024-08-03", "doi": null, "arxiv_id": "2408.01867"}
{"title": "Meta-Posterior Consistency for the Bayesian Inference of Metastable\n  System", "authors": [], "abstract": "The vast majority of the literature on learning dynamical systems or\nstochastic processes from time series has focused on stable or ergodic systems,\nfor both Bayesian and frequentist inference procedures. However, most\nreal-world systems are only metastable, that is, the dynamics appear to be\nstable on some time scale, but are in fact unstable over longer time scales.\nConsistency of inference for metastable systems may not be possible, but one\ncan ask about metaconsistency: Do inference procedures converge when\nobservations are taken over a large but finite time interval, but diverge on\nlonger time scales? In this paper we introduce, discuss, and quantify\nmetaconsistency in a Bayesian framework. We discuss how metaconsistency can be\nexploited to efficiently infer a model for a sub-system of a larger system,\nwhere inference on the global behavior may require much more data. We also\ndiscuss the relation between meta-consistency and the spectral properties of\nthe model dynamical system in the case of uniformly ergodic diffusions.", "categories": "stat.ML cs.LG math.PR math.ST stat.TH", "created": "2024-08-03", "doi": null, "arxiv_id": "2408.01868"}
{"title": "MALADE: Orchestration of LLM-powered Agents with Retrieval Augmented\n  Generation for Pharmacovigilance", "authors": [], "abstract": "In the era of Large Language Models (LLMs), given their remarkable text\nunderstanding and generation abilities, there is an unprecedented opportunity\nto develop new, LLM-based methods for trustworthy medical knowledge synthesis,\nextraction and summarization. This paper focuses on the problem of\nPharmacovigilance (PhV), where the significance and challenges lie in\nidentifying Adverse Drug Events (ADEs) from diverse text sources, such as\nmedical literature, clinical notes, and drug labels. Unfortunately, this task\nis hindered by factors including variations in the terminologies of drugs and\noutcomes, and ADE descriptions often being buried in large amounts of narrative\ntext. We present MALADE, the first effective collaborative multi-agent system\npowered by LLM with Retrieval Augmented Generation for ADE extraction from drug\nlabel data. This technique involves augmenting a query to an LLM with relevant\ninformation extracted from text resources, and instructing the LLM to compose a\nresponse consistent with the augmented data. MALADE is a general LLM-agnostic\narchitecture, and its unique capabilities are: (1) leveraging a variety of\nexternal sources, such as medical literature, drug labels, and FDA tools (e.g.,\nOpenFDA drug information API), (2) extracting drug-outcome association in a\nstructured format along with the strength of the association, and (3) providing\nexplanations for established associations. Instantiated with GPT-4 Turbo or\nGPT-4o, and FDA drug label data, MALADE demonstrates its efficacy with an Area\nUnder ROC Curve of 0.90 against the OMOP Ground Truth table of ADEs. Our\nimplementation leverages the Langroid multi-agent LLM framework and can be\nfound at https://github.com/jihyechoi77/malade.", "categories": "cs.CL cs.AI cs.IR cs.LG cs.MA q-bio.QM", "created": "2024-08-03", "doi": null, "arxiv_id": "2408.01869"}
{"title": "Safe Semi-Supervised Contrastive Learning Using In-Distribution Data as\n  Positive Examples", "authors": [], "abstract": "Semi-supervised learning methods have shown promising results in solving many\npractical problems when only a few labels are available. The existing methods\nassume that the class distributions of labeled and unlabeled data are equal;\nhowever, their performances are significantly degraded in class distribution\nmismatch scenarios where out-of-distribution (OOD) data exist in the unlabeled\ndata. Previous safe semi-supervised learning studies have addressed this\nproblem by making OOD data less likely to affect training based on labeled\ndata. However, even if the studies effectively filter out the unnecessary OOD\ndata, they can lose the basic information that all data share regardless of\nclass. To this end, we propose to apply a self-supervised contrastive learning\napproach to fully exploit a large amount of unlabeled data. We also propose a\ncontrastive loss function with coefficient schedule to aggregate as an anchor\nthe labeled negative examples of the same class into positive examples. To\nevaluate the performance of the proposed method, we conduct experiments on\nimage classification datasets - CIFAR-10, CIFAR-100, Tiny ImageNet, and\nCIFAR-100+Tiny ImageNet - under various mismatch ratios. The results show that\nself-supervised contrastive learning significantly improves classification\naccuracy. Moreover, aggregating the in-distribution examples produces better\nrepresentation and consequently further improves classification accuracy.", "categories": "cs.LG cs.AI cs.CV", "created": "2024-08-03", "doi": null, "arxiv_id": "2408.01872"}
{"title": "Re-Invoke: Tool Invocation Rewriting for Zero-Shot Tool Retrieval", "authors": [], "abstract": "Recent advances in large language models (LLMs) have enabled autonomous\nagents with complex reasoning and task-fulfillment capabilities using a wide\nrange of tools. However, effectively identifying the most relevant tools for a\ngiven task becomes a key bottleneck as the toolset size grows, hindering\nreliable tool utilization. To address this, we introduce Re-Invoke, an\nunsupervised tool retrieval method designed to scale effectively to large\ntoolsets without training. Specifically, we first generate a diverse set of\nsynthetic queries that comprehensively cover different aspects of the query\nspace associated with each tool document during the tool indexing phase.\nSecond, we leverage LLM's query understanding capabilities to extract key\ntool-related context and underlying intents from user queries during the\ninference phase. Finally, we employ a novel multi-view similarity ranking\nstrategy based on intents to pinpoint the most relevant tools for each query.\nOur evaluation demonstrates that Re-Invoke significantly outperforms\nstate-of-the-art alternatives in both single-tool and multi-tool scenarios, all\nwithin a fully unsupervised setting. Notably, on the ToolE datasets, we achieve\na 20% relative improvement in nDCG@5 for single-tool retrieval and a 39%\nimprovement for multi-tool retrieval.", "categories": "cs.CL", "created": "2024-08-03", "doi": null, "arxiv_id": "2408.01875"}
{"title": "FBINeRF: Feature-Based Integrated Recurrent Network for Pinhole and\n  Fisheye Neural Radiance Fields", "authors": [], "abstract": "Previous studies aiming to optimize and bundle-adjust camera poses using\nNeural Radiance Fields (NeRFs), such as BARF and DBARF, have demonstrated\nimpressive capabilities in 3D scene reconstruction. However, these approaches\nhave been designed for pinhole-camera pose optimization and do not perform well\nunder radial image distortions such as those in fisheye cameras. Furthermore,\ninaccurate depth initialization in DBARF results in erroneous geometric\ninformation affecting the overall convergence and quality of results. In this\npaper, we propose adaptive GRUs with a flexible bundle-adjustment method\nadapted to radial distortions and incorporate feature-based recurrent neural\nnetworks to generate continuous novel views from fisheye datasets. Other NeRF\nmethods for fisheye images, such as SCNeRF and OMNI-NeRF, use projected ray\ndistance loss for distorted pose refinement, causing severe artifacts, long\nrendering time, and are difficult to use in downstream tasks, where the dense\nvoxel representation generated by a NeRF method needs to be converted into a\nmesh representation. We also address depth initialization issues by adding\nMiDaS-based depth priors for pinhole images. Through extensive experiments, we\ndemonstrate the generalization capacity of FBINeRF and show high-fidelity\nresults for both pinhole-camera and fisheye-camera NeRFs.", "categories": "cs.CV", "created": "2024-08-03", "doi": null, "arxiv_id": "2408.01878"}
{"title": "Walk Wisely on Graph: Knowledge Graph Reasoning with Dual Agents via\n  Efficient Guidance-Exploration", "authors": [], "abstract": "Recent years, multi-hop reasoning has been widely studied for knowledge graph\n(KG) reasoning due to its efficacy and interpretability. However, previous\nmulti-hop reasoning approaches are subject to two primary shortcomings. First,\nagents struggle to learn effective and robust policies at the early phase due\nto sparse rewards. Second, these approaches often falter on specific datasets\nlike sparse knowledge graphs, where agents are required to traverse lengthy\nreasoning paths. To address these problems, we propose a multi-hop reasoning\nmodel with dual agents based on hierarchical reinforcement learning (HRL),\nwhich is named FULORA. FULORA tackles the above reasoning challenges by\neFficient GUidance-ExpLORAtion between dual agents. The high-level agent walks\non the simplified knowledge graph to provide stage-wise hints for the low-level\nagent walking on the original knowledge graph. In this framework, the low-level\nagent optimizes a value function that balances two objectives: (1) maximizing\nreturn, and (2) integrating efficient guidance from the high-level agent.\nExperiments conducted on three real-word knowledge graph datasets demonstrate\nthat FULORA outperforms RL-based baselines, especially in the case of\nlong-distance reasoning.", "categories": "cs.AI cs.LG", "created": "2024-08-03", "doi": null, "arxiv_id": "2408.01880"}
{"title": "Impact of Major Health Events on Pharmaceutical Stocks: A Comprehensive\n  Analysis Using Macroeconomic and Market Indicators", "authors": [], "abstract": "This study investigates the impact of significant health events on\npharmaceutical stock performance, employing a comprehensive analysis\nincorporating macroeconomic and market indicators. Using Ordinary Least Squares\n(OLS) regression, we evaluate the effects of thirteen major health events since\n2000, including the Anthrax attacks, SARS outbreak, H1N1 pandemic, and COVID-19\npandemic, on the pharmaceutical sector. The analysis covers different phases of\neach event beginning, peak, and ending to capture their temporal influence on\nstock prices. Our findings reveal distinct patterns in stock performance,\ndriven by market reactions to the initial news, peak impact, and eventual\nresolution of these crises. We also examine scenarios with and without key\nmacroeconomic (MA) and market (MI) indicators to isolate their contributions.\nThis detailed examination provides valuable insights for investors,\npolicymakers, and stakeholders in understanding the interplay between major\nhealth events and health market dynamics, guiding better decision-making during\nfuture health related disruptions.", "categories": "cs.CE", "created": "2024-08-03", "doi": null, "arxiv_id": "2408.01883"}
{"title": "Channel-Aware Distributed Transmission Control and Video Streaming in\n  UAV Networks", "authors": [], "abstract": "In this paper, we study the problem of distributed transmission control and\nvideo streaming optimization for unmanned aerial vehicles (UAVs) operating in\nunlicensed spectrum bands. We develop a rigorous cross-layer analysis framework\nthat jointly considers three inter-dependent factors: (i) in-band interference\nintroduced by ground/aerial nodes at the physical (PHY) layer, (ii)\nlimited-size queues with delay-constrained packet arrival at the medium access\ncontrol (MAC) layer, and (iii) video encoding rate at the application layer.\nFirst, we formulate an optimization problem to maximize the throughput by\noptimizing the fading threshold. To this end, we jointly analyze the\nqueue-related packet loss probabilities (i.e., buffer overflow and time\nthreshold event) as well as the outage probability due to the low\nsignal-to-interference-plus-noise ratio (SINR). We introduce the Distributed\nTransmission Control (DTC) algorithm that maximizes the throughput by adjusting\ntransmission policies to balance the trade-offs between packet drop from queues\nvs. transmission errors due to low SINRs. Second, we incorporate the video\ndistortion model to develop distributed peak signal-to-noise ratio (PSNR)\noptimization for video streaming. The formulated optimization incorporates two\ncross-layer parameters, specifically the fading threshold and video encoding\nrate. To tackle this problem, we develop the Joint Distributed Video\nTransmission and Encoder Control (JDVT-EC) algorithm that enhances the PSNR for\nall nodes by fine-tuning transmission policies and video encoding rates to\nbalance the trade-offs between packet loss and lossy video compression\ndistortions. Through extensive numerical analysis, we thoroughly examine the\nproposed algorithms and demonstrate that they are able to find the optimal\ntransmission policies and video encoding rates under various scenarios.", "categories": "cs.IT math.IT", "created": "2024-08-03", "doi": null, "arxiv_id": "2408.01885"}
{"title": "Cross-layer Attention Sharing for Large Language Models", "authors": [], "abstract": "As large language models (LLMs) evolve, the increase in model depth and\nparameter number leads to substantial redundancy. To enhance the efficiency of\nthe attention mechanism, previous works primarily compress the KV cache or\ngroup attention heads, while largely overlooking redundancy between layers. Our\ncomprehensive analyses across various LLMs show that highly similar attention\npatterns persist within most layers. It's intuitive to save the computation by\nsharing attention weights across layers. However, further analysis reveals two\nchallenges: (1) Directly sharing the weight matrix without carefully\nrearranging the attention heads proves to be ineffective; (2) Shallow layers\nare vulnerable to small deviations in attention weights. Driven by these\ninsights, we introduce LiSA, a lightweight substitute for self-attention in\nwell-trained LLMs. LiSA employs tiny feed-forward networks to align attention\nheads between adjacent layers and low-rank matrices to approximate differences\nin layer-wise attention weights. Evaluations encompassing 13 typical benchmarks\ndemonstrate that LiSA maintains high response quality in terms of accuracy and\nperplexity while reducing redundant attention calculations within 53-84% of the\ntotal layers. Our implementations of LiSA achieve a 6X compression of Q and K,\nwith maximum throughput improvements of 19.5% for LLaMA3-8B and 32.3% for\nLLaMA2-7B.", "categories": "cs.CL", "created": "2024-08-03", "doi": null, "arxiv_id": "2408.01890"}
{"title": "Re-ENACT: Reinforcement Learning for Emotional Speech Generation using\n  Actor-Critic Strategy", "authors": [], "abstract": "In this paper, we propose the first method to modify the prosodic features of\na given speech signal using actor-critic reinforcement learning strategy. Our\napproach uses a Bayesian framework to identify contiguous segments of\nimportance that links segments of the given utterances to perception of\nemotions in humans. We train a neural network to produce the variational\nposterior of a collection of Bernoulli random variables; our model applies a\nMarkov prior on it to ensure continuity. A sample from this distribution is\nused for downstream emotion prediction. Further, we train the neural network to\npredict a soft assignment over emotion categories as the target variable. In\nthe next step, we modify the prosodic features (pitch, intensity, and rhythm)\nof the masked segment to increase the score of target emotion. We employ an\nactor-critic reinforcement learning to train the prosody modifier by\ndiscretizing the space of modifications. Further, it provides a simple solution\nto the problem of gradient computation through WSOLA operation for rhythm\nmanipulation. Our experiments demonstrate that this framework changes the\nperceived emotion of a given speech utterance to the target. Further, we show\nthat our unified technique is on par with state-of-the-art emotion conversion\nmodels from supervised and unsupervised domains that require pairwise training.", "categories": "eess.AS cs.AI cs.LG", "created": "2024-08-03", "doi": null, "arxiv_id": "2408.01892"}
{"title": "A Feature-Based Approach to Generating Comprehensive End-to-End Tests", "authors": [], "abstract": "End-to-end (E2E) testing is essential for ensuring web application quality.\nHowever, manual test creation is time-consuming and current test generation\ntechniques produce random tests. In this paper, we present AUTOE2E, a novel\napproach that leverages Large Language Models (LLMs) to automate the generation\nof semantically meaningful feature-driven E2E test cases for web applications.\nAUTOE2E intelligently infers potential features within a web application and\ntranslates them into executable test scenarios. Furthermore, we address a\ncritical gap in the research community by introducing E2EBENCH, a new benchmark\nfor automatically assessing the feature coverage of E2E test suites. Our\nevaluation on E2EBENCH demonstrates that AUTOE2E achieves an average feature\ncoverage of 79%, outperforming the best baseline by 558%, highlighting its\neffectiveness in generating high-quality, comprehensive test cases.", "categories": "cs.SE", "created": "2024-08-03", "doi": null, "arxiv_id": "2408.01894"}
{"title": "Computational Trichromacy Reconstruction: Empowering the Color-Vision\n  Deficient to Recognize Colors Using Augmented Reality", "authors": [], "abstract": "We propose an assistive technology that helps individuals with Color Vision\nDeficiencies (CVD) to recognize/name colors. A dichromat's color perception is\na reduced two-dimensional (2D) subset of a normal trichromat's three\ndimensional color (3D) perception, leading to confusion when visual stimuli\nthat appear identical to the dichromat are referred to by different color\nnames. Using our proposed system, CVD individuals can interactively induce\ndistinct perceptual changes to originally confusing colors via a computational\ncolor space transformation. By combining their original 2D precepts for colors\nwith the discriminative changes, a three dimensional color space is\nreconstructed, where the dichromat can learn to resolve color name confusions\nand accurately recognize colors. Our system is implemented as an Augmented\nReality (AR) interface on smartphones, where users interactively control the\nrotation through swipe gestures and observe the induced color shifts in the\ncamera view or in a displayed image. Through psychophysical experiments and a\nlongitudinal user study, we demonstrate that such rotational color shifts have\ndiscriminative power (initially confusing colors become distinct under\nrotation) and exhibit structured perceptual shifts dichromats can learn with\nmodest training. The AR App is also evaluated in two real-world scenarios\n(building with lego blocks and interpreting artistic works); users all report\npositive experience in using the App to recognize object colors that they\notherwise could not.", "categories": "cs.HC cs.CV", "created": "2024-08-03", "doi": "10.1145/3654777.3676415", "arxiv_id": "2408.01895"}
{"title": "Remote Staking with Economic Safety", "authors": [], "abstract": "Proof-of-stake (PoS) blockchains require validators to lock their tokens as\ncollateral, slashing these tokens if they are identified as protocol violators.\nPoS chains have mostly been secured by their native tokens. However, using only\nthe native token upper-bounds the value eligible for staking by the market\ncapitalization of the native token. In contrast, the remote staking of another\ncrypto asset from a provider chain provides an avenue to improve the consumer\nchain's economic security. In this paper, we present the first known remote\nstaking protocols with guaranteed optimal economic safety: whenever there is a\nsafety violation on the consumer chain, at least one third of the provider's\nstake securing the consumer chain is slashed. To achieve this goal for a broad\nrange of provider and consumer chains, two independent contributions are made:\n1) a remote unbonding protocol that ensures slashing before the stake is\nunbonded on the provider chain if there is safety violation on the consumer\nchain; 2) a protocol to slash stake even without smart contracts on the\nprovider chain. The remote staking protocol is analyzed and implemented in the\ncase where the provider chain is Bitcoin and the consumer chain is a Cosmos SDK\nchain running the Tendermint consensus protocol.", "categories": "cs.CR", "created": "2024-08-03", "doi": null, "arxiv_id": "2408.01896"}
{"title": "CAF-YOLO: A Robust Framework for Multi-Scale Lesion Detection in\n  Biomedical Imagery", "authors": [], "abstract": "Object detection is of paramount importance in biomedical image analysis,\nparticularly for lesion identification. While current methodologies are\nproficient in identifying and pinpointing lesions, they often lack the\nprecision needed to detect minute biomedical entities (e.g., abnormal cells,\nlung nodules smaller than 3 mm), which are critical in blood and lung\npathology. To address this challenge, we propose CAF-YOLO, based on the YOLOv8\narchitecture, a nimble yet robust method for medical object detection that\nleverages the strengths of convolutional neural networks (CNNs) and\ntransformers. To overcome the limitation of convolutional kernels, which have a\nconstrained capacity to interact with distant information, we introduce an\nattention and convolution fusion module (ACFM). This module enhances the\nmodeling of both global and local features, enabling the capture of long-term\nfeature dependencies and spatial autocorrelation. Additionally, to improve the\nrestricted single-scale feature aggregation inherent in feed-forward networks\n(FFN) within transformer architectures, we design a multi-scale neural network\n(MSNN). This network improves multi-scale information aggregation by extracting\nfeatures across diverse scales. Experimental evaluations on widely used\ndatasets, such as BCCD and LUNA16, validate the rationale and efficacy of\nCAF-YOLO. This methodology excels in detecting and precisely locating diverse\nand intricate micro-lesions within biomedical imagery. Our codes are available\nat https://github.com/xiaochen925/CAF-YOLO.", "categories": "cs.CV", "created": "2024-08-03", "doi": null, "arxiv_id": "2408.01897"}
{"title": "Convergence Analysis of Weighted-Median Opinion Dynamics with Prejudice", "authors": [], "abstract": "The Friedkin-Johnsen (FJ) model introduces prejudice into the opinion\nevolution and has been successfully validated in many practical scenarios;\nhowever, due to its weighted average mechanism, only one prejudiced agent can\nalways guide all unprejudiced agents synchronizing to its prejudice under the\nconnected influence network, which may not be in line with some social\nrealities. To fundamentally address the limitation of the weighted average\nmechanism, a weighted-median opinion dynamics has been recently proposed;\nhowever, its theoretical analysis is challenging due to its nonlinear nature.\nThis paper studies the weighted-median opinion dynamics with prejudice, and\nobtains the convergence and convergence rate when all agents have prejudice,\nand a necessary and sufficient condition for asymptotic consensus when a\nportion of agents have prejudice. These results are the first time to analyze\nthe discrete-time and synchronous opinion dynamics with the weighted median\nmechanism, and address the phenomenon of the FJ model that connectivity leads\nto consensus when a few agents with the same prejudice join in an unprejudiced\ngroup.", "categories": "eess.SY cs.SY", "created": "2024-08-03", "doi": null, "arxiv_id": "2408.01899"}
{"title": "Quantifying gendered citation imbalance in computer science conferences", "authors": [], "abstract": "The number of citations received by papers often exhibits imbalances in terms\nof author attributes such as country of affiliation and gender. While recent\nstudies have quantified citation imbalance in terms of the authors' gender in\njournal papers, the computer science discipline, where researchers frequently\npresent their work at conferences, may exhibit unique patterns in gendered\ncitation imbalance. Additionally, understanding how network properties in\ncitations influence citation imbalances remains challenging due to a lack of\nsuitable reference models. In this paper, we develop a family of reference\nmodels for citation networks and investigate gender imbalance in citations\nbetween papers published in computer science conferences. By deploying these\nreference models, we found that homophily in citations is strongly associated\nwith gendered citation imbalance in computer science, whereas heterogeneity in\nthe number of citations received per paper has a relatively minor association\nwith it. Furthermore, we found that the gendered citation imbalance is most\npronounced in papers published in the highest-ranked conferences, is present\nacross different subfields, and extends to citation-based rankings of papers.\nOur study provides a framework for investigating associations between network\nproperties and citation imbalances, aiming to enhance our understanding of the\nstructure and dynamics of citations between research publications.", "categories": "cs.SI cs.DL", "created": "2024-08-03", "doi": null, "arxiv_id": "2408.01900"}
{"title": "A Comprehensive Survey on GNN Characterization", "authors": [], "abstract": "Characterizing graph neural networks (GNNs) is essential for identifying\nperformance bottlenecks and facilitating their deployment. Despite substantial\nwork in this area, a comprehensive survey on GNN characterization is lacking.\nThis work presents a comprehensive survey, proposing a triple-level\nclassification method to categorize, summarize, and compare existing efforts.\nIn addition, we identify promising future directions for GNN characterization.\nOur survey aims to help scholars systematically understand GNN performance\nbottlenecks and patterns from a computer architecture perspective, contributing\nto more efficient GNN execution.", "categories": "cs.AR", "created": "2024-08-03", "doi": null, "arxiv_id": "2408.01902"}
{"title": "The Artificial Intelligence Disclosure (AID) Framework: An Introduction", "authors": [], "abstract": "As the use of Generative Artificial Intelligence tools have grown in higher\neducation and research, there have been increasing calls for transparency and\ngranularity around the use and attribution of the use of these tools. Thus far,\nthis need has been met via the recommended inclusion of a note, with little to\nno guidance on what the note itself should include. This has been identified as\na problem to the use of AI in academic and research contexts. This article\nintroduces The Artificial Intelligence Disclosure (AID) Framework, a standard,\ncomprehensive, and detailed framework meant to inform the development and\nwriting of GenAI disclosure for education and research.", "categories": "cs.DL cs.AI", "created": "2024-08-03", "doi": null, "arxiv_id": "2408.01904"}
{"title": "Binary $[n,(n\\pm1)/2]$ cyclic codes with good minimum distances from\n  sequences", "authors": [], "abstract": "Recently, binary cyclic codes with parameters $[n,(n\\pm1)/2,\\geq \\sqrt{n}]$\nhave been a hot topic since their minimum distances have a square-root bound.\nIn this paper, we construct four classes of binary cyclic codes\n$\\mathcal{C}_{\\mathcal{S},0}$, $\\mathcal{C}_{\\mathcal{S},1}$ and\n$\\mathcal{C}_{\\mathcal{D},0}$, $\\mathcal{C}_{\\mathcal{D},1}$ by using two\nfamilies of sequences, and obtain some codes with parameters $[n,(n\\pm1)/2,\\geq\n\\sqrt{n}]$. For $m\\equiv2\\pmod4$, the code $\\mathcal{C}_{\\mathcal{S},0}$ has\nparameters $[2^m-1,2^{m-1},\\geq2^{\\frac{m}{2}}+2]$, and the code\n$\\mathcal{C}_{\\mathcal{D},0}$ has parameters\n$[2^m-1,2^{m-1},\\geq2^{\\frac{m}{2}}+2]$ if $h=1$ and\n$[2^m-1,2^{m-1},\\geq2^{\\frac{m}{2}}]$ if $h=2$.", "categories": "cs.IT math.IT", "created": "2024-08-03", "doi": null, "arxiv_id": "2408.01906"}
{"title": "Public Transit of the Future: Enhancing Well-Being through Designing\n  Human-centered Public Transportation Spaces", "authors": [], "abstract": "Studies show that psychological effects are among one of the top concerns for\npublic transportation users. While many Americans spend a significant portion\nof their time in public transportation spaces, the impact of the design and\nmaintenance of these spaces on user well-being has not been fully studied. In\nthis study, we conducted a survey to better understand the effect of\nimplementing different designs on people's well-being and perceptual metrics\n(N=304). Participants were presented with six images depicting different cabin\nconfigurations, including (1) the current version of the cabin space, (2) a\nlow-maintenance version, (3) an aesthetically enhanced version, (4) a bike\nrack-enabled version, (5) a version with an added workspace, and (6) an\nimproved version with biophilic design. After viewing each image, participants'\nwell-being metrics (e.g., stress, and emotion) and their public transportation\nperception metrics (e.g., perceptions of safety, and reasonable cost) were\nevaluated. Our results from linear mixed-effect modeling indicated that adding\nfunctional amenities and biophilic design elements led to an overall\nenhancement in well-being and perceptual metrics. Conversely, low maintenance\nworsened all measured well-being. This research lays the ground for developing\nhuman-centered public transportation spaces that can lead to an increase in\npublic transportation adoption.", "categories": "cs.HC", "created": "2024-08-03", "doi": null, "arxiv_id": "2408.01908"}
{"title": "Scaling Symbolic Execution to Large Software Systems", "authors": [], "abstract": "Static analysis is the analysis of a program without executing it, usually\ncarried out by an automated tool. Symbolic execution is a popular static\nanalysis technique used both in program verification and in bug detection\nsoftware. It works by interpreting the code, introducing a symbol for each\nvalue unknown at compile time (e.g. user-given inputs), and carrying out\ncalculations symbolically. The analysis engine strives to explore multiple\nexecution paths simultaneously, although checking all paths is an intractable\nproblem, due to the vast number of possibilities.\n  We focus on an error finding framework called the Clang Static Analyzer, and\nthe infrastructure built around it named CodeChecker. The emphasis is on\nachieving end-to-end scalability. This includes the run time and memory\nconsumption of the analysis, bug presentation to the users, automatic false\npositive suppression, incremental analysis, pattern discovery in the results,\nand usage in continuous integration loops. We also outline future directions\nand open problems concerning these tools.\n  While a rich literature exists on program verification software, error\nfinding tools normally need to settle for survey papers on individual\ntechniques. In this paper, we not only discuss individual methods, but also how\nthese decisions interact and reinforce each other, creating a system that is\ngreater than the sum of its parts. Although the Clang Static Analyzer can only\nhandle C-family languages, the techniques introduced in this paper are mostly\nlanguage-independent and applicable to other similar static analysis tools.", "categories": "cs.SE", "created": "2024-08-03", "doi": null, "arxiv_id": "2408.01909"}
{"title": "Scalable Signal Temporal Logic Guided Reinforcement Learning via Value\n  Function Space Optimization", "authors": [], "abstract": "The integration of reinforcement learning (RL) and formal methods has emerged\nas a promising framework for solving long-horizon planning problems.\nConventional approaches typically involve abstraction of the state and action\nspaces and manually created labeling functions or predicates. However, the\nefficiency of these approaches deteriorates as the tasks become increasingly\ncomplex, which results in exponential growth in the size of labeling functions\nor predicates. To address these issues, we propose a scalable model-based RL\nframework, called VFSTL, which schedules pre-trained skills to follow unseen\nSTL specifications without using hand-crafted predicates. Given a set of value\nfunctions obtained by goal-conditioned RL, we formulate an optimization problem\nto maximize the robustness value of Signal Temporal Logic (STL) defined\nspecifications, which is computed using value functions as predicates. To\nfurther reduce the computation burden, we abstract the environment state space\ninto the value function space (VFS). Then the optimization problem is solved by\nModel-Based Reinforcement Learning. Simulation results show that STL with value\nfunctions as predicates approximates the ground truth robustness and the\nplanning in VFS directly achieves unseen specifications using data from\nsensors.", "categories": "cs.RO", "created": "2024-08-04", "doi": null, "arxiv_id": "2408.01923"}
{"title": "Efficient Decision Trees for Tensor Regressions", "authors": [], "abstract": "We proposed the tensor-input tree (TT) method for scalar-on-tensor and\ntensor-on-tensor regression problems. We first address scalar-on-tensor problem\nby proposing scalar-output regression tree models whose input variable are\ntensors (i.e., multi-way arrays). We devised and implemented fast randomized\nand deterministic algorithms for efficient fitting of scalar-on-tensor trees,\nmaking TT competitive against tensor-input GP models. Based on scalar-on-tensor\ntree models, we extend our method to tensor-on-tensor problems using additive\ntree ensemble approaches. Theoretical justification and extensive experiments\non real and synthetic datasets are provided to illustrate the performance of\nTT.", "categories": "cs.LG stat.ME stat.ML", "created": "2024-08-04", "doi": null, "arxiv_id": "2408.01926"}
{"title": "A Semi-supervised Multi-channel Graph Convolutional Network for Query\n  Classification in E-commerce", "authors": [], "abstract": "Query intent classification is an essential module for customers to find\ndesired products on the e-commerce application quickly. Most existing query\nintent classification methods rely on the users' click behavior as a supervised\nsignal to construct training samples. However, these methods based entirely on\nposterior labels may lead to serious category imbalance problems because of the\nMatthew effect in click samples. Compared with popular categories, it is\ndifficult for products under long-tail categories to obtain traffic and user\nclicks, which makes the models unable to detect users' intent for products\nunder long-tail categories. This in turn aggravates the problem that long-tail\ncategories cannot obtain traffic, forming a vicious circle. In addition, due to\nthe randomness of the user's click, the posterior label is unstable for the\nquery with similar semantics, which makes the model very sensitive to the\ninput, leading to an unstable and incomplete recall of categories.\n  In this paper, we propose a novel Semi-supervised Multi-channel Graph\nConvolutional Network (SMGCN) to address the above problems from the\nperspective of label association and semi-supervised learning. SMGCN extends\ncategory information and enhances the posterior label by utilizing the\nsimilarity score between the query and categories. Furthermore, it leverages\nthe co-occurrence and semantic similarity graph of categories to strengthen the\nrelations among labels and weaken the influence of posterior label instability.\nWe conduct extensive offline and online A/B experiments, and the experimental\nresults show that SMGCN significantly outperforms the strong baselines, which\nshows its effectiveness and practicality.", "categories": "cs.CL cs.AI cs.IR", "created": "2024-08-04", "doi": null, "arxiv_id": "2408.01928"}
{"title": "Advancing H&E-to-IHC Stain Translation in Breast Cancer: A\n  Multi-Magnification and Attention-Based Approach", "authors": [], "abstract": "Breast cancer presents a significant healthcare challenge globally, demanding\nprecise diagnostics and effective treatment strategies, where histopathological\nexamination of Hematoxylin and Eosin (H&E) stained tissue sections plays a\ncentral role. Despite its importance, evaluating specific biomarkers like Human\nEpidermal Growth Factor Receptor 2 (HER2) for personalized treatment remains\nconstrained by the resource-intensive nature of Immunohistochemistry (IHC).\nRecent strides in deep learning, particularly in image-to-image translation,\noffer promise in synthesizing IHC-HER2 slides from H\\&E stained slides.\nHowever, existing methodologies encounter challenges, including managing\nmultiple magnifications in pathology images and insufficient focus on crucial\ninformation during translation. To address these issues, we propose a novel\nmodel integrating attention mechanisms and multi-magnification information\nprocessing. Our model employs a multi-magnification processing strategy to\nextract and utilize information from various magnifications within pathology\nimages, facilitating robust image translation. Additionally, an attention\nmodule within the generative network prioritizes critical information for image\ndistribution translation while minimizing less pertinent details. Rigorous\ntesting on a publicly available breast cancer dataset demonstrates superior\nperformance compared to existing methods, establishing our model as a\nstate-of-the-art solution in advancing pathology image translation from H&E to\nIHC staining.", "categories": "eess.IV cs.CV", "created": "2024-08-04", "doi": null, "arxiv_id": "2408.01929"}
{"title": "Defining and Evaluating Decision and Composite Risk in Language Models\n  Applied to Natural Language Inference", "authors": [], "abstract": "Despite their impressive performance, large language models (LLMs) such as\nChatGPT are known to pose important risks. One such set of risks arises from\nmisplaced confidence, whether over-confidence or under-confidence, that the\nmodels have in their inference. While the former is well studied, the latter is\nnot, leading to an asymmetry in understanding the comprehensive risk of the\nmodel based on misplaced confidence. In this paper, we address this asymmetry\nby defining two types of risk (decision and composite risk), and proposing an\nexperimental framework consisting of a two-level inference architecture and\nappropriate metrics for measuring such risks in both discriminative and\ngenerative LLMs. The first level relies on a decision rule that determines\nwhether the underlying language model should abstain from inference. The second\nlevel (which applies if the model does not abstain) is the model's inference.\nDetailed experiments on four natural language commonsense reasoning datasets\nusing both an open-source ensemble-based RoBERTa model and ChatGPT, demonstrate\nthe practical utility of the evaluation framework. For example, our results\nshow that our framework can get an LLM to confidently respond to an extra 20.1%\nof low-risk inference tasks that other methods might misclassify as high-risk,\nand skip 19.8% of high-risk tasks, which would have been answered incorrectly.", "categories": "cs.CL cs.AI", "created": "2024-08-04", "doi": null, "arxiv_id": "2408.01935"}
{"title": "Bilateral Trade Flow Prediction by Gravity-informed Graph Auto-encoder", "authors": [], "abstract": "The gravity models has been studied to analyze interaction between two\nobjects such as trade amount between a pair of countries, human migration\nbetween a pair of countries and traffic flow between two cities. Particularly\nin the international trade, predicting trade amount is instrumental to industry\nand government in business decision making and determining economic policies.\nWhereas the gravity models well captures such interaction between objects, the\nmodel simplifies the interaction to extract essential relationships or needs\nhandcrafted features to drive the models. Recent studies indicate the\nconnection between graph neural networks (GNNs) and the gravity models in\ninternational trade. However, to our best knowledge, hardly any previous\nstudies in the this domain directly predicts trade amount by GNNs. We propose\nGGAE (Gravity-informed Graph Auto-encoder) and its surrogate model, which is\ninspired by the gravity model, showing trade amount prediction by the gravity\nmodel can be formulated as an edge weight prediction problem in GNNs and solved\nby GGAE and its surrogate model. Furthermore, we conducted experiments to\nindicate GGAE with GNNs can improve trade amount prediction compared to the\ntraditional gravity model by considering complex relationships.", "categories": "cs.CE", "created": "2024-08-04", "doi": "10.1109/BigData55660.2022.10021066", "arxiv_id": "2408.01938"}
{"title": "A Jellyfish Cyborg: Exploiting Natural Embodied Intelligence as Soft\n  Robots", "authors": [], "abstract": "In the advanced field of bio-inspired robotics, the emergence of cyborgs\nrepresents the successful integration of engineering and biological systems.\nBuilding on previous research that showed how electrical stimuli could initiate\nand speed up a jellyfish's movement, this study presents a groundbreaking\napproach that explores how the natural embodied intelligence of the animal can\nbe harnessed to address pivotal challenges such as spontaneous exploration,\nnavigation in various environments, control of whole-body motion, and real-time\npredictions of behavior. We have developed a comprehensive data acquisition\nsystem and a unique setup for stimulating jellyfish, allowing for a detailed\nstudy of their movements. Through careful analysis of both spontaneous\nbehaviors and behaviors induced by targeted stimulation, we have identified\nsubtle differences between natural and induced motion patterns. By using a\nmachine learning method called physical reservoir computing, we have\nsuccessfully shown that future behaviors can be accurately predicted by\ndirectly measuring the jellyfish's body shape when the stimuli align with the\nanimal's natural dynamics. Our findings also reveal significant advancements in\nmotion control and real-time prediction capabilities of jellyfish cyborgs. In\nsummary, this research provides a comprehensive roadmap for optimizing the\ncapabilities of jellyfish cyborgs, with potential implications in marine\nreconnaissance and sustainable ecological interventions.", "categories": "cs.RO", "created": "2024-08-04", "doi": null, "arxiv_id": "2408.01941"}
{"title": "Visual Grounding for Object-Level Generalization in Reinforcement\n  Learning", "authors": [], "abstract": "Generalization is a pivotal challenge for agents following natural language\ninstructions. To approach this goal, we leverage a vision-language model (VLM)\nfor visual grounding and transfer its vision-language knowledge into\nreinforcement learning (RL) for object-centric tasks, which makes the agent\ncapable of zero-shot generalization to unseen objects and instructions. By\nvisual grounding, we obtain an object-grounded confidence map for the target\nobject indicated in the instruction. Based on this map, we introduce two routes\nto transfer VLM knowledge into RL. Firstly, we propose an object-grounded\nintrinsic reward function derived from the confidence map to more effectively\nguide the agent towards the target object. Secondly, the confidence map offers\na more unified, accessible task representation for the agent's policy, compared\nto language embeddings. This enables the agent to process unseen objects and\ninstructions through comprehensible visual confidence maps, facilitating\nzero-shot object-level generalization. Single-task experiments prove that our\nintrinsic reward significantly improves performance on challenging skill\nlearning. In multi-task experiments, through testing on tasks beyond the\ntraining set, we show that the agent, when provided with the confidence map as\nthe task representation, possesses better generalization capabilities than\nlanguage-based conditioning. The code is available at\nhttps://github.com/PKU-RL/COPL.", "categories": "cs.AI cs.CV", "created": "2024-08-04", "doi": null, "arxiv_id": "2408.01942"}
{"title": "RobNODDI: Robust NODDI Parameter Estimation with Adaptive Sampling under\n  Continuous Representation", "authors": [], "abstract": "Neurite Orientation Dispersion and Density Imaging (NODDI) is an important\nimaging technology used to evaluate the microstructure of brain tissue, which\nis of great significance for the discovery and treatment of various\nneurological diseases. Current deep learning-based methods perform parameter\nestimation through diffusion magnetic resonance imaging (dMRI) with a small\nnumber of diffusion gradients. These methods speed up parameter estimation and\nimprove accuracy. However, the diffusion directions used by most existing deep\nlearning models during testing needs to be strictly consistent with the\ndiffusion directions during training. This results in poor generalization and\nrobustness of deep learning models in dMRI parameter estimation. In this work,\nwe verify for the first time that the parameter estimation performance of\ncurrent mainstream methods will significantly decrease when the testing\ndiffusion directions and the training diffusion directions are inconsistent. A\nrobust NODDI parameter estimation method with adaptive sampling under\ncontinuous representation (RobNODDI) is proposed. Furthermore, long short-term\nmemory (LSTM) units and fully connected layers are selected to learn continuous\nrepresentation signals. To this end, we use a total of 100 subjects to conduct\nexperiments based on the Human Connectome Project (HCP) dataset, of which 60\nare used for training, 20 are used for validation, and 20 are used for testing.\nThe test results indicate that RobNODDI improves the generalization performance\nand robustness of the deep learning model, enhancing the stability and\nflexibility of deep learning NODDI parameter estimatimation applications.", "categories": "cs.CV eess.IV", "created": "2024-08-04", "doi": null, "arxiv_id": "2408.01944"}
{"title": "Generalized Maximum Likelihood Estimation for Perspective-n-Point\n  Problem", "authors": [], "abstract": "The Perspective-n-Point (PnP) problem has been widely studied in the\nliterature and applied in various vision-based pose estimation scenarios.\nHowever, existing methods ignore the anisotropy uncertainty of observations, as\ndemonstrated in several real-world datasets in this paper. This oversight may\nlead to suboptimal and inaccurate estimation, particularly in the presence of\nnoisy observations. To this end, we propose a generalized maximum likelihood\nPnP solver, named GMLPnP, that minimizes the determinant criterion by iterating\nthe GLS procedure to estimate the pose and uncertainty simultaneously. Further,\nthe proposed method is decoupled from the camera model. Results of synthetic\nand real experiments show that our method achieves better accuracy in common\npose estimation scenarios, GMLPnP improves rotation/translation accuracy by\n4.7%/2.0% on TUM-RGBD and 18.6%/18.4% on KITTI-360 dataset compared to the best\nbaseline. It is more accurate under very noisy observations in a vision-based\nUAV localization task, outperforming the best baseline by 34.4% in translation\nestimation accuracy.", "categories": "cs.CV cs.RO", "created": "2024-08-04", "doi": null, "arxiv_id": "2408.01945"}
{"title": "Masked Angle-Aware Autoencoder for Remote Sensing Images", "authors": [], "abstract": "To overcome the inherent domain gap between remote sensing (RS) images and\nnatural images, some self-supervised representation learning methods have made\npromising progress. However, they have overlooked the diverse angles present in\nRS objects. This paper proposes the Masked Angle-Aware Autoencoder (MA3E) to\nperceive and learn angles during pre-training. We design a \\textit{scaling\ncenter crop} operation to create the rotated crop with random orientation on\neach original image, introducing the explicit angle variation. MA3E inputs this\ncomposite image while reconstruct the original image, aiming to effectively\nlearn rotation-invariant representations by restoring the angle variation\nintroduced on the rotated crop. To avoid biases caused by directly\nreconstructing the rotated crop, we propose an Optimal Transport (OT) loss that\nautomatically assigns similar original image patches to each rotated crop patch\nfor reconstruction. MA3E demonstrates more competitive performance than\nexisting pre-training methods on seven different RS image datasets in three\ndownstream tasks.", "categories": "cs.CV", "created": "2024-08-04", "doi": null, "arxiv_id": "2408.01946"}
{"title": "Why Perturbing Symbolic Music is Necessary: Fitting the Distribution of\n  Never-used Notes through a Joint Probabilistic Diffusion Model", "authors": [], "abstract": "Existing music generation models are mostly language-based, neglecting the\nfrequency continuity property of notes, resulting in inadequate fitting of rare\nor never-used notes and thus reducing the diversity of generated samples. We\nargue that the distribution of notes can be modeled by translational invariance\nand periodicity, especially using diffusion models to generalize notes by\ninjecting frequency-domain Gaussian noise. However, due to the low-density\nnature of music symbols, estimating the distribution of notes latent in the\nhigh-density solution space poses significant challenges. To address this\nproblem, we introduce the Music-Diff architecture, which fits a joint\ndistribution of notes and accompanying semantic information to generate\nsymbolic music conditionally. We first enhance the fragmentation module for\nextracting semantics by using event-based notations and the structural\nsimilarity index, thereby preventing boundary blurring. As a prerequisite for\nmultivariate perturbation, we introduce a joint pre-training method to\nconstruct the progressions between notes and musical semantics while avoiding\ndirect modeling of low-density notes. Finally, we recover the perturbed notes\nby a multi-branch denoiser that fits multiple noise objectives via Pareto\noptimization. Our experiments suggest that in contrast to language models,\njoint probability diffusion models perturbing at both note and semantic levels\ncan provide more sample diversity and compositional regularity. The case study\nhighlights the rhythmic advantages of our model over language- and DDPMs-based\nmodels by analyzing the hierarchical structure expressed in the self-similarity\nmetrics.", "categories": "cs.SD cs.CL eess.AS", "created": "2024-08-04", "doi": null, "arxiv_id": "2408.01950"}
{"title": "CACE-Net: Co-guidance Attention and Contrastive Enhancement for\n  Effective Audio-Visual Event Localization", "authors": [], "abstract": "The audio-visual event localization task requires identifying concurrent\nvisual and auditory events from unconstrained videos within a network model,\nlocating them, and classifying their category. The efficient extraction and\nintegration of audio and visual modal information have always been challenging\nin this field. In this paper, we introduce CACE-Net, which differs from most\nexisting methods that solely use audio signals to guide visual information. We\npropose an audio-visual co-guidance attention mechanism that allows for\nadaptive bi-directional cross-modal attentional guidance between audio and\nvisual information, thus reducing inconsistencies between modalities. Moreover,\nwe have observed that existing methods have difficulty distinguishing between\nsimilar background and event and lack the fine-grained features for event\nclassification. Consequently, we employ background-event contrast enhancement\nto increase the discrimination of fused feature and fine-tuned pre-trained\nmodel to extract more refined and discernible features from complex multimodal\ninputs. Specifically, we have enhanced the model's ability to discern subtle\ndifferences between event and background and improved the accuracy of event\nclassification in our model. Experiments on the AVE dataset demonstrate that\nCACE-Net sets a new benchmark in the audio-visual event localization task,\nproving the effectiveness of our proposed methods in handling complex\nmultimodal learning and event localization in unconstrained videos. Code is\navailable at https://github.com/Brain-Cog-Lab/CACE-Net.", "categories": "cs.CV", "created": "2024-08-04", "doi": null, "arxiv_id": "2408.01952"}
{"title": "Dataset Scale and Societal Consistency Mediate Facial Impression Bias in\n  Vision-Language AI", "authors": [], "abstract": "Multimodal AI models capable of associating images and text hold promise for\nnumerous domains, ranging from automated image captioning to accessibility\napplications for blind and low-vision users. However, uncertainty about bias\nhas in some cases limited their adoption and availability. In the present work,\nwe study 43 CLIP vision-language models to determine whether they learn\nhuman-like facial impression biases, and we find evidence that such biases are\nreflected across three distinct CLIP model families. We show for the first time\nthat the the degree to which a bias is shared across a society predicts the\ndegree to which it is reflected in a CLIP model. Human-like impressions of\nvisually unobservable attributes, like trustworthiness and sexuality, emerge\nonly in models trained on the largest dataset, indicating that a better fit to\nuncurated cultural data results in the reproduction of increasingly subtle\nsocial biases. Moreover, we use a hierarchical clustering approach to show that\ndataset size predicts the extent to which the underlying structure of facial\nimpression bias resembles that of facial impression bias in humans. Finally, we\nshow that Stable Diffusion models employing CLIP as a text encoder learn facial\nimpression biases, and that these biases intersect with racial biases in Stable\nDiffusion XL-Turbo. While pretrained CLIP models may prove useful for\nscientific studies of bias, they will also require significant dataset curation\nwhen intended for use as general-purpose models in a zero-shot setting.", "categories": "cs.CV cs.AI cs.CL cs.CY cs.LG", "created": "2024-08-04", "doi": null, "arxiv_id": "2408.01959"}
{"title": "AnomalySD: Few-Shot Multi-Class Anomaly Detection with Stable Diffusion\n  Model", "authors": [], "abstract": "Anomaly detection is a critical task in industrial manufacturing, aiming to\nidentify defective parts of products. Most industrial anomaly detection methods\nassume the availability of sufficient normal data for training. This assumption\nmay not hold true due to the cost of labeling or data privacy policies.\nAdditionally, mainstream methods require training bespoke models for different\nobjects, which incurs heavy costs and lacks flexibility in practice. To address\nthese issues, we seek help from Stable Diffusion (SD) model due to its\ncapability of zero/few-shot inpainting, which can be leveraged to inpaint\nanomalous regions as normal. In this paper, a few-shot multi-class anomaly\ndetection framework that adopts Stable Diffusion model is proposed, named\nAnomalySD. To adapt SD to anomaly detection task, we design different\nhierarchical text descriptions and the foreground mask mechanism for\nfine-tuning SD. In the inference stage, to accurately mask anomalous regions\nfor inpainting, we propose multi-scale mask strategy and prototype-guided mask\nstrategy to handle diverse anomalous regions. Hierarchical text prompts are\nalso utilized to guide the process of inpainting in the inference stage. The\nanomaly score is estimated based on inpainting result of all masks. Extensive\nexperiments on the MVTec-AD and VisA datasets demonstrate the superiority of\nour approach. We achieved anomaly classification and segmentation results of\n93.6%/94.8% AUROC on the MVTec-AD dataset and 86.1%/96.5% AUROC on the VisA\ndataset under multi-class and one-shot settings.", "categories": "cs.CV cs.AI", "created": "2024-08-04", "doi": null, "arxiv_id": "2408.01960"}
{"title": "Representation Bias of Adolescents in AI: A Bilingual, Bicultural Study", "authors": [], "abstract": "Popular and news media often portray teenagers with sensationalism, as both a\nrisk to society and at risk from society. As AI begins to absorb some of the\nepistemic functions of traditional media, we study how teenagers in two\ncountries speaking two languages: 1) are depicted by AI, and 2) how they would\nprefer to be depicted. Specifically, we study the biases about teenagers\nlearned by static word embeddings (SWEs) and generative language models (GLMs),\ncomparing these with the perspectives of adolescents living in the U.S. and\nNepal. We find English-language SWEs associate teenagers with societal\nproblems, and more than 50% of the 1,000 words most associated with teenagers\nin the pretrained GloVe SWE reflect such problems. Given prompts about\nteenagers, 30% of outputs from GPT2-XL and 29% from LLaMA-2-7B GLMs discuss\nsocietal problems, most commonly violence, but also drug use, mental illness,\nand sexual taboo. Nepali models, while not free of such associations, are less\ndominated by social problems. Data from workshops with N=13 U.S. adolescents\nand N=18 Nepalese adolescents show that AI presentations are disconnected from\nteenage life, which revolves around activities like school and friendship.\nParticipant ratings of how well 20 trait words describe teens are decorrelated\nfrom SWE associations, with Pearson's r=.02, n.s. in English FastText and\nr=.06, n.s. in GloVe; and r=.06, n.s. in Nepali FastText and r=-.23, n.s. in\nGloVe. U.S. participants suggested AI could fairly present teens by\nhighlighting diversity, while Nepalese participants centered positivity.\nParticipants were optimistic that, if it learned from adolescents, rather than\nmedia sources, AI could help mitigate stereotypes. Our work offers an\nunderstanding of the ways SWEs and GLMs misrepresent a developmentally\nvulnerable group and provides a template for less sensationalized\ncharacterization.", "categories": "cs.CY cs.AI cs.CL cs.HC cs.LG", "created": "2024-08-04", "doi": null, "arxiv_id": "2408.01961"}
{"title": "The Implications of Open Generative Models in Human-Centered Data\n  Science Work: A Case Study with Fact-Checking Organizations", "authors": [], "abstract": "Calls to use open generative language models in academic research have\nhighlighted the need for reproducibility and transparency in scientific\nresearch. However, the impact of generative AI extends well beyond academia, as\ncorporations and public interest organizations have begun integrating these\nmodels into their data science pipelines. We expand this lens to include the\nimpact of open models on organizations, focusing specifically on fact-checking\norganizations, which use AI to observe and analyze large volumes of circulating\nmisinformation, yet must also ensure the reproducibility and impartiality of\ntheir work. We wanted to understand where fact-checking organizations use open\nmodels in their data science pipelines; what motivates their use of open models\nor proprietary models; and how their use of open or proprietary models can\ninform research on the societal impact of generative AI. To answer these\nquestions, we conducted an interview study with N=24 professionals at 20\nfact-checking organizations on six continents. Based on these interviews, we\noffer a five-component conceptual model of where fact-checking organizations\nemploy generative AI to support or automate parts of their data science\npipeline, including Data Ingestion, Data Analysis, Data Retrieval, Data\nDelivery, and Data Sharing. We then provide taxonomies of fact-checking\norganizations' motivations for using open models and the limitations that\nprevent them for further adopting open models, finding that they prefer open\nmodels for Organizational Autonomy, Data Privacy and Ownership, Application\nSpecificity, and Capability Transparency. However, they nonetheless use\nproprietary models due to perceived advantages in Performance, Usability, and\nSafety, as well as Opportunity Costs related to participation in emerging\ngenerative AI ecosystems. Our work provides novel perspective on open models in\ndata-driven organizations.", "categories": "cs.HC cs.AI cs.CL cs.CY cs.ET", "created": "2024-08-04", "doi": null, "arxiv_id": "2408.01962"}
{"title": "A Novel Metric for Measuring the Robustness of Large Language Models in\n  Non-adversarial Scenarios", "authors": [], "abstract": "We evaluate the robustness of several large language models on multiple\ndatasets. Robustness here refers to the relative insensitivity of the model's\nanswers to meaning-preserving variants of their input. Benchmark datasets are\nconstructed by introducing naturally-occurring, non-malicious perturbations, or\nby generating semantically equivalent paraphrases of input questions or\nstatements. We further propose a novel metric for assessing a model robustness,\nand demonstrate its benefits in the non-adversarial scenario by empirical\nevaluation of several models on the created datasets.", "categories": "cs.CL stat.AP", "created": "2024-08-04", "doi": null, "arxiv_id": "2408.01963"}
{"title": "Top K Enhanced Reinforcement Learning Attacks on Heterogeneous Graph\n  Node Classification", "authors": [], "abstract": "Graph Neural Networks (GNNs) have attracted substantial interest due to their\nexceptional performance on graph-based data. However, their robustness,\nespecially on heterogeneous graphs, remains underexplored, particularly against\nadversarial attacks. This paper proposes HeteroKRLAttack, a targeted evasion\nblack-box attack method for heterogeneous graphs. By integrating reinforcement\nlearning with a Top-K algorithm to reduce the action space, our method\nefficiently identifies effective attack strategies to disrupt node\nclassification tasks. We validate the effectiveness of HeteroKRLAttack through\nexperiments on multiple heterogeneous graph datasets, showing significant\nreductions in classification accuracy compared to baseline methods. An ablation\nstudy underscores the critical role of the Top-K algorithm in enhancing attack\nperformance. Our findings highlight potential vulnerabilities in current models\nand provide guidance for future defense strategies against adversarial attacks\non heterogeneous graphs.", "categories": "cs.LG cs.AI", "created": "2024-08-04", "doi": null, "arxiv_id": "2408.01964"}
{"title": "ML-EAT: A Multilevel Embedding Association Test for Interpretable and\n  Transparent Social Science", "authors": [], "abstract": "This research introduces the Multilevel Embedding Association Test (ML-EAT),\na method designed for interpretable and transparent measurement of intrinsic\nbias in language technologies. The ML-EAT addresses issues of ambiguity and\ndifficulty in interpreting the traditional EAT measurement by quantifying bias\nat three levels of increasing granularity: the differential association between\ntwo target concepts with two attribute concepts; the individual effect size of\neach target concept with two attribute concepts; and the association between\neach individual target concept and each individual attribute concept. Using the\nML-EAT, this research defines a taxonomy of EAT patterns describing the nine\npossible outcomes of an embedding association test, each of which is associated\nwith a unique EAT-Map, a novel four-quadrant visualization for interpreting the\nML-EAT. Empirical analysis of static and diachronic word embeddings, GPT-2\nlanguage models, and a CLIP language-and-image model shows that EAT patterns\nadd otherwise unobservable information about the component biases that make up\nan EAT; reveal the effects of prompting in zero-shot models; and can also\nidentify situations when cosine similarity is an ineffective metric, rendering\nan EAT unreliable. Our work contributes a method for rendering bias more\nobservable and interpretable, improving the transparency of computational\ninvestigations into human minds and societies.", "categories": "cs.CL cs.AI cs.CY", "created": "2024-08-04", "doi": null, "arxiv_id": "2408.01966"}
{"title": "A multi-task deep learning approach for lane-level pavement performance\n  prediction with segment-level data", "authors": [], "abstract": "The elaborate pavement performance prediction is an important premise of\nimplementing preventive maintenance. Our survey reveals that in practice, the\npavement performance is usually measured at segment-level, where an unique\nperformance value is obtained for all lanes within one segment of 1km length.\nIt still lacks more elaborate performance analysis at lane-level due to costly\ndata collection and difficulty in prediction modeling. Therefore, this study\ndeveloped a multi-task deep learning approach to predict the lane-level\npavement performance with a large amount of historical segment-level\nperformance measurement data. The unified prediction framework can effectively\naddress inherent correlation and differences across lanes. In specific, the\nprediction framework firstly employed an Long Short-Term Memory (LSTM) layer to\ncapture the segment-level pavement deterioration pattern. Then multiple\ntask-specific LSTM layers were designed based on number of lanes to capture\nlane-level differences in pavement performance. Finally, we concatenated\nmultiple task-specific LSTM outputs with auxiliary features for further\ntraining and obtained the lane-level predictions after fully connected layer.\nThe aforementioned prediction framework was validated with a real case in\nChina. It revealed a better model performance regardless of one-way 2-lane,\n3-lane, and 4-lane scenarios, all lower than 10% in terms of mean absolute\npercentage error. The proposed prediction framework also outperforms other\nensemble learning and shallow machine learning methods in almost every lane.", "categories": "cs.LG", "created": "2024-08-04", "doi": null, "arxiv_id": "2408.01967"}
{"title": "Optimal and efficient text counterfactuals using Graph Neural Networks", "authors": [], "abstract": "As NLP models become increasingly integral to decision-making processes, the\nneed for explainability and interpretability has become paramount. In this\nwork, we propose a framework that achieves the aforementioned by generating\nsemantically edited inputs, known as counterfactual interventions, which change\nthe model prediction, thus providing a form of counterfactual explanations for\nthe model. We test our framework on two NLP tasks - binary sentiment\nclassification and topic classification - and show that the generated edits are\ncontrastive, fluent and minimal, while the whole process remains significantly\nfaster that other state-of-the-art counterfactual editors.", "categories": "cs.CL", "created": "2024-08-04", "doi": null, "arxiv_id": "2408.01969"}
{"title": "SR-CIS: Self-Reflective Incremental System with Decoupled Memory and\n  Reasoning", "authors": [], "abstract": "The ability of humans to rapidly learn new knowledge while retaining old\nmemories poses a significant challenge for current deep learning models. To\nhandle this challenge, we draw inspiration from human memory and learning\nmechanisms and propose the Self-Reflective Complementary Incremental System\n(SR-CIS). Comprising the deconstructed Complementary Inference Module (CIM) and\nComplementary Memory Module (CMM), SR-CIS features a small model for fast\ninference and a large model for slow deliberation in CIM, enabled by the\nConfidence-Aware Online Anomaly Detection (CA-OAD) mechanism for efficient\ncollaboration. CMM consists of task-specific Short-Term Memory (STM) region and\na universal Long-Term Memory (LTM) region. By setting task-specific Low-Rank\nAdaptive (LoRA) and corresponding prototype weights and biases, it instantiates\nexternal storage for parameter and representation memory, thus deconstructing\nthe memory module from the inference module. By storing textual descriptions of\nimages during training and combining them with the Scenario Replay Module (SRM)\npost-training for memory combination, along with periodic short-to-long-term\nmemory restructuring, SR-CIS achieves stable incremental memory with limited\nstorage requirements. Balancing model plasticity and memory stability under\nconstraints of limited storage and low data resources, SR-CIS surpasses\nexisting competitive baselines on multiple standard and few-shot incremental\nlearning benchmarks.", "categories": "cs.AI cs.CV", "created": "2024-08-04", "doi": null, "arxiv_id": "2408.01970"}
{"title": "Sparse identification of time delay systems via pseudospectral\n  collocation", "authors": [], "abstract": "We present a pragmatic approach to the sparse identification of nonlinear\ndynamics for systems with discrete delays. It relies on approximating the\nunderlying delay model with a system of ordinary differential equations via\npseudospectral collocation. To minimize the reconstruction error, the new\nstrategy avoids optimizing all possible multiple unknown delays, identifying\nonly the maximum one. The computational burden is thus greatly reduced,\nimproving the performance of recent implementations that work directly on the\ndelay system.", "categories": "math.DS cs.NA math.NA", "created": "2024-08-04", "doi": null, "arxiv_id": "2408.01971"}
{"title": "RVI-SAC: Average Reward Off-Policy Deep Reinforcement Learning", "authors": [], "abstract": "In this paper, we propose an off-policy deep reinforcement learning (DRL)\nmethod utilizing the average reward criterion. While most existing DRL methods\nemploy the discounted reward criterion, this can potentially lead to a\ndiscrepancy between the training objective and performance metrics in\ncontinuing tasks, making the average reward criterion a recommended\nalternative. We introduce RVI-SAC, an extension of the state-of-the-art\noff-policy DRL method, Soft Actor-Critic (SAC), to the average reward\ncriterion. Our proposal consists of (1) Critic updates based on RVI Q-learning,\n(2) Actor updates introduced by the average reward soft policy improvement\ntheorem, and (3) automatic adjustment of Reset Cost enabling the average reward\nreinforcement learning to be applied to tasks with termination. We apply our\nmethod to the Gymnasium's Mujoco tasks, a subset of locomotion tasks, and\ndemonstrate that RVI-SAC shows competitive performance compared to existing\nmethods.", "categories": "cs.LG", "created": "2024-08-04", "doi": null, "arxiv_id": "2408.01972"}
{"title": "Label Augmentation for Neural Networks Robustness", "authors": [], "abstract": "Out-of-distribution generalization can be categorized into two types: common\nperturbations arising from natural variations in the real world and adversarial\nperturbations that are intentionally crafted to deceive neural networks. While\ndeep neural networks excel in accuracy under the assumption of identical\ndistributions between training and test data, they often encounter\nout-of-distribution scenarios resulting in a significant decline in accuracy.\nData augmentation methods can effectively enhance robustness against common\ncorruptions, but they typically fall short in improving robustness against\nadversarial perturbations. In this study, we develop Label Augmentation (LA),\nwhich enhances robustness against both common and intentional perturbations and\nimproves uncertainty estimation. Our findings indicate a Clean error rate\nimprovement of up to 23.29% when employing LA in comparisons to the baseline.\nAdditionally, it enhances robustness under common corruptions benchmark by up\nto 24.23%. When tested against FGSM and PGD attacks, improvements in\nadversarial robustness are noticeable, with enhancements of up to 53.18% for\nFGSM and 24.46% for PGD attacks.", "categories": "cs.CV", "created": "2024-08-04", "doi": null, "arxiv_id": "2408.01977"}
{"title": "AdvQDet: Detecting Query-Based Adversarial Attacks with Adversarial\n  Contrastive Prompt Tuning", "authors": [], "abstract": "Deep neural networks (DNNs) are known to be vulnerable to adversarial attacks\neven under a black-box setting where the adversary can only query the model.\nParticularly, query-based black-box adversarial attacks estimate adversarial\ngradients based on the returned probability vectors of the target model for a\nsequence of queries. During this process, the queries made to the target model\nare intermediate adversarial examples crafted at the previous attack step,\nwhich share high similarities in the pixel space. Motivated by this\nobservation, stateful detection methods have been proposed to detect and reject\nquery-based attacks. While demonstrating promising results, these methods\neither have been evaded by more advanced attacks or suffer from low efficiency\nin terms of the number of shots (queries) required to detect different attacks.\nArguably, the key challenge here is to assign high similarity scores for any\ntwo intermediate adversarial examples perturbed from the same clean image. To\naddress this challenge, we propose a novel Adversarial Contrastive Prompt\nTuning (ACPT) method to robustly fine-tune the CLIP image encoder to extract\nsimilar embeddings for any two intermediate adversarial queries. With ACPT, we\nfurther introduce a detection framework AdvQDet that can detect 7\nstate-of-the-art query-based attacks with $>99\\%$ detection rate within 5\nshots. We also show that ACPT is robust to 3 types of adaptive attacks. Code is\navailable at https://github.com/xinwong/AdvQDet.", "categories": "cs.CV", "created": "2024-08-04", "doi": null, "arxiv_id": "2408.01978"}
{"title": "Shaping Rewards, Shaping Routes: On Multi-Agent Deep Q-Networks for\n  Routing in Satellite Constellation Networks", "authors": [], "abstract": "Effective routing in satellite mega-constellations has become crucial to\nfacilitate the handling of increasing traffic loads, more complex network\narchitectures, as well as the integration into 6G networks. To enhance\nadaptability as well as robustness to unpredictable traffic demands, and to\nsolve dynamic routing environments efficiently, machine learning-based\nsolutions are being considered. For network control problems, such as\noptimizing packet forwarding decisions according to Quality of Service\nrequirements and maintaining network stability, deep reinforcement learning\ntechniques have demonstrated promising results. For this reason, we investigate\nthe viability of multi-agent deep Q-networks for routing in satellite\nconstellation networks. We focus specifically on reward shaping and quantifying\ntraining convergence for joint optimization of latency and load balancing in\nstatic and dynamic scenarios. To address identified drawbacks, we propose a\nnovel hybrid solution based on centralized learning and decentralized control.", "categories": "cs.NI cs.LG", "created": "2024-08-04", "doi": null, "arxiv_id": "2408.01979"}
{"title": "Characterizing the Performance of the Implicit Massively Parallel\n  Particle-in-Cell iPIC3D Code", "authors": [], "abstract": "Optimizing iPIC3D, an implicit Particle-in-Cell (PIC) code, for large-scale\n3D plasma simulations is crucial for space and astrophysical applications. This\nwork focuses on characterizing iPIC3D's communication efficiency through\nstrategic measures like optimal node placement, communication and computation\noverlap, and load balancing. Profiling and tracing tools are employed to\nanalyze iPIC3D's communication efficiency and provide practical\nrecommendations. Implementing optimized communication protocols addresses the\nGeospace Environmental Modeling (GEM) magnetic reconnection challenges in\nplasma physics with more precise simulations. This approach captures the\ncomplexities of 3D plasma simulations, particularly in magnetic reconnection,\nadvancing space and astrophysical research.", "categories": "physics.plasm-ph cs.DC cs.PF", "created": "2024-08-04", "doi": null, "arxiv_id": "2408.01983"}
{"title": "DeMansia: Mamba Never Forgets Any Tokens", "authors": [], "abstract": "This paper examines the mathematical foundations of transformer\narchitectures, highlighting their limitations particularly in handling long\nsequences. We explore prerequisite models such as Mamba, Vision Mamba (ViM),\nand LV-ViT that pave the way for our proposed architecture, DeMansia. DeMansia\nintegrates state space models with token labeling techniques to enhance\nperformance in image classification tasks, efficiently addressing the\ncomputational challenges posed by traditional transformers. The architecture,\nbenchmark, and comparisons with contemporary models demonstrate DeMansia's\neffectiveness. The implementation of this paper is available on GitHub at\nhttps://github.com/catalpaaa/DeMansia", "categories": "cs.CV cs.AI", "created": "2024-08-04", "doi": null, "arxiv_id": "2408.01986"}
{"title": "MetaWearS: A Shortcut in Wearable Systems Lifecycle with Only a Few\n  Shots", "authors": [], "abstract": "Wearable systems provide continuous health monitoring and can lead to early\ndetection of potential health issues. However, the lifecycle of wearable\nsystems faces several challenges. First, effective model training for new\nwearable devices requires substantial labeled data from various subjects\ncollected directly by the wearable. Second, subsequent model updates require\nfurther extensive labeled data for retraining. Finally, frequent model updating\non the wearable device can decrease the battery life in long-term data\nmonitoring. Addressing these challenges, in this paper, we propose MetaWearS, a\nmeta-learning method to reduce the amount of initial data collection required.\nMoreover, our approach incorporates a prototypical updating mechanism,\nsimplifying the update process by modifying the class prototype rather than\nretraining the entire model. We explore the performance of MetaWearS in two\ncase studies, namely, the detection of epileptic seizures and the detection of\natrial fibrillation. We show that by fine-tuning with just a few samples, we\nachieve 70% and 82% AUC for the detection of epileptic seizures and the\ndetection of atrial fibrillation, respectively. Compared to a conventional\napproach, our proposed method performs better with up to 45% AUC. Furthermore,\nupdating the model with only 16 minutes of additional labeled data increases\nthe AUC by up to 5.3%. Finally, MetaWearS reduces the energy consumption for\nmodel updates by 456x and 418x for epileptic seizure and AF detection,\nrespectively.", "categories": "cs.LG cs.AI cs.AR", "created": "2024-08-04", "doi": null, "arxiv_id": "2408.01988"}
{"title": "JobViz: Skill-driven Visual Exploration of Job Advertisements", "authors": [], "abstract": "Online job advertisements on various job portals or websites have become the\nmost popular way for people to find potential career opportunities nowadays.\nHowever, the majority of these job sites are limited to offering fundamental\nfilters such as job titles, keywords, and compensation ranges. This often poses\na challenge for job seekers in efficiently identifying relevant job\nadvertisements that align with their unique skill sets amidst a vast sea of\nlistings. Thus, we propose well-coordinated visualizations to provide job\nseekers with three levels of details of job information: a skill-job overview\nvisualizes skill sets, employment posts as well as relationships between them\nwith a hierarchical visualization design; a post exploration view leverages an\naugmented radar-chart glyph to represent job posts and further facilitates\nusers' swift comprehension of the pertinent skills necessitated by respective\npositions; a post detail view lists the specifics of selected job posts for\nprofound analysis and comparison. By using a real-world recruitment\nadvertisement dataset collected from 51Job, one of the largest job websites in\nChina, we conducted two case studies and user interviews to evaluate JobViz.\nThe results demonstrated the usefulness and effectiveness of our approach.", "categories": "cs.HC", "created": "2024-08-04", "doi": "10.1016/j.visinf.2024.07.001", "arxiv_id": "2408.01989"}
{"title": "User Experience of Visualizations in Motion: A Case Study and Design\n  Considerations", "authors": [], "abstract": "We present a systematic review, an empirical study, and a first set of\nconsiderations for designing visualizations in motion, derived from a concrete\nscenario in which these visualizations were used to support a primary task. In\npractice, when viewers are confronted with embedded visualizations, they often\nhave to focus on a primary task and can only quickly glance at a visualization\nshowing rich, often dynamically updated, information. As such, the\nvisualizations must be designed so as not to distract from the primary task,\nwhile at the same time being readable and useful for aiding the primary task.\nFor example, in games, players who are engaged in a battle have to look at\ntheir enemies but also read the remaining health of their own game character\nfrom the health bar over their character's head. Many trade-offs are possible\nin the design of embedded visualizations in such dynamic scenarios, which we\nexplore in-depth in this paper with a focus on user experience. We use video\ngames as an example of an application context with a rich existing set of\nvisualizations in motion. We begin our work with a systematic review of in-game\nvisualizations in motion. Next, we conduct an empirical user study to\ninvestigate how different embedded visualizations in motion designs impact user\nexperience. We conclude with a set of considerations and trade-offs for\ndesigning visualizations in motion more broadly as derived from what we learned\nabout video games. All supplemental materials of this paper are available at\nhttps://osf.io/3v8wm/}.", "categories": "cs.HC", "created": "2024-08-04", "doi": null, "arxiv_id": "2408.01991"}
{"title": "Towards Automatic Hands-on-Keyboard Attack Detection Using LLMs in EDR\n  Solutions", "authors": [], "abstract": "Endpoint Detection and Remediation (EDR) platforms are essential for\nidentifying and responding to cyber threats. This study presents a novel\napproach using Large Language Models (LLMs) to detect Hands-on-Keyboard (HOK)\ncyberattacks. Our method involves converting endpoint activity data into\nnarrative forms that LLMs can analyze to distinguish between normal operations\nand potential HOK attacks. We address the challenges of interpreting endpoint\ndata by segmenting narratives into windows and employing a dual training\nstrategy. The results demonstrate that LLM-based models have the potential to\noutperform traditional machine learning methods, offering a promising direction\nfor enhancing EDR capabilities and apply LLMs in cybersecurity.", "categories": "cs.CR cs.LG", "created": "2024-08-04", "doi": null, "arxiv_id": "2408.01993"}
{"title": "Configuring Safe Spiking Neural Controllers for Cyber-Physical Systems\n  through Formal Verification", "authors": [], "abstract": "Spiking Neural Networks (SNNs) are a subclass of neuromorphic models that\nhave great potential to be used as controllers in Cyber-Physical Systems (CPSs)\ndue to their energy efficiency. They can benefit from the prevalent approach of\nfirst training an Artificial Neural Network (ANN) and then translating to an\nSNN with subsequent hyperparameter tuning. The tuning is required to ensure\nthat the resulting SNN is accurate with respect to the ANN in terms of metrics\nlike Mean Squared Error (MSE). However, SNN controllers for safety-critical\nCPSs must also satisfy safety specifications, which are not guaranteed by the\nconversion approach. In this paper, we propose a solution which tunes the\n$temporal$ $window$ hyperparameter of the translated SNN to ensure both\naccuracy and compliance with the safe range specification that requires the SNN\noutputs to remain within a safe range. The core verification problem is\nmodelled using mixed-integer linear programming (MILP) and is solved with\nGurobi. When the controller fails to meet the range specification, we compute\ntight bounds on the SNN outputs as feedback for the CPS developer. To mitigate\nthe high computational cost of verification, we integrate data-driven steps to\nminimize verification calls. Our approach provides designers with the\nconfidence to safely integrate energy-efficient SNN controllers into modern\nCPSs. We demonstrate our approach with experimental results on five different\nbenchmark neural controllers.", "categories": "cs.ET cs.SY eess.SY", "created": "2024-08-04", "doi": null, "arxiv_id": "2408.01996"}
{"title": "Rate-Splitting Multiple Access for GEO-LEO Coexisting Satellite Systems:\n  A Traffic-Aware Throughput Maximization Precoder Design", "authors": [], "abstract": "The frequency coexistence between geostationary orbit (GEO) and low earth\norbit (LEO) satellite systems is expected to be a promising approach for\nrelieving spectrum scarcity. However, it is essential to manage mutual\ninterference between GEO and LEO satellite systems for frequency coexistence.\nSpecifically, \\emph{in-line interference}, caused by LEO satellites moving near\nthe line-of-sight path between GEO satellite and GEO users (GUs), can\nsignificantly degrade GEO system throughput. This paper put forth a novel\nrate-splitting multiple access (RSMA) with a super-common message for GEO-LEO\ncoexisting satellite systems (CSS). By employing a super-common message that\nGUs can decode, GUs can mitigate the in-line interference by successive\ninterference cancellation (SIC). Moreover, we formulate a traffic-aware\nthroughput maximization (TTM) problem to satisfy the heterogeneous traffic\ndemands of users by minimizing total unmet throughput demands (or user\ndissatisfaction). By doing so, the TTM precoder can be flexibly adjusted\naccording to the interference leakage from LEO satellites to GUs and target\ntraffic demands. Numerical results confirm that our proposed method ensures\nseamless connectivity even in the GEO-LEO in-line interference regime under\nimperfect channel state information (CSI) at both the transmitter and receiver.", "categories": "cs.IT cs.SY eess.SY math.IT", "created": "2024-08-04", "doi": null, "arxiv_id": "2408.01997"}
{"title": "What Happens Without Background? Constructing Foreground-Only Data for\n  Fine-Grained Tasks", "authors": [], "abstract": "Fine-grained recognition, a pivotal task in visual signal processing, aims to\ndistinguish between similar subclasses based on discriminative information\npresent in samples. However, prevailing methods often erroneously focus on\nbackground areas, neglecting the capture of genuinely effective discriminative\ninformation from the subject, thus impeding practical application. To\nfacilitate research into the impact of background noise on models and enhance\ntheir ability to concentrate on the subject's discriminative features, we\npropose an engineered pipeline that leverages the capabilities of SAM and Detic\nto create fine-grained datasets with only foreground subjects, devoid of\nbackground. Extensive cross-experiments validate this approach as a\npreprocessing step prior to training, enhancing algorithmic performance and\nholding potential for further modal expansion of the data.", "categories": "cs.CV", "created": "2024-08-04", "doi": null, "arxiv_id": "2408.01998"}
{"title": "Reinforcement Learning for an Efficient and Effective Malware\n  Investigation during Cyber Incident Response", "authors": [], "abstract": "This research focused on enhancing post-incident malware forensic\ninvestigation using reinforcement learning RL. We proposed an advanced MDP post\nincident malware forensics investigation model and framework to expedite post\nincident forensics. We then implement our RL Malware Investigation Model based\non structured MDP within the proposed framework. To identify malware artefacts,\nthe RL agent acquires and examines forensics evidence files, iteratively\nimproving its capabilities using Q Table and temporal difference learning. The\nQ learning algorithm significantly improved the agent ability to identify\nmalware. An epsilon greedy exploration strategy and Q learning updates enabled\nefficient learning and decision making. Our experimental testing revealed that\noptimal learning rates depend on the MDP environment complexity, with simpler\nenvironments benefiting from higher rates for quicker convergence and complex\nones requiring lower rates for stability. Our model performance in identifying\nand classifying malware reduced malware analysis time compared to human\nexperts, demonstrating robustness and adaptability. The study highlighted the\nsignificance of hyper parameter tuning and suggested adaptive strategies for\ncomplex environments. Our RL based approach produced promising results and is\nvalidated as an alternative to traditional methods notably by offering\ncontinuous learning and adaptation to new and evolving malware threats which\nultimately enhance the post incident forensics investigations.", "categories": "cs.CR cs.AI cs.ET", "created": "2024-08-04", "doi": null, "arxiv_id": "2408.01999"}
{"title": "Adelie: Detection and prevention of Byzantine behaviour in DAG-based\n  consensus protocols", "authors": [], "abstract": "Recent developments in the Byzantine Fault Tolerant consensus protocols have\nshown the DAG-based protocols to be a very promising technique. While early\nimplementations of DAG-based protocols such as Narwhal/Bullshark trade high\nthroughput for a low latency, the latest versions of DAG-based protocols such\nas Mysticeti and Shoal++ show that indeed a latency comparable to that of\ntraditional consensus protocols such as HotStuff can be achieve with the\nDAG-based consensus protocols while still maintaining high throughput.\nMysticeti in particular achieves a low latency by implementing a novel approach\nof using an uncertified DAG - a significant breakthrough comparing to the\ncertified DAG used in the previous generations of the protocol. However, the\nuncertified DAG exposes the system to new vectors of attacks by Byzantine\nvalidators that did not exist in the certified DAG protocols. In this paper we\ndescribe those issues and present the Adelie protocol, that addresses issues\nthat comes with an uncertified DAG. We also incorporate some of the techniques\nfrom the Shoal++ to reduce latency even further. This paper also presents an\nimplementation of Adelie protocol - bftd that demonstrates yet another\nbreakthrough in the maximum achieved TPS and low latency.", "categories": "cs.DC cs.CR", "created": "2024-08-04", "doi": null, "arxiv_id": "2408.02000"}
{"title": "AdaCBM: An Adaptive Concept Bottleneck Model for Explainable and\n  Accurate Diagnosis", "authors": [], "abstract": "The integration of vision-language models such as CLIP and Concept Bottleneck\nModels (CBMs) offers a promising approach to explaining deep neural network\n(DNN) decisions using concepts understandable by humans, addressing the\nblack-box concern of DNNs. While CLIP provides both explainability and\nzero-shot classification capability, its pre-training on generic image and text\ndata may limit its classification accuracy and applicability to medical image\ndiagnostic tasks, creating a transfer learning problem. To maintain\nexplainability and address transfer learning needs, CBM methods commonly design\npost-processing modules after the bottleneck module. However, this way has been\nineffective. This paper takes an unconventional approach by re-examining the\nCBM framework through the lens of its geometrical representation as a simple\nlinear classification system. The analysis uncovers that post-CBM fine-tuning\nmodules merely rescale and shift the classification outcome of the system,\nfailing to fully leverage the system's learning potential. We introduce an\nadaptive module strategically positioned between CLIP and CBM to bridge the gap\nbetween source and downstream domains. This simple yet effective approach\nenhances classification performance while preserving the explainability\nafforded by the framework. Our work offers a comprehensive solution that\nencompasses the entire process, from concept discovery to model training,\nproviding a holistic recipe for leveraging the strengths of GPT, CLIP, and CBM.", "categories": "cs.CV", "created": "2024-08-04", "doi": null, "arxiv_id": "2408.02001"}
{"title": "LLaSA: Large Language and E-Commerce Shopping Assistant", "authors": [], "abstract": "The e-commerce platform has evolved rapidly due to its widespread popularity\nand convenience. Developing an e-commerce shopping assistant for customers is\ncrucial to aiding them in quickly finding desired products and recommending\nprecisely what they need. However, most previous shopping assistants face two\nmain problems: (1) task-specificity, which necessitates the development of\ndifferent models for various tasks, thereby increasing development costs and\nlimiting effectiveness; and (2) poor generalization, where the trained model\nperforms inadequately on up-to-date products. To resolve these issues, we\nemploy Large Language Models (LLMs) to construct an omnipotent assistant,\nleveraging their adeptness at handling multiple tasks and their superior\ngeneralization capability. Nonetheless, LLMs lack inherent knowledge of\ne-commerce concepts. To address this, we create an instruction dataset\ncomprising 65,000 samples and diverse tasks, termed as EshopInstruct. Through\ninstruction tuning on our dataset, the assistant, named LLaSA, demonstrates the\npotential to function as an omnipotent assistant. Additionally, we propose\nvarious inference optimization strategies to enhance performance with limited\ninference resources. In the Amazon KDD Cup 2024 Challenge, our proposed method,\nLLaSA, achieved an overall ranking of 3rd place on ShopBench, including 57\ntasks and approximately 20,000 questions, and we secured top-5 rankings in each\ntrack, especially in track4, where we achieved the best performance result\namong all student teams. Our extensive practices fully demonstrate that LLMs\npossess the great potential to be competent e-commerce shopping assistants.", "categories": "cs.CL", "created": "2024-08-04", "doi": null, "arxiv_id": "2408.02006"}
{"title": "Joint Learning of Emotions in Music and Generalized Sounds", "authors": [], "abstract": "In this study, we aim to determine if generalized sounds and music can share\na common emotional space, improving predictions of emotion in terms of arousal\nand valence. We propose the use of multiple datasets as a multi-domain learning\ntechnique. Our approach involves creating a common space encompassing features\nthat characterize both generalized sounds and music, as they can evoke emotions\nin a similar manner. To achieve this, we utilized two publicly available\ndatasets, namely IADS-E and PMEmo, following a standardized experimental\nprotocol. We employed a wide variety of features that capture diverse aspects\nof the audio structure including key parameters of spectrum, energy, and\nvoicing. Subsequently, we performed joint learning on the common feature space,\nleveraging heterogeneous model architectures. Interestingly, this synergistic\nscheme outperforms the state-of-the-art in both sound and music emotion\nprediction. The code enabling full replication of the presented experimental\npipeline is available at https://github.com/LIMUNIMI/MusicSoundEmotions.", "categories": "cs.SD cs.AI eess.AS", "created": "2024-08-04", "doi": "10.1145/3678299.3678328", "arxiv_id": "2408.02009"}
{"title": "Isolating Signatures of Cyberattacks under Stressed Grid Conditions", "authors": [], "abstract": "In a controlled cyber-physical network, such as a power grid, any malicious\ndata injection in the sensor measurements can lead to widespread impact due to\nthe actions of the closed-loop controllers. While fast identification of the\nattack signatures is imperative for reliable operations, it is challenging to\ndo so in a large dynamical network with tightly coupled nodes. A particularly\nchallenging scenario arises when the cyberattacks are strategically launched\nduring a grid stress condition, caused by non-malicious physical disturbances.\nIn this work, we propose an algorithmic framework -- based on Koopman mode (KM)\ndecomposition -- for online identification and visualization of the cyberattack\nsignatures in streaming time-series measurements from a power network. The KMs\nare capable of capturing the spatial embedding of both natural and anomalous\nmodes of oscillations in the sensor measurements and thus revealing the\nspecific influences of cyberattacks, even under existing non-malicious grid\nstress events. Most importantly, it enables us to quantitatively compare the\noutcomes of different potential cyberattacks injected by an attacker. The\nperformance of the proposed algorithmic framework is illustrated on the IEEE\n68-bus test system using synthetic attack scenarios. Such knowledge regarding\nthe detection of various cyberattacks will enable us to devise appropriate\ndiagnostic scheme while considering varied constraints arising from different\nattacks.", "categories": "eess.SY cs.SY math.DS math.OC", "created": "2024-08-04", "doi": null, "arxiv_id": "2408.02011"}
{"title": "Decision Support System to triage of liver trauma", "authors": [], "abstract": "Trauma significantly impacts global health, accounting for over 5 million\ndeaths annually, which is comparable to mortality rates from diseases such as\ntuberculosis, AIDS, and malaria. In Iran, the financial repercussions of road\ntraffic accidents represent approximately 2% of the nation's Gross National\nProduct each year. Bleeding is the leading cause of mortality in trauma\npatients within the first 24 hours following an injury, making rapid diagnosis\nand assessment of severity crucial. Trauma patients require comprehensive scans\nof all organs, generating a large volume of data. Evaluating CT images for the\nentire body is time-consuming and requires significant expertise, underscoring\nthe need for efficient time management in diagnosis. Efficient diagnostic\nprocesses can significantly reduce treatment costs and decrease the likelihood\nof secondary complications. In this context, the development of a reliable\nDecision Support System (DSS) for trauma triage, particularly focused on the\nabdominal area, is vital. This paper presents a novel method for detecting\nliver bleeding and lacerations using CT scans, utilising the GAN Pix2Pix\ntranslation model. The effectiveness of the method is quantified by Dice score\nmetrics, with the model achieving an accuracy of 97% for liver bleeding and 93%\nfor liver laceration detection. These results represent a notable improvement\nover current state-of-the-art technologies. The system's design integrates\nseamlessly with existing medical imaging technologies, making it a practical\naddition to emergency medical services. This research underscores the potential\nof advanced image translation models like GAN Pix2Pix in improving the\nprecision and speed of medical diagnostics in critical care scenarios.", "categories": "eess.IV cs.CV", "created": "2024-08-04", "doi": null, "arxiv_id": "2408.02012"}
{"title": "Blockchain-Enabled Dynamic Spectrum Sharing for Satellite and\n  Terrestrial Communication Networks", "authors": [], "abstract": "Dynamic spectrum sharing (DSS) between satellite and terrestrial networks has\nincreasingly engaged the academic and industrial sectors. Nevertheless,\nfacilitating secure, efficient and scalable sharing continues to pose a pivotal\nchallenge. Emerging as a promising technology to bridge the trust gap among\nmultiple participants, blockchain has been envisioned to enable DSS in a\ndecentralized manner. However, satellites with limited resources may struggle\nto support the frequent interactions required by blockchain networks.\nAdditionally,given the extensive coverage of satellites, spectrum sharing needs\nvary by regions, challenging traditional blockchain approaches to accommodate\ndifferences. In this work, a partitioned, self-governed, and customized dynamic\nspectrum sharing approach (PSC-DSS) is proposed for spectrum sharing between\nsatellite access networks and terrestrial access networks. This approach\nestablishes a sharded and tiered architecture which allows various regions to\nmanage spectrum autonomously while jointly maintaining a single blockchain\nledger. Moreover, a spectrum-consensus integrated mechanism, which decouples\nDSS process and couples it with blockchain consensus protocol, is designed to\nenable regions to conduct DSS transactions in parallel and dynamically innovate\nspectrum sharing schemes without affecting others. Furthermore, a theoretical\nframework is derived to justify the stability performance of PSC-DSS. Finally,\nsimulations and experiments are conducted to validate the advantageous\nperformance of PSC-DSS in terms of low-overhead, high efficiency, and robust\nstability.", "categories": "cs.DC", "created": "2024-08-04", "doi": null, "arxiv_id": "2408.02013"}
{"title": "Unsupervised Representation Learning by Balanced Self Attention Matching", "authors": [], "abstract": "Many leading self-supervised methods for unsupervised representation\nlearning, in particular those for embedding image features, are built on\nvariants of the instance discrimination task, whose optimization is known to be\nprone to instabilities that can lead to feature collapse. Different techniques\nhave been devised to circumvent this issue, including the use of negative pairs\nwith different contrastive losses, the use of external memory banks, and\nbreaking of symmetry by using separate encoding networks with possibly\ndifferent structures. Our method, termed BAM, rather than directly matching\nfeatures of different views (augmentations) of input images, is based on\nmatching their self-attention vectors, which are the distributions of\nsimilarities to the entire set of augmented images of a batch. We obtain rich\nrepresentations and avoid feature collapse by minimizing a loss that matches\nthese distributions to their globally balanced and entropy regularized version,\nwhich is obtained through a simple self-optimal-transport computation. We\nablate and verify our method through a wide set of experiments that show\ncompetitive performance with leading methods on both semi-supervised and\ntransfer-learning benchmarks. Our implementation and pre-trained models are\navailable at github.com/DanielShalam/BAM .", "categories": "cs.CV cs.LG", "created": "2024-08-04", "doi": null, "arxiv_id": "2408.02014"}
{"title": "Individualized multi-horizon MRI trajectory prediction for Alzheimer's\n  Disease", "authors": [], "abstract": "Neurodegeneration as measured through magnetic resonance imaging (MRI) is\nrecognized as a potential biomarker for diagnosing Alzheimer's disease (AD),\nbut is generally considered less specific than amyloid or tau based biomarkers.\nDue to a large amount of variability in brain anatomy between different\nindividuals, we hypothesize that leveraging MRI time series can help improve\nspecificity, by treating each patient as their own baseline. Here we turn to\nconditional variational autoencoders to generate individualized MRI predictions\ngiven the subject's age, disease status and one previous scan. Using serial\nimaging data from the Alzheimer's Disease Neuroimaging Initiative, we train a\nnovel architecture to build a latent space distribution which can be sampled\nfrom to generate future predictions of changing anatomy. This enables us to\nextrapolate beyond the dataset and predict MRIs up to 10 years. We evaluated\nthe model on a held-out set from ADNI and an independent dataset (from Open\nAccess Series of Imaging Studies). By comparing to several alternatives, we\nshow that our model produces more individualized images with higher resolution.\nFurther, if an individual already has a follow-up MRI, we demonstrate a usage\nof our model to compute a likelihood ratio classifier for disease status. In\npractice, the model may be able to assist in early diagnosis of AD and provide\na counterfactual baseline trajectory for treatment effect estimation.\nFurthermore, it generates a synthetic dataset that can potentially be used for\ndownstream tasks such as anomaly detection and classification.", "categories": "cs.CV cs.AI", "created": "2024-08-04", "doi": null, "arxiv_id": "2408.02018"}
{"title": "Personalized Federated Learning on Heterogeneous and Long-Tailed Data\n  via Expert Collaborative Learning", "authors": [], "abstract": "Personalized Federated Learning (PFL) aims to acquire customized models for\neach client without disclosing raw data by leveraging the collective knowledge\nof distributed clients. However, the data collected in real-world scenarios is\nlikely to follow a long-tailed distribution. For example, in the medical\ndomain, it is more common for the number of general health notes to be much\nlarger than those specifically relatedto certain diseases. The presence of\nlong-tailed data can significantly degrade the performance of PFL models.\nAdditionally, due to the diverse environments in which each client operates,\ndata heterogeneity is also a classic challenge in federated learning. In this\npaper, we explore the joint problem of global long-tailed distribution and data\nheterogeneity in PFL and propose a method called Expert Collaborative Learning\n(ECL) to tackle this problem. Specifically, each client has multiple experts,\nand each expert has a different training subset, which ensures that each class,\nespecially the minority classes, receives sufficient training. Multiple experts\ncollaborate synergistically to produce the final prediction output. Without\nspecial bells and whistles, the vanilla ECL outperforms other state-of-the-art\nPFL methods on several benchmark datasets under different degrees of data\nheterogeneity and long-tailed distribution.", "categories": "cs.LG", "created": "2024-08-04", "doi": null, "arxiv_id": "2408.02019"}
{"title": "Scenario-based Thermal Management Parametrization Through Deep\n  Reinforcement Learning", "authors": [], "abstract": "The thermal system of battery electric vehicles demands advanced control. Its\nthermal management needs to effectively control active components across\nvarying operating conditions. While robust control function parametrization is\nrequired, current methodologies show significant drawbacks. They consume\nconsiderable time, human effort, and extensive real-world testing.\nConsequently, there is a need for innovative and intelligent solutions that are\ncapable of autonomously parametrizing embedded controllers. Addressing this\nissue, our paper introduces a learning-based tuning approach. We propose a\nmethodology that benefits from automated scenario generation for increased\nrobustness across vehicle usage scenarios. Our deep reinforcement learning\nagent processes the tuning task context and incorporates an image-based\ninterpretation of embedded parameter sets. We demonstrate its applicability to\na valve controller parametrization task and verify it in real-world vehicle\ntesting. The results highlight the competitive performance to baseline methods.\nThis novel approach contributes to the shift towards virtual development of\nthermal management functions, with promising potential of large-scale parameter\ntuning in the automotive industry.", "categories": "cs.LG cs.AI cs.CE cs.SY eess.SY", "created": "2024-08-04", "doi": null, "arxiv_id": "2408.02022"}
{"title": "A Smart City Infrastructure Ontology for Threats, Cybercrime, and\n  Digital Forensic Investigation", "authors": [], "abstract": "Cybercrime and the market for cyber-related compromises are becoming\nattractive revenue sources for state-sponsored actors, cybercriminals and\ntechnical individuals affected by financial hardships. Due to burgeoning\ncybercrime on new technological frontiers, efforts have been made to assist\ndigital forensic investigators (DFI) and law enforcement agencies (LEA) in\ntheir investigative efforts.\n  Forensic tool innovations and ontology developments, such as the Unified\nCyber Ontology (UCO) and Cyber-investigation Analysis Standard Expression\n(CASE), have been proposed to assist DFI and LEA. Although these tools and\nontologies are useful, they lack extensive information sharing and tool\ninteroperability features, and the ontologies lack the latest Smart City\nInfrastructure (SCI) context that was proposed.\n  To mitigate the weaknesses in both solutions and to ensure a safer\ncyber-physical environment for all, we propose the Smart City Ontological\nParadigm Expression (SCOPE), an expansion profile of the UCO and CASE ontology\nthat implements SCI threat models, SCI digital forensic evidence, attack\ntechniques, patterns and classifications from MITRE.\n  We showcase how SCOPE could present complex data such as SCI-specific\nthreats, cybercrime, investigation data and incident handling workflows via an\nincident scenario modelled after publicly reported real-world incidents\nattributed to Advanced Persistent Threat (APT) groups. We also make SCOPE\navailable to the community so that threats, digital evidence and cybercrime in\nemerging trends such as SCI can be identified, represented, and shared\ncollaboratively.", "categories": "cs.CR", "created": "2024-08-04", "doi": null, "arxiv_id": "2408.02023"}
{"title": "Faster Diffusion Action Segmentation", "authors": [], "abstract": "Temporal Action Segmentation (TAS) is an essential task in video analysis,\naiming to segment and classify continuous frames into distinct action segments.\nHowever, the ambiguous boundaries between actions pose a significant challenge\nfor high-precision segmentation. Recent advances in diffusion models have\ndemonstrated substantial success in TAS tasks due to their stable training\nprocess and high-quality generation capabilities. However, the heavy sampling\nsteps required by diffusion models pose a substantial computational burden,\nlimiting their practicality in real-time applications. Additionally, most\nrelated works utilize Transformer-based encoder architectures. Although these\narchitectures excel at capturing long-range dependencies, they incur high\ncomputational costs and face feature-smoothing issues when processing long\nvideo sequences. To address these challenges, we propose EffiDiffAct, an\nefficient and high-performance TAS algorithm. Specifically, we develop a\nlightweight temporal feature encoder that reduces computational overhead and\nmitigates the rank collapse phenomenon associated with traditional\nself-attention mechanisms. Furthermore, we introduce an adaptive skip strategy\nthat allows for dynamic adjustment of timestep lengths based on computed\nsimilarity metrics during inference, thereby further enhancing computational\nefficiency. Comprehensive experiments on the 50Salads, Breakfast, and GTEA\ndatasets demonstrated the effectiveness of the proposed algorithm.", "categories": "cs.CV", "created": "2024-08-04", "doi": null, "arxiv_id": "2408.02024"}
{"title": "Contrastive Learning-based Chaining-Cluster for Multilingual Voice-Face\n  Association", "authors": [], "abstract": "The innate correlation between a person's face and voice has recently emerged\nas a compelling area of study, especially within the context of multilingual\nenvironments. This paper introduces our novel solution to the Face-Voice\nAssociation in Multilingual Environments (FAME) 2024 challenge, focusing on a\ncontrastive learning-based chaining-cluster method to enhance face-voice\nassociation. This task involves the challenges of building biometric relations\nbetween auditory and visual modality cues and modelling the prosody\ninterdependence between different languages while addressing both intrinsic and\nextrinsic variability present in the data. To handle these non-trivial\nchallenges, our method employs supervised cross-contrastive (SCC) learning to\nestablish robust associations between voices and faces in multi-language\nscenarios. Following this, we have specifically designed a\nchaining-cluster-based post-processing step to mitigate the impact of outliers\noften found in unconstrained in the wild data. We conducted extensive\nexperiments to investigate the impact of language on face-voice association.\nThe overall results were evaluated on the FAME public evaluation platform,\nwhere we achieved 2nd place. The results demonstrate the superior performance\nof our method, and we validate the robustness and effectiveness of our proposed\napproach. Code is available at https://github.com/colaudiolab/FAME24_solution.", "categories": "cs.SD cs.AI eess.AS", "created": "2024-08-04", "doi": null, "arxiv_id": "2408.02025"}
{"title": "Multivariate Information Measures: A Copula-based Approach", "authors": [], "abstract": "Multivariate datasets are common in various real-world applications.\nRecently, copulas have received significant attention for modeling dependencies\namong random variables. A copula-based information measure is required to\nquantify the uncertainty inherent in these dependencies. This paper introduces\na multivariate variant of the cumulative copula entropy and explores its\nvarious properties, including bounds, stochastic orders, and\nconvergence-related results. Additionally, we define a cumulative copula\ninformation generating function and derive it for several well-known families\nof multivariate copulas. A fractional generalization of the multivariate\ncumulative copula entropy is also introduced and examined. We present a\nnon-parametric estimator of the cumulative copula entropy using empirical beta\ncopula. Furthermore, we propose a new distance measure between two copulas\nbased on the Kullback-Leibler divergence and discuss a goodness-of-fit test\nbased on this measure.", "categories": "stat.ME cs.IT math.IT", "created": "2024-08-04", "doi": null, "arxiv_id": "2408.02028"}
{"title": "Mining Path Association Rules in Large Property Graphs (with Appendix)", "authors": [], "abstract": "How can we mine frequent path regularities from a graph with edge labels and\nvertex attributes? The task of association rule mining successfully discovers\nregular patterns in item sets and substructures. Still, to our best knowledge,\nthis concept has not yet been extended to path patterns in large property\ngraphs. In this paper, we introduce the problem of path association rule mining\n(PARM). Applied to any \\emph{reachability path} between two vertices within a\nlarge graph, PARM discovers regular ways in which path patterns, identified by\nvertex attributes and edge labels, co-occur with each other. We develop an\nefficient and scalable algorithm PIONEER that exploits an anti-monotonicity\nproperty to effectively prune the search space. Further, we devise\napproximation techniques and employ parallelization to achieve scalable path\nassociation rule mining. Our experimental study using real-world graph data\nverifies the significance of path association rules and the efficiency of our\nsolutions.", "categories": "cs.DB cs.AI", "created": "2024-08-04", "doi": null, "arxiv_id": "2408.02029"}
{"title": "Self-Introspective Decoding: Alleviating Hallucinations for Large\n  Vision-Language Models", "authors": [], "abstract": "While Large Vision-Language Models (LVLMs) have rapidly advanced in recent\nyears, the prevalent issue known as the `hallucination' problem has emerged as\na significant bottleneck, hindering their real-world deployments. Existing\nmethods mitigate this issue mainly from two perspectives: One approach\nleverages extra knowledge like robust instruction tuning LVLMs with curated\ndatasets or employing auxiliary analysis networks, which inevitable incur\nadditional costs. Another approach, known as contrastive decoding, induces\nhallucinations by manually disturbing the vision or instruction raw inputs and\nmitigates them by contrasting the outputs of the disturbed and original LVLMs.\nHowever, these approaches rely on empirical holistic input disturbances and\ndouble the inference cost. To avoid these issues, we propose a simple yet\neffective method named Self-Introspective Decoding (SID). Our empirical\ninvestigation reveals that pretrained LVLMs can introspectively assess the\nimportance of vision tokens based on preceding vision and text (both\ninstruction and generated) tokens. We develop the Context and Text-aware Token\nSelection (CT2S) strategy, which preserves only unimportant vision tokens after\nearly layers of LVLMs to adaptively amplify text-informed hallucination during\nthe auto-regressive decoding. This approach ensures that multimodal knowledge\nabsorbed in the early layers induces multimodal contextual rather than aimless\nhallucinations. Subsequently, the original token logits subtract the amplified\nvision-and-text association hallucinations, guiding LVLMs decoding faithfully.\nExtensive experiments illustrate SID generates less-hallucination and\nhigher-quality texts across various metrics, without extra knowledge and much\nadditional computation burdens.", "categories": "cs.CV cs.AI", "created": "2024-08-04", "doi": null, "arxiv_id": "2408.02032"}
{"title": "Enhancing Human Action Recognition and Violence Detection Through Deep\n  Learning Audiovisual Fusion", "authors": [], "abstract": "This paper proposes a hybrid fusion-based deep learning approach based on two\ndifferent modalities, audio and video, to improve human activity recognition\nand violence detection in public places. To take advantage of audiovisual\nfusion, late fusion, intermediate fusion, and hybrid fusion-based deep learning\n(HFBDL) are used and compared. Since the objective is to detect and recognize\nhuman violence in public places, Real-life violence situation (RLVS) dataset is\nexpanded and used. Simulating results of HFBDL show 96.67\\% accuracy on\nvalidation data, which is more accurate than the other state-of-the-art methods\non this dataset. To showcase our model's ability in real-world scenarios,\nanother dataset of 54 sounded videos of both violent and non-violent situations\nwas recorded. The model could successfully detect 52 out of 54 videos\ncorrectly. The proposed method shows a promising performance on real scenarios.\nThus, it can be used for human action recognition and violence detection in\npublic places for security purposes.", "categories": "cs.CV cs.LG cs.MM eess.IV", "created": "2024-08-04", "doi": null, "arxiv_id": "2408.02033"}
{"title": "Robustness of Watermarking on Text-to-Image Diffusion Models", "authors": [], "abstract": "Watermarking has become one of promising techniques to not only aid in\nidentifying AI-generated images but also serve as a deterrent against the\nunethical use of these models. However, the robustness of watermarking\ntechniques has not been extensively studied recently. In this paper, we\ninvestigate the robustness of generative watermarking, which is created from\nthe integration of watermarking embedding and text-to-image generation\nprocessing in generative models, e.g., latent diffusion models. Specifically,\nwe propose three attacking methods, i.e., discriminator-based attacks, edge\nprediction-based attacks, and fine-tune-based attacks, under the scenario where\nthe watermark decoder is not accessible. The model is allowed to be fine-tuned\nto created AI agents with specific generative tasks for personalizing or\nspecializing. We found that generative watermarking methods are robust to\ndirect evasion attacks, like discriminator-based attacks, or manipulation based\non the edge information in edge prediction-based attacks but vulnerable to\nmalicious fine-tuning. Experimental results show that our fine-tune-based\nattacks can decrease the accuracy of the watermark detection to nearly\n$67.92\\%$. In addition, We conduct an ablation study on the length of\nfine-tuned messages, encoder/decoder's depth and structure to identify key\nfactors that impact the performance of fine-tune-based attacks.", "categories": "cs.CR", "created": "2024-08-04", "doi": null, "arxiv_id": "2408.02035"}
{"title": "LEGO: Self-Supervised Representation Learning for Scene Text Images", "authors": [], "abstract": "In recent years, significant progress has been made in scene text recognition\nby data-driven methods. However, due to the scarcity of annotated real-world\ndata, the training of these methods predominantly relies on synthetic data. The\ndistribution gap between synthetic and real data constrains the further\nperformance improvement of these methods in real-world applications. To tackle\nthis problem, a highly promising approach is to utilize massive amounts of\nunlabeled real data for self-supervised training, which has been widely proven\neffective in many NLP and CV tasks. Nevertheless, generic self-supervised\nmethods are unsuitable for scene text images due to their sequential nature. To\naddress this issue, we propose a Local Explicit and Global Order-aware\nself-supervised representation learning method (LEGO) that accounts for the\ncharacteristics of scene text images. Inspired by the human cognitive process\nof learning words, which involves spelling, reading, and writing, we propose\nthree novel pre-text tasks for LEGO to model sequential, semantic, and\nstructural features, respectively. The entire pre-training process is optimized\nby using a consistent Text Knowledge Codebook. Extensive experiments validate\nthat LEGO outperforms previous scene text self-supervised methods. The\nrecognizer incorporated with our pre-trained model achieves superior or\ncomparable performance compared to state-of-the-art scene text recognition\nmethods on six benchmarks. Furthermore, we demonstrate that LEGO can achieve\nsuperior performance in other text-related tasks.", "categories": "cs.CV", "created": "2024-08-04", "doi": null, "arxiv_id": "2408.02036"}
{"title": "Distributionally Robust Optimization for Computation Offloading in\n  Aerial Access Networks", "authors": [], "abstract": "With the rapid increment of multiple users for data offloading and\ncomputation, it is challenging to guarantee the quality of service (QoS) in\nremote areas. To deal with the challenge, it is promising to combine aerial\naccess networks (AANs) with multi-access edge computing (MEC) equipments to\nprovide computation services with high QoS. However, as for uncertain data\nsizes of tasks, it is intractable to optimize the offloading decisions and the\naerial resources. Hence, in this paper, we consider the AAN to provide MEC\nservices for uncertain tasks. Specifically, we construct the uncertainty sets\nbased on historical data to characterize the possible probability distribution\nof the uncertain tasks. Then, based on the constructed uncertainty sets, we\nformulate a distributionally robust optimization problem to minimize the system\ndelay. Next,we relax the problem and reformulate it into a linear programming\nproblem. Accordingly, we design a MEC-based distributionally robust latency\noptimization algorithm. Finally, simulation results reveal that the proposed\nalgorithm achieves a superior balance between reducing system latency and\nminimizing energy consumption, as compared to other benchmark mechanisms in the\nexisting literature.", "categories": "cs.NI", "created": "2024-08-04", "doi": null, "arxiv_id": "2408.02037"}
{"title": "Pixel-Level Domain Adaptation: A New Perspective for Enhancing Weakly\n  Supervised Semantic Segmentation", "authors": [], "abstract": "Recent attention has been devoted to the pursuit of learning semantic\nsegmentation models exclusively from image tags, a paradigm known as\nimage-level Weakly Supervised Semantic Segmentation (WSSS). Existing attempts\nadopt the Class Activation Maps (CAMs) as priors to mine object regions yet\nobserve the imbalanced activation issue, where only the most discriminative\nobject parts are located. In this paper, we argue that the distribution\ndiscrepancy between the discriminative and the non-discriminative parts of\nobjects prevents the model from producing complete and precise pseudo masks as\nground truths. For this purpose, we propose a Pixel-Level Domain Adaptation\n(PLDA) method to encourage the model in learning pixel-wise domain-invariant\nfeatures. Specifically, a multi-head domain classifier trained adversarially\nwith the feature extraction is introduced to promote the emergence of pixel\nfeatures that are invariant with respect to the shift between the source (i.e.,\nthe discriminative object parts) and the target (\\textit{i.e.}, the\nnon-discriminative object parts) domains. In addition, we come up with a\nConfident Pseudo-Supervision strategy to guarantee the discriminative ability\nof each pixel for the segmentation task, which serves as a complement to the\nintra-image domain adversarial training. Our method is conceptually simple,\nintuitive and can be easily integrated into existing WSSS methods. Taking\nseveral strong baseline models as instances, we experimentally demonstrate the\neffectiveness of our approach under a wide range of settings.", "categories": "cs.CV", "created": "2024-08-04", "doi": null, "arxiv_id": "2408.02039"}
{"title": "Deep Spectral Methods for Unsupervised Ultrasound Image Interpretation", "authors": [], "abstract": "Ultrasound imaging is challenging to interpret due to non-uniform\nintensities, low contrast, and inherent artifacts, necessitating extensive\ntraining for non-specialists. Advanced representation with clear tissue\nstructure separation could greatly assist clinicians in mapping underlying\nanatomy and distinguishing between tissue layers. Decomposing an image into\nsemantically meaningful segments is mainly achieved using supervised\nsegmentation algorithms. Unsupervised methods are beneficial, as acquiring\nlarge labeled datasets is difficult and costly, but despite their advantages,\nthey still need to be explored in ultrasound. This paper proposes a novel\nunsupervised deep learning strategy tailored to ultrasound to obtain easily\ninterpretable tissue separations. We integrate key concepts from unsupervised\ndeep spectral methods, which combine spectral graph theory with deep learning\nmethods. We utilize self-supervised transformer features for spectral\nclustering to generate meaningful segments based on ultrasound-specific metrics\nand shape and positional priors, ensuring semantic consistency across the\ndataset. We evaluate our unsupervised deep learning strategy on three\nultrasound datasets, showcasing qualitative results across anatomical contexts\nwithout label requirements. We also conduct a comparative analysis against\nother clustering algorithms to demonstrate superior segmentation performance,\nboundary preservation, and label consistency.", "categories": "cs.CV", "created": "2024-08-04", "doi": null, "arxiv_id": "2408.02043"}
{"title": "Fine-tuning multilingual language models in Twitter/X sentiment\n  analysis: a study on Eastern-European V4 languages", "authors": [], "abstract": "The aspect-based sentiment analysis (ABSA) is a standard NLP task with\nnumerous approaches and benchmarks, where large language models (LLM) represent\nthe current state-of-the-art. We focus on ABSA subtasks based on Twitter/X data\nin underrepresented languages. On such narrow tasks, small tuned language\nmodels can often outperform universal large ones, providing available and cheap\nsolutions.\n  We fine-tune several LLMs (BERT, BERTweet, Llama2, Llama3, Mistral) for\nclassification of sentiment towards Russia and Ukraine in the context of the\nongoing military conflict. The training/testing dataset was obtained from the\nacademic API from Twitter/X during 2023, narrowed to the languages of the V4\ncountries (Czech Republic, Slovakia, Poland, Hungary). Then we measure their\nperformance under a variety of settings including translations, sentiment\ntargets, in-context learning and more, using GPT4 as a reference model. We\ndocument several interesting phenomena demonstrating, among others, that some\nmodels are much better fine-tunable on multilingual Twitter tasks than others,\nand that they can reach the SOTA level with a very small training set. Finally\nwe identify combinations of settings providing the best results.", "categories": "cs.CL cs.AI", "created": "2024-08-04", "doi": null, "arxiv_id": "2408.02044"}
{"title": "DNA-SE: Towards Deep Neural-Nets Assisted Semiparametric Estimation", "authors": [], "abstract": "Semiparametric statistics play a pivotal role in a wide range of domains,\nincluding but not limited to missing data, causal inference, and transfer\nlearning, to name a few. In many settings, semiparametric theory leads to\n(nearly) statistically optimal procedures that yet involve numerically solving\nFredholm integral equations of the second kind. Traditional numerical methods,\nsuch as polynomial or spline approximations, are difficult to scale to\nmulti-dimensional problems. Alternatively, statisticians may choose to\napproximate the original integral equations by ones with closed-form solutions,\nresulting in computationally more efficient, but statistically suboptimal or\neven incorrect procedures. To bridge this gap, we propose a novel framework by\nformulating the semiparametric estimation problem as a bi-level optimization\nproblem; and then we develop a scalable algorithm called Deep Neural-Nets\nAssisted Semiparametric Estimation (DNA-SE) by leveraging the universal\napproximation property of Deep Neural-Nets (DNN) to streamline semiparametric\nprocedures. Through extensive numerical experiments and a real data analysis,\nwe demonstrate the numerical and statistical advantages of $\\dnase$ over\ntraditional methods. To the best of our knowledge, we are the first to bring\nDNN into semiparametric statistics as a numerical solver of integral equations\nin our proposed general framework.", "categories": "stat.ML cs.LG", "created": "2024-08-04", "doi": null, "arxiv_id": "2408.02045"}
{"title": "Latency-Aware Resource Allocation for Mobile Edge Generation and\n  Computing via Deep Reinforcement Learning", "authors": [], "abstract": "Recently, the integration of mobile edge computing (MEC) and generative\nartificial intelligence (GAI) technology has given rise to a new area called\nmobile edge generation and computing (MEGC), which offers mobile users\nheterogeneous services such as task computing and content generation. In this\nletter, we investigate the joint communication, computation, and the AIGC\nresource allocation problem in an MEGC system. A latency minimization problem\nis first formulated to enhance the quality of service for mobile users. Due to\nthe strong coupling of the optimization variables, we propose a new deep\nreinforcement learning-based algorithm to solve it efficiently. Numerical\nresults demonstrate that the proposed algorithm can achieve lower latency than\ntwo baseline algorithms.", "categories": "eess.SY cs.AI cs.SY", "created": "2024-08-04", "doi": null, "arxiv_id": "2408.02047"}
{"title": "3D Single-object Tracking in Point Clouds with High Temporal Variation", "authors": [], "abstract": "The high temporal variation of the point clouds is the key challenge of 3D\nsingle-object tracking (3D SOT). Existing approaches rely on the assumption\nthat the shape variation of the point clouds and the motion of the objects\nacross neighboring frames are smooth, failing to cope with high temporal\nvariation data. In this paper, we present a novel framework for 3D SOT in point\nclouds with high temporal variation, called HVTrack. HVTrack proposes three\nnovel components to tackle the challenges in the high temporal variation\nscenario: 1) A Relative-Pose-Aware Memory module to handle temporal point cloud\nshape variations; 2) a Base-Expansion Feature Cross-Attention module to deal\nwith similar object distractions in expanded search areas; 3) a Contextual\nPoint Guided Self-Attention module for suppressing heavy background noise. We\nconstruct a dataset with high temporal variation (KITTI-HV) by setting\ndifferent frame intervals for sampling in the KITTI dataset. On the KITTI-HV\nwith 5 frame intervals, our HVTrack surpasses the state-of-the-art tracker\nCXTracker by 11.3%/15.7% in Success/Precision.", "categories": "cs.CV cs.AI", "created": "2024-08-04", "doi": null, "arxiv_id": "2408.02049"}
{"title": "EOL: Transductive Few-Shot Open-Set Recognition by Enhancing Outlier\n  Logits", "authors": [], "abstract": "In Few-Shot Learning (FSL), models are trained to recognise unseen objects\nfrom a query set, given a few labelled examples from a support set. In standard\nFSL, models are evaluated on query instances sampled from the same class\ndistribution of the support set. In this work, we explore the more nuanced and\npractical challenge of Open-Set Few-Shot Recognition (OSFSL). Unlike standard\nFSL, OSFSL incorporates unknown classes into the query set, thereby requiring\nthe model not only to classify known classes but also to identify outliers.\nBuilding on the groundwork laid by previous studies, we define a novel\ntransductive inference technique that leverages the InfoMax principle to\nexploit the unlabelled query set. We called our approach the Enhanced Outlier\nLogit (EOL) method. EOL refines class prototype representations through model\ncalibration, effectively balancing the inlier-outlier ratio. This calibration\nenhances pseudo-label accuracy for the query set and improves the optimisation\nobjective within the transductive inference process. We provide a comprehensive\nempirical evaluation demonstrating that EOL consistently surpasses traditional\nmethods, recording performance improvements ranging from approximately $+1.3%$\nto $+6.3%$ across a variety of classification and outlier detection metrics and\nbenchmarks, even in the presence of inlier-outlier imbalance.", "categories": "cs.CV cs.LG", "created": "2024-08-04", "doi": null, "arxiv_id": "2408.02052"}
{"title": "PanicleNeRF: low-cost, high-precision in-field phenotypingof rice\n  panicles with smartphone", "authors": [], "abstract": "The rice panicle traits significantly influence grain yield, making them a\nprimary target for rice phenotyping studies. However, most existing techniques\nare limited to controlled indoor environments and difficult to capture the rice\npanicle traits under natural growth conditions. Here, we developed PanicleNeRF,\na novel method that enables high-precision and low-cost reconstruction of rice\npanicle three-dimensional (3D) models in the field using smartphone. The\nproposed method combined the large model Segment Anything Model (SAM) and the\nsmall model You Only Look Once version 8 (YOLOv8) to achieve high-precision\nsegmentation of rice panicle images. The NeRF technique was then employed for\n3D reconstruction using the images with 2D segmentation. Finally, the resulting\npoint clouds are processed to successfully extract panicle traits. The results\nshow that PanicleNeRF effectively addressed the 2D image segmentation task,\nachieving a mean F1 Score of 86.9% and a mean Intersection over Union (IoU) of\n79.8%, with nearly double the boundary overlap (BO) performance compared to\nYOLOv8. As for point cloud quality, PanicleNeRF significantly outperformed\ntraditional SfM-MVS (structure-from-motion and multi-view stereo) methods, such\nas COLMAP and Metashape. The panicle length was then accurately extracted with\nthe rRMSE of 2.94% for indica and 1.75% for japonica rice. The panicle volume\nestimated from 3D point clouds strongly correlated with the grain number (R2 =\n0.85 for indica and 0.82 for japonica) and grain mass (0.80 for indica and 0.76\nfor japonica). This method provides a low-cost solution for high-throughput\nin-field phenotyping of rice panicles, accelerating the efficiency of rice\nbreeding.", "categories": "cs.CV", "created": "2024-08-04", "doi": null, "arxiv_id": "2408.02053"}
{"title": "Step Saver: Predicting Minimum Denoising Steps for Diffusion Model Image\n  Generation", "authors": [], "abstract": "In this paper, we introduce an innovative NLP model specifically fine-tuned\nto determine the minimal number of denoising steps required for any given text\nprompt. This advanced model serves as a real-time tool that recommends the\nideal denoise steps for generating high-quality images efficiently. It is\ndesigned to work seamlessly with the Diffusion model, ensuring that images are\nproduced with superior quality in the shortest possible time. Although our\nexplanation focuses on the DDIM scheduler, the methodology is adaptable and can\nbe applied to various other schedulers like Euler, Euler Ancestral, Heun, DPM2\nKarras, UniPC, and more. This model allows our customers to conserve costly\ncomputing resources by executing the fewest necessary denoising steps to\nachieve optimal quality in the produced images.", "categories": "cs.CV", "created": "2024-08-04", "doi": null, "arxiv_id": "2408.02054"}
{"title": "MedSyn: LLM-based Synthetic Medical Text Generation Framework", "authors": [], "abstract": "Generating synthetic text addresses the challenge of data availability in\nprivacy-sensitive domains such as healthcare. This study explores the\napplicability of synthetic data in real-world medical settings. We introduce\nMedSyn, a novel medical text generation framework that integrates large\nlanguage models with a Medical Knowledge Graph (MKG). We use MKG to sample\nprior medical information for the prompt and generate synthetic clinical notes\nwith GPT-4 and fine-tuned LLaMA models. We assess the benefit of synthetic data\nthrough application in the ICD code prediction task. Our research indicates\nthat synthetic data can increase the classification accuracy of vital and\nchallenging codes by up to 17.8% compared to settings without synthetic data.\nFurthermore, to provide new data for further research in the healthcare domain,\nwe present the largest open-source synthetic dataset of clinical notes for the\nRussian language, comprising over 41k samples covering 219 ICD-10 codes.", "categories": "cs.CL cs.LG", "created": "2024-08-04", "doi": null, "arxiv_id": "2408.02056"}
{"title": "A Demand-aware Networked System Using Telemetry and ML with ReactNET", "authors": [], "abstract": "Emerging network applications ranging from video streaming to\nvirtual/augmented reality need to provide stringent quality-of-service (QoS)\nguarantees in complex and dynamic environments with shared resources. A\npromising approach to meeting these requirements is to automate complex network\noperations and create self-adjusting networks. These networks should\nautomatically gather contextual information, analyze how to efficiently ensure\nQoS requirements, and adapt accordingly. This paper presents ReactNET, a\nself-adjusting networked system designed to achieve this vision by leveraging\nemerging network programmability and machine learning techniques.\nProgrammability empowers ReactNET by providing fine-grained telemetry\ninformation, while machine learning-based classification techniques enable the\nsystem to learn and adjust the network to changing conditions. Our preliminary\nimplementation of ReactNET in P4 and Python demonstrates its effectiveness in\nvideo streaming applications.", "categories": "cs.NI", "created": "2024-08-04", "doi": null, "arxiv_id": "2408.02057"}
{"title": "ParkingE2E: Camera-based End-to-end Parking Network, from Images to\n  Planning", "authors": [], "abstract": "Autonomous parking is a crucial task in the intelligent driving field.\nTraditional parking algorithms are usually implemented using rule-based\nschemes. However, these methods are less effective in complex parking scenarios\ndue to the intricate design of the algorithms. In contrast,\nneural-network-based methods tend to be more intuitive and versatile than the\nrule-based methods. By collecting a large number of expert parking trajectory\ndata and emulating human strategy via learning-based methods, the parking task\ncan be effectively addressed. In this paper, we employ imitation learning to\nperform end-to-end planning from RGB images to path planning by imitating human\ndriving trajectories. The proposed end-to-end approach utilizes a target query\nencoder to fuse images and target features, and a transformer-based decoder to\nautoregressively predict future waypoints. We conducted extensive experiments\nin real-world scenarios, and the results demonstrate that the proposed method\nachieved an average parking success rate of 87.8% across four different\nreal-world garages. Real-vehicle experiments further validate the feasibility\nand effectiveness of the method proposed in this paper.", "categories": "cs.CV cs.AI cs.RO", "created": "2024-08-04", "doi": null, "arxiv_id": "2408.02061"}
{"title": "A Multi-class Ride-hailing Service Subsidy System Utilizing Deep Causal\n  Networks", "authors": [], "abstract": "In the ride-hailing industry, subsidies are predominantly employed to\nincentivize consumers to place more orders, thereby fostering market growth.\nCausal inference techniques are employed to estimate the consumer elasticity\nwith different subsidy levels. However, the presence of confounding effects\nposes challenges in achieving an unbiased estimate of the uplift effect. We\nintroduce a consumer subsidizing system to capture relationships between\nsubsidy propensity and the treatment effect, which proves effective while\nmaintaining a lightweight online environment.", "categories": "cs.LG stat.ML", "created": "2024-08-04", "doi": null, "arxiv_id": "2408.02065"}
{"title": "PromptSAM+: Malware Detection based on Prompt Segment Anything Model", "authors": [], "abstract": "Machine learning and deep learning (ML/DL) have been extensively applied in\nmalware detection, and some existing methods demonstrate robust performance.\nHowever, several issues persist in the field of malware detection: (1) Existing\nwork often overemphasizes accuracy at the expense of practicality, rarely\nconsidering false positive and false negative rates as important metrics. (2)\nConsidering the evolution of malware, the performance of classifiers\nsignificantly declines over time, greatly reducing the practicality of malware\ndetectors. (3) Prior ML/DL-based efforts heavily rely on ample labeled data for\nmodel training, largely dependent on feature engineering or domain knowledge to\nbuild feature databases, making them vulnerable if correct labels are scarce.\nWith the development of computer vision, vision-based malware detection\ntechnology has also rapidly evolved. In this paper, we propose a visual malware\ngeneral enhancement classification framework, `PromptSAM+', based on a large\nvisual network segmentation model, the Prompt Segment Anything Model(named\nPromptSAM+). Our experimental results indicate that 'PromptSAM+' is effective\nand efficient in malware detection and classification, achieving high accuracy\nand low rates of false positives and negatives. The proposed method outperforms\nthe most advanced image-based malware detection technologies on several\ndatasets. 'PromptSAM+' can mitigate aging in existing image-based malware\nclassifiers, reducing the considerable manpower needed for labeling new malware\nsamples through active learning. We conducted experiments on datasets for both\nWindows and Android platforms, achieving favorable outcomes. Additionally, our\nablation experiments on several datasets demonstrate that our model identifies\neffective modules within the large visual network.", "categories": "cs.CR", "created": "2024-08-04", "doi": null, "arxiv_id": "2408.02066"}
{"title": "Why distinctiveness centrality is distinctive", "authors": [], "abstract": "This paper responds to a commentary by Neal (2024) regarding the\nDistinctiveness centrality metrics introduced by Fronzetti Colladon and Naldi\n(2020). Distinctiveness centrality offers a novel reinterpretation of degree\ncentrality, particularly emphasizing the significance of direct connections to\nloosely connected peers within (social) networks. This response paper presents\na more comprehensive analysis of the correlation between Distinctiveness and\nthe Beta and Gamma measures. All five distinctiveness measures are considered,\nas well as a more meaningful range of the {\\alpha} parameter and different\nnetwork topologies, distinguishing between weighted and unweighted networks.\nFindings indicate significant variability in correlations, supporting the\nviability of Distinctiveness as alternative or complementary metrics within\nsocial network analysis. Moreover, the paper presents computational complexity\nanalysis and simplified R code for practical implementation. Encouraging\ninitial findings suggest potential applications in diverse domains, inviting\nfurther exploration and comparative analyses.", "categories": "cs.SI physics.soc-ph", "created": "2024-08-04", "doi": null, "arxiv_id": "2408.02076"}
{"title": "LDFaceNet: Latent Diffusion-based Network for High-Fidelity Deepfake\n  Generation", "authors": [], "abstract": "Over the past decade, there has been tremendous progress in the domain of\nsynthetic media generation. This is mainly due to the powerful methods based on\ngenerative adversarial networks (GANs). Very recently, diffusion probabilistic\nmodels, which are inspired by non-equilibrium thermodynamics, have taken the\nspotlight. In the realm of image generation, diffusion models (DMs) have\nexhibited remarkable proficiency in producing both realistic and heterogeneous\nimagery through their stochastic sampling procedure. This paper proposes a\nnovel facial swapping module, termed as LDFaceNet (Latent Diffusion based Face\nSwapping Network), which is based on a guided latent diffusion model that\nutilizes facial segmentation and facial recognition modules for a conditioned\ndenoising process. The model employs a unique loss function to offer\ndirectional guidance to the diffusion process. Notably, LDFaceNet can\nincorporate supplementary facial guidance for desired outcomes without any\nretraining. To the best of our knowledge, this represents the first application\nof the latent diffusion model in the face-swapping task without prior training.\nThe results of this study demonstrate that the proposed method can generate\nextremely realistic and coherent images by leveraging the potential of the\ndiffusion model for facial swapping, thereby yielding superior visual outcomes\nand greater diversity.", "categories": "cs.CV", "created": "2024-08-04", "doi": null, "arxiv_id": "2408.02078"}
{"title": "Improving Neural Surface Reconstruction with Feature Priors from\n  Multi-View Image", "authors": [], "abstract": "Recent advancements in Neural Surface Reconstruction (NSR) have significantly\nimproved multi-view reconstruction when coupled with volume rendering. However,\nrelying solely on photometric consistency in image space falls short of\naddressing complexities posed by real-world data, including occlusions and\nnon-Lambertian surfaces. To tackle these challenges, we propose an\ninvestigation into feature-level consistent loss, aiming to harness valuable\nfeature priors from diverse pretext visual tasks and overcome current\nlimitations. It is crucial to note the existing gap in determining the most\neffective pretext visual task for enhancing NSR. In this study, we\ncomprehensively explore multi-view feature priors from seven pretext visual\ntasks, comprising thirteen methods. Our main goal is to strengthen NSR training\nby considering a wide range of possibilities. Additionally, we examine the\nimpact of varying feature resolutions and evaluate both pixel-wise and\npatch-wise consistent losses, providing insights into effective strategies for\nimproving NSR performance. By incorporating pre-trained representations from\nMVSFormer and QuadTree, our approach can generate variations of MVS-NeuS and\nMatch-NeuS, respectively. Our results, analyzed on DTU and EPFL datasets,\nreveal that feature priors from image matching and multi-view stereo outperform\nother pretext tasks. Moreover, we discover that extending patch-wise\nphotometric consistency to the feature level surpasses the performance of\npixel-wise approaches. These findings underscore the effectiveness of these\ntechniques in enhancing NSR outcomes.", "categories": "cs.CV", "created": "2024-08-04", "doi": null, "arxiv_id": "2408.02079"}
{"title": "Secure and Transparent Medical Record Management System Using Python and\n  Blockchain", "authors": [], "abstract": "In this paper, we propose a robust health record storage and management\nsystem built on blockchain technology to address the challenges faced by\ntraditional healthcare record systems. The primary advantage of employing\nblockchain in healthcare record management is its ability to provide a secure\nand decentralized platform. Unlike traditional centralized databases, where a\nsingle point of failure can compromise data integrity and security, blockchain\ndistributes data across a network of nodes, ensuring redundancy and resilience\nagainst cyber-attacks. This distributed nature of blockchain enhances data\nsecurity and privacy, crucial considerations when dealing with sensitive health\ninformation. Central to our proposed system is the utilization of smart\ncontracts, which are self-executing contracts with predefined rules and\nconditions. Smart contracts automate processes related to health record\nmanagement, such as data access, sharing, and updating, based on predefined\npermissions and protocols. This automation not only streamlines administrative\ntasks but also reduces the risk of human errors and ensures data accuracy and\nconsistency. Furthermore, our system prioritizes patient empowerment by\ngranting individuals complete control over their health records. Patients can\nsecurely access and manage their data using cryptographic keys, granting\npermission to healthcare providers or other authorized entities as needed.\nOverall, our proposed health record storage and management system on the\nblockchain offer significant advantages over traditional systems, including\nenhanced security, data integrity, transparency, and patient control. By\nleveraging blockchain technology and smart contracts, healthcare organizations\ncan revolutionize their record management practices, and maintaining secure\necosystems.", "categories": "cs.CR", "created": "2024-08-04", "doi": null, "arxiv_id": "2408.02081"}
{"title": "Constructing Mechanical Design Agent Based on Large Language Models", "authors": [], "abstract": "Since ancient times, mechanical design aids have been developed to assist\nhuman users, aimed at improving the efficiency and effectiveness of design.\nHowever, even with the widespread use of contemporary Computer-Aided Design\n(CAD) systems, there are still high learning costs, repetitive work, and other\nchallenges. In recent years, the rise of Large Language Models (LLMs) has\nintroduced new productivity opportunities to the field of mechanical design.\nYet, it remains unrealistic to rely on LLMs alone to complete mechanical design\ntasks directly. Through a series of explorations, we propose a method for\nconstructing a comprehensive Mechanical Design Agent (MDA) by guiding LLM\nlearning. To verify the validity of our proposed method, we conducted a series\nof experiments and presented relevant cases.", "categories": "cs.CE", "created": "2024-08-04", "doi": null, "arxiv_id": "2408.02087"}
{"title": "KAN-RCBEVDepth: A multi-modal fusion algorithm in object detection for\n  autonomous driving", "authors": [], "abstract": "Accurate 3D object detection in autonomous driving is critical yet\nchallenging due to occlusions, varying object scales, and complex urban\nenvironments. This paper introduces the RCBEV-KAN algorithm, a pioneering\nmethod designed to enhance 3D object detection by fusing multimodal sensor data\nfrom cameras, LiDAR, and millimeter-wave radar. Our innovative Bird's Eye View\n(BEV)-based approach, utilizing a Transformer architecture, significantly\nboosts detection precision and efficiency by seamlessly integrating diverse\ndata sources, improving spatial relationship handling, and optimizing\ncomputational processes. Experimental results show that the RCBEV-KAN model\ndemonstrates superior performance across most detection categories, achieving\nhigher Mean Distance AP (0.389 vs. 0.316, a 23% improvement), better ND Score\n(0.484 vs. 0.415, a 17% improvement), and faster Evaluation Time (71.28s, 8%\nfaster). These results indicate that RCBEV-KAN is more accurate, reliable, and\nefficient, making it ideal for dynamic and challenging autonomous driving\nenvironments.", "categories": "cs.CV cs.AI", "created": "2024-08-04", "doi": null, "arxiv_id": "2408.02088"}
{"title": "First Order Stochastic Optimization with Oblivious Noise", "authors": [], "abstract": "We initiate the study of stochastic optimization with oblivious noise,\nbroadly generalizing the standard heavy-tailed noise setup. In our setting, in\naddition to random observation noise, the stochastic gradient may be subject to\nindependent oblivious noise, which may not have bounded moments and is not\nnecessarily centered. Specifically, we assume access to a noisy oracle for the\nstochastic gradient of $f$ at $x$, which returns a vector $\\nabla f(\\gamma, x)\n+ \\xi$, where $\\gamma$ is the bounded variance observation noise and $\\xi$ is\nthe oblivious noise that is independent of $\\gamma$ and $x$. The only\nassumption we make on the oblivious noise $\\xi$ is that $\\mathbf{Pr}[\\xi = 0]\n\\ge \\alpha$ for some $\\alpha \\in (0, 1)$. In this setting, it is not\ninformation-theoretically possible to recover a single solution close to the\ntarget when the fraction of inliers $\\alpha$ is less than $1/2$. Our main\nresult is an efficient list-decodable learner that recovers a small list of\ncandidates, at least one of which is close to the true solution. On the other\nhand, if $\\alpha = 1-\\epsilon$, where $0< \\epsilon < 1/2$ is sufficiently small\nconstant, the algorithm recovers a single solution. Along the way, we develop a\nrejection-sampling-based algorithm to perform noisy location estimation, which\nmay be of independent interest.", "categories": "cs.DS", "created": "2024-08-04", "doi": null, "arxiv_id": "2408.02090"}
{"title": "Past Movements-Guided Motion Representation Learning for Human Motion\n  Prediction", "authors": [], "abstract": "Human motion prediction based on 3D skeleton is a significant challenge in\ncomputer vision, primarily focusing on the effective representation of motion.\nIn this paper, we propose a self-supervised learning framework designed to\nenhance motion representation. This framework consists of two stages: first,\nthe network is pretrained through the self-reconstruction of past sequences,\nand the guided reconstruction of future sequences based on past movements. We\ndesign a velocity-based mask strategy to focus on the joints with large-scale\nmoving. Subsequently, the pretrained network undergoes finetuning for specific\ntasks. Self-reconstruction, guided by patterns of past motion, substantially\nimproves the model's ability to represent the spatiotemporal relationships\namong joints but also captures the latent relationships between past and future\nsequences. This capability is crucial for motion prediction tasks that solely\ndepend on historical motion data. By employing this straightforward yet\neffective training paradigm, our method outperforms existing\n\\textit{state-of-the-art} methods, reducing the average prediction errors by\n8.8\\% across Human3.6M, 3DPW, and AMASS datasets. The code is available at\nhttps://github.com/JunyuShi02/PMG-MRL.", "categories": "cs.CV", "created": "2024-08-04", "doi": null, "arxiv_id": "2408.02091"}
{"title": "SEAtech: Deception Techniques in Social Engineering Attacks: An Analysis\n  of Emerging Trends and Countermeasures", "authors": [], "abstract": "Social Engineering is the act of manipulating individuals to perform actions\nor reveal information. Social engineering tactics are widely recognized as a\nsignificant risk to information security. The increasing digital environment\nhas increased the prevalence of social engineering attacks, bringing huge\nthreats to both people and organizations. This paper explores current deception\ntechniques used during social engineering attacks to understand emerging trends\nand discuss effective countermeasures. It is always a good idea to have\nknowledge of counter measures and risks from these increasing cyber threats. We\nhave also explored the types of deception attacks and role of social\nengineering in Advanced Persistent Threats. Today major concern for\ncybersecurity and other web related attacks is due to social engineering\nattacks that is also the driving force of increasing cybercrimes worldwide. By\nuncovering emerging trends and analyzing the psychological underpinnings of\nthese attacks this paper highlights the known deception techniques, emerging\ntrends and counter measures of social engineering attacks.", "categories": "cs.SI", "created": "2024-08-04", "doi": null, "arxiv_id": "2408.02092"}
{"title": "Secure Semantic Communications: From Perspective of Physical Layer\n  Security", "authors": [], "abstract": "Semantic communications have been envisioned as a potential technique that\ngoes beyond Shannon paradigm. Unlike modern communications that provide\nbit-level security, the eaves-dropping of semantic communications poses a\nsignificant risk of potentially exposing intention of legitimate user. To\naddress this challenge, a novel deep neural network (DNN) enabled secure\nsemantic communication (DeepSSC) system is developed by capitalizing on\nphysical layer security. To balance the tradeoff between security and\nreliability, a two-phase training method for DNNs is devised. Particularly,\nPhase I aims at semantic recovery of legitimate user, while Phase II attempts\nto minimize the leakage of semantic information to eavesdroppers. The loss\nfunctions of DeepSSC in Phases I and II are respectively designed according to\nShannon capacity and secure channel capacity, which are approximated with\nvariational inference. Moreover, we define the metric of secure bilingual\nevaluation understudy (S-BLEU) to assess the security of semantic\ncommunications. Finally, simulation results demonstrate that DeepSSC achieves a\nsignificant boost to semantic security particularly in high signal-to-noise\nratio regime, despite a minor degradation of reliability.", "categories": "cs.IT eess.SP math.IT", "created": "2024-08-04", "doi": null, "arxiv_id": "2408.02095"}
{"title": "View-consistent Object Removal in Radiance Fields", "authors": [], "abstract": "Radiance Fields (RFs) have emerged as a crucial technology for 3D scene\nrepresentation, enabling the synthesis of novel views with remarkable realism.\nHowever, as RFs become more widely used, the need for effective editing\ntechniques that maintain coherence across different perspectives becomes\nevident. Current methods primarily depend on per-frame 2D image inpainting,\nwhich often fails to maintain consistency across views, thus compromising the\nrealism of edited RF scenes. In this work, we introduce a novel RF editing\npipeline that significantly enhances consistency by requiring the inpainting of\nonly a single reference image. This image is then projected across multiple\nviews using a depth-based approach, effectively reducing the inconsistencies\nobserved with per-frame inpainting. However, projections typically assume\nphotometric consistency across views, which is often impractical in real-world\nsettings. To accommodate realistic variations in lighting and viewpoint, our\npipeline adjusts the appearance of the projected views by generating multiple\ndirectional variants of the inpainted image, thereby adapting to different\nphotometric conditions. Additionally, we present an effective and robust\nmulti-view object segmentation approach as a valuable byproduct of our\npipeline. Extensive experiments demonstrate that our method significantly\nsurpasses existing frameworks in maintaining content consistency across views\nand enhancing visual quality. More results are available at\nhttps://vulab-ai.github.io/View-consistent_Object_Removal_in_Radiance_Fields.", "categories": "cs.CV", "created": "2024-08-04", "doi": null, "arxiv_id": "2408.02100"}
{"title": "Effective Demonstration Annotation for In-Context Learning via Language\n  Model-Based Determinantal Point Process", "authors": [], "abstract": "In-context learning (ICL) is a few-shot learning paradigm that involves\nlearning mappings through input-output pairs and appropriately applying them to\nnew instances. Despite the remarkable ICL capabilities demonstrated by Large\nLanguage Models (LLMs), existing works are highly dependent on large-scale\nlabeled support sets, not always feasible in practical scenarios. To refine\nthis approach, we focus primarily on an innovative selective annotation\nmechanism, which precedes the standard demonstration retrieval. We introduce\nthe Language Model-based Determinant Point Process (LM-DPP) that simultaneously\nconsiders the uncertainty and diversity of unlabeled instances for optimal\nselection. Consequently, this yields a subset for annotation that strikes a\ntrade-off between the two factors. We apply LM-DPP to various language models,\nincluding GPT-J, LlaMA, and GPT-3. Experimental results on 9 NLU and 2\nGeneration datasets demonstrate that LM-DPP can effectively select canonical\nexamples. Further analysis reveals that LLMs benefit most significantly from\nsubsets that are both low uncertainty and high diversity.", "categories": "cs.CL", "created": "2024-08-04", "doi": null, "arxiv_id": "2408.02103"}
{"title": "AvatarPose: Avatar-guided 3D Pose Estimation of Close Human Interaction\n  from Sparse Multi-view Videos", "authors": [], "abstract": "Despite progress in human motion capture, existing multi-view methods often\nface challenges in estimating the 3D pose and shape of multiple closely\ninteracting people. This difficulty arises from reliance on accurate 2D joint\nestimations, which are hard to obtain due to occlusions and body contact when\npeople are in close interaction. To address this, we propose a novel method\nleveraging the personalized implicit neural avatar of each individual as a\nprior, which significantly improves the robustness and precision of this\nchallenging pose estimation task. Concretely, the avatars are efficiently\nreconstructed via layered volume rendering from sparse multi-view videos. The\nreconstructed avatar prior allows for the direct optimization of 3D poses based\non color and silhouette rendering loss, bypassing the issues associated with\nnoisy 2D detections. To handle interpenetration, we propose a collision loss on\nthe overlapping shape regions of avatars to add penetration constraints.\nMoreover, both 3D poses and avatars are optimized in an alternating manner. Our\nexperimental results demonstrate state-of-the-art performance on several public\ndatasets.", "categories": "cs.CV", "created": "2024-08-04", "doi": null, "arxiv_id": "2408.02110"}
{"title": "Understanding Deep Learning via Notions of Rank", "authors": [], "abstract": "Despite the extreme popularity of deep learning in science and industry, its\nformal understanding is limited. This thesis puts forth notions of rank as key\nfor developing a theory of deep learning, focusing on the fundamental aspects\nof generalization and expressiveness. In particular, we establish that\ngradient-based training can induce an implicit regularization towards low rank\nfor several neural network architectures, and demonstrate empirically that this\nphenomenon may facilitate an explanation of generalization over natural data\n(e.g., audio, images, and text). Then, we characterize the ability of graph\nneural networks to model interactions via a notion of rank, which is commonly\nused for quantifying entanglement in quantum physics. A central tool underlying\nthese results is a connection between neural networks and tensor\nfactorizations. Practical implications of our theory for designing explicit\nregularization schemes and data preprocessing algorithms are presented.", "categories": "cs.LG cs.AI cs.NE stat.ML", "created": "2024-08-04", "doi": null, "arxiv_id": "2408.02111"}
{"title": "An Abstraction-Preserving Block Matrix Implementation in Maple", "authors": [], "abstract": "A Maple implementation of partitioned matrices is described. A recursive\nblock data structure is used, with all operations preserving the block\nabstraction. These include constructor functions, ring operations such as\naddition and product, and inversion. The package is demonstrated by calculating\nthe PLU factorization of a block matrix.", "categories": "cs.SC", "created": "2024-08-04", "doi": null, "arxiv_id": "2408.02112"}
{"title": "Recent Advances in Multi-Choice Machine Reading Comprehension: A Survey\n  on Methods and Datasets", "authors": [], "abstract": "This paper provides a thorough examination of recent developments in the\nfield of multi-choice Machine Reading Comprehension (MRC). Focused on benchmark\ndatasets, methodologies, challenges, and future trajectories, our goal is to\noffer researchers a comprehensive overview of the current landscape in\nmulti-choice MRC. The analysis delves into 30 existing cloze-style and\nmultiple-choice MRC benchmark datasets, employing a refined classification\nmethod based on attributes such as corpus style, domain, complexity, context\nstyle, question style, and answer style. This classification system enhances\nour understanding of each dataset's diverse attributes and categorizes them\nbased on their complexity. Furthermore, the paper categorizes recent\nmethodologies into Fine-tuned and Prompt-tuned methods. Fine-tuned methods\ninvolve adapting pre-trained language models (PLMs) to a specific task through\nretraining on domain-specific datasets, while prompt-tuned methods use prompts\nto guide PLM response generation, presenting potential applications in\nzero-shot or few-shot learning scenarios. By contributing to ongoing\ndiscussions, inspiring future research directions, and fostering innovations,\nthis paper aims to propel multi-choice MRC towards new frontiers of\nachievement.", "categories": "cs.CL cs.LG", "created": "2024-08-04", "doi": null, "arxiv_id": "2408.02114"}
{"title": "Assessing the XDC Network: A Comprehensive Evaluation of its qualitative\n  and technical aspects", "authors": [], "abstract": "This research provides a thorough assessment of the XDC Network, a delegated\nproof of stake (XDPoS) consensus-based blockchain technology, across its\ntechnical, security, and business dimensions. The study evaluates the network's\ndecentralization, scalability, and security features, including its Nakamoto\ncoefficient, validator participation, and client distribution. Additionally, it\nexamines the developer ecosystem, including GitHub metrics, and business\naspects such as transaction costs and predictability. The findings of this\nresearch will provide valuable insights into the strengths and weaknesses of\nthe XDC Network, informing stakeholders and decision-makers about its\nsuitability for various use cases, particularly in trade finance, asset\ntokenization, and enterprise blockchain solutions.", "categories": "cs.CR", "created": "2024-08-04", "doi": null, "arxiv_id": "2408.02115"}
{"title": "Value-Based Rationales Improve Social Experience: A Multiagent\n  Simulation Study", "authors": [], "abstract": "We propose Exanna, a framework to realize agents that incorporate values in\ndecision making. An Exannaagent considers the values of itself and others when\nproviding rationales for its actions and evaluating the rationales provided by\nothers. Via multiagent simulation, we demonstrate that considering values in\ndecision making and producing rationales, especially for norm-deviating\nactions, leads to (1) higher conflict resolution, (2) better social experience,\n(3) higher privacy, and (4) higher flexibility.", "categories": "cs.MA cs.AI cs.LG", "created": "2024-08-04", "doi": null, "arxiv_id": "2408.02117"}
{"title": "FovEx: Human-inspired Explanations for Vision Transformers and\n  Convolutional Neural Networks", "authors": [], "abstract": "Explainability in artificial intelligence (XAI) remains a crucial aspect for\nfostering trust and understanding in machine learning models. Current visual\nexplanation techniques, such as gradient-based or class-activation-based\nmethods, often exhibit a strong dependence on specific model architectures.\nConversely, perturbation-based methods, despite being model-agnostic, are\ncomputationally expensive as they require evaluating models on a large number\nof forward passes. In this work, we introduce Foveation-based Explanations\n(FovEx), a novel XAI method inspired by human vision. FovEx seamlessly\nintegrates biologically inspired perturbations by iteratively creating foveated\nrenderings of the image and combines them with gradient-based visual\nexplorations to determine locations of interest efficiently. These locations\nare selected to maximize the performance of the model to be explained with\nrespect to the downstream task and then combined to generate an attribution\nmap. We provide a thorough evaluation with qualitative and quantitative\nassessments on established benchmarks. Our method achieves state-of-the-art\nperformance on both transformers (on 4 out of 5 metrics) and convolutional\nmodels (on 3 out of 5 metrics), demonstrating its versatility among various\narchitectures. Furthermore, we show the alignment between the explanation map\nproduced by FovEx and human gaze patterns (+14\\% in NSS compared to RISE,\n+203\\% in NSS compared to GradCAM). This comparison enhances our confidence in\nFovEx's ability to close the interpretation gap between humans and machines.", "categories": "cs.CV cs.LG", "created": "2024-08-04", "doi": null, "arxiv_id": "2408.02123"}
{"title": "Abstraction in Neural Networks", "authors": [], "abstract": "We show how brain networks, modeled as Spiking Neural Networks, can be viewed\nat different levels of abstraction. Lower levels include complications such as\nfailures of neurons and edges. Higher levels are more abstract, making\nsimplifying assumptions to avoid these complications. We show precise\nrelationships between executions of networks at different levels, which enables\nus to understand the behavior of lower-level networks in terms of the behavior\nof higher-level networks.\n  We express our results using two abstract networks, A1 and A2, one to express\nfiring guarantees and the other to express non-firing guarantees, and one\ndetailed network D. The abstract networks contain reliable neurons and edges,\nwhereas the detailed network has neurons and edges that may fail, subject to\nsome constraints. Here we consider just initial stopping failures. To define\nthese networks, we begin with abstract network A1 and modify it systematically\nto obtain the other two networks. To obtain A2, we simply lower the firing\nthresholds of the neurons. To obtain D, we introduce failures of neurons and\nedges, and incorporate redundancy in the neurons and edges in order to\ncompensate for the failures. We also define corresponding inputs for the\nnetworks, and corresponding executions of the networks.\n  We prove two main theorems, one relating corresponding executions of A1 and D\nand the other relating corresponding executions of A2 and D. Together, these\ngive both firing and non-firing guarantees for the detailed network D. We also\ngive a third theorem, relating the effects of D on an external reliable\nactuator neuron to the effects of the abstract networks on the same actuator\nneuron.", "categories": "cs.NE cs.DS", "created": "2024-08-04", "doi": null, "arxiv_id": "2408.02125"}
{"title": "Automatic Platform Configuration and Software Integration for\n  Software-Defined Vehicles", "authors": [], "abstract": "In the automotive industry, platform configuration and software integration\nare mostly manual tasks performed during the development phase, requiring\nconsideration of various safety and non-safety requirements. This manual\nprocess often leads to prolonged development cycles and provides limited\nflexibility. This paper introduces a novel approach to automate platform\nconfiguration and software integration for software-defined vehicles (SDVs),\nshifting these activities from the development phase to runtime. Our approach\nfeatures an integration manager that combines model-based methods and\nvirtualization technologies to generate and execute deployment plans. By\nleveraging model-based systems engineering (MBSE), our method automatically\ngenerates platform configuration and software integration plans, which are then\nconverted into deployment-ready formats using code generation techniques.\nUtilizing virtualization and container orchestration technologies, the proposed\nsystem enables dynamic and flexible resource allocation while ensuring\ncompliance with safety requirements. Communication between the development and\nruntime platforms is facilitated via a REST API. A proof of concept was\nimplemented on a simulated SDV platform with the Intel Whiskey Lake Board. This\ndemonstration showcases the integration manager on an SDV with a central\ncomputer, highlighting the potential to shorten development cycles and adapt to\ndiverse vehicle configurations.", "categories": "cs.SE", "created": "2024-08-04", "doi": null, "arxiv_id": "2408.02127"}
{"title": "Table Transformers for Imputing Textual Attributes", "authors": [], "abstract": "Missing data in tabular dataset is a common issue as the performance of\ndownstream tasks usually depends on the completeness of the training dataset.\nPrevious missing data imputation methods focus on numeric and categorical\ncolumns, but we propose a novel end-to-end approach called Table Transformers\nfor Imputing Textual Attributes (TTITA) based on the transformer to impute\nunstructured textual columns using other columns in the table. We conduct\nextensive experiments on two Amazon Reviews datasets, and our approach shows\ncompetitive performance outperforming baseline models such as recurrent neural\nnetworks and Llama2. The performance improvement is more significant when the\ntarget sequence has a longer length. Additionally, we incorporated multi-task\nlearning to simultaneously impute for heterogeneous columns, boosting the\nperformance for text imputation. We also qualitatively compare with ChatGPT for\nrealistic applications.", "categories": "cs.CL", "created": "2024-08-04", "doi": null, "arxiv_id": "2408.02128"}
{"title": "OntoForms: User interface structure from a domain ontology", "authors": [], "abstract": "This paper presents a software component that generates a user interface\nstructure for populating a domain ontology. The core of this work is an\nalgorithm that takes an ontology and returns a structure describing the user\ninterface. The component also provides functions for populating the ontology\nand editing existing individuals. Unlike previous approaches, this method can\nbe implemented without any configuration. Additionally, it offers an\neasy-to-use configuration mechanism that allows irrelevant classes to be hidden\nand automatically populated. What distinguishes this work is that, instead of\nexploring the ontology using syntactic methods or queries, our algorithm\nemploys services that implement description logic inference mechanisms. This\nwork illustrates the proposed approach using the well-known wine ontology.", "categories": "cs.SE", "created": "2024-08-04", "doi": null, "arxiv_id": "2408.02130"}
{"title": "Model Hijacking Attack in Federated Learning", "authors": [], "abstract": "Machine learning (ML), driven by prominent paradigms such as centralized and\nfederated learning, has made significant progress in various critical\napplications ranging from autonomous driving to face recognition. However, its\nremarkable success has been accompanied by various attacks. Recently, the model\nhijacking attack has shown that ML models can be hijacked to execute tasks\ndifferent from their original tasks, which increases both accountability and\nparasitic computational risks. Nevertheless, thus far, this attack has only\nfocused on centralized learning. In this work, we broaden the scope of this\nattack to the federated learning domain, where multiple clients collaboratively\ntrain a global model without sharing their data. Specifically, we present\nHijackFL, the first-of-its-kind hijacking attack against the global model in\nfederated learning. The adversary aims to force the global model to perform a\ndifferent task (called hijacking task) from its original task without the\nserver or benign client noticing. To accomplish this, unlike existing methods\nthat use data poisoning to modify the target model's parameters, HijackFL\nsearches for pixel-level perturbations based on their local model (without\nmodifications) to align hijacking samples with the original ones in the feature\nspace. When performing the hijacking task, the adversary applies these cloaks\nto the hijacking samples, compelling the global model to identify them as\noriginal samples and predict them accordingly. We conduct extensive experiments\non four benchmark datasets and three popular models. Empirical results\ndemonstrate that its attack performance outperforms baselines. We further\ninvestigate the factors that affect its performance and discuss possible\ndefenses to mitigate its impact.", "categories": "cs.CR cs.LG", "created": "2024-08-04", "doi": null, "arxiv_id": "2408.02131"}
{"title": "Decide: Knowledge-Based Version Incompatibility Detection in Deep\n  Learning Stacks", "authors": [], "abstract": "Version incompatibility issues are prevalent when reusing or reproducing deep\nlearning (DL) models and applications. Compared with official API\ndocumentation, which is often incomplete or out-of-date, Stack Overflow (SO)\ndiscussions possess a wealth of version knowledge that has not been explored by\nprevious approaches. To bridge this gap, we present Decide, a web-based\nvisualization of a knowledge graph that contains 2,376 version knowledge\nextracted from SO discussions. As an interactive tool, Decide allows users to\neasily check whether two libraries are compatible and explore compatibility\nknowledge of certain DL stack components with or without the version specified.\nA video demonstrating the usage of Decide is available at\nhttps://youtu.be/wqPxF2ZaZo0.", "categories": "cs.SE", "created": "2024-08-04", "doi": "10.1145/3663529.3663796", "arxiv_id": "2408.02133"}
{"title": "A First Look at Chebyshev-Sobolev Series for Digital Ink", "authors": [], "abstract": "Considering digital ink as plane curves provides a valuable framework for\nvarious applications, including signature verification, note-taking, and\nmathematical handwriting recognition. These plane curves can be obtained as\nparameterized pairs of approximating truncated series (x(s), y(s)) determined\nby sampled points. Earlier work has found that representing these truncated\nseries (polynomials) in a Legendre or Legendre-Sobolev basis has a number of\ndesirable properties. These include compact data representation, meaningful\nclustering of like symbols in the vector space of polynomial coefficients,\nlinear separability of classes in this space, and highly efficient calculation\nof variation between curves. In this work, we take a first step at examining\nthe use of Chebyshev-Sobolev series for symbol recognition. The early\nindication is that this representation may be superior to Legendre-Sobolev\nrepresentation for some purposes.", "categories": "cs.CV", "created": "2024-08-04", "doi": null, "arxiv_id": "2408.02135"}
{"title": "Extra Throughput versus Days Lost in load-shifting V2G services:\n  Influence of dominant degradation mechanism", "authors": [], "abstract": "Electric vehicle (EV) batteries are often underutilized. Vehicle-to-grid\n(V2G) services can tap into this unused potential, but increased battery usage\nmay lead to more degradation and shorter battery life. This paper substantiates\nthe advantages of providing load-shifting V2G services when the battery is\naging, primarily due to calendar aging mechanisms (active degradation\nmechanisms while the battery is not used). After parameterizing a physics-based\ndigital-twin for three different dominant degradation patterns within the same\nchemistry (NMC), we introduce a novel metric for evaluating the benefit and\nassociated harm of V2G services: \\textit{throughput gained versus days lost\n(TvD)} and show its strong relationship to the ratio of loss of lithium\ninventory (LLI) due to calendar aging to the total LLI\n($\\text{LLI}_\\text{Cal}/\\text{LLI}$). Our results that focus systematically on\ndegradation mechanisms via lifetime simulation of digital-twins significantly\nexpand prior work that was primarily concentrating on quantifying and reducing\nthe degradation of specific cells by probing their usage and charging patterns.\nExamining various cell chemistries and conditions enables us to take a broader\nview and determine whether a particular battery pack is appropriate for\nload-shifting (V2G) services. Our research demonstrates that the decision \"to\nV2G or not to V2G\" can be made by merely estimating the portion of capacity\ndeterioration caused by calendar aging. Specifically, TvD is primarily\ninfluenced by the chemistry of cells and the environmental temperature where\nthe car is parked, while the usage intensity and charging patterns of EVs play\na lesser role.", "categories": "eess.SY cs.SY", "created": "2024-08-04", "doi": null, "arxiv_id": "2408.02139"}
{"title": "VidModEx: Interpretable and Efficient Black Box Model Extraction for\n  High-Dimensional Spaces", "authors": [], "abstract": "In the domain of black-box model extraction, conventional methods reliant on\nsoft labels or surrogate datasets struggle with scaling to high-dimensional\ninput spaces and managing the complexity of an extensive array of interrelated\nclasses. In this work, we present a novel approach that utilizes SHAP (SHapley\nAdditive exPlanations) to enhance synthetic data generation. SHAP quantifies\nthe individual contributions of each input feature towards the victim model's\noutput, facilitating the optimization of an energy-based GAN towards a\ndesirable output. This method significantly boosts performance, achieving a\n16.45% increase in the accuracy of image classification models and extending to\nvideo classification models with an average improvement of 26.11% and a maximum\nof 33.36% on challenging datasets such as UCF11, UCF101, Kinetics 400, Kinetics\n600, and Something-Something V2. We further demonstrate the effectiveness and\npractical utility of our method under various scenarios, including the\navailability of top-k prediction probabilities, top-k prediction labels, and\ntop-1 labels.", "categories": "cs.CV cs.AI cs.LG", "created": "2024-08-04", "doi": null, "arxiv_id": "2408.02140"}
{"title": "An efficient strategy for path planning with a tethered marsupial\n  robotics system", "authors": [], "abstract": "A marsupial robotics system comprises three components: an Unmanned Ground\nVehicle (UGV), an Unmanned Aerial Vehicle (UAV), and a tether connecting both\nrobots. Marsupial systems are highly beneficial in industry as they extend the\nUAV's battery life during flight. This paper introduces a novel strategy for a\nspecific path planning problem in marsupial systems, where each of the\ncomponents must avoid collisions with ground and aerial obstacles modeled as 3D\ncuboids. Given an initial configuration in which the UAV is positioned atop the\nUGV, the goal is to reach an aerial target with the UAV. We assume that the UGV\nfirst moves to a position from which the UAV can take off and fly through a\nvertical plane to reach an aerial target. We propose an approach that\ndiscretizes the space to approximate an optimal solution, minimizing the sum of\nthe lengths of the ground and air paths. First, we assume a taut tether and use\na novel algorithm that leverages the convexity of the tether and the geometry\nof obstacles to efficiently determine the locus of feasible take-off points for\nthe UAV. We then apply this result to scenarios that involve loose tethers. The\nsimulation test results show that our approach can solve complex situations in\nseconds, outperforming a baseline planning algorithm based on RRT* (Rapidly\nexploring Random Trees).", "categories": "cs.RO", "created": "2024-08-04", "doi": null, "arxiv_id": "2408.02141"}
{"title": "Analyzing Cultural Representations of Emotions in LLMs through Mixed\n  Emotion Survey", "authors": [], "abstract": "Large Language Models (LLMs) have gained widespread global adoption,\nshowcasing advanced linguistic capabilities across multiple of languages. There\nis a growing interest in academia to use these models to simulate and study\nhuman behaviors. However, it is crucial to acknowledge that an LLM's\nproficiency in a specific language might not fully encapsulate the norms and\nvalues associated with its culture. Concerns have emerged regarding potential\nbiases towards Anglo-centric cultures and values due to the predominance of\nWestern and US-based training data. This study focuses on analyzing the\ncultural representations of emotions in LLMs, in the specific case of\nmixed-emotion situations. Our methodology is based on the studies of Miyamoto\net al. (2010), which identified distinctive emotional indicators in Japanese\nand American human responses. We first administer their mixed emotion survey to\nfive different LLMs and analyze their outputs. Second, we experiment with\ncontextual variables to explore variations in responses considering both\nlanguage and speaker origin. Thirdly, we expand our investigation to encompass\nadditional East Asian and Western European origin languages to gauge their\nalignment with their respective cultures, anticipating a closer fit. We find\nthat (1) models have limited alignment with the evidence in the literature; (2)\nwritten language has greater effect on LLMs' response than information on\nparticipants origin; and (3) LLMs responses were found more similar for East\nAsian languages than Western European languages.", "categories": "cs.CL cs.AI", "created": "2024-08-04", "doi": null, "arxiv_id": "2408.02143"}
{"title": "Video-based Pedestrian and Vehicle Traffic Analysis During Football\n  Games", "authors": [], "abstract": "This paper utilizes video analytics to study pedestrian and vehicle traffic\nbehavior, focusing on analyzing traffic patterns during football gamedays. The\nUniversity of Florida (UF) hosts six to seven home football games on Saturdays\nduring the college football season, attracting significant pedestrian activity.\nThrough video analytics, this study provides valuable insights into the impact\nof these events on traffic volumes and safety at intersections. Comparing\npedestrian and vehicle activities on gamedays versus non-gamedays reveals\ndiffering patterns. For example, pedestrian volume substantially increases\nduring gamedays, which is positively correlated with the probability of the\naway team winning. This correlation is likely because fans of the home team\nenjoy watching difficult games. Win probabilities as an early predictor of\npedestrian volumes at intersections can be a tool to help traffic professionals\nanticipate traffic management needs. Pedestrian-to-vehicle (P2V) conflicts\nnotably increase on gamedays, particularly a few hours before games start.\nAddressing this, a \"Barnes Dance\" movement phase within the intersection is\nrecommended. Law enforcement presence during high-activity gamedays can help\nensure pedestrian compliance and enhance safety. In contrast, we identified\nthat vehicle-to-vehicle (V2V) conflicts generally do not increase on gamedays\nand may even decrease due to heightened driver caution.", "categories": "cs.CV cs.CY", "created": "2024-08-04", "doi": null, "arxiv_id": "2408.02146"}
{"title": "Generative Retrieval with Few-shot Indexing", "authors": [], "abstract": "Existing generative retrieval (GR) approaches rely on training-based\nindexing, i.e., fine-tuning a model to memorise the associations between a\nquery and the document identifier (docid) of a relevant document.\nTraining-based indexing has three limitations: high training overhead,\nunder-utilization of the pre-trained knowledge of large language models (LLMs),\nand challenges in adapting to a dynamic document corpus. To address the above\nissues, we propose a novel few-shot indexing-based GR framework (Few-Shot GR).\nIt has a novel few-shot indexing process, where we prompt an LLM to generate\ndocids for all documents in a corpus, ultimately creating a docid bank for the\nentire corpus. During retrieval, we feed a query to the same LLM and constrain\nit to generate a docid within the docid bank created during indexing, and then\nmap the generated docid back to its corresponding document. Few-Shot GR relies\nsolely on prompting an LLM without requiring any training, making it more\nefficient. Moreover, we devise few-shot indexing with one-to-many mapping to\nfurther enhance Few-Shot GR. Experiments show that Few-Shot GR achieves\nsuperior performance to state-of-the-art GR methods that require heavy\ntraining.", "categories": "cs.IR cs.AI cs.CL cs.LG", "created": "2024-08-04", "doi": null, "arxiv_id": "2408.02152"}
{"title": "ARVO: Atlas of Reproducible Vulnerabilities for Open Source Software", "authors": [], "abstract": "High-quality datasets of real-world vulnerabilities are enormously valuable\nfor downstream research in software security, but existing datasets are\ntypically small, require extensive manual effort to update, and are missing\ncrucial features that such research needs. In this paper, we introduce ARVO: an\nAtlas of Reproducible Vulnerabilities in Open-source software. By sourcing\nvulnerabilities from C/C++ projects that Google's OSS-Fuzz discovered and\nimplementing a reliable re-compilation system, we successfully reproduce more\nthan 5,000 memory vulnerabilities across over 250 projects, each with a\ntriggering input, the canonical developer-written patch for fixing the\nvulnerability, and the ability to automatically rebuild the project from source\nand run it at its vulnerable and patched revisions. Moreover, our dataset can\nbe automatically updated as OSS-Fuzz finds new vulnerabilities, allowing it to\ngrow over time. We provide a thorough characterization of the ARVO dataset,\nshow that it can locate fixes more accurately than Google's own OSV\nreproduction effort, and demonstrate its value for future research through two\ncase studies: firstly evaluating real-world LLM-based vulnerability repair, and\nsecondly identifying over 300 falsely patched (still-active) zero-day\nvulnerabilities from projects improperly labeled by OSS-Fuzz.", "categories": "cs.CR cs.AI cs.LG", "created": "2024-08-04", "doi": null, "arxiv_id": "2408.02153"}
{"title": "Calibration-Disentangled Learning and Relevance-Prioritized Reranking\n  for Calibrated Sequential Recommendation", "authors": [], "abstract": "Calibrated recommendation, which aims to maintain personalized proportions of\ncategories within recommendations, is crucial in practical scenarios since it\nenhances user satisfaction by reflecting diverse interests. However, achieving\ncalibration in a sequential setting (i.e., calibrated sequential\nrecommendation) is challenging due to the need to adapt to users' evolving\npreferences. Previous methods typically leverage reranking algorithms to\ncalibrate recommendations after training a model without considering the effect\nof calibration and do not effectively tackle the conflict between relevance and\ncalibration during the reranking process. In this work, we propose LeapRec\n(Calibration-Disentangled Learning and Relevance-Prioritized Reranking), a\nnovel approach for the calibrated sequential recommendation that addresses\nthese challenges. LeapRec consists of two phases, model training phase and\nreranking phase. In the training phase, a backbone model is trained using our\nproposed calibration-disentangled learning-to-rank loss, which optimizes\npersonalized rankings while integrating calibration considerations. In the\nreranking phase, relevant items are prioritized at the top of the list, with\nitems needed for calibration following later to address potential conflicts\nbetween relevance and calibration. Through extensive experiments on four\nreal-world datasets, we show that LeapRec consistently outperforms previous\nmethods in the calibrated sequential recommendation. Our code is available at\nhttps://github.com/jeon185/LeapRec.", "categories": "cs.IR cs.AI", "created": "2024-08-04", "doi": "10.1145/3627673.3679728", "arxiv_id": "2408.02156"}
{"title": "PanoFree: Tuning-Free Holistic Multi-view Image Generation with\n  Cross-view Self-Guidance", "authors": [], "abstract": "Immersive scene generation, notably panorama creation, benefits significantly\nfrom the adaptation of large pre-trained text-to-image (T2I) models for\nmulti-view image generation. Due to the high cost of acquiring multi-view\nimages, tuning-free generation is preferred. However, existing methods are\neither limited to simple correspondences or require extensive fine-tuning to\ncapture complex ones. We present PanoFree, a novel method for tuning-free\nmulti-view image generation that supports an extensive array of\ncorrespondences. PanoFree sequentially generates multi-view images using\niterative warping and inpainting, addressing the key issues of inconsistency\nand artifacts from error accumulation without the need for fine-tuning. It\nimproves error accumulation by enhancing cross-view awareness and refines the\nwarping and inpainting processes via cross-view guidance, risky area estimation\nand erasing, and symmetric bidirectional guided generation for loop closure,\nalongside guidance-based semantic and density control for scene structure\npreservation. In experiments on Planar, 360{\\deg}, and Full Spherical\nPanoramas, PanoFree demonstrates significant error reduction, improves global\nconsistency, and boosts image quality without extra fine-tuning. Compared to\nexisting methods, PanoFree is up to 5x more efficient in time and 3x more\nefficient in GPU memory usage, and maintains superior diversity of results (2x\nbetter in our user study). PanoFree offers a viable alternative to costly\nfine-tuning or the use of additional pre-trained models. Project website at\nhttps://panofree.github.io/.", "categories": "cs.CV", "created": "2024-08-04", "doi": null, "arxiv_id": "2408.02157"}
{"title": "SPINEX-TimeSeries: Similarity-based Predictions with Explainable\n  Neighbors Exploration for Time Series and Forecasting Problems", "authors": [], "abstract": "This paper introduces a new addition to the SPINEX (Similarity-based\nPredictions with Explainable Neighbors Exploration) family, tailored\nspecifically for time series and forecasting analysis. This new algorithm\nleverages the concept of similarity and higher-order temporal interactions\nacross multiple time scales to enhance predictive accuracy and interpretability\nin forecasting. To evaluate the effectiveness of SPINEX, we present\ncomprehensive benchmarking experiments comparing it against 18 algorithms and\nacross 49 synthetic and real datasets characterized by varying trends,\nseasonality, and noise levels. Our performance assessment focused on\nforecasting accuracy and computational efficiency. Our findings reveal that\nSPINEX consistently ranks among the top 5 performers in forecasting precision\nand has a superior ability to handle complex temporal dynamics compared to\ncommonly adopted algorithms. Moreover, the algorithm's explainability features,\nPareto efficiency, and medium complexity (on the order of O(log n)) are\ndemonstrated through detailed visualizations to enhance the prediction and\ndecision-making process. We note that integrating similarity-based concepts\nopens new avenues for research in predictive analytics, promising more accurate\nand transparent decision making.", "categories": "stat.ME cs.LG stat.CO stat.ML", "created": "2024-08-04", "doi": null, "arxiv_id": "2408.02159"}
{"title": "Distilling Machine Learning's Added Value: Pareto Fronts in Atmospheric\n  Applications", "authors": [], "abstract": "While the added value of machine learning (ML) for weather and climate\napplications is measurable, explaining it remains challenging, especially for\nlarge deep learning models. Inspired by climate model hierarchies, we propose\nthat a full hierarchy of Pareto-optimal models, defined within an appropriately\ndetermined error-complexity plane, can guide model development and help\nunderstand the models' added value. We demonstrate the use of Pareto fronts in\natmospheric physics through three sample applications, with hierarchies ranging\nfrom semi-empirical models with minimal tunable parameters (simplest) to deep\nlearning algorithms (most complex). First, in cloud cover parameterization, we\nfind that neural networks identify nonlinear relationships between cloud cover\nand its thermodynamic environment, and assimilate previously neglected features\nsuch as vertical gradients in relative humidity that improve the representation\nof low cloud cover. This added value is condensed into a ten-parameter equation\nthat rivals the performance of deep learning models. Second, we establish a ML\nmodel hierarchy for emulating shortwave radiative transfer, distilling the\nimportance of bidirectional vertical connectivity for accurately representing\nabsorption and scattering, especially for multiple cloud layers. Third, we\nemphasize the importance of convective organization information when modeling\nthe relationship between tropical precipitation and its surrounding\nenvironment. We discuss the added value of temporal memory when high-resolution\nspatial information is unavailable, with implications for precipitation\nparameterization. Therefore, by comparing data-driven models directly with\nexisting schemes using Pareto optimality, we promote process understanding by\nhierarchically unveiling system complexity, with the hope of improving the\ntrustworthiness of ML models in atmospheric applications.", "categories": "physics.comp-ph cs.LG physics.ao-ph", "created": "2024-08-04", "doi": null, "arxiv_id": "2408.02161"}
{"title": "Improvement and Empirical Testing of a Novel Autonomous\n  Microplastics-Collecting Semisubmersible", "authors": [], "abstract": "Since their invention, plastics have become ubiquitous in modern societies\nall around the world, and their impact on the environment has, in recent years,\nbecome nearly as well-known. Plastics produced by humans have reached nearly\nevery corner of the world, and throughout their centuries-long lifetimes,\nplastics continually break down into smaller and smaller particles due to the\nphysical stresses which they are subjected to. These stresses eventually,\ninevitably, break these plastics down into microplastics -pieces of plastic\nsmall enough to be consumed by organisms in bodies of water throughout the\nglobe. These microplastics can very easily bioaccumulate, and have been found\neverywhere from the Great Lakes to the bloodstreams of humans. The effects of\nthese plastics are poorly understood, however, they have been linked to\ninfertility, halted growth, and a host of other maladies in aquatic organisms.\nCurrently, removal of these plastics has been neglected, with no governmental\naction to remove them from marine environments, and this project aims to begin\nprototyping a solution to this issue. A significant percentage of microplastics\nare found at the surface of waterways, thus trawling in surface waters using an\nautonomously propelled net is proposed as a way to solve this seemingly\nintractable issue. By attaching motors and a guidance system to a manta trawl,\na device currently used for collecting microorganisms, the process of\ncollecting microplastics in open water can be automated, and thus the work of\nremoving plastics from the environment on a large scale can begin.", "categories": "cs.RO", "created": "2024-08-04", "doi": null, "arxiv_id": "2408.02162"}
{"title": "SelfBC: Self Behavior Cloning for Offline Reinforcement Learning", "authors": [], "abstract": "Policy constraint methods in offline reinforcement learning employ additional\nregularization techniques to constrain the discrepancy between the learned\npolicy and the offline dataset. However, these methods tend to result in overly\nconservative policies that resemble the behavior policy, thus limiting their\nperformance. We investigate this limitation and attribute it to the static\nnature of traditional constraints. In this paper, we propose a novel dynamic\npolicy constraint that restricts the learned policy on the samples generated by\nthe exponential moving average of previously learned policies. By integrating\nthis self-constraint mechanism into off-policy methods, our method facilitates\nthe learning of non-conservative policies while avoiding policy collapse in the\noffline setting. Theoretical results show that our approach results in a nearly\nmonotonically improved reference policy. Extensive experiments on the D4RL\nMuJoCo domain demonstrate that our proposed method achieves state-of-the-art\nperformance among the policy constraint methods.", "categories": "cs.LG cs.AI", "created": "2024-08-04", "doi": null, "arxiv_id": "2408.02165"}
{"title": "Discrete Shortest Paths in Optimal Power Flow Feasible Regions", "authors": [], "abstract": "Optimal power flow (OPF) is a critical optimization problem for power systems\nto operate at points where cost or operational objectives are optimized. Due to\nthe non-convexity of the set of feasible OPF operating points, it is\nnon-trivial to transition the power system from its current operating point to\nthe optimal one without violating constraints. On top of that, practical\nconsiderations dictate that the transition should be achieved using a small\nnumber of small-magnitude control actions. To solve this problem, this paper\nproposes an algorithm for computing a transition path by framing it as a\nshortest path problem. This problem is formulated in terms of a discretized\npiece-wise linear path, where the number of pieces is fixed a priori in order\nto limit the number of control actions. This formulation yields a nonlinear\noptimization problem (NLP) with a block tridiagonal structure, which we\nleverage by utilizing a specialized interior point method. An initial feasible\npath for our method is generated by solving a sequence of relaxations which are\nthen tightened in a homotopy-like procedure. Numerical experiments illustrate\nthe effectiveness of the algorithm.", "categories": "math.OC cs.SY eess.SY", "created": "2024-08-04", "doi": null, "arxiv_id": "2408.02172"}
{"title": "On the Equilibrium of a Class of Leader-Follower Games with\n  Decision-Dependent Chance Constraints", "authors": [], "abstract": "In this paper, we study the existence of equilibrium in a\nsingle-leader-multiple-follower game with decision-dependent chance constraints\n(DDCCs), where decision-dependent uncertainties (DDUs) exist in the constraints\nof followers. DDUs refer to the uncertainties impacted by the leader's\nstrategy, while the leader cannot capture their exact probability\ndistributions. To address such problems, we first use decision-dependent\nambiguity sets under moment information and Cantelli's inequality to transform\nDDCCs into second-order cone constraints. This simplifies the game model by\neliminating the probability distributions. We further prove that there exists\nat least one equilibrium point for this game by applying Kakutani's fixed-point\ntheorem. Finally, a numerical example is provided to show the impact of DDUs on\nthe equilibrium of such game models.", "categories": "math.OC cs.GT", "created": "2024-08-04", "doi": null, "arxiv_id": "2408.02174"}
{"title": "StreamVoice+: Evolving into End-to-end Streaming Zero-shot Voice\n  Conversion", "authors": [], "abstract": "StreamVoice has recently pushed the boundaries of zero-shot voice conversion\n(VC) in the streaming domain. It uses a streamable language model (LM) with a\ncontext-aware approach to convert semantic features from automatic speech\nrecognition (ASR) into acoustic features with the desired speaker timbre.\nDespite its innovations, StreamVoice faces challenges due to its dependency on\na streaming ASR within a cascaded framework, which complicates system\ndeployment and optimization, affects VC system's design and performance based\non the choice of ASR, and struggles with conversion stability when faced with\nlow-quality semantic inputs. To overcome these limitations, we introduce\nStreamVoice+, an enhanced LM-based end-to-end streaming framework that operates\nindependently of streaming ASR. StreamVoice+ integrates a semantic encoder and\na connector with the original StreamVoice framework, now trained using a\nnon-streaming ASR. This model undergoes a two-stage training process:\ninitially, the StreamVoice backbone is pre-trained for voice conversion and the\nsemantic encoder for robust semantic extraction. Subsequently, the system is\nfine-tuned end-to-end, incorporating a LoRA matrix to activate comprehensive\nstreaming functionality. Furthermore, StreamVoice+ mainly introduces two\nstrategic enhancements to boost conversion quality: a residual compensation\nmechanism in the connector to ensure effective semantic transmission and a\nself-refinement strategy that leverages pseudo-parallel speech pairs generated\nby the conversion backbone to improve speech decoupling. Experiments\ndemonstrate that StreamVoice+ not only achieves higher naturalness and speaker\nsimilarity in voice conversion than its predecessor but also provides versatile\nsupport for both streaming and non-streaming conversion scenarios.", "categories": "eess.AS cs.SD", "created": "2024-08-04", "doi": null, "arxiv_id": "2408.02178"}
{"title": "X.509 Information Security Certification Based on Post-Quantum\n  Cryptography", "authors": [], "abstract": "In recent years, with the advancement of quantum computing, mainstream\nasymmetric cryptographic methods in the current Public Key Infrastructure (PKI)\nsystems are gradually being threatened. Therefore, this study explores X.509\nsecurity certificates based on Post-Quantum Cryptography (PQC) and discusses\nimplemented solutions. This study compares mainstream asymmetric cryptographic\nmethods (including RSA and Elliptic Curve Digital Signature Algorithm (ECDSA))\nwith standard PQC methods (including Falcon, Dilithium, SPHINCS+), comparing\nthe efficiency of certificate generation, signature generation, and signature\nverification. Finally, recommendations for a solution based on PQC for X.509\nsecurity certificates are proposed.", "categories": "cs.CR cs.SE", "created": "2024-08-04", "doi": "10.1109/ICSSES62373.2024.10561274", "arxiv_id": "2408.02179"}
{"title": "AssemAI: Interpretable Image-Based Anomaly Detection for Manufacturing\n  Pipelines", "authors": [], "abstract": "Anomaly detection in manufacturing pipelines remains a critical challenge,\nintensified by the complexity and variability of industrial environments. This\npaper introduces AssemAI, an interpretable image-based anomaly detection system\ntailored for smart manufacturing pipelines. Our primary contributions include\nthe creation of a tailored image dataset and the development of a custom object\ndetection model, YOLO-FF, designed explicitly for anomaly detection in\nmanufacturing assembly environments. Utilizing the preprocessed image dataset\nderived from an industry-focused rocket assembly pipeline, we address the\nchallenge of imbalanced image data and demonstrate the importance of\nimage-based methods in anomaly detection. The proposed approach leverages\ndomain knowledge in data preparation, model development and reasoning. We\ncompare our method against several baselines, including simple CNN and custom\nVisual Transformer (ViT) models, showcasing the effectiveness of our custom\ndata preparation and pretrained CNN integration. Additionally, we incorporate\nexplainability techniques at both user and model levels, utilizing ontology for\nuser-friendly explanations and SCORE-CAM for in-depth feature and model\nanalysis. Finally, the model was also deployed in a real-time setting. Our\nresults include ablation studies on the baselines, providing a comprehensive\nevaluation of the proposed system. This work highlights the broader impact of\nadvanced image-based anomaly detection in enhancing the reliability and\nefficiency of smart manufacturing processes.", "categories": "cs.CV", "created": "2024-08-04", "doi": null, "arxiv_id": "2408.02181"}
{"title": "RoPotter: Toward Robotic Pottery and Deformable Object Manipulation with\n  Structural Priors", "authors": [], "abstract": "Humans are capable of continuously manipulating a wide variety of deformable\nobjects into complex shapes. This is made possible by our intuitive\nunderstanding of material properties and mechanics of the object, for reasoning\nabout object states even when visual perception is occluded. These capabilities\nallow us to perform diverse tasks ranging from cooking with dough to expressing\nourselves with pottery-making. However, developing robotic systems to robustly\nperform similar tasks remains challenging, as current methods struggle to\neffectively model volumetric deformable objects and reason about the complex\nbehavior they typically exhibit. To study the robotic systems and algorithms\ncapable of deforming volumetric objects, we introduce a novel robotics task of\ncontinuously deforming clay on a pottery wheel. We propose a pipeline for\nperception and pottery skill-learning, called RoPotter, wherein we demonstrate\nthat structural priors specific to the task of pottery-making can be exploited\nto simplify the pottery skill-learning process. Namely, we can project the\ncross-section of the clay to a plane to represent the state of the clay,\nreducing dimensionality. We also demonstrate a mesh-based method of occluded\nclay state recovery, toward robotic agents capable of continuously deforming\nclay. Our experiments show that by using the reduced representation with\nstructural priors based on the deformation behaviors of the clay, RoPotter can\nperform the long-horizon pottery task with 44.4% lower final shape error\ncompared to the state-of-the-art baselines.", "categories": "cs.RO", "created": "2024-08-04", "doi": null, "arxiv_id": "2408.02184"}
{"title": "Dense Feature Interaction Network for Image Inpainting Localization", "authors": [], "abstract": "Image inpainting, which is the task of filling in missing areas in an image,\nis a common image editing technique. Inpainting can be used to conceal or alter\nimage contents in malicious manipulation of images, driving the need for\nresearch in image inpainting detection. Existing methods mostly rely on a basic\nencoder-decoder structure, which often results in a high number of false\npositives or misses the inpainted regions, especially when dealing with targets\nof varying semantics and scales. Additionally, the absence of an effective\napproach to capture boundary artifacts leads to less accurate edge\nlocalization. In this paper, we describe a new method for inpainting detection\nbased on a Dense Feature Interaction Network (DeFI-Net). DeFI-Net uses a novel\nfeature pyramid architecture to capture and amplify multi-scale representations\nacross various stages, thereby improving the detection of image inpainting by\nbetter revealing feature-level interactions. Additionally, the network can\nadaptively direct the lower-level features, which carry edge and shape\ninformation, to refine the localization of manipulated regions while\nintegrating the higher-level semantic features. Using DeFI-Net, we develop a\nmethod combining complementary representations to accurately identify inpainted\nareas. Evaluation on five image inpainting datasets demonstrate the\neffectiveness of our approach, which achieves state-of-the-art performance in\ndetecting inpainting across diverse models.", "categories": "cs.CV", "created": "2024-08-04", "doi": null, "arxiv_id": "2408.02191"}
{"title": "Unsupervised Domain Adaption Harnessing Vision-Language Pre-training", "authors": [], "abstract": "This paper addresses two vital challenges in Unsupervised Domain Adaptation\n(UDA) with a focus on harnessing the power of Vision-Language Pre-training\n(VLP) models. Firstly, UDA has primarily relied on ImageNet pre-trained models.\nHowever, the potential of VLP models in UDA remains largely unexplored. The\nrich representation of VLP models holds significant promise for enhancing UDA\ntasks. To address this, we propose a novel method called Cross-Modal Knowledge\nDistillation (CMKD), leveraging VLP models as teacher models to guide the\nlearning process in the target domain, resulting in state-of-the-art\nperformance. Secondly, current UDA paradigms involve training separate models\nfor each task, leading to significant storage overhead and impractical model\ndeployment as the number of transfer tasks grows. To overcome this challenge,\nwe introduce Residual Sparse Training (RST) exploiting the benefits conferred\nby VLP's extensive pre-training, a technique that requires minimal adjustment\n(approximately 0.1\\%$\\sim$0.5\\%) of VLP model parameters to achieve performance\ncomparable to fine-tuning. Combining CMKD and RST, we present a comprehensive\nsolution that effectively leverages VLP models for UDA tasks while reducing\nstorage overhead for model deployment. Furthermore, CMKD can serve as a\nbaseline in conjunction with other methods like FixMatch, enhancing the\nperformance of UDA. Our proposed method outperforms existing techniques on\nstandard benchmarks. Our code will be available at:\nhttps://github.com/Wenlve-Zhou/VLP-UDA.", "categories": "cs.CV", "created": "2024-08-04", "doi": "10.1109/TCSVT.2024.3391304", "arxiv_id": "2408.02192"}
{"title": "CodeACT: Code Adaptive Compute-efficient Tuning Framework for Code LLMs", "authors": [], "abstract": "Large language models (LLMs) have shown great potential in code-related\ntasks, yet open-source models lag behind their closed-source counterparts. To\nbridge this performance gap, existing methods generate vast amounts of\nsynthetic data for fine-tuning, leading to inefficiencies in training.\nMotivated by the need for more effective and efficient training, we propose the\nCode Adaptive Compute-efficient Tuning (CodeACT) framework. CodeACT introduces\nthe Complexity and Diversity Aware Sampling (CDAS) method to select\nhigh-quality training data based on complexity and diversity, and the Dynamic\nPack padding strategy to reduce computational resource usage by minimizing\npadding tokens during training. Experimental results demonstrate that\nCodeACT-DeepSeek-Coder-6.7B, fine-tuned on only 40% of the EVOL-Instruct data,\nachieves an 8.6% performance increase on HumanEval, reduces training time by\n78%, and decreases peak GPU memory usage by 27%. These findings underscore\nCodeACT's ability to enhance the performance and efficiency of open-source\nmodels. By optimizing both the data selection and training processes, CodeACT\noffers a comprehensive approach to improving the capabilities of open-source\nLLMs while significantly reducing computational requirements, addressing the\ndual challenges of data quality and training efficiency, and paving the way for\nmore resource-efficient and performant models.", "categories": "cs.CL cs.LG", "created": "2024-08-04", "doi": null, "arxiv_id": "2408.02193"}
{"title": "Undecidability of Translational Tiling of the 3-dimensional Space with a\n  Set of 6 Polycubes", "authors": [], "abstract": "This paper focuses on the undecidability of translational tiling of\n$n$-dimensional space $\\mathbb{Z}^n$ with a set of $k$ tiles. It is known that\ntiling $\\mathbb{Z}^2$ with translated copies with a set of $8$ tiles is\nundecidable. Greenfeld and Tao gave strong evidence in a series of works that\nfor sufficiently large dimension $n$, the translational tiling problem for\n$\\mathbb{Z}^n$ might be undecidable for just one tile. This paper shows the\nundecidability of translational tiling of $\\mathbb{Z}^3$ with a set of $6$\ntiles.", "categories": "math.CO cs.CC math.MG", "created": "2024-08-04", "doi": null, "arxiv_id": "2408.02196"}
{"title": "Synergistic Learning with Multi-Task DeepONet for Efficient PDE Problem\n  Solving", "authors": [], "abstract": "Multi-task learning (MTL) is an inductive transfer mechanism designed to\nleverage useful information from multiple tasks to improve generalization\nperformance compared to single-task learning. It has been extensively explored\nin traditional machine learning to address issues such as data sparsity and\noverfitting in neural networks. In this work, we apply MTL to problems in\nscience and engineering governed by partial differential equations (PDEs).\nHowever, implementing MTL in this context is complex, as it requires\ntask-specific modifications to accommodate various scenarios representing\ndifferent physical processes. To this end, we present a multi-task deep\noperator network (MT-DeepONet) to learn solutions across various functional\nforms of source terms in a PDE and multiple geometries in a single concurrent\ntraining session. We introduce modifications in the branch network of the\nvanilla DeepONet to account for various functional forms of a parameterized\ncoefficient in a PDE. Additionally, we handle parameterized geometries by\nintroducing a binary mask in the branch network and incorporating it into the\nloss term to improve convergence and generalization to new geometry tasks. Our\napproach is demonstrated on three benchmark problems: (1) learning different\nfunctional forms of the source term in the Fisher equation; (2) learning\nmultiple geometries in a 2D Darcy Flow problem and showcasing better transfer\nlearning capabilities to new geometries; and (3) learning 3D parameterized\ngeometries for a heat transfer problem and demonstrate the ability to predict\non new but similar geometries. Our MT-DeepONet framework offers a novel\napproach to solving PDE problems in engineering and science under a unified\numbrella based on synergistic learning that reduces the overall training cost\nfor neural operators.", "categories": "cs.LG", "created": "2024-08-04", "doi": null, "arxiv_id": "2408.02198"}
{"title": "A Fast Fourier-Galerkin Method for Solving Boundary Integral Equations\n  on Torus-Shaped Surfaces", "authors": [], "abstract": "In this paper, we introduce a fast Fourier-Galerkin method for solving\nboundary integral equations on torus-shaped surfaces, which are diffeomorphic\nto a torus. We analyze the properties of the integral operator's kernel to\nderive the decay pattern of the entries in the representation matrix.\nLeveraging this decay pattern, we devise a truncation strategy that efficiently\ncompresses the dense representation matrix of the integral operator into a\nsparser form containing only $\\mathcal{O}(N\\ln^2 N)$ nonzero entries, where $N$\ndenotes the degrees of freedom of the discretization method. We prove that this\ntruncation strategy achieves a quasi-optimal convergence order of\n$\\mathcal{O}(N^{-p/2}\\ln N)$, with $p$ representing the degree of regularity of\nthe exact solution to the boundary integral equation. Additionally, we confirm\nthat the truncation strategy preserves stability throughout the solution\nprocess. Numerical experiments validate our theoretical findings and\ndemonstrate the effectiveness of the proposed method.", "categories": "math.NA cs.NA", "created": "2024-08-04", "doi": null, "arxiv_id": "2408.02199"}
{"title": "Evaluating the Performance of Large Language Models for SDG Mapping\n  (Technical Report)", "authors": [], "abstract": "The use of large language models (LLMs) is expanding rapidly, and open-source\nversions are becoming available, offering users safer and more adaptable\noptions. These models enable users to protect data privacy by eliminating the\nneed to provide data to third parties and can be customized for specific tasks.\nIn this study, we compare the performance of various language models on the\nSustainable Development Goal (SDG) mapping task, using the output of GPT-4o as\nthe baseline. The selected open-source models for comparison include Mixtral,\nLLaMA 2, LLaMA 3, Gemma, and Qwen2. Additionally, GPT-4o-mini, a more\nspecialized version of GPT-4o, was included to extend the comparison. Given the\nmulti-label nature of the SDG mapping task, we employed metrics such as F1\nscore, precision, and recall with micro-averaging to evaluate different aspects\nof the models' performance. These metrics are derived from the confusion matrix\nto ensure a comprehensive evaluation. We provide a clear observation and\nanalysis of each model's performance by plotting curves based on F1 score,\nprecision, and recall at different thresholds. According to the results of this\nexperiment, LLaMA 2 and Gemma still have significant room for improvement. The\nother four models do not exhibit particularly large differences in performance.\nThe outputs from all seven models are available on Zenodo:\nhttps://doi.org/10.5281/zenodo.12789375.", "categories": "cs.LG cs.CL", "created": "2024-08-04", "doi": null, "arxiv_id": "2408.02201"}
{"title": "Towards AI-Safety-by-Design: A Taxonomy of Runtime Guardrails in\n  Foundation Model based Systems", "authors": [], "abstract": "The rapid advancement and widespread deployment of foundation model (FM)\nbased systems have revolutionized numerous applications across various domains.\nHowever, the fast-growing capabilities and autonomy have also raised\nsignificant concerns about responsible AI and AI safety. Recently, there have\nbeen increasing attention toward implementing guardrails to ensure the runtime\nbehavior of FM-based systems is safe and responsible. Given the early stage of\nFMs and their applications (such as agents), the design of guardrails have not\nyet been systematically studied. It remains underexplored which software\nqualities should be considered when designing guardrails and how these\nqualities can be ensured from a software architecture perspective. Therefore,\nin this paper, we present a taxonomy for guardrails to classify and compare the\ncharacteristics and design options of guardrails. Our taxonomy is organized\ninto three main categories: the motivation behind adopting runtime guardrails,\nthe quality attributes to consider, and the design options available. This\ntaxonomy provides structured and concrete guidance for making architectural\ndesign decisions when designing guardrails and highlights trade-offs arising\nfrom the design decisions.", "categories": "cs.SE cs.AI", "created": "2024-08-04", "doi": null, "arxiv_id": "2408.02205"}
{"title": "Large-scale Deployment of Vision-based Tactile Sensors on Multi-fingered\n  Grippers", "authors": [], "abstract": "Vision-based Tactile Sensors (VBTSs) show significant promise in that they\ncan leverage image measurements to provide high-spatial-resolution human-like\nperformance. However, current VBTS designs, typically confined to the\nfingertips of robotic grippers, prove somewhat inadequate, as many grasping and\nmanipulation tasks require multiple contact points with the object. With an end\ngoal of enabling large-scale, multi-surface tactile sensing via VBTSs, our\nresearch (i) develops a synchronized image acquisition system with minimal\nlatency,(ii) proposes a modularized VBTS design for easy integration into\nfinger phalanges, and (iii) devises a zero-shot calibration approach to improve\ndata efficiency in the simultaneous calibration of multiple VBTSs. In\nvalidating the system within a miniature 3-fingered robotic gripper equipped\nwith 7 VBTSs we demonstrate improved tactile perception performance by covering\nthe contact surfaces of both gripper fingers and palm. Additionally, we show\nthat our VBTS design can be seamlessly integrated into various end-effector\nmorphologies significantly reducing the data requirements for calibration.", "categories": "cs.RO", "created": "2024-08-04", "doi": null, "arxiv_id": "2408.02206"}
{"title": "MARCO: A Memory-Augmented Reinforcement Framework for Combinatorial\n  Optimization", "authors": [], "abstract": "Neural Combinatorial Optimization (NCO) is an emerging domain where deep\nlearning techniques are employed to address combinatorial optimization problems\nas a standalone solver. Despite their potential, existing NCO methods often\nsuffer from inefficient search space exploration, frequently leading to local\noptima entrapment or redundant exploration of previously visited states. This\npaper introduces a versatile framework, referred to as Memory-Augmented\nReinforcement for Combinatorial Optimization (MARCO), that can be used to\nenhance both constructive and improvement methods in NCO through an innovative\nmemory module. MARCO stores data collected throughout the optimization\ntrajectory and retrieves contextually relevant information at each state. This\nway, the search is guided by two competing criteria: making the best decision\nin terms of the quality of the solution and avoiding revisiting already\nexplored solutions. This approach promotes a more efficient use of the\navailable optimization budget. Moreover, thanks to the parallel nature of NCO\nmodels, several search threads can run simultaneously, all sharing the same\nmemory module, enabling an efficient collaborative exploration. Empirical\nevaluations, carried out on the maximum cut, maximum independent set and\ntravelling salesman problems, reveal that the memory module effectively\nincreases the exploration, enabling the model to discover diverse,\nhigher-quality solutions. MARCO achieves good performance in a low\ncomputational cost, establishing a promising new direction in the field of NCO.", "categories": "cs.NE cs.AI", "created": "2024-08-04", "doi": "10.24963/ijcai.2024/766", "arxiv_id": "2408.02207"}
{"title": "Multi-level Traffic-Responsive Tilt Camera Surveillance through\n  Predictive Correlated Online Learning", "authors": [], "abstract": "In urban traffic management, the primary challenge of dynamically and\nefficiently monitoring traffic conditions is compounded by the insufficient\nutilization of thousands of surveillance cameras along the intelligent\ntransportation system. This paper introduces the multi-level Traffic-responsive\nTilt Camera surveillance system (TTC-X), a novel framework designed for dynamic\nand efficient monitoring and management of traffic in urban networks. By\nleveraging widely deployed pan-tilt-cameras (PTCs), TTC-X overcomes the\nlimitations of a fixed field of view in traditional surveillance systems by\nproviding mobilized and 360-degree coverage. The innovation of TTC-X lies in\nthe integration of advanced machine learning modules, including a\ndetector-predictor-controller structure, with a novel Predictive Correlated\nOnline Learning (PiCOL) methodology and the Spatial-Temporal Graph Predictor\n(STGP) for real-time traffic estimation and PTC control. The TTC-X is tested\nand evaluated under three experimental scenarios (e.g., maximum traffic flow\ncapture, dynamic route planning, traffic state estimation) based on a\nsimulation environment calibrated using real-world traffic data in Brooklyn,\nNew York. The experimental results showed that TTC-X captured over 60\\% total\nnumber of vehicles at the network level, dynamically adjusted its route\nrecommendation in reaction to unexpected full-lane closure events, and\nreconstructed link-level traffic states with best MAE less than 1.25\nvehicle/hour. Demonstrating scalability, cost-efficiency, and adaptability,\nTTC-X emerges as a powerful solution for urban traffic management in both\ncyber-physical and real-world environments.", "categories": "eess.SY cs.LG cs.SY physics.soc-ph", "created": "2024-08-04", "doi": null, "arxiv_id": "2408.02208"}
{"title": "ExoViP: Step-by-step Verification and Exploration with Exoskeleton\n  Modules for Compositional Visual Reasoning", "authors": [], "abstract": "Compositional visual reasoning methods, which translate a complex query into\na structured composition of feasible visual tasks, have exhibited a strong\npotential in complicated multi-modal tasks. Empowered by recent advances in\nlarge language models (LLMs), this multi-modal challenge has been brought to a\nnew stage by treating LLMs as few-shot/zero-shot planners, i.e.,\nvision-language (VL) programming. Such methods, despite their numerous merits,\nsuffer from challenges due to LLM planning mistakes or inaccuracy of visual\nexecution modules, lagging behind the non-compositional models. In this work,\nwe devise a \"plug-and-play\" method, ExoViP, to correct errors in both the\nplanning and execution stages through introspective verification. We employ\nverification modules as \"exoskeletons\" to enhance current VL programming\nschemes. Specifically, our proposed verification module utilizes a mixture of\nthree sub-verifiers to validate predictions after each reasoning step,\nsubsequently calibrating the visual module predictions and refining the\nreasoning trace planned by LLMs. Experimental results on two representative VL\nprogramming methods showcase consistent improvements on five compositional\nreasoning tasks on standard benchmarks. In light of this, we believe that\nExoViP can foster better performance and generalization on open-domain\nmulti-modal challenges.", "categories": "cs.CV", "created": "2024-08-04", "doi": null, "arxiv_id": "2408.02210"}
{"title": "SceneMotifCoder: Example-driven Visual Program Learning for Generating\n  3D Object Arrangements", "authors": [], "abstract": "Despite advances in text-to-3D generation methods, generation of multi-object\narrangements remains challenging. Current methods exhibit failures in\ngenerating physically plausible arrangements that respect the provided text\ndescription. We present SceneMotifCoder (SMC), an example-driven framework for\ngenerating 3D object arrangements through visual program learning. SMC\nleverages large language models (LLMs) and program synthesis to overcome these\nchallenges by learning visual programs from example arrangements. These\nprograms are generalized into compact, editable meta-programs. When combined\nwith 3D object retrieval and geometry-aware optimization, they can be used to\ncreate object arrangements varying in arrangement structure and contained\nobjects. Our experiments show that SMC generates high-quality arrangements\nusing meta-programs learned from few examples. Evaluation results demonstrates\nthat object arrangements generated by SMC better conform to user-specified text\ndescriptions and are more physically plausible when compared with\nstate-of-the-art text-to-3D generation and layout methods.", "categories": "cs.GR", "created": "2024-08-04", "doi": null, "arxiv_id": "2408.02211"}
{"title": "Demystifying AMD SEV Performance Penalty for NFV Deployment", "authors": [], "abstract": "Network Function Virtualization (NFV) has shifted communication networks\ntowards more adaptable software solutions, but this transition raises new\nsecurity concerns, particularly in public cloud deployments. While Intel's\nSoftware Guard Extensions (SGX) offers a potential remedy, it requires complex\napplication adaptations. This paper investigates AMD's Secure Encrypted\nVirtualization (SEV) as an alternative approach for securing NFV. SEV encrypts\nvirtual machine (VM) memory, protecting it from threats, including those at the\nhypervisor level, without requiring application modifications. We explore the\npracticality and performance implications of executing native network function\n(NF) implementations in AMD SEV-SNP, the latest iteration of SEV. Our study\nfocuses on running an unmodified Snort NF within SEV. Results show an average\nperformance penalty of approximately 20% across various traffic and packet\nconfigurations, demonstrating a trade-off between security and performance that\nmay be acceptable for many NFV deployments.", "categories": "cs.NI", "created": "2024-08-04", "doi": null, "arxiv_id": "2408.02212"}
{"title": "Is Large Language Model Good at Database Knob Tuning? A Comprehensive\n  Experimental Evaluation", "authors": [], "abstract": "Knob tuning plays a crucial role in optimizing databases by adjusting knobs\nto enhance database performance. However, traditional tuning methods often\nfollow a Try-Collect-Adjust approach, proving inefficient and\ndatabase-specific. Moreover, these methods are often opaque, making it\nchallenging for DBAs to grasp the underlying decision-making process.\n  The emergence of large language models (LLMs) like GPT-4 and Claude-3 has\nexcelled in complex natural language tasks, yet their potential in database\nknob tuning remains largely unexplored. This study harnesses LLMs as\nexperienced DBAs for knob-tuning tasks with carefully designed prompts. We\nidentify three key subtasks in the tuning system: knob pruning, model\ninitialization, and knob recommendation, proposing LLM-driven solutions to\nreplace conventional methods for each subtask.\n  We conduct extensive experiments to compare LLM-driven approaches against\ntraditional methods across the subtasks to evaluate LLMs' efficacy in the knob\ntuning domain. Furthermore, we explore the adaptability of LLM-based solutions\nin diverse evaluation settings, encompassing new benchmarks, database engines,\nand hardware environments. Our findings reveal that LLMs not only match or\nsurpass traditional methods but also exhibit notable interpretability by\ngenerating responses in a coherent ``chain-of-thought'' manner. We further\nobserve that LLMs exhibit remarkable generalizability through simple\nadjustments in prompts, eliminating the necessity for additional training or\nextensive code modifications.\n  Drawing insights from our experimental findings, we identify several\nopportunities for future research aimed at advancing the utilization of LLMs in\nthe realm of database management.", "categories": "cs.DB cs.AI", "created": "2024-08-04", "doi": null, "arxiv_id": "2408.02213"}
{"title": "More Than Positive and Negative: Communicating Fine Granularity in\n  Medical Diagnosis", "authors": [], "abstract": "With the advance of deep learning, much progress has been made in building\npowerful artificial intelligence (AI) systems for automatic Chest X-ray (CXR)\nanalysis. Most existing AI models are trained to be a binary classifier with\nthe aim of distinguishing positive and negative cases. However, a large gap\nexists between the simple binary setting and complicated real-world medical\nscenarios. In this work, we reinvestigate the problem of automatic radiology\ndiagnosis. We first observe that there is considerable diversity among cases\nwithin the positive class, which means simply classifying them as positive\nloses many important details. This motivates us to build AI models that can\ncommunicate fine-grained knowledge from medical images like human experts. To\nthis end, we first propose a new benchmark on fine granularity learning from\nmedical images. Specifically, we devise a division rule based on medical\nknowledge to divide positive cases into two subcategories, namely atypical\npositive and typical positive. Then, we propose a new metric termed\nAUC$^\\text{FG}$ on the two subcategories for evaluation of the ability to\nseparate them apart. With the proposed benchmark, we encourage the community to\ndevelop AI diagnosis systems that could better learn fine granularity from\nmedical images. Last, we propose a simple risk modulation approach to this\nproblem by only using coarse labels in training. Empirical results show that\ndespite its simplicity, the proposed method achieves superior performance and\nthus serves as a strong baseline.", "categories": "cs.CV", "created": "2024-08-04", "doi": null, "arxiv_id": "2408.02214"}
{"title": "Exploring Query Understanding for Amazon Product Search", "authors": [], "abstract": "Online shopping platforms, such as Amazon, offer services to billions of\npeople worldwide. Unlike web search or other search engines, product search\nengines have their unique characteristics, primarily featuring short queries\nwhich are mostly a combination of product attributes and structured product\nsearch space. The uniqueness of product search underscores the crucial\nimportance of the query understanding component. However, there are limited\nstudies focusing on exploring this impact within real-world product search\nengines. In this work, we aim to bridge this gap by conducting a comprehensive\nstudy and sharing our year-long journey investigating how the query\nunderstanding service impacts Amazon Product Search. Firstly, we explore how\nquery understanding-based ranking features influence the ranking process. Next,\nwe delve into how the query understanding system contributes to understanding\nthe performance of a ranking model. Building on the insights gained from our\nstudy on the evaluation of the query understanding-based ranking model, we\npropose a query understanding-based multi-task learning framework for ranking.\nWe present our studies and investigations using the real-world system on Amazon\nSearch.", "categories": "cs.IR", "created": "2024-08-04", "doi": null, "arxiv_id": "2408.02215"}
{"title": "Climate-Driven Doubling of Maize Loss Probability in U.S. Crop\n  Insurance: Spatiotemporal Prediction and Possible Policy Responses", "authors": [], "abstract": "Climate change not only threatens agricultural producers but also strains\nfinancial institutions. These important food system actors include government\nentities tasked with both insuring grower livelihoods and supporting response\nto continued global warming. We use an artificial neural network to predict\nfuture maize yields in the U.S. Corn Belt, finding alarming changes to\ninstitutional risk exposure within the Federal Crop Insurance Program.\nSpecifically, our machine learning method anticipates more frequent and more\nsevere yield losses that would result in the annual probability of Yield\nProtection (YP) claims to more than double at mid-century relative to\nsimulations without continued climate change. Furthermore, our dual finding of\nrelatively unchanged average yields paired with decreasing yield stability\nreveals targeted opportunities to adjust coverage formulas to include\nvariability. This important structural shift may help regulators support grower\nadaptation to continued climate change by recognizing the value of\nrisk-reducing strategies such as regenerative agriculture. Altogether, paired\nwith open source interactive tools for deeper investigation, our risk profile\nsimulations fill an actionable gap in current understanding, bridging granular\nhistoric yield estimation and climate-informed prediction of future\ninsurer-relevant loss.", "categories": "cs.LG q-fin.RM", "created": "2024-08-04", "doi": null, "arxiv_id": "2408.02217"}
{"title": "Enabling Practical Transparent Checkpointing for MPI: A Topological Sort\n  Approach", "authors": [], "abstract": "MPI is the de facto standard for parallel computing on a cluster of\ncomputers. Checkpointing is an important component in any strategy for software\nresilience and for long-running jobs that must be executed by chaining together\ntime-bounded resource allocations. This work solves an old problem: a practical\nand general algorithm for transparent checkpointing of MPI that is both\nefficient and compatible with most of the latest network software. Transparent\ncheckpointing is attractive due to its generality and ease of use for most MPI\napplication developers. Earlier efforts at transparent checkpointing for MPI,\none decade ago, had two difficult problems: (i) by relying on a specific MPI\nimplementation tied to a specific network technology; and (ii) by failing to\ndemonstrate sufficiently low runtime overhead.\n  Problem (i) (network dependence) was already solved in 2019 by MANA's\nintroduction of split processes. Problem (ii) (efficient runtime overhead) is\nsolved in this work. This paper introduces an approach that avoids these\nlimitations, employing a novel topological sort to algorithmically determine a\nsafe future synchronization point. The algorithm is valid for both blocking and\nnon-blocking collective communication in MPI. We demonstrate the efficacy and\nscalability of our approach through both micro-benchmarks and a set of five\nreal-world MPI applications, notably including the widely used VASP (Vienna Ab\nInitio Simulation Package), which is responsible for 11% of the workload on the\nPerlmutter supercomputer at Lawrence Berkley National Laboratory. VASP was\npreviously cited as a special challenge for checkpointing, in part due to its\nmulti-algorithm codes.", "categories": "cs.DC", "created": "2024-08-04", "doi": null, "arxiv_id": "2408.02218"}
{"title": "Static Code Analysis with CodeChecker", "authors": [], "abstract": "CodeChecker is an open source project that integrates different static\nanalysis tools such as the Clang Static Analyzer and Clang-Tidy into the build\nsystems, continuous integration loops, and development workflows of C++\nprogrammers. It has a powerful issue management system to make it easier to\nevaluate the reports of the static analysis tools.\n  This document was handed out as supportive material for a code analysis\nlecture at the 2018 3COWS conference in Kosice, Slovakia.", "categories": "cs.SE", "created": "2024-08-04", "doi": null, "arxiv_id": "2408.02220"}
{"title": "SoK: Fighting Counterfeits with Cyber-Physical Synergy Based on\n  Physically-Unclonable Identifiers of Paper Surface", "authors": [], "abstract": "Counterfeit products cause severe harm to public safety and health by\npenetrating untrusted supply chains. Numerous anti-counterfeiting techniques\nhave been proposed, among which the use of inherent, unclonable irregularities\nof paper surfaces has shown considerable potential as a high-performance\neconomical solution. Prior works do not consider supply chains cohesively,\neither focusing on creating or improving unclonable identifiers or on securing\ndigital records of products. This work aims to systematically unify these two\nseparate but connected research areas by comprehensively analyzing the needs of\nsupply chains. We construct a generalized paper-based authentication framework\nand identify important shortcomings and promising ideas in the existing\nliterature. Next, we do a stage-wise security analysis of our consolidated\nframework by drawing inspiration from works in signal processing, cryptography,\nand biometric systems. Finally, we examine key representative scenarios that\nillustrate the range of practical and technical challenges in real-world supply\nchains, and we outline the best practices to guide future research.", "categories": "cs.CR", "created": "2024-08-04", "doi": null, "arxiv_id": "2408.02221"}
{"title": "Cross-modulated Attention Transformer for RGBT Tracking", "authors": [], "abstract": "Existing Transformer-based RGBT trackers achieve remarkable performance\nbenefits by leveraging self-attention to extract uni-modal features and\ncross-attention to enhance multi-modal feature interaction and template-search\ncorrelation computation. Nevertheless, the independent search-template\ncorrelation calculations ignore the consistency between branches, which can\nresult in ambiguous and inappropriate correlation weights. It not only limits\nthe intra-modal feature representation, but also harms the robustness of\ncross-attention for multi-modal feature interaction and search-template\ncorrelation computation. To address these issues, we propose a novel approach\ncalled Cross-modulated Attention Transformer (CAFormer), which performs\nintra-modality self-correlation, inter-modality feature interaction, and\nsearch-template correlation computation in a unified attention model, for RGBT\ntracking. In particular, we first independently generate correlation maps for\neach modality and feed them into the designed Correlation Modulated Enhancement\nmodule, modulating inaccurate correlation weights by seeking the consensus\nbetween modalities. Such kind of design unifies self-attention and\ncross-attention schemes, which not only alleviates inaccurate attention weight\ncomputation in self-attention but also eliminates redundant computation\nintroduced by extra cross-attention scheme. In addition, we propose a\ncollaborative token elimination strategy to further improve tracking inference\nefficiency and accuracy. Extensive experiments on five public RGBT tracking\nbenchmarks show the outstanding performance of the proposed CAFormer against\nstate-of-the-art methods.", "categories": "cs.CV", "created": "2024-08-04", "doi": null, "arxiv_id": "2408.02222"}
{"title": "Large Language Model Aided QoS Prediction for Service Recommendation", "authors": [], "abstract": "Large language models (LLMs) have seen rapid improvement in the recent years,\nand are used in a wider range of applications. After being trained on large\ntext corpus, LLMs obtain the capability of extracting rich features from\ntextual data. Such capability is potentially useful for the web service\nrecommendation task, where the web users and services have intrinsic attributes\nthat can be described using natural language sentences and are useful for\nrecommendation. In this paper, we explore the possibility and practicality of\nusing LLMs for web service recommendation. We propose the large language model\naided QoS prediction (llmQoS) model, which use LLMs to extract useful\ninformation from attributes of web users and services via descriptive\nsentences. This information is then used in combination with the QoS values of\nhistorical interactions of users and services, to predict QoS values for any\ngiven user-service pair. Our proposed model is shown to overcome the data\nsparsity issue for QoS prediction. We show that on the WSDream dataset, llmQoS\noutperforms comparable baseline models consistently.", "categories": "cs.LG cs.DC", "created": "2024-08-04", "doi": null, "arxiv_id": "2408.02223"}
