{"title": "Cops and Attacking Robbers with Cycle Constraints", "authors": [], "abstract": "This paper considers the Cops and Attacking Robbers game, a variant of Cops\nand Robbers, where the robber is empowered to attack a cop in the same way a\ncop can capture the robber. In a graph $G$, the number of cops required to\ncapture a robber in the Cops and Attacking Robbers game is denoted by\n$\\attCop(G)$. We characterise the triangle-free graphs $G$ with $\\attCop(G)\n\\leq 2$ via a natural generalisation of the cop-win characterisation by\nNowakowski and Winkler \\cite{nowakowski1983vertex}. We also prove that all\nbipartite planar graphs $G$ have $\\attCop(G) \\leq 4$ and show this is tight by\nconstructing a bipartite planar graph $G$ with $\\attCop(G) = 4$. Finally we\nconstruct $17$ non-isomorphic graphs $H$ of order $58$ with $\\attCop(H) = 6$\nand $\\cop(H)=3$. This provides the first example of a graph $H$ with\n$\\attCop(H) - \\cop(H) \\geq 3$ extending work by Bonato, Finbow, Gordinowicz,\nHaidar, Kinnersley, Mitsche, Pra\\l{}at, and Stacho \\cite{bonato2014robber}. We\nconclude with a list of conjectures and open problems.", "categories": "math.CO cs.DM", "created": "2024-08-05", "doi": null, "arxiv_id": "2408.02225"}
{"title": "REVISION: Rendering Tools Enable Spatial Fidelity in Vision-Language\n  Models", "authors": [], "abstract": "Text-to-Image (T2I) and multimodal large language models (MLLMs) have been\nadopted in solutions for several computer vision and multimodal learning tasks.\nHowever, it has been found that such vision-language models lack the ability to\ncorrectly reason over spatial relationships. To tackle this shortcoming, we\ndevelop the REVISION framework which improves spatial fidelity in\nvision-language models. REVISION is a 3D rendering based pipeline that\ngenerates spatially accurate synthetic images, given a textual prompt. REVISION\nis an extendable framework, which currently supports 100+ 3D assets, 11 spatial\nrelationships, all with diverse camera perspectives and backgrounds. Leveraging\nimages from REVISION as additional guidance in a training-free manner\nconsistently improves the spatial consistency of T2I models across all spatial\nrelationships, achieving competitive performance on the VISOR and T2I-CompBench\nbenchmarks. We also design RevQA, a question-answering benchmark to evaluate\nthe spatial reasoning abilities of MLLMs, and find that state-of-the-art models\nare not robust to complex spatial reasoning under adversarial settings. Our\nresults and findings indicate that utilizing rendering-based frameworks is an\neffective approach for developing spatially-aware generative models.", "categories": "cs.CV", "created": "2024-08-05", "doi": null, "arxiv_id": "2408.02231"}
{"title": "A Multi-Source Heterogeneous Knowledge Injected Prompt Learning Method\n  for Legal Charge Prediction", "authors": [], "abstract": "Legal charge prediction, an essential task in legal AI, seeks to assign\naccurate charge labels to case descriptions, attracting significant recent\ninterest. Existing methods primarily employ diverse neural network structures\nfor modeling case descriptions directly, failing to effectively leverage\nmulti-source external knowledge. We propose a prompt learning framework-based\nmethod that simultaneously leverages multi-source heterogeneous external\nknowledge from a legal knowledge base, a conversational LLM, and related legal\narticles. Specifically, we match knowledge snippets in case descriptions via\nthe legal knowledge base and encapsulate them into the input through a hard\nprompt template. Additionally, we retrieve legal articles related to a given\ncase description through contrastive learning, and then obtain factual elements\nwithin the case description through a conversational LLM. We fuse the embedding\nvectors of soft prompt tokens with the encoding vector of factual elements to\nachieve knowledge-enhanced model forward inference. Experimental results show\nthat our method achieved state-of-the-art results on CAIL-2018, the largest\nlegal charge prediction dataset, and our method has lower data dependency. Case\nstudies also demonstrate our method's strong interpretability.", "categories": "cs.CL cs.AI", "created": "2024-08-05", "doi": null, "arxiv_id": "2408.02233"}
{"title": "An integrated view of Quantum Technology? Mapping Media, Business, and\n  Policy Narratives", "authors": [], "abstract": "Narratives play a vital role in shaping public perceptions and policy on\nemerging technologies like quantum technology (QT). However, little is known\nabout the construction and variation of QT narratives across societal domains.\nThis study examines how QT is presented in business, media, and government\ntexts using thematic narrative analysis. Our research design utilizes an\nextensive dataset of 36 government documents, 165 business reports, and 2,331\nmedia articles published over 20 years. We employ a computational social\nscience approach, combining BERTopic modeling with qualitative assessment to\nextract themes and narratives. The findings show that public discourse on QT\nreflects prevailing social and political agendas, focusing on technical and\ncommercial potential, global conflicts, national strategies, and social issues.\nMedia articles provide the most balanced coverage, while business and\ngovernment discourses often overlook societal implications. We discuss the\nramifications for integrating QT into society and the need for wellinformed\npublic discourse.", "categories": "cs.CY", "created": "2024-08-05", "doi": null, "arxiv_id": "2408.02236"}
{"title": "Do Large Language Models Speak All Languages Equally? A Comparative\n  Study in Low-Resource Settings", "authors": [], "abstract": "Large language models (LLMs) have garnered significant interest in natural\nlanguage processing (NLP), particularly their remarkable performance in various\ndownstream tasks in resource-rich languages. Recent studies have highlighted\nthe limitations of LLMs in low-resource languages, primarily focusing on binary\nclassification tasks and giving minimal attention to South Asian languages.\nThese limitations are primarily attributed to constraints such as dataset\nscarcity, computational costs, and research gaps specific to low-resource\nlanguages. To address this gap, we present datasets for sentiment and hate\nspeech tasks by translating from English to Bangla, Hindi, and Urdu,\nfacilitating research in low-resource language processing. Further, we\ncomprehensively examine zero-shot learning using multiple LLMs in English and\nwidely spoken South Asian languages. Our findings indicate that GPT-4\nconsistently outperforms Llama 2 and Gemini, with English consistently\ndemonstrating superior performance across diverse tasks compared to\nlow-resource languages. Furthermore, our analysis reveals that natural language\ninference (NLI) exhibits the highest performance among the evaluated tasks,\nwith GPT-4 demonstrating superior capabilities.", "categories": "cs.CL", "created": "2024-08-05", "doi": null, "arxiv_id": "2408.02237"}
{"title": "BOTS-LM: Training Large Language Models for Setswana", "authors": [], "abstract": "In this work we present BOTS-LM, a series of bilingual language models\nproficient in both Setswana and English. Leveraging recent advancements in data\navailability and efficient fine-tuning, BOTS-LM achieves performance similar to\nmodels significantly larger than itself while maintaining computational\nefficiency. Our initial release features an 8 billion parameter generative\nlarge language model, with upcoming 0.5 billion and 1 billion parameter large\nlanguage models and a 278 million parameter encoder-only model soon to be\nreleased. We find the 8 billion parameter model significantly outperforms\nLlama-3-70B and Aya 23 on English-Setswana translation tasks, approaching the\nperformance of dedicated machine translation models, while approaching 70B\nparameter performance on Setswana reasoning as measured by a machine translated\nsubset of the MMLU benchmark. To accompany the BOTS-LM series of language\nmodels, we release the largest Setswana web dataset, SetsText, totalling over\n267 million tokens. In addition, we release the largest machine translated\nSetswana dataset, the first and largest synthetic Setswana dataset, training\nand evaluation code, training logs, and MMLU-tsn, a machine translated subset\nof MMLU.", "categories": "cs.CL", "created": "2024-08-05", "doi": null, "arxiv_id": "2408.02239"}
{"title": "Scalable Multilevel Monte Carlo Methods Exploiting Parallel\n  Redistribution on Coarse Levels", "authors": [], "abstract": "We study an element agglomeration coarsening strategy that requires data\nredistribution at coarse levels when the number of coarse elements becomes\nsmaller than the used computational units (cores). The overall procedure\ngenerates coarse elements (general unstructured unions of fine grid elements)\nwithin the framework of element-based algebraic multigrid methods (or AMGe)\nstudied previously. The AMGe generated coarse spaces have the ability to\nexhibit approximation properties of the same order as the fine-level ones since\nby construction they contain the piecewise polynomials of the same order as the\nfine level ones. These approximation properties are key for the successful use\nof AMGe in multilevel solvers for nonlinear partial differential equations as\nwell as for multilevel Monte Carlo (MLMC) simulations. The ability to coarsen\nwithout being constrained by the number of available cores, as described in the\npresent paper, allows to improve the scalability of these solvers as well as in\nthe overall MLMC method. The paper illustrates this latter fact with detailed\nscalability study of MLMC simulations applied to model Darcy equations with a\nstochastic log-normal permeability field.", "categories": "math.NA cs.NA", "created": "2024-08-05", "doi": null, "arxiv_id": "2408.02241"}
{"title": "Methods to improve run time of hydrologic models: opportunities and\n  challenges in the machine learning era", "authors": [], "abstract": "The application of Machine Learning (ML) to hydrologic modeling is fledgling.\nIts applicability to capture the dependencies on watersheds to forecast better\nwithin a short period is fascinating. One of the key reasons to adopt ML\nalgorithms over physics-based models is its computational efficiency advantage\nand flexibility to work with various data sets. The diverse applications,\nparticularly in emergency response and expanding over a large scale, demand the\nhydrological model in a short time and make researchers adopt data-driven\nmodeling approaches unhesitatingly. In this work, in the era of ML and deep\nlearning (DL), how it can help to improve the overall run time of physics-based\nmodel and potential constraints that should be addressed while modeling. This\npaper covers the opportunities and challenges of adopting ML for hydrological\nmodeling and subsequently how it can help to improve the simulation time of\nphysics-based models and future works that should be addressed.", "categories": "cs.LG", "created": "2024-08-05", "doi": null, "arxiv_id": "2408.02242"}
{"title": "Self-Enhancing Video Data Management System for Compositional Events\n  with Large Language Models [Technical Report]", "authors": [], "abstract": "Complex video queries can be answered by decomposing them into modular\nsubtasks. However, existing video data management systems assume the existence\nof predefined modules for each subtask. We introduce VOCAL-UDF, a novel\nself-enhancing system that supports compositional queries over videos without\nthe need for predefined modules. VOCAL-UDF automatically identifies and\nconstructs missing modules and encapsulates them as user-defined functions\n(UDFs), thus expanding its querying capabilities. To achieve this, we formulate\na unified UDF model that leverages large language models (LLMs) to aid in new\nUDF generation. VOCAL-UDF handles a wide range of concepts by supporting both\nprogram-based UDFs (i.e., Python functions generated by LLMs) and\ndistilled-model UDFs (lightweight vision models distilled from strong\npretrained models). To resolve the inherent ambiguity in user intent, VOCAL-UDF\ngenerates multiple candidate UDFs and uses active learning to efficiently\nselect the best one. With the self-enhancing capability, VOCAL-UDF\nsignificantly improves query performance across three video datasets.", "categories": "cs.DB", "created": "2024-08-05", "doi": null, "arxiv_id": "2408.02243"}
{"title": "Evaluating Vision-Language Models for Zero-Shot Detection,\n  Classification, and Association of Motorcycles, Passengers, and Helmets", "authors": [], "abstract": "Motorcycle accidents pose significant risks, particularly when riders and\npassengers do not wear helmets. This study evaluates the efficacy of an\nadvanced vision-language foundation model, OWLv2, in detecting and classifying\nvarious helmet-wearing statuses of motorcycle occupants using video data. We\nextend the dataset provided by the CVPR AI City Challenge and employ a cascaded\nmodel approach for detection and classification tasks, integrating OWLv2 and\nCNN models. The results highlight the potential of zero-shot learning to\naddress challenges arising from incomplete and biased training datasets,\ndemonstrating the usage of such models in detecting motorcycles, helmet usage,\nand occupant positions under varied conditions. We have achieved an average\nprecision of 0.5324 for helmet detection and provided precision-recall curves\ndetailing the detection and classification performance. Despite limitations\nsuch as low-resolution data and poor visibility, our research shows promising\nadvancements in automated vehicle safety and traffic safety enforcement\nsystems.", "categories": "cs.CV cs.AI", "created": "2024-08-05", "doi": null, "arxiv_id": "2408.02244"}
{"title": "Curriculum learning based pre-training using Multi-Modal Contrastive\n  Masked Autoencoders", "authors": [], "abstract": "In this paper, we propose a new pre-training method for image understanding\ntasks under Curriculum Learning (CL) paradigm which leverages RGB-D. The method\nutilizes Multi-Modal Contrastive Masked Autoencoder and Denoising techniques.\nRecent approaches either use masked autoencoding (e.g., MultiMAE) or\ncontrastive learning(e.g., Pri3D, or combine them in a single contrastive\nmasked autoencoder architecture such as CMAE and CAV-MAE. However, none of the\nsingle contrastive masked autoencoder is applicable to RGB-D datasets. To\nimprove the performance and efficacy of such methods, we propose a new\npre-training strategy based on CL. Specifically, in the first stage, we\npre-train the model using contrastive learning to learn cross-modal\nrepresentations. In the second stage, we initialize the modality-specific\nencoders using the weights from the first stage and then pre-train the model\nusing masked autoencoding and denoising/noise prediction used in diffusion\nmodels. Masked autoencoding focuses on reconstructing the missing patches in\nthe input modality using local spatial correlations, while denoising learns\nhigh frequency components of the input data. Our approach is scalable, robust\nand suitable for pre-training with limited RGB-D datasets. Extensive\nexperiments on multiple datasets such as ScanNet, NYUv2 and SUN RGB-D show the\nefficacy and superior performance of our approach. Specifically, we show an\nimprovement of +1.0% mIoU against Mask3D on ScanNet semantic segmentation. We\nfurther demonstrate the effectiveness of our approach in low-data regime by\nevaluating it for semantic segmentation task against the state-of-the-art\nmethods.", "categories": "cs.CV", "created": "2024-08-05", "doi": null, "arxiv_id": "2408.02245"}
{"title": "AMIDER: A Multidisciplinary Research Database and Its Application to\n  Promote Open Science", "authors": [], "abstract": "The AMIDER, Advanced Multidisciplinary Integrated-Database for Exploring new\nResearch, is a newly developed research data catalog to demonstrate an advanced\ndatabase application. AMIDER is characterized as a multidisciplinary database\nequipped with a user-friendly web application. Its catalog view displays\ndiverse research data at once beyond any limitation of each individual\ndiscipline. Some useful functions, such as a selectable data download, data\nformat conversion, and display of data visual information, are also\nimplemented. Further advanced functions, such as visualization of dataset\nmutual relationship, are also implemented as a preliminary trial. These\ncharacteristics and functions are expected to enhance the accessibility to\nindividual research data, even from non-expertized users, and be helpful for\ncollaborations among diverse scientific fields beyond individual disciplines.\nMultidisciplinary data management is also one of AMIDER's uniqueness, where\nvarious metadata schemas can be mapped to a uniform metadata table, and\nstandardized and self-describing data formats are adopted. AMIDER website\n(https://amider.rois.ac.jp/) had been launched in April 2024. As of July 2024,\nover 15,000 metadata in various research fields of polar science have been\nregistered in the database, and approximately 500 visitors are viewing the\nwebsite every day on average. Expansion of the database to further\nmultidisciplinary scientific fields, not only polar science, is planned, and\nadvanced attempts, such as applying Natural Language Processing (NLP) to\nmetadata, have also been considered.", "categories": "cs.DB", "created": "2024-08-05", "doi": null, "arxiv_id": "2408.02246"}
{"title": "ReDel: A Toolkit for LLM-Powered Recursive Multi-Agent Systems", "authors": [], "abstract": "Recently, there has been increasing interest in using Large Language Models\n(LLMs) to construct complex multi-agent systems to perform tasks such as\ncompiling literature reviews, drafting consumer reports, and planning\nvacations. Many tools and libraries exist for helping create such systems,\nhowever none support recursive multi-agent systems -- where the models\nthemselves flexibly decide when to delegate tasks and how to organize their\ndelegation structure. In this work, we introduce ReDel: a toolkit for recursive\nmulti-agent systems that supports custom tool-use, delegation schemes,\nevent-based logging, and interactive replay in an easy-to-use web interface. We\nshow that, using ReDel, we are able to achieve significant performance gains on\nagentic benchmarks and easily identify potential areas of improvements through\nthe visualization and debugging tools. Our code, documentation, and PyPI\npackage are open-source and free to use under the MIT license.", "categories": "cs.CL cs.MA cs.SE", "created": "2024-08-05", "doi": null, "arxiv_id": "2408.02248"}
{"title": "Hierarchical Clustering using Reversible Binary Cellular Automata for\n  High-Dimensional Data", "authors": [], "abstract": "This work proposes a hierarchical clustering algorithm for high-dimensional\ndatasets using the cyclic space of reversible finite cellular automata. In\ncellular automaton (CA) based clustering, if two objects belong to the same\ncycle, they are closely related and considered as part of the same cluster.\nHowever, if a high-dimensional dataset is clustered using the cycles of one CA,\nclosely related objects may belong to different cycles. This paper identifies\nthe relationship between objects in two different cycles based on the median of\nall elements in each cycle so that they can be grouped in the next stage.\nFurther, to minimize the number of intermediate clusters which in turn reduces\nthe computational cost, a rule selection strategy is taken to find the best\nrules based on information propagation and cycle structure. After encoding the\ndataset using frequency-based encoding such that the consecutive data elements\nmaintain a minimum hamming distance in encoded form, our proposed clustering\nalgorithm iterates over three stages to finally cluster the data elements into\nthe desired number of clusters given by user. This algorithm can be applied to\nvarious fields, including healthcare, sports, chemical research, agriculture,\netc. When verified over standard benchmark datasets with various performance\nmetrics, our algorithm is at par with the existing algorithms with quadratic\ntime complexity.", "categories": "cs.FL cs.CV", "created": "2024-08-05", "doi": null, "arxiv_id": "2408.02250"}
{"title": "Advancing Post-OCR Correction: A Comparative Study of Synthetic Data", "authors": [], "abstract": "This paper explores the application of synthetic data in the post-OCR domain\non multiple fronts by conducting experiments to assess the impact of data\nvolume, augmentation, and synthetic data generation methods on model\nperformance. Furthermore, we introduce a novel algorithm that leverages\ncomputer vision feature detection algorithms to calculate glyph similarity for\nconstructing post-OCR synthetic data. Through experiments conducted across a\nvariety of languages, including several low-resource ones, we demonstrate that\nmodels like ByT5 can significantly reduce Character Error Rates (CER) without\nthe need for manually annotated data, and our proposed synthetic data\ngeneration method shows advantages over traditional methods, particularly in\nlow-resource languages.", "categories": "cs.CL", "created": "2024-08-05", "doi": null, "arxiv_id": "2408.02253"}
{"title": "To Aggregate or Not to Aggregate. That is the Question: A Case Study on\n  Annotation Subjectivity in Span Prediction", "authors": [], "abstract": "This paper explores the task of automatic prediction of text spans in a legal\nproblem description that support a legal area label. We use a corpus of problem\ndescriptions written by laypeople in English that is annotated by practising\nlawyers. Inherent subjectivity exists in our task because legal area\ncategorisation is a complex task, and lawyers often have different views on a\nproblem, especially in the face of legally-imprecise descriptions of issues.\nExperiments show that training on majority-voted spans outperforms training on\ndisaggregated ones.", "categories": "cs.CL", "created": "2024-08-05", "doi": null, "arxiv_id": "2408.02257"}
{"title": "Cross-Domain Semantic Segmentation on Inconsistent Taxonomy using VLMs", "authors": [], "abstract": "The challenge of semantic segmentation in Unsupervised Domain Adaptation\n(UDA) emerges not only from domain shifts between source and target images but\nalso from discrepancies in class taxonomies across domains. Traditional UDA\nresearch assumes consistent taxonomy between the source and target domains,\nthereby limiting their ability to recognize and adapt to the taxonomy of the\ntarget domain. This paper introduces a novel approach, Cross-Domain Semantic\nSegmentation on Inconsistent Taxonomy using Vision Language Models (CSI), which\neffectively performs domain-adaptive semantic segmentation even in situations\nof source-target class mismatches. CSI leverages the semantic generalization\npotential of Visual Language Models (VLMs) to create synergy with previous UDA\nmethods. It leverages segment reasoning obtained through traditional UDA\nmethods, combined with the rich semantic knowledge embedded in VLMs, to relabel\nnew classes in the target domain. This approach allows for effective adaptation\nto extended taxonomies without requiring any ground truth label for the target\ndomain. Our method has shown to be effective across various benchmarks in\nsituations of inconsistent taxonomy settings (coarse-to-fine taxonomy and open\ntaxonomy) and demonstrates consistent synergy effects when integrated with\nprevious state-of-the-art UDA methods. The implementation is available at\nhttp://github.com/jkee58/CSI.", "categories": "cs.CV", "created": "2024-08-05", "doi": null, "arxiv_id": "2408.02261"}
{"title": "Towards Identifying Code Proficiency through the Analysis of Python\n  Textbooks", "authors": [], "abstract": "Python, one of the most prevalent programming languages today, is widely\nutilized in various domains, including web development, data science, machine\nlearning, and DevOps. Recent scholarly efforts have proposed a methodology to\nassess Python competence levels, similar to how proficiency in natural\nlanguages is evaluated. This method involves assigning levels of competence to\nPython constructs, for instance, placing simple 'print' statements at the most\nbasic level and abstract base classes at the most advanced. The aim is to gauge\nthe level of proficiency a developer must have to understand a piece of source\ncode. This is particularly crucial for software maintenance and evolution\ntasks, such as debugging or adding new features. For example, in a code review\nprocess, this method could determine the competence level required for\nreviewers. However, categorizing Python constructs by proficiency levels poses\nsignificant challenges. Prior attempts, which relied heavily on expert opinions\nand developer surveys, have led to considerable discrepancies. In response,\nthis paper presents a new approach to identifying Python competency levels\nthrough the systematic analysis of introductory Python programming textbooks.\nBy comparing the sequence in which Python constructs are introduced in these\ntextbooks with the current state of the art, we have uncovered notable\ndiscrepancies in the order of introduction of Python constructs. Our study\nunderscores a misalignment in the sequences, demonstrating that pinpointing\nproficiency levels is not trivial. Insights from the study serve as pivotal\nsteps toward reinforcing the idea that textbooks serve as a valuable source for\nevaluating developers' proficiency, and particularly in terms of their ability\nto undertake maintenance and evolution tasks.", "categories": "cs.SE", "created": "2024-08-05", "doi": null, "arxiv_id": "2408.02262"}
{"title": "VoxelTrack: Exploring Voxel Representation for 3D Point Cloud Object\n  Tracking", "authors": [], "abstract": "Current LiDAR point cloud-based 3D single object tracking (SOT) methods\ntypically rely on point-based representation network. Despite demonstrated\nsuccess, such networks suffer from some fundamental problems: 1) It contains\npooling operation to cope with inherently disordered point clouds, hindering\nthe capture of 3D spatial information that is useful for tracking, a regression\ntask. 2) The adopted set abstraction operation hardly handles\ndensity-inconsistent point clouds, also preventing 3D spatial information from\nbeing modeled. To solve these problems, we introduce a novel tracking\nframework, termed VoxelTrack. By voxelizing inherently disordered point clouds\ninto 3D voxels and extracting their features via sparse convolution blocks,\nVoxelTrack effectively models precise and robust 3D spatial information,\nthereby guiding accurate position prediction for tracked objects. Moreover,\nVoxelTrack incorporates a dual-stream encoder with cross-iterative feature\nfusion module to further explore fine-grained 3D spatial information for\ntracking. Benefiting from accurate 3D spatial information being modeled, our\nVoxelTrack simplifies tracking pipeline with a single regression loss.\nExtensive experiments are conducted on three widely-adopted datasets including\nKITTI, NuScenes and Waymo Open Dataset. The experimental results confirm that\nVoxelTrack achieves state-of-the-art performance (88.3%, 71.4% and 63.6% mean\nprecision on the three datasets, respectively), and outperforms the existing\ntrackers with a real-time speed of 36 Fps on a single TITAN RTX GPU. The source\ncode and model will be released.", "categories": "cs.CV", "created": "2024-08-05", "doi": null, "arxiv_id": "2408.02263"}
{"title": "Explain via Any Concept: Concept Bottleneck Model with Open Vocabulary\n  Concepts", "authors": [], "abstract": "The concept bottleneck model (CBM) is an interpretable-by-design framework\nthat makes decisions by first predicting a set of interpretable concepts, and\nthen predicting the class label based on the given concepts. Existing CBMs are\ntrained with a fixed set of concepts (concepts are either annotated by the\ndataset or queried from language models). However, this closed-world assumption\nis unrealistic in practice, as users may wonder about the role of any desired\nconcept in decision-making after the model is deployed. Inspired by the large\nsuccess of recent vision-language pre-trained models such as CLIP in zero-shot\nclassification, we propose \"OpenCBM\" to equip the CBM with open vocabulary\nconcepts via: (1) Aligning the feature space of a trainable image feature\nextractor with that of a CLIP's image encoder via a prototype based feature\nalignment; (2) Simultaneously training an image classifier on the downstream\ndataset; (3) Reconstructing the trained classification head via any set of\nuser-desired textual concepts encoded by CLIP's text encoder. To reveal\npotentially missing concepts from users, we further propose to iteratively find\nthe closest concept embedding to the residual parameters during the\nreconstruction until the residual is small enough. To the best of our\nknowledge, our \"OpenCBM\" is the first CBM with concepts of open vocabularies,\nproviding users the unique benefit such as removing, adding, or replacing any\ndesired concept to explain the model's prediction even after a model is\ntrained. Moreover, our model significantly outperforms the previous\nstate-of-the-art CBM by 9% in the classification accuracy on the benchmark\ndataset CUB-200-2011.", "categories": "cs.CV", "created": "2024-08-05", "doi": null, "arxiv_id": "2408.02265"}
{"title": "CHORDination: Evaluating Visual Design Choices in Chord Diagrams for\n  Network Data", "authors": [], "abstract": "Chord diagrams are widely used for visualizing data connectivity and flow\nbetween nodes in a network. They are effective for representing complex\nstructures through an intuitive and visually appealing circular layout. While\nprevious work has focused on improving aesthetics and interactivity, the\ninfluence of fundamental design elements on user perception and information\nretrieval remains under-explored. In this study, we explored the three primary\ncomponents of chord diagram anatomy, namely the nodes, circular outline, and\narc connections, in three sequential experiment phases. In phase one, we\nconducted a controlled experiment (N=90) to find the perceptually and\ninformation optimized node widths (narrow, medium, wide) and quantities (low,\nmedium, high). This optimal set of node width and quantity sets the foundation\nfor subsequent evaluations and were kept fixed for consistency. In phase two of\nthe study, we conducted an expert design review for identifying the optimal\nradial tick marks and color gradients. Then in phase three, we evaluated the\nperceptual and information retrieval performance of the design choices in a\ncontrolled experiment (N=24) by comparing four chord diagram designs (baseline,\nradial tick marks, arc color gradients, both tick marks and color gradients).\nResults indicated that node width and quantity significantly affected users'\ninformation retrieval performance and subjective ratings, whereas the presence\nof tick marks predominantly influenced subjective experiences. Based on these\nfindings, we discuss the design implications of these visual elements and offer\nguidance and recommendations for optimizing chord diagram designs in network\nvisualization tasks.", "categories": "cs.HC", "created": "2024-08-05", "doi": null, "arxiv_id": "2408.02268"}
{"title": "Nonlinear Perturbation-based Non-Convex Optimization over Time-Varying\n  Networks", "authors": [], "abstract": "Decentralized optimization strategies are helpful for various applications,\nfrom networked estimation to distributed machine learning. This paper studies\nfinite-sum minimization problems described over a network of nodes and proposes\na computationally efficient algorithm that solves distributed convex problems\nand optimally finds the solution to locally non-convex objective functions. In\ncontrast to batch gradient optimization in some literature, our algorithm is on\na single-time scale with no extra inner consensus loop. It evaluates one\ngradient entry per node per time. Further, the algorithm addresses link-level\nnonlinearity representing, for example, logarithmic quantization of the\nexchanged data or clipping of the exchanged data bits. Leveraging\nperturbation-based theory and algebraic Laplacian network analysis proves\noptimal convergence and dynamics stability over time-varying and switching\nnetworks. The time-varying network setup might be due to packet drops or link\nfailures. Despite the nonlinear nature of the dynamics, we prove exact\nconvergence in the face of odd sign-preserving sector-bound nonlinear data\ntransmission over the links. Illustrative numerical simulations further\nhighlight our contributions.", "categories": "eess.SY cs.DC cs.SY eess.SP math.OC", "created": "2024-08-05", "doi": null, "arxiv_id": "2408.02269"}
{"title": "StyEmp: Stylizing Empathetic Response Generation via Multi-Grained\n  Prefix Encoder and Personality Reinforcement", "authors": [], "abstract": "Recent approaches for empathetic response generation mainly focus on\nemotional resonance and user understanding, without considering the system's\npersonality. Consistent personality is evident in real human expression and is\nimportant for creating trustworthy systems. To address this problem, we propose\nStyEmp, which aims to stylize the empathetic response generation with a\nconsistent personality. Specifically, it incorporates a multi-grained prefix\nmechanism designed to capture the intricate relationship between a system's\npersonality and its empathetic expressions. Furthermore, we introduce a\npersonality reinforcement module that leverages contrastive learning to\ncalibrate the generation model, ensuring that responses are both empathetic and\nreflective of a distinct personality. Automatic and human evaluations on the\nEMPATHETICDIALOGUES benchmark show that StyEmp outperforms competitive\nbaselines in terms of both empathy and personality expressions.", "categories": "cs.CL", "created": "2024-08-05", "doi": null, "arxiv_id": "2408.02271"}
{"title": "COM Kitchens: An Unedited Overhead-view Video Dataset as a\n  Vision-Language Benchmark", "authors": [], "abstract": "Procedural video understanding is gaining attention in the vision and\nlanguage community. Deep learning-based video analysis requires extensive data.\nConsequently, existing works often use web videos as training resources, making\nit challenging to query instructional contents from raw video observations. To\naddress this issue, we propose a new dataset, COM Kitchens. The dataset\nconsists of unedited overhead-view videos captured by smartphones, in which\nparticipants performed food preparation based on given recipes. Fixed-viewpoint\nvideo datasets often lack environmental diversity due to high camera setup\ncosts. We used modern wide-angle smartphone lenses to cover cooking counters\nfrom sink to cooktop in an overhead view, capturing activity without in-person\nassistance. With this setup, we collected a diverse dataset by distributing\nsmartphones to participants. With this dataset, we propose the novel\nvideo-to-text retrieval task Online Recipe Retrieval (OnRR) and new video\ncaptioning domain Dense Video Captioning on unedited Overhead-View videos\n(DVC-OV). Our experiments verified the capabilities and limitations of current\nweb-video-based SOTA methods in handling these tasks.", "categories": "cs.CV cs.CL cs.MM", "created": "2024-08-05", "doi": null, "arxiv_id": "2408.02272"}
{"title": "Accelerated 3D Maxwell Integral Equation Solver using the Interpolated\n  Factored Green Function Method", "authors": [], "abstract": "This article presents an $O(N\\log N)$ method for numerical solution of\nMaxwell's equations for dielectric scatterers using a 3D boundary integral\nequation (BIE) method. The underlying BIE method used is based on a hybrid\nNystr\\\"{o}m-collocation method using Chebyshev polynomials. It is well known\nthat such an approach produces a dense linear system, which requires $O(N^2)$\noperations in each step of an iterative solver. In this work, we propose an\napproach using the recently introduced Interpolated Factored Green's Function\n(IFGF) acceleration strategy to reduce the cost of each iteration to $O(N\\log\nN)$. To the best of our knowledge, this paper presents the first ever\napplication of the IFGF method to fully-vectorial 3D Maxwell problems. The\nChebyshev-based integral solver and IFGF method are first introduced, followed\nby the extension of the scalar IFGF to the vectorial Maxwell case. Several\nexamples are presented verifying the $O(N\\log N)$ computational complexity of\nthe approach, including scattering from spheres, complex CAD models, and\nnanophotonic waveguiding devices. In one particular example with more than 6\nmillion unknowns, the accelerated IFGF solver runs 42x faster than the\nunaccelerated method.", "categories": "math.NA cs.NA physics.comp-ph", "created": "2024-08-05", "doi": null, "arxiv_id": "2408.02274"}
{"title": "Geometric Algebra Meets Large Language Models: Instruction-Based\n  Transformations of Separate Meshes in 3D, Interactive and Controllable Scenes", "authors": [], "abstract": "This paper introduces a novel integration of Large Language Models (LLMs)\nwith Conformal Geometric Algebra (CGA) to revolutionize controllable 3D scene\nediting, particularly for object repositioning tasks, which traditionally\nrequires intricate manual processes and specialized expertise. These\nconventional methods typically suffer from reliance on large training datasets\nor lack a formalized language for precise edits. Utilizing CGA as a robust\nformal language, our system, shenlong, precisely models spatial transformations\nnecessary for accurate object repositioning. Leveraging the zero-shot learning\ncapabilities of pre-trained LLMs, shenlong translates natural language\ninstructions into CGA operations which are then applied to the scene,\nfacilitating exact spatial transformations within 3D scenes without the need\nfor specialized pre-training. Implemented in a realistic simulation\nenvironment, shenlong ensures compatibility with existing graphics pipelines.\nTo accurately assess the impact of CGA, we benchmark against robust Euclidean\nSpace baselines, evaluating both latency and accuracy. Comparative performance\nevaluations indicate that shenlong significantly reduces LLM response times by\n16% and boosts success rates by 9.6% on average compared to the traditional\nmethods. Notably, shenlong achieves a 100% perfect success rate in common\npractical queries, a benchmark where other systems fall short. These\nadvancements underscore shenlong's potential to democratize 3D scene editing,\nenhancing accessibility and fostering innovation across sectors such as\neducation, digital entertainment, and virtual reality.", "categories": "cs.CV cs.AI cs.GR", "created": "2024-08-05", "doi": null, "arxiv_id": "2408.02275"}
{"title": "Integrating a Digital Twin Concept in the Zero Emission Sea Transporter\n  (ZEST) Project for Sustainable Maritime Transport using Stonefish Simulator", "authors": [], "abstract": "In response to stringent emission reduction targets imposed by the\nInternational Maritime Organization (IMO) and the European Green Deal's Fit for\n55 legislation package, the maritime industry has shifted its focus towards\ndecarbonization. While significant attention has been placed on vessels\nexceeding 5,000 gross tons (GT), emissions from coastal and short sea shipping,\namounting to approximately 13% of global shipping transportation and 15% within\nthe European Union (EU), have not received adequate consideration. This\nabstract introduces the Zero Emission Sea Transporter (ZEST) project, designed\nto address this issue by developing a zero-emissions multi-purpose catamaran\nfor short sea route", "categories": "cs.RO", "created": "2024-08-05", "doi": null, "arxiv_id": "2408.02277"}
{"title": "DRFormer: Multi-Scale Transformer Utilizing Diverse Receptive Fields for\n  Long Time-Series Forecasting", "authors": [], "abstract": "Long-term time series forecasting (LTSF) has been widely applied in finance,\ntraffic prediction, and other domains. Recently, patch-based transformers have\nemerged as a promising approach, segmenting data into sub-level patches that\nserve as input tokens. However, existing methods mostly rely on predetermined\npatch lengths, necessitating expert knowledge and posing challenges in\ncapturing diverse characteristics across various scales. Moreover, time series\ndata exhibit diverse variations and fluctuations across different temporal\nscales, which traditional approaches struggle to model effectively. In this\npaper, we propose a dynamic tokenizer with a dynamic sparse learning algorithm\nto capture diverse receptive fields and sparse patterns of time series data. In\norder to build hierarchical receptive fields, we develop a multi-scale\nTransformer model, coupled with multi-scale sequence extraction, capable of\ncapturing multi-resolution features. Additionally, we introduce a group-aware\nrotary position encoding technique to enhance intra- and inter-group position\nawareness among representations across different temporal scales. Our proposed\nmodel, named DRFormer, is evaluated on various real-world datasets, and\nexperimental results demonstrate its superiority compared to existing methods.\nOur code is available at: https://github.com/ruixindingECNU/DRFormer.", "categories": "cs.LG cs.AI stat.ML", "created": "2024-08-05", "doi": "10.1145/3627673.3679724", "arxiv_id": "2408.02279"}
{"title": "Hardware Aware Ensemble Selection for Balancing Predictive Accuracy and\n  Cost", "authors": [], "abstract": "Automated Machine Learning (AutoML) significantly simplifies the deployment\nof machine learning models by automating tasks from data preprocessing to model\nselection to ensembling. AutoML systems for tabular data often employ post hoc\nensembling, where multiple models are combined to improve predictive accuracy.\nThis typically results in longer inference times, a major limitation in\npractical deployments. Addressing this, we introduce a hardware-aware ensemble\nselection approach that integrates inference time into post hoc ensembling. By\nleveraging an existing framework for ensemble selection with quality diversity\noptimization, our method evaluates ensemble candidates for their predictive\naccuracy and hardware efficiency. This dual focus allows for a balanced\nconsideration of accuracy and operational efficiency. Thus, our approach\nenables practitioners to choose from a Pareto front of accurate and efficient\nensembles. Our evaluation using 83 classification datasets shows that our\napproach sustains competitive accuracy and can significantly improve ensembles'\noperational efficiency. The results of this study provide a foundation for\nextending these principles to additional hardware constraints, setting the\nstage for the development of more resource-efficient AutoML systems.", "categories": "cs.LG cs.AI", "created": "2024-08-05", "doi": null, "arxiv_id": "2408.02280"}
{"title": "Enhanced Equilibria-Solving via Private Information Pre-Branch Structure\n  in Adversarial Team Games", "authors": [], "abstract": "In ex ante coordinated adversarial team games (ATGs), a team competes against\nan adversary, and the team members are only allowed to coordinate their\nstrategies before the game starts. The team-maxmin equilibrium with correlation\n(TMECor) is a suitable solution concept for ATGs. One class of TMECor-solving\nmethods transforms the problem into solving NE in two-player zero-sum games,\nleveraging well-established tools for the latter. However, existing methods are\nfundamentally action-based, resulting in poor generalizability and low solving\nefficiency due to the exponential growth in the size of the transformed game.\nTo address the above issues, we propose an efficient game transformation method\nbased on private information, where all team members are represented by a\nsingle coordinator. We designed a structure called private information\npre-branch, which makes decisions considering all possible private information\nfrom teammates. We prove that the size of the game transformed by our method is\nexponentially reduced compared to the current state-of-the-art. Moreover, we\ndemonstrate equilibria equivalence. Experimentally, our method achieves a\nsignificant speedup of 182.89$\\times$ to 694.44$\\times$ in scenarios where the\ncurrent state-of-the-art method can work, such as small-scale Kuhn poker and\nLeduc poker. Furthermore, our method is applicable to larger games and those\nwith dynamically changing private information, such as Goofspiel.", "categories": "cs.GT", "created": "2024-08-05", "doi": null, "arxiv_id": "2408.02283"}
{"title": "Cascading Refinement Video Denoising with Uncertainty Adaptivity", "authors": [], "abstract": "Accurate alignment is crucial for video denoising. However, estimating\nalignment in noisy environments is challenging. This paper introduces a\ncascading refinement video denoising method that can refine alignment and\nrestore images simultaneously. Better alignment enables restoration of more\ndetailed information in each frame. Furthermore, better image quality leads to\nbetter alignment. This method has achieved SOTA performance by a large margin\non the CRVD dataset. Simultaneously, aiming to deal with multi-level noise, an\nuncertainty map was created after each iteration. Because of this, redundant\ncomputation on the easily restored videos was avoided. By applying this method,\nthe entire computation was reduced by 25% on average.", "categories": "cs.CV", "created": "2024-08-05", "doi": null, "arxiv_id": "2408.02284"}
{"title": "Joint-Motion Mutual Learning for Pose Estimation in Videos", "authors": [], "abstract": "Human pose estimation in videos has long been a compelling yet challenging\ntask within the realm of computer vision. Nevertheless, this task remains\ndifficult because of the complex video scenes, such as video defocus and\nself-occlusion. Recent methods strive to integrate multi-frame visual features\ngenerated by a backbone network for pose estimation. However, they often ignore\nthe useful joint information encoded in the initial heatmap, which is a\nby-product of the backbone generation. Comparatively, methods that attempt to\nrefine the initial heatmap fail to consider any spatio-temporal motion\nfeatures. As a result, the performance of existing methods for pose estimation\nfalls short due to the lack of ability to leverage both local joint (heatmap)\ninformation and global motion (feature) dynamics.\n  To address this problem, we propose a novel joint-motion mutual learning\nframework for pose estimation, which effectively concentrates on both local\njoint dependency and global pixel-level motion dynamics. Specifically, we\nintroduce a context-aware joint learner that adaptively leverages initial\nheatmaps and motion flow to retrieve robust local joint feature. Given that\nlocal joint feature and global motion flow are complementary, we further\npropose a progressive joint-motion mutual learning that synergistically\nexchanges information and interactively learns between joint feature and motion\nflow to improve the capability of the model. More importantly, to capture more\ndiverse joint and motion cues, we theoretically analyze and propose an\ninformation orthogonality objective to avoid learning redundant information\nfrom multi-cues. Empirical experiments show our method outperforms prior arts\non three challenging benchmarks.", "categories": "cs.CV", "created": "2024-08-05", "doi": null, "arxiv_id": "2408.02285"}
{"title": "Spin glass model of in-context learning", "authors": [], "abstract": "Large language models show a surprising in-context learning ability -- being\nable to use a prompt to form a prediction for a query, yet without additional\ntraining, in stark contrast to old-fashioned supervised learning. Providing a\nmechanistic interpretation and linking the empirical phenomenon to physics are\nthus challenging and remain unsolved. We study a simple yet expressive\ntransformer with linear attention, and map this structure to a spin glass model\nwith real-valued spins, where the couplings and fields explain the intrinsic\ndisorder in data. The spin glass model explains how the weight parameters\ninteract with each other during pre-training, and most importantly why an\nunseen function can be predicted by providing only a prompt yet without\ntraining. Our theory reveals that for single instance learning, increasing the\ntask diversity leads to the emergence of the in-context learning, by allowing\nthe Boltzmann distribution to converge to a unique correct solution of weight\nparameters. Therefore the pre-trained transformer displays a prediction power\nin a novel prompt setting. The proposed spin glass model thus establishes a\nfoundation to understand the empirical success of large language models.", "categories": "cond-mat.dis-nn cond-mat.stat-mech cs.AI cs.CL", "created": "2024-08-05", "doi": null, "arxiv_id": "2408.02288"}
{"title": "Decoupled Vocabulary Learning Enables Zero-Shot Translation from Unseen\n  Languages", "authors": [], "abstract": "Multilingual neural machine translation systems learn to map sentences of\ndifferent languages into a common representation space. Intuitively, with a\ngrowing number of seen languages the encoder sentence representation grows more\nflexible and easily adaptable to new languages. In this work, we test this\nhypothesis by zero-shot translating from unseen languages. To deal with unknown\nvocabularies from unknown languages we propose a setup where we decouple\nlearning of vocabulary and syntax, i.e. for each language we learn word\nrepresentations in a separate step (using cross-lingual word embeddings), and\nthen train to translate while keeping those word representations frozen. We\ndemonstrate that this setup enables zero-shot translation from entirely unseen\nlanguages. Zero-shot translating with a model trained on Germanic and Romance\nlanguages we achieve scores of 42.6 BLEU for Portuguese-English and 20.7 BLEU\nfor Russian-English on TED domain. We explore how this zero-shot translation\ncapability develops with varying number of languages seen by the encoder.\nLastly, we explore the effectiveness of our decoupled learning strategy for\nunsupervised machine translation. By exploiting our model's zero-shot\ntranslation capability for iterative back-translation we attain near parity\nwith a supervised setting.", "categories": "cs.CL", "created": "2024-08-05", "doi": null, "arxiv_id": "2408.02290"}
{"title": "SelfGeo: Self-supervised and Geodesic-consistent Estimation of Keypoints\n  on Deformable Shapes", "authors": [], "abstract": "Unsupervised 3D keypoints estimation from Point Cloud Data (PCD) is a complex\ntask, even more challenging when an object shape is deforming. As keypoints\nshould be semantically and geometrically consistent across all the 3D frames -\neach keypoint should be anchored to a specific part of the deforming shape\nirrespective of intrinsic and extrinsic motion. This paper presents, \"SelfGeo\",\na self-supervised method that computes persistent 3D keypoints of non-rigid\nobjects from arbitrary PCDs without the need of human annotations. The gist of\nSelfGeo is to estimate keypoints between frames that respect invariant\nproperties of deforming bodies. Our main contribution is to enforce that\nkeypoints deform along with the shape while keeping constant geodesic distances\namong them. This principle is then propagated to the design of a set of losses\nwhich minimization let emerge repeatable keypoints in specific semantic\nlocations of the non-rigid shape. We show experimentally that the use of\ngeodesic has a clear advantage in challenging dynamic scenes and with different\nclasses of deforming shapes (humans and animals). Code and data are available\nat: https://github.com/IIT-PAVIS/SelfGeo", "categories": "cs.CV", "created": "2024-08-05", "doi": null, "arxiv_id": "2408.02291"}
{"title": "OPENGRASP-LITE Version 1.0: A Tactile Artificial Hand with a Compliant\n  Linkage Mechanism", "authors": [], "abstract": "Recent research has seen notable progress in the development of linkage-based\nartificial hands. While previous designs have focused on adaptive grasping,\ndexterity and biomimetic artificial skin, only a few systems have proposed a\nlightweight, accessible solution integrating tactile sensing with a compliant\nlinkage-based mechanism. This paper introduces OPENGRASP LITE, an open-source,\nhighly integrated, tactile, and lightweight artificial hand. Leveraging\ncompliant linkage systems and MEMS barometer-based tactile sensing, it offers\nversatile grasping capabilities with six degrees of actuation. By providing\ntactile sensors and enabling soft grasping, it serves as an accessible platform\nfor further research in tactile artificial hands.", "categories": "cs.RO cs.SY eess.SY", "created": "2024-08-05", "doi": null, "arxiv_id": "2408.02293"}
{"title": "Generalized Gaussian Temporal Difference Error For Uncertainty-aware\n  Reinforcement Learning", "authors": [], "abstract": "Conventional uncertainty-aware temporal difference (TD) learning methods\noften rely on simplistic assumptions, typically including a zero-mean Gaussian\ndistribution for TD errors. Such oversimplification can lead to inaccurate\nerror representations and compromised uncertainty estimation. In this paper, we\nintroduce a novel framework for generalized Gaussian error modeling in deep\nreinforcement learning, applicable to both discrete and continuous control\nsettings. Our framework enhances the flexibility of error distribution modeling\nby incorporating higher-order moments, particularly kurtosis, thereby improving\nthe estimation and mitigation of data-dependent noise, i.e., aleatoric\nuncertainty. We examine the influence of the shape parameter of the generalized\nGaussian distribution (GGD) on aleatoric uncertainty and provide a closed-form\nexpression that demonstrates an inverse relationship between uncertainty and\nthe shape parameter. Additionally, we propose a theoretically grounded\nweighting scheme to fully leverage the GGD. To address epistemic uncertainty,\nwe enhance the batch inverse variance weighting by incorporating bias reduction\nand kurtosis considerations, resulting in improved robustness. Extensive\nexperimental evaluations using policy gradient algorithms demonstrate the\nconsistent efficacy of our method, showcasing significant performance\nimprovements.", "categories": "cs.LG cs.AI math.PR stat.ML", "created": "2024-08-05", "doi": null, "arxiv_id": "2408.02295"}
{"title": "Heart Rate and its Variability from Short-term ECG Recordings as\n  Biomarkers for Detecting Mild Cognitive Impairment in Indian Population", "authors": [], "abstract": "Alterations in Heart Rate (HR) and Heart Rate Variability (HRV) can reflect\nautonomic dysfunction associated with neurodegeneration. We investigate the\ninfluence of Mild Cognitive Impairment (MCI) on HR and its variability measures\nin the Indian population by designing a complete signal processing pipeline to\ndetect the R-wave peaks and compute HR and HRV features from ECG recordings of\n10 seconds, for point-of-care applications. The study cohort involves 297 urban\nparticipants, among which 48.48% are male and 51.51% are female. From the\nAddenbrooke's Cognitive Examination-III (ACE-III), MCI is detected in 19.19% of\nparticipants and the rest, 80.8% of them are cognitively healthy. Statistical\nfeatures like central tendency (mean and root mean square (RMS) of the\nNormal-to-Normal (NN) intervals) and dispersion (standard deviation (SD) of all\nNN intervals (SDNN) and root mean square of successive differences of NN\nintervals (RMSSD)) of beat-to-beat intervals are computed. The Wilcoxon rank\nsum test reveals that mean of NN intervals (p = 0.0021), the RMS of NN\nintervals (p = 0.0014), the SDNN (p = 0.0192) and the RMSSD (p = 0.0206) values\ndiffer significantly between MCI and non-MCI classes, for a level of\nsignificance, 0.05. Machine learning classifiers like, Support Vector Machine\n(SVM), Discriminant Analysis (DA) and Naive Bayes (NB) driven by mean NN\nintervals, RMS, SDNN and RMSSD, show a high accuracy of 80.80% on each\nindividual feature input. Individuals with MCI are observed to have\ncomparatively higher HR than healthy subjects. HR and its variability can be\nconsidered as potential biomarkers for detecting MCI.", "categories": "cs.LG eess.SP", "created": "2024-08-05", "doi": null, "arxiv_id": "2408.02296"}
{"title": "Perception Matters: Enhancing Embodied AI with Uncertainty-Aware\n  Semantic Segmentation", "authors": [], "abstract": "Embodied AI has made significant progress acting in unexplored environments.\nHowever, tasks such as object search have largely focused on efficient policy\nlearning. In this work, we identify several gaps in current search methods:\nThey largely focus on dated perception models, neglect temporal aggregation,\nand transfer from ground truth directly to noisy perception at test time,\nwithout accounting for the resulting overconfidence in the perceived state. We\naddress the identified problems through calibrated perception probabilities and\nuncertainty across aggregation and found decisions, thereby adapting the models\nfor sequential tasks. The resulting methods can be directly integrated with\npretrained models across a wide family of existing search approaches at no\nadditional training cost. We perform extensive evaluations of aggregation\nmethods across both different semantic perception models and policies,\nconfirming the importance of calibrated uncertainties in both the aggregation\nand found decisions. We make the code and trained models available at\nhttp://semantic-search.cs.uni-freiburg.de.", "categories": "cs.RO cs.CV", "created": "2024-08-05", "doi": null, "arxiv_id": "2408.02297"}
{"title": "Backward Compatibility in Attributive Explanation and Enhanced Model\n  Training Method", "authors": [], "abstract": "Model update is a crucial process in the operation of ML/AI systems. While\nupdating a model generally enhances the average prediction performance, it also\nsignificantly impacts the explanations of predictions. In real-world\napplications, even minor changes in explanations can have detrimental\nconsequences. To tackle this issue, this paper introduces BCX, a quantitative\nmetric that evaluates the backward compatibility of feature attribution\nexplanations between pre- and post-update models. BCX utilizes practical\nagreement metrics to calculate the average agreement between the explanations\nof pre- and post-update models, specifically among samples on which both models\naccurately predict. In addition, we propose BCXR, a BCX-aware model training\nmethod by designing surrogate losses which theoretically lower bounds agreement\nscores. Furthermore, we present a universal variant of BCXR that improves all\nagreement metrics, utilizing L2 distance among the explanations of the models.\nTo validate our approach, we conducted experiments on eight real-world\ndatasets, demonstrating that BCXR achieves superior trade-offs between\npredictive performances and BCX scores, showcasing the effectiveness of our\nBCXR methods.", "categories": "cs.LG", "created": "2024-08-05", "doi": null, "arxiv_id": "2408.02298"}
{"title": "A Lower Bound for Local Search Proportional Approval Voting", "authors": [], "abstract": "Selecting $k$ out of $m$ items based on the preferences of $n$ heterogeneous\nagents is a widely studied problem in algorithmic game theory. If agents have\napproval preferences over individual items and harmonic utility functions over\nbundles -- an agent receives $\\sum_{j=1}^t\\frac{1}{j}$ utility if $t$ of her\napproved items are selected -- then welfare optimisation is captured by a\nvoting rule known as Proportional Approval Voting (PAV). PAV also satisfies\ndemanding fairness axioms. However, finding a winning set of items under PAV is\nNP-hard. In search of a tractable method with strong fairness guarantees, a\nbounded local search version of PAV was proposed by Aziz et al. It proceeds by\nstarting with an arbitrary size-$k$ set $W$ and, at each step, checking if\nthere is a pair of candidates $a\\in W$, $b\\not\\in W$ such that swapping $a$ and\n$b$ increases the total welfare by at least $\\varepsilon$; if yes, it performs\nthe swap. Aziz et al.~show that setting $\\varepsilon=\\frac{n}{k^2}$ ensures\nboth the desired fairness guarantees and polynomial running time. However, they\nleave it open whether the algorithm converges in polynomial time if\n$\\varepsilon$ is very small (in particular, if we do not stop until there are\nno welfare-improving swaps). We resolve this open question, by showing that if\n$\\varepsilon$ can be arbitrarily small, the running time of this algorithm may\nbe super-polynomial. Specifically, we prove a lower bound of~$\\Omega(k^{\\log\nk})$ if improvements are chosen lexicographically. To complement our lower\nbound, we provide an empirical comparison of two variants of local search --\nbetter-response and best-response -- on several real-life data sets and a\nvariety of synthetic data sets. Our experiments indicate that, empirically,\nbetter response exhibits faster running time than best response.", "categories": "cs.GT", "created": "2024-08-05", "doi": null, "arxiv_id": "2408.02300"}
{"title": "Network Fission Ensembles for Low-Cost Self-Ensembles", "authors": [], "abstract": "Recent ensemble learning methods for image classification have been shown to\nimprove classification accuracy with low extra cost. However, they still\nrequire multiple trained models for ensemble inference, which eventually\nbecomes a significant burden when the model size increases. In this paper, we\npropose a low-cost ensemble learning and inference, called Network Fission\nEnsembles (NFE), by converting a conventional network itself into a multi-exit\nstructure. Starting from a given initial network, we first prune some of the\nweights to reduce the training burden. We then group the remaining weights into\nseveral sets and create multiple auxiliary paths using each set to construct\nmulti-exits. We call this process Network Fission. Through this, multiple\noutputs can be obtained from a single network, which enables ensemble learning.\nSince this process simply changes the existing network structure to multi-exits\nwithout using additional networks, there is no extra computational burden for\nensemble learning and inference. Moreover, by learning from multiple losses of\nall exits, the multi-exits improve performance via regularization, and high\nperformance can be achieved even with increased network sparsity. With our\nsimple yet effective method, we achieve significant improvement compared to\nexisting ensemble methods. The code is available at\nhttps://github.com/hjdw2/NFE.", "categories": "cs.CV cs.LG", "created": "2024-08-05", "doi": null, "arxiv_id": "2408.02301"}
{"title": "SNFinLLM: Systematic and Nuanced Financial Domain Adaptation of Chinese\n  Large Language Models", "authors": [], "abstract": "Large language models (LLMs) have become powerful tools for advancing natural\nlanguage processing applications in the financial industry. However, existing\nfinancial LLMs often face challenges such as hallucinations or superficial\nparameter training, resulting in suboptimal performance, particularly in\nfinancial computing and machine reading comprehension (MRC). To address these\nissues, we propose a novel large language model specifically designed for the\nChinese financial domain, named SNFinLLM. SNFinLLM excels in domain-specific\ntasks such as answering questions, summarizing financial research reports,\nanalyzing sentiment, and executing financial calculations. We then perform the\nsupervised fine-tuning (SFT) to enhance the model's proficiency across various\nfinancial domains. Specifically, we gather extensive financial data and create\na high-quality instruction dataset composed of news articles, professional\npapers, and research reports of finance domain. Utilizing both domain-specific\nand general datasets, we proceed with continuous pre-training on an established\nopen-source base model, resulting in SNFinLLM-base. Following this, we engage\nin supervised fine-tuning (SFT) to bolster the model's capability across\nmultiple financial tasks. Crucially, we employ a straightforward Direct\nPreference Optimization (DPO) method to better align the model with human\npreferences. Extensive experiments conducted on finance benchmarks and our\nevaluation dataset demonstrate that SNFinLLM markedly outperforms other\nstate-of-the-art financial language models. For more details, check out our\ndemo video here: https://www.youtube.com/watch?v=GYT-65HZwus.", "categories": "cs.CL", "created": "2024-08-05", "doi": null, "arxiv_id": "2408.02302"}
{"title": "PROF: Protected Order Flow in a Profit-Seeking World", "authors": [], "abstract": "Users of decentralized finance (DeFi) applications face significant risks\nfrom adversarial actions that manipulate the order of transactions to extract\nvalue from users. Such actions -- an adversarial form of what is called\nmaximal-extractable value (MEV) -- impact both individual outcomes and the\nstability of the DeFi ecosystem. MEV exploitation, moreover, is being\ninstitutionalized through an architectural paradigm known Proposer-Builder\nSeparation (PBS).\n  This work introduces a system called PROF (PRotected Order Flow) that is\ndesigned to limit harmful forms of MEV in existing PBS systems. PROF aims at\nthis goal using two ideas. First, PROF imposes an ordering on a set (\"bundle\")\nof privately input transactions and enforces that ordering all the way through\nto block production -- preventing transaction-order manipulation. Second, PROF\ncreates bundles whose inclusion is profitable to block producers, thereby\nensuring that bundles see timely inclusion in blocks.\n  PROF is backward-compatible, meaning that it works with existing and future\nPBS designs. PROF is also compatible with any desired algorithm for ordering\ntransactions within a PROF bundle (e.g., first-come, first-serve, fee-based,\netc.). It executes efficiently, i.e., with low latency, and requires no\nadditional trust assumptions among PBS entities. We quantitatively and\nqualitatively analyze incentive structure of PROF, and its utility to users\ncompared with existing solutions. We also report on inclusion likelihood of\nPROF transactions, and concrete latency numbers through our end-to-end\nimplementation.", "categories": "cs.CR", "created": "2024-08-05", "doi": null, "arxiv_id": "2408.02303"}
{"title": "Embedding Compression in Recommender Systems: A Survey", "authors": [], "abstract": "To alleviate the problem of information explosion, recommender systems are\nwidely deployed to provide personalized information filtering services.\nUsually, embedding tables are employed in recommender systems to transform\nhigh-dimensional sparse one-hot vectors into dense real-valued embeddings.\nHowever, the embedding tables are huge and account for most of the parameters\nin industrial-scale recommender systems. In order to reduce memory costs and\nimprove efficiency, various approaches are proposed to compress the embedding\ntables. In this survey, we provide a comprehensive review of embedding\ncompression approaches in recommender systems. We first introduce deep learning\nrecommendation models and the basic concept of embedding compression in\nrecommender systems. Subsequently, we systematically organize existing\napproaches into three categories, namely low-precision, mixed-dimension, and\nweight-sharing, respectively. Lastly, we summarize the survey with some general\nsuggestions and provide future prospects for this field.", "categories": "cs.IR", "created": "2024-08-05", "doi": "10.1145/3637841", "arxiv_id": "2408.02304"}
{"title": "Mixture-of-Noises Enhanced Forgery-Aware Predictor for Multi-Face\n  Manipulation Detection and Localization", "authors": [], "abstract": "With the advancement of face manipulation technology, forgery images in\nmulti-face scenarios are gradually becoming a more complex and realistic\nchallenge. Despite this, detection and localization methods for such multi-face\nmanipulations remain underdeveloped. Traditional manipulation localization\nmethods either indirectly derive detection results from localization masks,\nresulting in limited detection performance, or employ a naive two-branch\nstructure to simultaneously obtain detection and localization results, which\ncannot effectively benefit the localization capability due to limited\ninteraction between two tasks. This paper proposes a new framework, namely\nMoNFAP, specifically tailored for multi-face manipulation detection and\nlocalization. The MoNFAP primarily introduces two novel modules: the\nForgery-aware Unified Predictor (FUP) Module and the Mixture-of-Noises Module\n(MNM). The FUP integrates detection and localization tasks using a token\nlearning strategy and multiple forgery-aware transformers, which facilitates\nthe use of classification information to enhance localization capability.\nBesides, motivated by the crucial role of noise information in forgery\ndetection, the MNM leverages multiple noise extractors based on the concept of\nthe mixture of experts to enhance the general RGB features, further boosting\nthe performance of our framework. Finally, we establish a comprehensive\nbenchmark for multi-face detection and localization and the proposed\n\\textit{MoNFAP} achieves significant performance. The codes will be made\navailable.", "categories": "cs.CV", "created": "2024-08-05", "doi": null, "arxiv_id": "2408.02306"}
{"title": "Low-Cost Self-Ensembles Based on Multi-Branch Transformation and Grouped\n  Convolution", "authors": [], "abstract": "Recent advancements in low-cost ensemble learning have demonstrated improved\nefficiency for image classification. However, the existing low-cost ensemble\nmethods show relatively lower accuracy compared to conventional ensemble\nlearning. In this paper, we propose a new low-cost ensemble learning, which can\nsimultaneously achieve high efficiency and classification performance. A CNN is\ntransformed into a multi-branch structure without introduction of additional\ncomponents, which maintains the computational complexity as that of the\noriginal single model and also enhances diversity among the branches' outputs\nvia sufficient separation between different pathways of the branches. In\naddition, we propose a new strategy that applies grouped convolution in the\nbranches with different numbers of groups in different branches, which boosts\nthe diversity of the branches' outputs. For training, we employ knowledge\ndistillation using the ensemble of the outputs as the teacher signal. The high\ndiversity among the outputs enables to form a powerful teacher, enhancing the\nindividual branch's classification performance and consequently the overall\nensemble performance. Experimental results show that our method achieves\nstate-of-the-art classification accuracy and higher uncertainty estimation\nperformance compared to previous low-cost ensemble methods. The code is\navailable at https://github.com/hjdw2/SEMBG.", "categories": "cs.CV", "created": "2024-08-05", "doi": null, "arxiv_id": "2408.02307"}
{"title": "On the Robustness of Malware Detectors to Adversarial Samples", "authors": [], "abstract": "Adversarial examples add imperceptible alterations to inputs with the\nobjective to induce misclassification in machine learning models. They have\nbeen demonstrated to pose significant challenges in domains like image\nclassification, with results showing that an adversarially perturbed image to\nevade detection against one classifier is most likely transferable to other\nclassifiers. Adversarial examples have also been studied in malware analysis.\nUnlike images, program binaries cannot be arbitrarily perturbed without\nrendering them non-functional. Due to the difficulty of crafting adversarial\nprogram binaries, there is no consensus on the transferability of adversarially\nperturbed programs to different detectors. In this work, we explore the\nrobustness of malware detectors against adversarially perturbed malware. We\ninvestigate the transferability of adversarial attacks developed against one\ndetector, against other machine learning-based malware detectors, and code\nsimilarity techniques, specifically, locality sensitive hashing-based\ndetectors. Our analysis reveals that adversarial program binaries crafted for\none detector are generally less effective against others. We also evaluate an\nensemble of detectors and show that they can potentially mitigate the impact of\nadversarial program binaries. Finally, we demonstrate that substantial program\nchanges made to evade detection may result in the transformation technique\nbeing identified, implying that the adversary must make minimal changes to the\nprogram binary.", "categories": "cs.CR cs.LG", "created": "2024-08-05", "doi": null, "arxiv_id": "2408.02310"}
{"title": "PTM4Tag+: Tag Recommendation of Stack Overflow Posts with Pre-trained\n  Models", "authors": [], "abstract": "Stack Overflow is one of the most influential Software Question & Answer\n(SQA) websites, hosting millions of programming-related questions and answers.\nTags play a critical role in efficiently organizing the contents in Stack\nOverflow and are vital to support a range of site operations, e.g., querying\nrelevant content. Poorly selected tags often raise problems like tag ambiguity\nand tag explosion. Thus, a precise and accurate automated tag recommendation\ntechnique is demanded.\n  Inspired by the recent success of pre-trained models (PTMs) in natural\nlanguage processing (NLP), we present PTM4Tag+, a tag recommendation framework\nfor Stack Overflow posts that utilizes PTMs in language modeling. PTM4Tag+ is\nimplemented with a triplet architecture, which considers three key components\nof a post, i.e., Title, Description, and Code, with independent PTMs. We\nutilize a number of popular pre-trained models, including the BERT-based models\n(e.g., BERT, RoBERTa, CodeBERT, BERTOverflow, and ALBERT), and encoder-decoder\nmodels (e.g., PLBART, CoTexT, and CodeT5). Our results show that leveraging\nCodeT5 under the PTM4Tag+ framework achieves the best performance among the\neight considered PTMs and outperforms the state-of-the-art Convolutional Neural\nNetwork-based approach by a substantial margin in terms of average P\nrecision@k, Recall@k, and F1-score@k (k ranges from 1 to 5). Specifically,\nCodeT5 improves the performance of F1-score@1-5 by 8.8%, 12.4%, 15.3%, 16.4%,\nand 16.6%. Moreover, to address the concern with inference latency, we\nexperiment PTM4Tag+ with smaller PTM models (i.e., DistilBERT, DistilRoBERTa,\nCodeBERT-small, and CodeT5-small). We find that although smaller PTMs cannot\noutperform larger PTMs, they still maintain over 93.96% of the performance on\naverage, meanwhile shortening the mean inference time by more than 47.2%", "categories": "cs.SE", "created": "2024-08-05", "doi": null, "arxiv_id": "2408.02311"}
{"title": "Optimization of Iterative Blind Detection based on Expectation\n  Maximization and Belief Propagation", "authors": [], "abstract": "We study iterative blind symbol detection for block-fading linear\ninter-symbol interference channels. Based on the factor graph framework, we\ndesign a joint channel estimation and detection scheme that combines the\nexpectation maximization (EM) algorithm and the ubiquitous belief propagation\n(BP) algorithm. Interweaving the iterations of both schemes significantly\nreduces the EM algorithm's computational burden while retaining its excellent\nperformance. To this end, we apply simple yet effective model-based learning\nmethods to find a suitable parameter update schedule by introducing momentum in\nboth the EM parameter updates as well as in the BP message passing. Numerical\nsimulations verify that the proposed method can learn efficient schedules that\ngeneralize well and even outperform coherent BP detection in high\nsignal-to-noise scenarios.", "categories": "cs.IT cs.LG eess.SP math.IT", "created": "2024-08-05", "doi": null, "arxiv_id": "2408.02312"}
{"title": "A Lean Transformer Model for Dynamic Malware Analysis and Detection", "authors": [], "abstract": "Malware is a fast-growing threat to the modern computing world and existing\nlines of defense are not efficient enough to address this issue. This is mainly\ndue to the fact that many prevention solutions rely on signature-based\ndetection methods that can easily be circumvented by hackers. Therefore, there\nis a recurrent need for behavior-based analysis where a suspicious file is ran\nin a secured environment and its traces are collected to reports for analysis.\nPrevious works have shown some success leveraging Neural Networks and API calls\nsequences extracted from these execution reports.\n  Recently, Large Language Models and Generative AI have demonstrated\nimpressive capabilities mainly in Natural Language Processing tasks and\npromising applications in the cybersecurity field for both attackers and\ndefenders.\n  In this paper, we design an Encoder-Only model, based on the Transformers\narchitecture, to detect malicious files, digesting their API call sequences\ncollected by an execution emulation solution. We are also limiting the size of\nthe model architecture and the number of its parameters since it is often\nconsidered that Large Language Models may be overkill for specific tasks such\nas the one we are dealing with hereafter. In addition to achieving decent\ndetection results, this approach has the advantage of reducing our carbon\nfootprint by limiting training and inference times and facilitating technical\noperations with less hardware requirements.\n  We also carry out some analysis of our results and highlight the limits and\npossible improvements when using Transformers to analyze malicious files.", "categories": "cs.CR cs.LG", "created": "2024-08-05", "doi": null, "arxiv_id": "2408.02313"}
{"title": "Quantum Clustering for Cybersecurity", "authors": [], "abstract": "In this study, we develop a novel quantum machine learning (QML) framework to\nanalyze cybersecurity vulnerabilities using data from the 2022 CISA Known\nExploited Vulnerabilities catalog, which includes detailed information on\nvulnerability types, severity levels, common vulnerability scoring system\n(CVSS) scores, and product specifics. Our framework preprocesses this data into\na quantum-compatible format, enabling clustering analysis through our advanced\nquantum techniques, QCSWAPK-means and QkernelK-means. These quantum algorithms\ndemonstrate superior performance compared to state-of-the-art classical\nclustering techniques like k-means and spectral clustering, achieving\nSilhouette scores of 0.491, Davies-Bouldin indices below 0.745, and\nCalinski-Harabasz scores exceeding 884, indicating more distinct and\nwell-separated clusters. Our framework categorizes vulnerabilities into\ndistinct groups, reflecting varying levels of risk severity: Cluster 0,\nprimarily consisting of critical Microsoft-related vulnerabilities; Cluster 1,\nfeaturing medium severity vulnerabilities from various enterprise software\nvendors and network solutions; Cluster 2, with high severity vulnerabilities\nfrom Adobe, Cisco, and Google; and Cluster 3, encompassing vulnerabilities from\nMicrosoft and Oracle with high to medium severity. These findings highlight the\npotential of QML to enhance the precision of vulnerability assessments and\nprioritization, advancing cybersecurity practices by enabling more strategic\nand proactive defense mechanisms.", "categories": "quant-ph cs.CR", "created": "2024-08-05", "doi": null, "arxiv_id": "2408.02314"}
{"title": "Machine learning-based input-augmented Koopman modeling and predictive\n  control of nonlinear processes", "authors": [], "abstract": "Koopman-based modeling and model predictive control have been a promising\nalternative for optimal control of nonlinear processes. Good Koopman modeling\nperformance significantly depends on an appropriate nonlinear mapping from the\noriginal state-space to a lifted state space. In this work, we propose an\ninput-augmented Koopman modeling and model predictive control approach. Both\nthe states and the known inputs are lifted using two deep neural networks\n(DNNs), and a Koopman model with nonlinearity in inputs is trained within the\nhigher-dimensional state-space. A Koopman-based model predictive control\nproblem is formulated. To bypass non-convex optimization induced by the\nnonlinearity in the Koopman model, we further present an iterative\nimplementation algorithm, which approximates the optimal control input via\nsolving a convex optimization problem iteratively. The proposed method is\napplied to a chemical process and a biological water treatment process via\nsimulations. The efficacy and advantages of the proposed modeling and control\napproach are demonstrated.", "categories": "eess.SY cs.SY", "created": "2024-08-05", "doi": null, "arxiv_id": "2408.02315"}
{"title": "Real-time Trajectory Optimization of Impaired Aircraft based on Steady\n  State Manoeuvres", "authors": [], "abstract": "Aircraft failures alter dynamics, diminishing manoeuvrability. Such\nmanoeuvring flight envelope variations, governed by the aircraft's complex\nnonlinear dynamics, are unpredictable by pilots and existing flight management\nsystems. To prevent in-flight Loss of Control, post-failure trajectories must\nbe optimal, planned in real-time, avoid terrain, and adhere to the impaired\naircraft's reduced manoeuvrability and dynamic constraints. This paper presents\na novel real-time trajectory optimization method for impaired aircraft based on\na combination of differential flatness theory, the pseudospectral method,\nnonlinear programming, and inverse dynamics. In the proposed method, which\nutilizes a high-fidelity nonlinear six degree-of-freedom model, to conform to\naircraft's altered dynamics a sequence of trim points is selected from the\nimpaired aircraft's manoeuvring flight envelope based on the chosen\noptimization criteria, ensuring that the resulting three-dimensional trajectory\nobserves terrain avoidance. Then, the required control inputs are obtained for\neach manoeuvre in less than a second. The method is applied to the NASA Generic\nTransport Model with rudder failure near a complex mountainous terrain. Both an\noptimal one-piece trajectory and a near-optimal piecewise path consisting of\nseveral optimal trajectories, are generated in non-real-time and real-time,\nrespectively, and compared. Results show that the near-optimal real-time\ntrajectory retains up to 80% of the optimality.", "categories": "eess.SY cs.SY", "created": "2024-08-05", "doi": null, "arxiv_id": "2408.02316"}
{"title": "XDC Network Assessment: Decentralization, Scalability and Security", "authors": [], "abstract": "XinFin, in 2019, unveiled the XDC network, an enterprise-ready hybrid\nblockchain platform that is open-source and specializes in tokenization for\nreal-world decentralized finance. Overseeing the XDC network is currently the\nXDC Foundation, a non-profit organization established to encourage the growth,\nenhancement, and adoption of the XDC Network through community-driven projects\nsuch as GitHub. This whitepaper discusses the real-time assessment of the XDC\nnetwork's decentralization, scalability, and security aspects as well as the\nNakamoto coefficient estimation that follows, which is a measure of a\ndecentralized system's decentralization nature that quantifies the minimal\nnumber of nodes or entities needed to compromise the system. A high coefficient\ndenotes greater decentralization, while a low number denotes increased\ndisruption risk. The XDC network's real-time computation of the high Nakamoto\ncoefficient demonstrates its highly decentralized character. The article also\naddresses the diversity of consensus and execution clients, the host\ndistribution, the geo-distribution, and some of the outstanding issues and\nbusiness considerations.", "categories": "cs.CR", "created": "2024-08-05", "doi": null, "arxiv_id": "2408.02318"}
{"title": "Self-centering 3-DOF feet controller for hands-free locomotion control\n  in telepresence and virtual reality", "authors": [], "abstract": "We present a novel seated foot controller for handling 3-DOF aimed to control\nlocomotion for telepresence robotics and virtual reality environments. Tilting\nthe feet on two axes yields in forward, backward and sideways motion. In\naddition, a separate rotary joint allows for rotation around the vertical axis.\nAttached springs on all joints self-center the controller. The HTC Vive tracker\nis used to translate the trackers' orientation into locomotion commands. The\nproposed self-centering foot controller was used successfully for the ANA\nAvatar XPRIZE competition, where a naive operator traversed the robot through a\nlonger distance, surpassing obstacles while solving various interaction and\nmanipulation tasks in between. We publicly provide the models of the mostly\n3D-printed feet controller for reproduction.", "categories": "cs.RO cs.HC", "created": "2024-08-05", "doi": null, "arxiv_id": "2408.02319"}
{"title": "A Sharp Convergence Theory for The Probability Flow ODEs of Diffusion\n  Models", "authors": [], "abstract": "Diffusion models, which convert noise into new data instances by learning to\nreverse a diffusion process, have become a cornerstone in contemporary\ngenerative modeling. In this work, we develop non-asymptotic convergence theory\nfor a popular diffusion-based sampler (i.e., the probability flow ODE sampler)\nin discrete time, assuming access to $\\ell_2$-accurate estimates of the (Stein)\nscore functions. For distributions in $\\mathbb{R}^d$, we prove that\n$d/\\varepsilon$ iterations -- modulo some logarithmic and lower-order terms --\nare sufficient to approximate the target distribution to within $\\varepsilon$\ntotal-variation distance. This is the first result establishing nearly linear\ndimension-dependency (in $d$) for the probability flow ODE sampler. Imposing\nonly minimal assumptions on the target data distribution (e.g., no smoothness\nassumption is imposed), our results also characterize how $\\ell_2$ score\nestimation errors affect the quality of the data generation processes. In\ncontrast to prior works, our theory is developed based on an elementary yet\nversatile non-asymptotic approach without the need of resorting to SDE and ODE\ntoolboxes.", "categories": "cs.LG cs.NA eess.SP math.NA math.ST stat.ML stat.TH", "created": "2024-08-05", "doi": null, "arxiv_id": "2408.02320"}
{"title": "The OpenCitations Index", "authors": [], "abstract": "This article presents the OpenCitations Index, a collection of open citation\ndata maintained by OpenCitations, an independent, not-for-profit infrastructure\norganisation for open scholarship dedicated to publishing open bibliographic\nand citation data using Semantic Web and Linked Open Data technologies. The\ncollection involves citation data harvested from multiple sources. To address\nthe possibility of different sources providing citation data for bibliographic\nentities represented with different identifiers, therefore potentially\nrepresenting same citation, a deduplication mechanism has been implemented.\nThis ensures that citations integrated into OpenCitations Index are accurately\nidentified uniquely, even when different identifiers are used. This mechanism\nfollows a specific workflow, which encompasses a preprocessing of the original\nsource data, a management of the provided bibliographic metadata, and the\ngeneration of new citation data to be integrated into the OpenCitations Index.\nThe process relies on another data collection: OpenCitations Meta, and on the\nuse of a new globally persistent identifier, namely OMID (OpenCitations Meta\nIdentifier). As of July 2024, OpenCitations Index stores over 2 billion unique\ncitation links, harvest from Crossref, the National Institute of Heath Open\nCitation Collection (NIH-OCC), DataCite, OpenAIRE, and the Japan Link Center\n(JaLC). OpenCitations Index can be systematically accessed and queried through\nseveral services, including SPARQL endpoint, REST APIs, and web interfaces.\nAdditionally, dataset dumps are available for free download and reuse (under\nCC0 waiver) in various formats (CSV, N-Triples, and Scholix), including\nprovenance and change tracking information.", "categories": "cs.DL", "created": "2024-08-05", "doi": null, "arxiv_id": "2408.02321"}
{"title": "Explosive neural networks via higher-order interactions in curved\n  statistical manifolds", "authors": [], "abstract": "Higher-order interactions underlie complex phenomena in systems such as\nbiological and artificial neural networks, but their study is challenging due\nto the lack of tractable standard models. By leveraging the maximum entropy\nprinciple in curved statistical manifolds, here we introduce curved neural\nnetworks as a class of prototypical models for studying higher-order phenomena.\nThrough exact mean-field descriptions, we show that these curved neural\nnetworks implement a self-regulating annealing process that can accelerate\nmemory retrieval, leading to explosive order-disorder phase transitions with\nmulti-stability and hysteresis effects. Moreover, by analytically exploring\ntheir memory capacity using the replica trick near ferromagnetic and spin-glass\nphase boundaries, we demonstrate that these networks enhance memory capacity\nover the classical associative-memory networks. Overall, the proposed framework\nprovides parsimonious models amenable to analytical study, revealing novel\nhigher-order phenomena in complex network systems.", "categories": "cond-mat.dis-nn cond-mat.stat-mech cs.IT math.IT nlin.AO stat.ML", "created": "2024-08-05", "doi": null, "arxiv_id": "2408.02326"}
{"title": "From Generalist to Specialist: Exploring CWE-Specific Vulnerability\n  Detection", "authors": [], "abstract": "Vulnerability Detection (VD) using machine learning faces a significant\nchallenge: the vast diversity of vulnerability types. Each Common Weakness\nEnumeration (CWE) represents a unique category of vulnerabilities with distinct\ncharacteristics, code semantics, and patterns. Treating all vulnerabilities as\na single label with a binary classification approach may oversimplify the\nproblem, as it fails to capture the nuances and context-specific to each CWE.\nAs a result, a single binary classifier might merely rely on superficial text\npatterns rather than understanding the intricacies of each vulnerability type.\nRecent reports showed that even the state-of-the-art Large Language Model (LLM)\nwith hundreds of billions of parameters struggles to generalize well to detect\nvulnerabilities. Our work investigates a different approach that leverages\nCWE-specific classifiers to address the heterogeneity of vulnerability types.\nWe hypothesize that training separate classifiers for each CWE will enable the\nmodels to capture the unique characteristics and code semantics associated with\neach vulnerability category. To confirm this, we conduct an ablation study by\ntraining individual classifiers for each CWE and evaluating their performance\nindependently. Our results demonstrate that CWE-specific classifiers outperform\na single binary classifier trained on all vulnerabilities. Building upon this,\nwe explore strategies to combine them into a unified vulnerability detection\nsystem using a multiclass approach. Even if the lack of large and high-quality\ndatasets for vulnerability detection is still a major obstacle, our results\nshow that multiclass detection can be a better path toward practical\nvulnerability detection in the future. All our models and code to produce our\nresults are open-sourced.", "categories": "cs.CR cs.SE", "created": "2024-08-05", "doi": null, "arxiv_id": "2408.02329"}
{"title": "Spatio-Temporal Communication Compression in Distributed Prime-Dual\n  Flows", "authors": [], "abstract": "In this paper, we study distributed prime-dual flows for multi-agent\noptimization with spatio-temporal compressions. The central aim of multi-agent\noptimization is for a network of agents to collaboratively solve a system-level\noptimization problem with local objective functions and node-to-node\ncommunication by distributed algorithms. The scalability of such algorithms\ncrucially depends on the complexity of the communication messages, and a number\nof communication compressors for distributed optimization have recently been\nproposed in the literature. First of all, we introduce a general\nspatio-temporal compressor characterized by the stability of the resulting\ndynamical system along the vector field of the compressor. We show that several\nimportant distributed optimization compressors such as the greedy sparsifier,\nthe uniform quantizer, and the scalarizer all fall into the category of this\nspatio-temporal compressor. Next, we propose two distributed prime-dual flows\nwith the spatio-temporal compressors being applied to local node states and\nlocal error states, respectively, and prove (exponential) convergence of the\nnode trajectories to the global optimizer for (strongly) convex cost functions.\nFinally, a few numerical examples are present to illustrate our theoretical\nresults.", "categories": "eess.SY cs.SY", "created": "2024-08-05", "doi": null, "arxiv_id": "2408.02332"}
{"title": "Infusing Environmental Captions for Long-Form Video Language Grounding", "authors": [], "abstract": "In this work, we tackle the problem of long-form video-language grounding\n(VLG). Given a long-form video and a natural language query, a model should\ntemporally localize the precise moment that answers the query. Humans can\neasily solve VLG tasks, even with arbitrarily long videos, by discarding\nirrelevant moments using extensive and robust knowledge gained from experience.\nUnlike humans, existing VLG methods are prone to fall into superficial cues\nlearned from small-scale datasets, even when they are within irrelevant frames.\nTo overcome this challenge, we propose EI-VLG, a VLG method that leverages\nricher textual information provided by a Multi-modal Large Language Model\n(MLLM) as a proxy for human experiences, helping to effectively exclude\nirrelevant frames. We validate the effectiveness of the proposed method via\nextensive experiments on a challenging EgoNLQ benchmark.", "categories": "cs.CV cs.LG", "created": "2024-08-05", "doi": null, "arxiv_id": "2408.02336"}
{"title": "Developing PUGG for Polish: A Modern Approach to KBQA, MRC, and IR\n  Dataset Construction", "authors": [], "abstract": "Advancements in AI and natural language processing have revolutionized\nmachine-human language interactions, with question answering (QA) systems\nplaying a pivotal role. The knowledge base question answering (KBQA) task,\nutilizing structured knowledge graphs (KG), allows for handling extensive\nknowledge-intensive questions. However, a significant gap exists in KBQA\ndatasets, especially for low-resource languages. Many existing construction\npipelines for these datasets are outdated and inefficient in human labor, and\nmodern assisting tools like Large Language Models (LLM) are not utilized to\nreduce the workload. To address this, we have designed and implemented a\nmodern, semi-automated approach for creating datasets, encompassing tasks such\nas KBQA, Machine Reading Comprehension (MRC), and Information Retrieval (IR),\ntailored explicitly for low-resource environments. We executed this pipeline\nand introduced the PUGG dataset, the first Polish KBQA dataset, and novel\ndatasets for MRC and IR. Additionally, we provide a comprehensive\nimplementation, insightful findings, detailed statistics, and evaluation of\nbaseline models.", "categories": "cs.AI cs.CL cs.LG", "created": "2024-08-05", "doi": null, "arxiv_id": "2408.02337"}
{"title": "A Landscape-Aware Differential Evolution for Multimodal Optimization\n  Problems", "authors": [], "abstract": "How to simultaneously locate multiple global peaks and achieve certain\naccuracy on the found peaks are two key challenges in solving multimodal\noptimization problems (MMOPs). In this paper, a landscape-aware differential\nevolution (LADE) algorithm is proposed for MMOPs, which utilizes landscape\nknowledge to maintain sufficient diversity and provide efficient search\nguidance. In detail, the landscape knowledge is efficiently utilized in the\nfollowing three aspects. First, a landscape-aware peak exploration helps each\nindividual evolve adaptively to locate a peak and simulates the regions of the\nfound peaks according to search history to avoid an individual locating a found\npeak. Second, a landscape-aware peak distinction distinguishes whether an\nindividual locates a new global peak, a new local peak, or a found peak.\nAccuracy refinement can thus only be conducted on the global peaks to enhance\nthe search efficiency. Third, a landscape-aware reinitialization specifies the\ninitial position of an individual adaptively according to the distribution of\nthe found peaks, which helps explore more peaks. The experiments are conducted\non 20 widely-used benchmark MMOPs. Experimental results show that LADE obtains\ngenerally better or competitive performance compared with seven well-performed\nalgorithms proposed recently and four winner algorithms in the IEEE CEC\ncompetitions for multimodal optimization.", "categories": "cs.NE", "created": "2024-08-05", "doi": null, "arxiv_id": "2408.02340"}
{"title": "An approach to optimize inference of the DIART speaker diarization\n  pipeline", "authors": [], "abstract": "Speaker diarization answers the question \"who spoke when\" for an audio file.\nIn some diarization scenarios, low latency is required for transcription.\nSpeaker diarization with low latency is referred to as online speaker\ndiarization. The DIART pipeline is an online speaker diarization system. It\nconsists of a segmentation and an embedding model. The embedding model has the\nlargest share of the overall latency. The aim of this paper is to optimize the\ninference latency of the DIART pipeline. Different inference optimization\nmethods such as knowledge distilation, pruning, quantization and layer fusion\nare applied to the embedding model of the pipeline. It turns out that knowledge\ndistillation optimizes the latency, but has a negative effect on the accuracy.\nQuantization and layer fusion also have a positive influence on the latency\nwithout worsening the accuracy. Pruning, on the other hand, does not improve\nlatency.", "categories": "cs.SD cs.CL eess.AS", "created": "2024-08-05", "doi": null, "arxiv_id": "2408.02341"}
{"title": "Machine Learning Applications in Medical Prognostics: A Comprehensive\n  Review", "authors": [], "abstract": "Machine learning (ML) has revolutionized medical prognostics by integrating\nadvanced algorithms with clinical data to enhance disease prediction, risk\nassessment, and patient outcome forecasting. This comprehensive review\ncritically examines the application of various ML techniques in medical\nprognostics, focusing on their efficacy, challenges, and future directions. The\nmethodologies discussed include Random Forest (RF) for sepsis prediction,\nlogistic regression for cardiovascular risk assessment, Convolutional Neural\nNetworks (CNNs) for cancer detection, and Long Short-Term Memory (LSTM)\nnetworks for predicting clinical deterioration. RF models demonstrate robust\nperformance in handling high-dimensional data and capturing non-linear\nrelationships, making them particularly effective for sepsis prediction.\nLogistic regression remains valuable for its interpretability and ease of use\nin cardiovascular risk assessment. CNNs have shown exceptional accuracy in\ncancer detection, leveraging their ability to learn complex visual patterns\nfrom medical imaging. LSTM networks excel in analyzing temporal data, providing\naccurate predictions of clinical deterioration. The review highlights the\nstrengths and limitations of each technique, the importance of model\ninterpretability, and the challenges of data quality and privacy. Future\nresearch directions include the integration of multi-modal data sources, the\napplication of transfer learning, and the development of continuous learning\nsystems. These advancements aim to enhance the predictive power and clinical\napplicability of ML models, ultimately improving patient outcomes in healthcare\nsettings.", "categories": "cs.LG", "created": "2024-08-05", "doi": null, "arxiv_id": "2408.02344"}
{"title": "Nonlocal particle approximation for linear and fast diffusion equations", "authors": [], "abstract": "We construct deterministic particle solutions for linear and fast diffusion\nequations using a nonlocal approximation. We exploit the $2$-Wasserstein\ngradient flow structure of the equations in order to obtain the nonlocal\napproximating PDEs by regularising the corresponding internal energy with\nsuitably chosen mollifying kernels, either compactly or globally supported.\nWeak solutions are obtained by the JKO scheme. From the technical point of\nview, we improve known commutator estimates, fundamental in the\nnonlocal-to-local limit, to include globally supported kernels which, in\nparticular cases, allow us to justify the limit without any further\nperturbation needed. Furthermore, we prove geodesic convexity of the nonlocal\nenergies in order to prove convergence of the particle solutions to the\nnonlocal equations towards weak solutions of the local equations. We overcome\nthe crucial difficulty of dealing with the singularity of the first variation\nof the free energies at the origin. As a byproduct, we provide convergence\nrates expressed as a scaling relationship between the number of particles and\nthe localisation parameter. The analysis we perform leverages the fact that\nglobally supported kernels yield a better convergence rate compared to\ncompactly supported kernels. Our result is relevant in statistics, more\nprecisely in sampling Gibbs and heavy-tailed distributions.", "categories": "math.AP cs.NA math.NA", "created": "2024-08-05", "doi": null, "arxiv_id": "2408.02345"}
{"title": "Exploiting Hankel-Toeplitz Structures for Fast Computation of Kernel\n  Precision Matrices", "authors": [], "abstract": "The Hilbert-space Gaussian Process (HGP) approach offers a\nhyperparameter-independent basis function approximation for speeding up\nGaussian Process (GP) inference by projecting the GP onto M basis functions.\nThese properties result in a favorable data-independent $\\mathcal{O}(M^3)$\ncomputational complexity during hyperparameter optimization but require a\ndominating one-time precomputation of the precision matrix costing\n$\\mathcal{O}(NM^2)$ operations. In this paper, we lower this dominating\ncomputational complexity to $\\mathcal{O}(NM)$ with no additional\napproximations. We can do this because we realize that the precision matrix can\nbe split into a sum of Hankel-Toeplitz matrices, each having $\\mathcal{O}(M)$\nunique entries. Based on this realization we propose computing only these\nunique entries at $\\mathcal{O}(NM)$ costs. Further, we develop two theorems\nthat prescribe sufficient conditions for the complexity reduction to hold\ngenerally for a wide range of other approximate GP models, such as the\nVariational Fourier Feature (VFF) approach. The two theorems do this with no\nassumptions on the data and no additional approximations of the GP models\nthemselves. Thus, our contribution provides a pure speed-up of several\nexisting, widely used, GP approximations, without further approximations.", "categories": "cs.LG stat.ML", "created": "2024-08-05", "doi": null, "arxiv_id": "2408.02346"}
{"title": "Improved Bounds for High-Dimensional Equivalence and Product Testing\n  using Subcube Queries", "authors": [], "abstract": "We study property testing in the subcube conditional model introduced by\nBhattacharyya and Chakraborty (2017). We obtain the first equivalence test for\n$n$-dimensional distributions that is quasi-linear in $n$, improving the\npreviously known $\\tilde{O}(n^2/\\varepsilon^2)$ query complexity bound to\n$\\tilde{O}(n/\\varepsilon^2)$. We extend this result to general finite alphabets\nwith logarithmic cost in the alphabet size.\n  By exploiting the specific structure of the queries that we use (which are\nmore restrictive than general subcube queries), we obtain a cubic improvement\nover the best known test for distributions over $\\{1,\\ldots,N\\}$ under the\ninterval querying model of Canonne, Ron and Servedio (2015), attaining a query\ncomplexity of $\\tilde{O}((\\log N)/\\varepsilon^2)$, which for fixed\n$\\varepsilon$ almost matches the known lower bound of $\\Omega((\\log N)/\\log\\log\nN)$. We also derive a product test for $n$-dimensional distributions with\n$\\tilde{O}(n / \\varepsilon^2)$ queries, and provide an $\\Omega(\\sqrt{n} /\n\\varepsilon^2)$ lower bound for this property.", "categories": "cs.DS", "created": "2024-08-05", "doi": null, "arxiv_id": "2408.02347"}
{"title": "Earth System Data Cubes: Avenues for advancing Earth system research", "authors": [], "abstract": "Recent advancements in Earth system science have been marked by the\nexponential increase in the availability of diverse, multivariate datasets\ncharacterised by moderate to high spatio-temporal resolutions. Earth System\nData Cubes (ESDCs) have emerged as one suitable solution for transforming this\nflood of data into a simple yet robust data structure. ESDCs achieve this by\norganising data into an analysis-ready format aligned with a spatio-temporal\ngrid, facilitating user-friendly analysis and diminishing the need for\nextensive technical data processing knowledge. Despite these significant\nbenefits, the completion of the entire ESDC life cycle remains a challenging\ntask. Obstacles are not only of a technical nature but also relate to\ndomain-specific problems in Earth system research. There exist barriers to\nrealising the full potential of data collections in light of novel cloud-based\ntechnologies, particularly in curating data tailored for specific application\ndomains. These include transforming data to conform to a spatio-temporal grid\nwith minimum distortions and managing complexities such as spatio-temporal\nautocorrelation issues. Addressing these challenges is pivotal for the\neffective application of Artificial Intelligence (AI) approaches. Furthermore,\nadhering to open science principles for data dissemination, reproducibility,\nvisualisation, and reuse is crucial for fostering sustainable research.\nOvercoming these challenges offers a substantial opportunity to advance\ndata-driven Earth system research, unlocking the full potential of an\nintegrated, multidimensional view of Earth system processes. This is\nparticularly true when such research is coupled with innovative research\nparadigms and technological progress.", "categories": "cs.CV cs.DB", "created": "2024-08-05", "doi": null, "arxiv_id": "2408.02348"}
{"title": "Active Sensing of Knee Osteoarthritis Progression with Reinforcement\n  Learning", "authors": [], "abstract": "Osteoarthritis (OA) is the most common musculoskeletal disease, which has no\ncure. Knee OA (KOA) is one of the highest causes of disability worldwide, and\nit costs billions of United States dollars to the global community. Prediction\nof KOA progression has been of high interest to the community for years, as it\ncan advance treatment development through more efficient clinical trials and\nimprove patient outcomes through more efficient healthcare utilization.\nExisting approaches for predicting KOA, however, are predominantly static, i.e.\nconsider data from a single time point to predict progression many years into\nthe future, and knee level, i.e. consider progression in a single joint only.\nDue to these and related reasons, these methods fail to deliver the level of\npredictive performance, which is sufficient to result in cost savings and\nbetter patient outcomes. Collecting extensive data from all patients on a\nregular basis could address the issue, but it is limited by the high cost at a\npopulation level. In this work, we propose to go beyond static prediction\nmodels in OA, and bring a novel Active Sensing (AS) approach, designed to\ndynamically follow up patients with the objective of maximizing the number of\ninformative data acquisitions, while minimizing their total cost over a period\nof time. Our approach is based on Reinforcement Learning (RL), and it leverages\na novel reward function designed specifically for AS of disease progression in\nmore than one part of a human body. Our method is end-to-end, relies on\nmulti-modal Deep Learning, and requires no human input at inference time.\nThroughout an exhaustive experimental evaluation, we show that using RL can\nprovide a higher monetary benefit when compared to state-of-the-art baselines.", "categories": "cs.LG cs.AI", "created": "2024-08-05", "doi": null, "arxiv_id": "2408.02349"}
{"title": "High-performance computing for the BGK model of the Boltzmann equation\n  with a meshfree Arbitrary Lagrangian-Eulerian (ALE) method", "authors": [], "abstract": "In this paper, we present high-performance computing for the BGK model of the\nBoltzmann equations with a meshfree method. We use the\nArbitrary-Lagrangian-Eulerian (ALE) method, where the approximation of spatial\nderivatives and the reconstruction of a function is based on the weighted least\nsquares method. We have used the Graphics Processing Unit (GPU) to accelerate\nthe code and compared with the CPU code. Two and three dimensional driven\ncavity problems are solved, where we have obtained the speed up up to 307 times\nand 127 times in two and three dimensional cases, respectively.", "categories": "math.NA cs.NA", "created": "2024-08-05", "doi": null, "arxiv_id": "2408.02350"}
{"title": "RECE: Reduced Cross-Entropy Loss for Large-Catalogue Sequential\n  Recommenders", "authors": [], "abstract": "Scalability is a major challenge in modern recommender systems. In sequential\nrecommendations, full Cross-Entropy (CE) loss achieves state-of-the-art\nrecommendation quality but consumes excessive GPU memory with large item\ncatalogs, limiting its practicality. Using a GPU-efficient locality-sensitive\nhashing-like algorithm for approximating large tensor of logits, this paper\nintroduces a novel RECE (REduced Cross-Entropy) loss. RECE significantly\nreduces memory consumption while allowing one to enjoy the state-of-the-art\nperformance of full CE loss. Experimental results on various datasets show that\nRECE cuts training peak memory usage by up to 12 times compared to existing\nmethods while retaining or exceeding performance metrics of CE loss. The\napproach also opens up new possibilities for large-scale applications in other\ndomains.", "categories": "cs.IR cs.LG", "created": "2024-08-05", "doi": "10.1145/3627673.3679986", "arxiv_id": "2408.02354"}
{"title": "Quantile Regression using Random Forest Proximities", "authors": [], "abstract": "Due to the dynamic nature of financial markets, maintaining models that\nproduce precise predictions over time is difficult. Often the goal isn't just\npoint prediction but determining uncertainty. Quantifying uncertainty,\nespecially the aleatoric uncertainty due to the unpredictable nature of market\ndrivers, helps investors understand varying risk levels. Recently, quantile\nregression forests (QRF) have emerged as a promising solution: Unlike most\nbasic quantile regression methods that need separate models for each quantile,\nquantile regression forests estimate the entire conditional distribution of the\ntarget variable with a single model, while retaining all the salient features\nof a typical random forest. We introduce a novel approach to compute quantile\nregressions from random forests that leverages the proximity (i.e., distance\nmetric) learned by the model and infers the conditional distribution of the\ntarget variable. We evaluate the proposed methodology using publicly available\ndatasets and then apply it towards the problem of forecasting the average daily\nvolume of corporate bonds. We show that using quantile regression using Random\nForest proximities demonstrates superior performance in approximating\nconditional target distributions and prediction intervals to the original\nversion of QRF. We also demonstrate that the proposed framework is\nsignificantly more computationally efficient than traditional approaches to\nquantile regressions.", "categories": "stat.ML cs.LG q-fin.ST q-fin.TR", "created": "2024-08-05", "doi": null, "arxiv_id": "2408.02355"}
{"title": "On the consistent reasoning paradox of intelligence and optimal trust in\n  AI: The power of 'I don't know'", "authors": [], "abstract": "We introduce the Consistent Reasoning Paradox (CRP). Consistent reasoning,\nwhich lies at the core of human intelligence, is the ability to handle tasks\nthat are equivalent, yet described by different sentences ('Tell me the time!'\nand 'What is the time?'). The CRP asserts that consistent reasoning implies\nfallibility -- in particular, human-like intelligence in AI necessarily comes\nwith human-like fallibility. Specifically, it states that there are problems,\ne.g. in basic arithmetic, where any AI that always answers and strives to mimic\nhuman intelligence by reasoning consistently will hallucinate (produce wrong,\nyet plausible answers) infinitely often. The paradox is that there exists a\nnon-consistently reasoning AI (which therefore cannot be on the level of human\nintelligence) that will be correct on the same set of problems. The CRP also\nshows that detecting these hallucinations, even in a probabilistic sense, is\nstrictly harder than solving the original problems, and that there are problems\nthat an AI may answer correctly, but it cannot provide a correct logical\nexplanation for how it arrived at the answer. Therefore, the CRP implies that\nany trustworthy AI (i.e., an AI that never answers incorrectly) that also\nreasons consistently must be able to say 'I don't know'. Moreover, this can\nonly be done by implicitly computing a new concept that we introduce, termed\nthe 'I don't know' function -- something currently lacking in modern AI. In\nview of these insights, the CRP also provides a glimpse into the behaviour of\nArtificial General Intelligence (AGI). An AGI cannot be 'almost sure', nor can\nit always explain itself, and therefore to be trustworthy it must be able to\nsay 'I don't know'.", "categories": "cs.AI cs.LG math.OC math.PR", "created": "2024-08-05", "doi": null, "arxiv_id": "2408.02357"}
{"title": "Potential Hessian Ascent: The Sherrington-Kirkpatrick Model", "authors": [], "abstract": "We provide the first iterative spectral algorithm to find near-optima of a\nrandom quadratic objective over the discrete hypercube. The algorithm is a\nrandomized Hessian ascent in the solid cube, where we modify the objective by\nsubtracting a specific instance-independent potential function [Chen et al.,\nCommunications on Pure and Applied Mathematics, 76(7), 2023]. This extends\nSubag's algorithmic program of Hessian ascent from the sphere [Subag,\nCommunications on Pure and Applied Mathematics, 74(5), 2021] to the more\ncomplex geometry of the cube.\n  Utilizing tools from free probability theory, we construct an approximate\nprojector into the top-eigenspaces of the Hessian with well-behaved diagonal\nentries, and use it as the covariance matrix for the random increments. With\nhigh probability, the empirical distribution of the iterates approximates the\nsolution to the primal version of the Auffinger-Chen SDE [Auffinger et al.,\nCommunications in Mathematical Physics, 335, 2015]. We then bound the change to\nthe modified objective function for every iterate via a Taylor expansion whose\nderivatives are controlled using various Gaussian concentration bounds and\nsmoothness properties of (a semiconcave regularization of) the Fenchel-Legendre\ndual to the solution of the Parisi PDE.\n  These results lay the groundwork for demonstrating the (possible) existence\nof low-degree sum-of-squares certificates over high-entropy step distributions\nfor a relaxed version of the Parisi formula [Open Question 1.8,\narXiv:2401.14383].", "categories": "math.PR cs.DS math-ph math.MP", "created": "2024-08-05", "doi": null, "arxiv_id": "2408.02360"}
{"title": "Dialogue Ontology Relation Extraction via Constrained Chain-of-Thought\n  Decoding", "authors": [], "abstract": "State-of-the-art task-oriented dialogue systems typically rely on\ntask-specific ontologies for fulfilling user queries. The majority of\ntask-oriented dialogue data, such as customer service recordings, comes without\nontology and annotation. Such ontologies are normally built manually, limiting\nthe application of specialised systems. Dialogue ontology construction is an\napproach for automating that process and typically consists of two steps: term\nextraction and relation extraction. In this work, we focus on relation\nextraction in a transfer learning set-up. To improve the generalisation, we\npropose an extension to the decoding mechanism of large language models. We\nadapt Chain-of-Thought (CoT) decoding, recently developed for reasoning\nproblems, to generative relation extraction. Here, we generate multiple\nbranches in the decoding space and select the relations based on a confidence\nthreshold. By constraining the decoding to ontology terms and relations, we aim\nto decrease the risk of hallucination. We conduct extensive experimentation on\ntwo widely used datasets and find improvements in performance on target\nontology for source fine-tuned and one-shot prompted large language models.", "categories": "cs.CL cs.AI cs.LG", "created": "2024-08-05", "doi": null, "arxiv_id": "2408.02361"}
{"title": "Equilibrium Formulation of a 3 DOF Compliant Mechanism using Sylvester\n  Dialytic Method of Elimination", "authors": [], "abstract": "This paper studies the equilibrium formulation of a three degree of freedom\nplanar compliant platform mechanism, which is in contact with a solid body in\nits environment. The mechanism includes two platforms, which are connected in\nparallel by three linear springs. The capability of deformation by manipulating\nboth platforms exceptionally complicates the problem. The analysis aims to\ndetermine all equilibrium configurations for two different cases: FIRST CASE\nall three springs have zero free lengths and SECOND CASE only two of the\nsprings have zero free lengths. The proposed procedure calculates the pose of\nthe top platform when it is not in contact with the surface, and then detects\nif the top platform is in contact to determine the equilibrium configurations.\nTo solve the geometric equations of the mechanism, we use Sylvester method of\nelimination. The approach obtains 4th and 48th degree polynomial equations for\nthe first and second cases, respectively. Numerical examples have been applied\nto verify the process of analysis. The results, which are numerically\ncalculated by software Maple, prove the validity of the analysis.", "categories": "eess.SY cs.SY", "created": "2024-08-05", "doi": null, "arxiv_id": "2408.02363"}
{"title": "StoDIP: Efficient 3D MRF image reconstruction with deep image priors and\n  stochastic iterations", "authors": [], "abstract": "Magnetic Resonance Fingerprinting (MRF) is a time-efficient approach to\nquantitative MRI for multiparametric tissue mapping. The reconstruction of\nquantitative maps requires tailored algorithms for removing aliasing artefacts\nfrom the compressed sampled MRF acquisitions. Within approaches found in the\nliterature, many focus solely on two-dimensional (2D) image reconstruction,\nneglecting the extension to volumetric (3D) scans despite their higher\nrelevance and clinical value. A reason for this is that transitioning to 3D\nimaging without appropriate mitigations presents significant challenges,\nincluding increased computational cost and storage requirements, and the need\nfor large amount of ground-truth (artefact-free) data for training. To address\nthese issues, we introduce StoDIP, a new algorithm that extends the\nground-truth-free Deep Image Prior (DIP) reconstruction to 3D MRF imaging.\nStoDIP employs memory-efficient stochastic updates across the multicoil MRF\ndata, a carefully selected neural network architecture, as well as faster\nnonuniform FFT (NUFFT) transformations. This enables a faster convergence\ncompared against a conventional DIP implementation without these features.\nTested on a dataset of whole-brain scans from healthy volunteers, StoDIP\ndemonstrated superior performance over the ground-truth-free reconstruction\nbaselines, both quantitatively and qualitatively.", "categories": "eess.IV cs.CV cs.LG", "created": "2024-08-05", "doi": null, "arxiv_id": "2408.02367"}
{"title": "Operationalizing Contextual Integrity in Privacy-Conscious Assistants", "authors": [], "abstract": "Advanced AI assistants combine frontier LLMs and tool access to autonomously\nperform complex tasks on behalf of users. While the helpfulness of such\nassistants can increase dramatically with access to user information including\nemails and documents, this raises privacy concerns about assistants sharing\ninappropriate information with third parties without user supervision. To steer\ninformation-sharing assistants to behave in accordance with privacy\nexpectations, we propose to operationalize $\\textit{contextual integrity}$\n(CI), a framework that equates privacy with the appropriate flow of information\nin a given context. In particular, we design and evaluate a number of\nstrategies to steer assistants' information-sharing actions to be CI compliant.\nOur evaluation is based on a novel form filling benchmark composed of synthetic\ndata and human annotations, and it reveals that prompting frontier LLMs to\nperform CI-based reasoning yields strong results.", "categories": "cs.AI", "created": "2024-08-05", "doi": null, "arxiv_id": "2408.02373"}
{"title": "A Few-Shot Approach for Relation Extraction Domain Adaptation using\n  Large Language Models", "authors": [], "abstract": "Knowledge graphs (KGs) have been successfully applied to the analysis of\ncomplex scientific and technological domains, with automatic KG generation\nmethods typically building upon relation extraction models capturing\nfine-grained relations between domain entities in text. While these relations\nare fully applicable across scientific areas, existing models are trained on\nfew domain-specific datasets such as SciERC and do not perform well on new\ntarget domains. In this paper, we experiment with leveraging in-context\nlearning capabilities of Large Language Models to perform schema-constrained\ndata annotation, collecting in-domain training instances for a\nTransformer-based relation extraction model deployed on titles and abstracts of\nresearch papers in the Architecture, Construction, Engineering and Operations\n(AECO) domain. By assessing the performance gain with respect to a baseline\nDeep Learning architecture trained on off-domain data, we show that by using a\nfew-shot learning strategy with structured prompts and only minimal expert\nannotation the presented approach can potentially support domain adaptation of\na science KG generation model.", "categories": "cs.CL cs.AI", "created": "2024-08-05", "doi": null, "arxiv_id": "2408.02377"}
{"title": "Perfect Information Monte Carlo with Postponing Reasoning", "authors": [], "abstract": "Imperfect information games, such as Bridge and Skat, present challenges due\nto state-space explosion and hidden information, posing formidable obstacles\nfor search algorithms. Determinization-based algorithms offer a resolution by\nsampling hidden information and solving the game in a perfect information\nsetting, facilitating rapid and effective action estimation. However,\ntransitioning to perfect information introduces challenges, notably one called\nstrategy fusion.This research introduces `Extended Perfect Information Monte\nCarlo' (EPIMC), an online algorithm inspired by the state-of-the-art\ndeterminization-based approach Perfect Information Monte Carlo (PIMC). EPIMC\nenhances the capabilities of PIMC by postponing the perfect information\nresolution, reducing alleviating issues related to strategy fusion. However,\nthe decision to postpone the leaf evaluator introduces novel considerations,\nsuch as the interplay between prior levels of reasoning and the newly deferred\nresolution. In our empirical analysis, we investigate the performance of EPIMC\nacross a range of games, with a particular focus on those characterized by\nvarying degrees of strategy fusion. Our results demonstrate notable performance\nenhancements, particularly in games where strategy fusion significantly impacts\ngameplay. Furthermore, our research contributes to the theoretical foundation\nof determinization-based algorithms addressing challenges associated with\nstrategy fusion.%, thereby enhancing our understanding of these algorithms\nwithin the context of imperfect information game scenarios.", "categories": "cs.AI", "created": "2024-08-05", "doi": null, "arxiv_id": "2408.02380"}
{"title": "Cross Psuedo Supervision Framework for Sparsely Labelled Geo-spatial\n  Images", "authors": [], "abstract": "Land Use Land Cover (LULC) mapping is essential for urban and resource\nplanning and is one of the key elements in developing smart and sustainable\ncities. This study introduces a semi-supervised segmentation model for LULC\nprediction using high-resolution satellite images with a huge diversity in data\ndistributions in different areas from the country of India. Our approach\nensures a robust generalization across different types of buildings, roads,\ntrees, and water bodies within these distinct areas. We propose a modified\nCross Pseudo Supervision framework to train image segmentation models on\nsparsely labelled data. The proposed framework addresses the limitations of the\npopular \"Cross Pseudo Supervision\" technique for semi-supervised learning.\nSpecifically, it tackles the challenges of training segmentation models on\nnoisy satellite image data with sparse and inaccurate labels. This\ncomprehensive approach enhances the accuracy and utility of LULC mapping for\nvarious urban planning applications.", "categories": "cs.CV", "created": "2024-08-05", "doi": null, "arxiv_id": "2408.02382"}
{"title": "Strategic Federated Learning: Application to Smart Meter Data Clustering", "authors": [], "abstract": "Federated learning (FL) involves several clients that share with a fusion\ncenter (FC), the model each client has trained with its own data. Conventional\nFL, which can be interpreted as an estimation or distortion-based approach,\nignores the final use of model information (MI) by the FC and the other\nclients. In this paper, we introduce a novel FL framework in which the FC uses\nan aggregate version of the MI to make decisions that affect the client's\nutility functions. Clients cannot choose the decisions and can only use the MI\nreported to the FC to maximize their utility. Depending on the alignment\nbetween the client and FC utilities, the client may have an individual interest\nin adding strategic noise to the model. This general framework is stated and\nspecialized to the case of clustering, in which noisy cluster representative\ninformation is reported. This is applied to the problem of power consumption\nscheduling. In this context, utility non-alignment occurs, for instance, when\nthe client wants to consume when the price of electricity is low, whereas the\nFC wants the consumption to occur when the total power is the lowest. This is\nillustrated with aggregated real data from Ausgrid \\cite{ausgrid}. Our\nnumerical analysis clearly shows that the client can increase his utility by\nadding noise to the model reported to the FC. Corresponding results and source\ncodes can be downloaded from \\cite{source-code}.", "categories": "cs.LG cs.GT", "created": "2024-08-05", "doi": null, "arxiv_id": "2408.02384"}
{"title": "Responsibility and Regulation: Exploring Social Measures of Trust in\n  Medical AI", "authors": [], "abstract": "This paper explores expert accounts of autonomous systems (AS) development in\nthe medical device domain (MD) involving applications of artificial\nintelligence (AI), machine learning (ML), and other algorithmic and\nmathematical modelling techniques. We frame our observations with respect to\nnotions of responsible innovation (RI) and the emerging problem of how to do RI\nin practice. In contribution to the ongoing discourse surrounding trustworthy\nautonomous system (TAS) [29], we illuminate practical challenges inherent in\ndeploying novel AS within existing governance structures, including domain\nspecific regulations and policies, and rigorous testing and development\nprocesses, and discuss the implications of these for the distribution of\nresponsibility in novel AI deployment.", "categories": "cs.HC", "created": "2024-08-05", "doi": "10.1145/3686038.3686041", "arxiv_id": "2408.02386"}
{"title": "Extension preservation on dense graph classes", "authors": [], "abstract": "Preservation theorems provide a direct correspondence between the syntactic\nstructure of first-order sentences and the closure properties of their\nrespective classes of models. A line of work has explored preservation theorems\nrelativised to combinatorially tame classes of sparse structures [Atserias et\nal., JACM 2006; Atserias et al., SiCOMP 2008; Dawar, JCSS 2010; Dawar and\nEleftheriadis, 2024]. In this article we initiate the study of preservation\ntheorems for dense graph classes. In contrast to the sparse setting, we show\nthat extension preservation fails on most natural dense classes of low\ncomplexity. Nonetheless, we isolate a technical condition which is sufficient\nfor extension preservation to hold, providing a dense analogue to a result of\n[Atserias et al., SiCOMP 2008].", "categories": "cs.LO", "created": "2024-08-05", "doi": null, "arxiv_id": "2408.02388"}
{"title": "Fast Estimation of Percolation Centrality", "authors": [], "abstract": "In this work, we present a new algorithm to approximate the percolation\ncentrality of every node in a graph. Such a centrality measure quantifies the\nimportance of the vertices in a network during a contagious process. In this\npaper, we present a randomized approximation algorithm that can compute\nprobabilistically guaranteed high-quality percolation centrality estimates,\ngeneralizing techniques used by Pellegrina and Vandin (TKDD 2024) for the\nbetweenness centrality. The estimation obtained by our algorithm is within\n$\\varepsilon$ of the value with probability at least $1-\\delta$, for fixed\nconstants $\\varepsilon,\\delta \\in (0,1)$. We our theoretical results with an\nextensive experimental analysis on several real-world networks and provide\nempirical evidence that our algorithm improves the current state of the art in\nspeed, and sample size while maintaining high accuracy of the percolation\ncentrality estimates.", "categories": "cs.SI cs.DS", "created": "2024-08-05", "doi": null, "arxiv_id": "2408.02389"}
{"title": "MaFreeI2P: A Matching-Free Image-to-Point Cloud Registration Paradigm\n  with Active Camera Pose Retrieval", "authors": [], "abstract": "Image-to-point cloud registration seeks to estimate their relative camera\npose, which remains an open question due to the data modality gaps. The recent\nmatching-based methods tend to tackle this by building 2D-3D correspondences.\nIn this paper, we reveal the information loss inherent in these methods and\npropose a matching-free paradigm, named MaFreeI2P. Our key insight is to\nactively retrieve the camera pose in SE(3) space by contrasting the geometric\nfeatures between the point cloud and the query image. To achieve this, we first\nsample a set of candidate camera poses and construct their cost volume using\nthe cross-modal features. Superior to matching, cost volume can preserve more\ninformation and its feature similarity implicitly reflects the confidence level\nof the sampled poses. Afterwards, we employ a convolutional network to\nadaptively formulate a similarity assessment function, where the input cost\nvolume is further improved by filtering and pose-based weighting. Finally, we\nupdate the camera pose based on the similarity scores, and adopt a heuristic\nstrategy to iteratively shrink the pose sampling space for convergence. Our\nMaFreeI2P achieves a very competitive registration accuracy and recall on the\nKITTI-Odometry and Apollo-DaoxiangLake datasets.", "categories": "cs.CV eess.IV", "created": "2024-08-05", "doi": null, "arxiv_id": "2408.02392"}
{"title": "CMR-Agent: Learning a Cross-Modal Agent for Iterative Image-to-Point\n  Cloud Registration", "authors": [], "abstract": "Image-to-point cloud registration aims to determine the relative camera pose\nof an RGB image with respect to a point cloud. It plays an important role in\ncamera localization within pre-built LiDAR maps. Despite the modality gaps,\nmost learning-based methods establish 2D-3D point correspondences in feature\nspace without any feedback mechanism for iterative optimization, resulting in\npoor accuracy and interpretability. In this paper, we propose to reformulate\nthe registration procedure as an iterative Markov decision process, allowing\nfor incremental adjustments to the camera pose based on each intermediate\nstate. To achieve this, we employ reinforcement learning to develop a\ncross-modal registration agent (CMR-Agent), and use imitation learning to\ninitialize its registration policy for stability and quick-start of the\ntraining. According to the cross-modal observations, we propose a 2D-3D hybrid\nstate representation that fully exploits the fine-grained features of RGB\nimages while reducing the useless neutral states caused by the spatial\ntruncation of camera frustum. Additionally, the overall framework is\nwell-designed to efficiently reuse one-shot cross-modal embeddings, avoiding\nrepetitive and time-consuming feature extraction. Extensive experiments on the\nKITTI-Odometry and NuScenes datasets demonstrate that CMR-Agent achieves\ncompetitive accuracy and efficiency in registration. Once the one-shot\nembeddings are completed, each iteration only takes a few milliseconds.", "categories": "cs.CV cs.RO", "created": "2024-08-05", "doi": null, "arxiv_id": "2408.02394"}
{"title": "Global Observability Analysis of a Growth Model for Insects Farming", "authors": [], "abstract": "The Hermetia illucens insects or the black soldier fly has been attracting a\ngrowing interest in the food and feed industry. For its high nutritional value\non the one hand, and because it is an adequate species for insects in\ncontrolled environmental agriculture systems, on the other. Therefore, several\nmodels describing this larvae's behaviour have been developed in the\nliterature. Due to the complex nature of living organisms, systems of\ncontrolled environment agriculture are characterised by their strong\nnonlinearities. In this paper, we present a three dimensional nonlinear model\ndescribing the black soldier fly dry biomass weight dynamic changes due to the\ntemperature's influence. In practice, this biomass weight is not measured in\nreal time. This becomes problematic for applying feedback control strategies\nthat assume full information of the states. Thus, this work investigates the\nobservability of the dry biomass of a Hermetia illucens farming batch. The\ninstantaneous and global observability of the aforementioned model is proven by\nconstructing an injective transformation between the state space and a higher\ndimensional space where the transformed states are observable.", "categories": "eess.SY cs.SY", "created": "2024-08-05", "doi": "10.23919/ECC64448.2024.10590940", "arxiv_id": "2408.02395"}
{"title": "Tensorial template matching for fast cross-correlation with rotations\n  and its application for tomography", "authors": [], "abstract": "Object detection is a main task in computer vision. Template matching is the\nreference method for detecting objects with arbitrary templates. However,\ntemplate matching computational complexity depends on the rotation accuracy,\nbeing a limiting factor for large 3D images (tomograms). Here, we implement a\nnew algorithm called tensorial template matching, based on a mathematical\nframework that represents all rotations of a template with a tensor field.\nContrary to standard template matching, the computational complexity of the\npresented algorithm is independent of the rotation accuracy. Using both,\nsynthetic and real data from tomography, we demonstrate that tensorial template\nmatching is much faster than template matching and has the potential to improve\nits accuracy", "categories": "cs.CV q-bio.QM", "created": "2024-08-05", "doi": null, "arxiv_id": "2408.02398"}
{"title": "Teaching Action Research", "authors": [], "abstract": "Action research entered into software engineering as one of the responses to\nthe software engineering research crisis at the end of the last millennium. As\none of the challenges in the crisis was the lack of empirical results and the\ntransfer of research results into practices, action research could address\nthese challenges. It is a methodology where collaboration and host\norganizations are the focus of knowledge discovery, development, and\ndocumentation. Although the method is often well received in industrial\ncontexts, it isn't easy to learn as it requires experience and varies from\norganization to organization. This chapter describes the pillars of action\nresearch as a methodology and how to teach them. The chapter includes examples\nof teaching action research at the bachelor, master, and PhD levels. In\naddition to theory, the chapter contains examples from practice.", "categories": "cs.SE", "created": "2024-08-05", "doi": null, "arxiv_id": "2408.02399"}
{"title": "Enhancing AI-based Generation of Software Exploits with Contextual\n  Information", "authors": [], "abstract": "This practical experience report explores Neural Machine Translation (NMT)\nmodels' capability to generate offensive security code from natural language\n(NL) descriptions, highlighting the significance of contextual understanding\nand its impact on model performance. Our study employs a dataset comprising\nreal shellcodes to evaluate the models across various scenarios, including\nmissing information, necessary context, and unnecessary context. The\nexperiments are designed to assess the models' resilience against incomplete\ndescriptions, their proficiency in leveraging context for enhanced accuracy,\nand their ability to discern irrelevant information. The findings reveal that\nthe introduction of contextual data significantly improves performance.\nHowever, the benefits of additional context diminish beyond a certain point,\nindicating an optimal level of contextual information for model training.\nMoreover, the models demonstrate an ability to filter out unnecessary context,\nmaintaining high levels of accuracy in the generation of offensive security\ncode. This study paves the way for future research on optimizing context use in\nAI-driven code generation, particularly for applications requiring a high\ndegree of technical precision such as the generation of offensive code.", "categories": "cs.SE cs.AI", "created": "2024-08-05", "doi": null, "arxiv_id": "2408.02402"}
{"title": "Online Fair Allocation with Best-of-Many-Worlds Guarantees", "authors": [], "abstract": "We investigate the online fair allocation problem with sequentially arriving\nitems under various input models, with the goal of balancing fairness and\nefficiency. We propose the unconstrained PACE (Pacing According to Current\nEstimated utility) algorithm, a parameter-free allocation dynamic that requires\nno prior knowledge of the input while using only integral allocations. PACE\nattains near-optimal convergence or approximation guarantees under stationary,\nstochastic-but-nonstationary, and adversarial input types, thereby achieving\nthe first best-of-many-worlds guarantee in online fair allocation. Beyond\ntheoretical bounds, PACE is highly simple, efficient, and decentralized, and is\nthus likely to perform well on a broad range of real-world inputs. Numerical\nresults support the conclusion that PACE works well under a variety of input\nmodels. We find that PACE performs very well on two real-world datasets even\nunder the true temporal arrivals in the data, which are highly nonstationary.", "categories": "cs.GT cs.DS math.OC", "created": "2024-08-05", "doi": null, "arxiv_id": "2408.02403"}
{"title": "Feedback Reciprocal Graph Collaborative Filtering", "authors": [], "abstract": "Collaborative filtering on user-item interaction graphs has achieved success\nin the industrial recommendation. However, recommending users' truly fascinated\nitems poses a seesaw dilemma for collaborative filtering models learned from\nthe interaction graph. On the one hand, not all items that users interact with\nare equally appealing. Some items are genuinely fascinating to users, while\nothers are unfascinated. Training graph collaborative filtering models in the\nabsence of distinction between them can lead to the recommendation of\nunfascinating items to users. On the other hand, disregarding the interacted\nbut unfascinating items during graph collaborative filtering will result in an\nincomplete representation of users' interaction intent, leading to a decline in\nthe model's recommendation capabilities. To address this seesaw problem, we\npropose Feedback Reciprocal Graph Collaborative Filtering (FRGCF), which\nemphasizes the recommendation of fascinating items while attenuating the\nrecommendation of unfascinating items. Specifically, FRGCF first partitions the\nentire interaction graph into the Interacted & Fascinated (I&F) graph and the\nInteracted & Unfascinated (I&U) graph based on the user feedback. Then, FRGCF\nintroduces separate collaborative filtering on the I&F graph and the I&U graph\nwith feedback-reciprocal contrastive learning and macro-level feedback\nmodeling. This enables the I&F graph recommender to learn multi-grained\ninteraction characteristics from the I&U graph without being misdirected by it.\nExtensive experiments on four benchmark datasets and a billion-scale industrial\ndataset demonstrate that FRGCF improves the performance by recommending more\nfascinating items and fewer unfascinating items. Besides, online A/B tests on\nTaobao's recommender system verify the superiority of FRGCF.", "categories": "cs.IR", "created": "2024-08-05", "doi": null, "arxiv_id": "2408.02404"}
{"title": "Multi-weather Cross-view Geo-localization Using Denoising Diffusion\n  Models", "authors": [], "abstract": "Cross-view geo-localization in GNSS-denied environments aims to determine an\nunknown location by matching drone-view images with the correct geo-tagged\nsatellite-view images from a large gallery. Recent research shows that learning\ndiscriminative image representations under specific weather conditions can\nsignificantly enhance performance. However, the frequent occurrence of unseen\nextreme weather conditions hinders progress. This paper introduces MCGF, a\nMulti-weather Cross-view Geo-localization Framework designed to dynamically\nadapt to unseen weather conditions. MCGF establishes a joint optimization\nbetween image restoration and geo-localization using denoising diffusion\nmodels. For image restoration, MCGF incorporates a shared encoder and a\nlightweight restoration module to help the backbone eliminate weather-specific\ninformation. For geo-localization, MCGF uses EVA-02 as a backbone for feature\nextraction, with cross-entropy loss for training and cosine distance for\ntesting. Extensive experiments on University160k-WX demonstrate that MCGF\nachieves competitive results for geo-localization in varying weather\nconditions.", "categories": "cs.CV cs.AI", "created": "2024-08-05", "doi": null, "arxiv_id": "2408.02408"}
{"title": "Fairness in Multi-Proposer-Multi-Responder Ultimatum Game", "authors": [], "abstract": "The Ultimatum Game is conventionally formulated in the context of two\nplayers. Nonetheless, real-life scenarios often entail community interactions\namong numerous individuals. To address this, we introduce an extended version\nof the Ultimatum Game, called the Multi-Proposer-Multi-Responder Ultimatum\nGame. In this model, multiple responders and proposers simultaneously interact\nin a one-shot game, introducing competition both within proposers and within\nresponders. We derive subgame-perfect Nash equilibria for all scenarios and\nexplore how these non-trivial values might provide insight into proposal and\nrejection behavior experimentally observed in the context of one vs. one\nUltimatum Game scenarios. Additionally, by considering the asymptotic numbers\nof players, we propose two potential estimates for a \"fair\" threshold: either\n31.8% or 36.8% of the pie (share) for the responder.", "categories": "math.OC cs.GT econ.TH", "created": "2024-08-05", "doi": null, "arxiv_id": "2408.02410"}
{"title": "PENDRAM: Enabling High-Performance and Energy-Efficient Processing of\n  Deep Neural Networks through a Generalized DRAM Data Mapping Policy", "authors": [], "abstract": "Convolutional Neural Networks (CNNs), a prominent type of Deep Neural\nNetworks (DNNs), have emerged as a state-of-the-art solution for solving\nmachine learning tasks. To improve the performance and energy efficiency of CNN\ninference, the employment of specialized hardware accelerators is prevalent.\nHowever, CNN accelerators still face performance- and energy-efficiency\nchallenges due to high off-chip memory (DRAM) access latency and energy, which\nare especially crucial for latency- and energy-constrained embedded\napplications. Moreover, different DRAM architectures have different profiles of\naccess latency and energy, thus making it challenging to optimize them for high\nperformance and energy-efficient CNN accelerators. To address this, we present\nPENDRAM, a novel design space exploration methodology that enables\nhigh-performance and energy-efficient CNN acceleration through a generalized\nDRAM data mapping policy. Specifically, it explores the impact of different\nDRAM data mapping policies and DRAM architectures across different CNN\npartitioning and scheduling schemes on the DRAM access latency and energy, then\nidentifies the pareto-optimal design choices. The experimental results show\nthat our DRAM data mapping policy improves the energy-delay-product of DRAM\naccesses in the CNN accelerator over other mapping policies by up to 96%. In\nthis manner, our PENDRAM methodology offers high-performance and\nenergy-efficient CNN acceleration under any given DRAM architectures for\ndiverse embedded AI applications.", "categories": "cs.AR cs.AI cs.LG cs.NE", "created": "2024-08-05", "doi": null, "arxiv_id": "2408.02412"}
{"title": "Why Are My Prompts Leaked? Unraveling Prompt Extraction Threats in\n  Customized Large Language Models", "authors": [], "abstract": "The drastic increase of large language models' (LLMs) parameters has led to a\nnew research direction of fine-tuning-free downstream customization by prompts,\ni.e., task descriptions. While these prompt-based services (e.g. OpenAI's GPTs)\nplay an important role in many businesses, there has emerged growing concerns\nabout the prompt leakage, which undermines the intellectual properties of these\nservices and causes downstream attacks. In this paper, we analyze the\nunderlying mechanism of prompt leakage, which we refer to as prompt\nmemorization, and develop corresponding defending strategies. By exploring the\nscaling laws in prompt extraction, we analyze key attributes that influence\nprompt extraction, including model sizes, prompt lengths, as well as the types\nof prompts. Then we propose two hypotheses that explain how LLMs expose their\nprompts. The first is attributed to the perplexity, i.e. the familiarity of\nLLMs to texts, whereas the second is based on the straightforward token\ntranslation path in attention matrices. To defend against such threats, we\ninvestigate whether alignments can undermine the extraction of prompts. We find\nthat current LLMs, even those with safety alignments like GPT-4, are highly\nvulnerable to prompt extraction attacks, even under the most straightforward\nuser attacks. Therefore, we put forward several defense strategies with the\ninspiration of our findings, which achieve 83.8\\% and 71.0\\% drop in the prompt\nextraction rate for Llama2-7B and GPT-3.5, respectively. Source code is\navaliable at \\url{https://github.com/liangzid/PromptExtractionEval}.", "categories": "cs.CL cs.CR", "created": "2024-08-05", "doi": null, "arxiv_id": "2408.02416"}
{"title": "Infusing Emotions into Task-oriented Dialogue Systems: Understanding,\n  Management, and Generation", "authors": [], "abstract": "Emotions are indispensable in human communication, but are often overlooked\nin task-oriented dialogue (ToD) modelling, where the task success is the\nprimary focus. While existing works have explored user emotions or similar\nconcepts in some ToD tasks, none has so far included emotion modelling into a\nfully-fledged ToD system nor conducted interaction with human or simulated\nusers. In this work, we incorporate emotion into the complete ToD processing\nloop, involving understanding, management, and generation. To this end, we\nextend the EmoWOZ dataset (Feng et al., 2022) with system affective behaviour\nlabels. Through interactive experimentation involving both simulated and human\nusers, we demonstrate that our proposed framework significantly enhances the\nuser's emotional experience as well as the task success.", "categories": "cs.CL", "created": "2024-08-05", "doi": null, "arxiv_id": "2408.02417"}
{"title": "Demystifying Spatial Dependence: Interactive Visualizations for\n  Interpreting Local Spatial Autocorrelation", "authors": [], "abstract": "The Local Moran's I statistic is a valuable tool for identifying localized\npatterns of spatial autocorrelation. Understanding these patterns is crucial in\nspatial analysis, but interpreting the statistic can be difficult. To simplify\nthis process, we introduce three novel visualizations that enhance the\ninterpretation of Local Moran's I results. These visualizations can be\ninteractively linked to one another, and to established visualizations, to\noffer a more holistic exploration of the results. We provide a JavaScript\nlibrary with implementations of these new visual elements, along with a web\ndashboard that demonstrates their integrated use.", "categories": "cs.GR", "created": "2024-08-05", "doi": null, "arxiv_id": "2408.02418"}
{"title": "FE-Adapter: Adapting Image-based Emotion Classifiers to Videos", "authors": [], "abstract": "Utilizing large pre-trained models for specific tasks has yielded impressive\nresults. However, fully fine-tuning these increasingly large models is becoming\nprohibitively resource-intensive. This has led to a focus on more\nparameter-efficient transfer learning, primarily within the same modality. But\nthis approach has limitations, particularly in video understanding where\nsuitable pre-trained models are less common. Addressing this, our study\nintroduces a novel cross-modality transfer learning approach from images to\nvideos, which we call parameter-efficient image-to-video transfer learning. We\npresent the Facial-Emotion Adapter (FE-Adapter), designed for efficient\nfine-tuning in video tasks. This adapter allows pre-trained image models, which\ntraditionally lack temporal processing capabilities, to analyze dynamic video\ncontent efficiently. Notably, it uses about 15 times fewer parameters than\nprevious methods, while improving accuracy. Our experiments in video emotion\nrecognition demonstrate that the FE-Adapter can match or even surpass existing\nfine-tuning and video emotion models in both performance and efficiency. This\nbreakthrough highlights the potential for cross-modality approaches in\nenhancing the capabilities of AI models, particularly in fields like video\nemotion analysis where the demand for efficiency and accuracy is constantly\nrising.", "categories": "cs.CV", "created": "2024-08-05", "doi": "10.1109/FG59268.2024.10581905", "arxiv_id": "2408.02421"}
{"title": "FPT+: A Parameter and Memory Efficient Transfer Learning Method for\n  High-resolution Medical Image Classification", "authors": [], "abstract": "The success of large-scale pre-trained models has established fine-tuning as\na standard method for achieving significant improvements in downstream tasks.\nHowever, fine-tuning the entire parameter set of a pre-trained model is costly.\nParameter-efficient transfer learning (PETL) has recently emerged as a\ncost-effective alternative for adapting pre-trained models to downstream tasks.\nDespite its advantages, the increasing model size and input resolution present\nchallenges for PETL, as the training memory consumption is not reduced as\neffectively as the parameter usage. In this paper, we introduce Fine-grained\nPrompt Tuning plus (FPT+), a PETL method designed for high-resolution medical\nimage classification, which significantly reduces memory consumption compared\nto other PETL methods. FPT+ performs transfer learning by training a\nlightweight side network and accessing pre-trained knowledge from a large\npre-trained model (LPM) through fine-grained prompts and fusion modules.\nSpecifically, we freeze the LPM and construct a learnable lightweight side\nnetwork. The frozen LPM processes high-resolution images to extract\nfine-grained features, while the side network employs the corresponding\ndown-sampled low-resolution images to minimize the memory usage. To enable the\nside network to leverage pre-trained knowledge, we propose fine-grained prompts\nand fusion modules, which collaborate to summarize information through the\nLPM's intermediate activations. We evaluate FPT+ on eight medical image\ndatasets of varying sizes, modalities, and complexities. Experimental results\ndemonstrate that FPT+ outperforms other PETL methods, using only 1.03% of the\nlearnable parameters and 3.18% of the memory required for fine-tuning an entire\nViT-B model. Our code is available at https://github.com/YijinHuang/FPT.", "categories": "cs.CV", "created": "2024-08-05", "doi": null, "arxiv_id": "2408.02426"}
{"title": "Attenuation-adjusted deep learning of pore defects in 2D radiographs of\n  additive manufacturing powders", "authors": [], "abstract": "The presence of gas pores in metal feedstock powder for additive\nmanufacturing greatly affects the final AM product. Since current porosity\nanalysis often involves lengthy X-ray computed tomography (XCT) scans with a\nfull rotation around the sample, motivation exists to explore methods that\nallow for high throughput -- possibly enabling in-line porosity analysis during\nmanufacturing. Through labelling pore pixels on single 2D radiographs of\npowders, this work seeks to simulate such future efficient setups. High\nsegmentation accuracy is achieved by combining a model of X-ray attenuation\nthrough particles with a variant of the widely applied UNet architecture;\nnotably, F1-score increases by $11.4\\%$ compared to the baseline UNet. The\nproposed pore segmentation is enabled by: 1) pretraining on synthetic data, 2)\nmaking tight particle cutouts, and 3) subtracting an ideal particle without\npores generated from a distance map inspired by Lambert-Beers law. This paper\nexplores four image processing methods, where the fastest (yet still\nunoptimized) segments a particle in mean $0.014s$ time with F1-score $0.78$,\nand the most accurate in $0.291s$ with F1-score $0.87$. Due to their scalable\nnature, these strategies can be involved in making high throughput porosity\nanalysis of metal feedstock powder for additive manufacturing.", "categories": "cs.CV cs.LG eess.IV", "created": "2024-08-05", "doi": null, "arxiv_id": "2408.02427"}
{"title": "Bridging the Gap to Next Generation Power System Planning and Operation\n  with Quantum Computation", "authors": [], "abstract": "Innovative solutions and developments are being inspected to tackle rising\nelectrical power demand to be supplied by clean forms of energy. The\nintegration of renewable energy generations, varying nature loads, importance\nof active role of distribution system and consumer participation in grid\noperation has changed the landscape of classical power grids. Implementation of\nsmarter applications to plan, monitor, operate the grid safely are deemed\nparamount for efficient, secure and reliable functioning of grid. Although\nsophisticated computations to process gigantic volume of data to produce useful\ninformation in a time critical manner is the paradigm of future grid\noperations, it brings along the burden of computational complexity.\nAdvancements in quantum technologies holds promising solution for dealing with\ndemanding computational complexity of power system related applications. In\nthis article, we lay out clear motivations for seeking quantum solutions for\nsolving computational burden challenges associated with power system\napplications. Next we present an overview of quantum solutions for various\npower system related applications available in current literature and suggest\nfuture topics for research. We further highlight challenges with existing\nquantum solutions for exploiting full quantum capabilities. Additionally, this\npaper serves as a bridge for power engineers to the quantum world by outlining\nessential quantum computation fundamentals for enabling smoother transition to\nfuture of power system computations.", "categories": "quant-ph cs.SY eess.SY", "created": "2024-08-05", "doi": null, "arxiv_id": "2408.02432"}
{"title": "On Probabilistic Embeddings in Optimal Dimension Reduction", "authors": [], "abstract": "Dimension reduction algorithms are a crucial part of many data science\npipelines, including data exploration, feature creation and selection, and\ndenoising. Despite their wide utilization, many non-linear dimension reduction\nalgorithms are poorly understood from a theoretical perspective. In this work\nwe consider a generalized version of multidimensional scaling, which is posed\nas an optimization problem in which a mapping from a high-dimensional feature\nspace to a lower-dimensional embedding space seeks to preserve either inner\nproducts or norms of the distribution in feature space, and which encompasses\nmany commonly used dimension reduction algorithms. We analytically investigate\nthe variational properties of this problem, leading to the following insights:\n1) Solutions found using standard particle descent methods may lead to\nnon-deterministic embeddings, 2) A relaxed or probabilistic formulation of the\nproblem admits solutions with easily interpretable necessary conditions, 3) The\nglobally optimal solutions to the relaxed problem actually must give a\ndeterministic embedding. This progression of results mirrors the classical\ndevelopment of optimal transportation, and in a case relating to the\nGromov-Wasserstein distance actually gives explicit insight into the structure\nof the optimal embeddings, which are parametrically determined and\ndiscontinuous. Finally, we illustrate that a standard computational\nimplementation of this task does not learn deterministic embeddings, which\nmeans that it learns sub-optimal mappings, and that the embeddings learned in\nthat context have highly misleading clustering structure, underscoring the\ndelicate nature of solving this problem computationally.", "categories": "stat.ML cs.LG math.AP", "created": "2024-08-05", "doi": null, "arxiv_id": "2408.02433"}
{"title": "Steer-by-prior Editing of Symbolic Music Loops", "authors": [], "abstract": "With the goal of building a system capable of controllable symbolic music\nloop generation and editing, this paper explores a generalisation of Masked\nLanguage Modelling we call Superposed Language Modelling. Rather than input\ntokens being known or unknown, a Superposed Language Model takes priors over\nthe sequence as input, enabling us to apply various constraints to the\ngeneration at inference time. After detailing our approach, we demonstrate our\nmodel across various editing tasks in the domain of multi-instrument MIDI\nloops. We end by highlighting some limitations of the approach and avenues for\nfuture work. We provides examples from the SLM across multiple generation and\nediting tasks at https://erl-j.github.io/slm-mml-demo/.", "categories": "cs.SD eess.AS", "created": "2024-08-05", "doi": null, "arxiv_id": "2408.02434"}
{"title": "Long Input Benchmark for Russian Analysis", "authors": [], "abstract": "Recent advancements in Natural Language Processing (NLP) have fostered the\ndevelopment of Large Language Models (LLMs) that can solve an immense variety\nof tasks. One of the key aspects of their application is their ability to work\nwith long text documents and to process long sequences of tokens. This has\ncreated a demand for proper evaluation of long-context understanding. To\naddress this need for the Russian language, we propose LIBRA (Long Input\nBenchmark for Russian Analysis), which comprises 21 adapted datasets to study\nthe LLM's abilities to understand long texts thoroughly. The tests are divided\ninto four complexity groups and allow the evaluation of models across various\ncontext lengths ranging from 4k up to 128k tokens. We provide the open-source\ndatasets, codebase, and public leaderboard for LIBRA to guide forthcoming\nresearch.", "categories": "cs.CL cs.AI", "created": "2024-08-05", "doi": null, "arxiv_id": "2408.02439"}
{"title": "Let Me Speak Freely? A Study on the Impact of Format Restrictions on\n  Performance of Large Language Models", "authors": [], "abstract": "Structured generation, the process of producing content in standardized\nformats like JSON and XML, is widely utilized in real-world applications to\nextract key output information from large language models (LLMs). This study\ninvestigates whether such constraints on generation space impact LLMs'\nabilities, including reasoning and domain knowledge comprehension.\nSpecifically, we evaluate LLMs' performance when restricted to adhere to\nstructured formats versus generating free-form responses across various common\ntasks. Surprisingly, we observe a significant decline in LLMs' reasoning\nabilities under format restrictions. Furthermore, we find that stricter format\nconstraints generally lead to greater performance degradation in reasoning\ntasks.", "categories": "cs.CL", "created": "2024-08-05", "doi": null, "arxiv_id": "2408.02442"}
{"title": "RIs-Calib: An Open-Source Spatiotemporal Calibrator for Multiple 3D\n  Radars and IMUs Based on Continuous-Time Estimation", "authors": [], "abstract": "Aided inertial navigation system (INS), typically consisting of an inertial\nmeasurement unit (IMU) and an exteroceptive sensor, has been widely accepted as\na feasible solution for navigation. Compared with vision-aided and LiDAR-aided\nINS, radar-aided INS could achieve better performance in adverse weather\nconditions since the radar utilizes low-frequency measuring signals with less\nattenuation effect in atmospheric gases and rain. For such a radar-aided INS,\naccurate spatiotemporal transformation is a fundamental prerequisite to\nachieving optimal information fusion. In this work, we present RIs-Calib: a\nspatiotemporal calibrator for multiple 3D radars and IMUs based on\ncontinuous-time estimation, which enables accurate spatiotemporal calibration\nand does not require any additional artificial infrastructure or prior\nknowledge. Our approach starts with a rigorous and robust procedure for state\ninitialization, followed by batch optimizations, where all parameters can be\nrefined to global optimal states steadily. We validate and evaluate RIs-Calib\non both simulated and real-world experiments, and the results demonstrate that\nRIs-Calib is capable of accurate and consistent calibration. We open-source our\nimplementations at (https://github.com/Unsigned-Long/RIs-Calib) to benefit the\nresearch community.", "categories": "cs.RO", "created": "2024-08-05", "doi": null, "arxiv_id": "2408.02444"}
{"title": "Second 6G life Workshop on Post Shannon Theory", "authors": [], "abstract": "The one-day workshop, held prior to the \"ZIF Workshop on Information Theory\nand Related Fields\", provided an excellent opportunity for in-depth discussions\non several topics within the field of post-Shannon theory. The agenda covered\ndeterministic and randomized identification, focusing on various methods and\nalgorithms for identifying data or signals deterministically and through\nrandomized processes. It explored the theoretical foundations and practical\napplications of these techniques. The session on resources for increasing\nidentification capacity examined the different resources and strategies that\ncan be utilized to boost the capacity for identifying information. This\nincluded discussions on both hardware and software solutions, as well as\ninnovative approaches to resource allocation and optimization. Participants\ndelved into common randomness generation, essential for various cryptographic\nprotocols and communication systems. The session highlighted recent\nadvancements and practical implementations of common randomness in secure\ncommunications. The workshop concluded with a detailed look at the development\nand practical deployment of identification codes. Experts shared insights on\ncode construction techniques, implementation challenges, and real-world\napplications in various communication systems. We extend our thanks to the\nesteemed speakers for their valuable contributions: Caspar von Lengerke, Wafa\nLabidi, Ilya Vorobyev, Johannes Rosenberger, Jonathan Huffmann, and Pau\nColomer. Their presentations and insights significantly enriched the workshop.\nAdditionally, we are grateful to all the participants whose active engagement,\nconstructive comments, and stimulating discussions made the event a success.\nYour involvement was crucial in fostering a collaborative and intellectually\nvibrant environment.", "categories": "cs.IT math.IT", "created": "2024-08-05", "doi": null, "arxiv_id": "2408.02446"}
{"title": "An Evaluation of Requirements Modeling for Cyber-Physical Systems via\n  LLMs", "authors": [], "abstract": "Cyber-physical systems (CPSs) integrate cyber and physical components and\nenable them to interact with each other to meet user needs. The needs for CPSs\nspan rich application domains such as healthcare and medicine, smart home,\nsmart building, etc. This indicates that CPSs are all about solving real-world\nproblems. With the increasing abundance of sensing devices and effectors, the\nproblems wanted to solve with CPSs are becoming more and more complex. It is\nalso becoming increasingly difficult to extract and express CPS requirements\naccurately. Problem frame approach aims to shape real-world problems by\ncapturing the characteristics and interconnections of components, where the\nproblem diagram is central to expressing the requirements. CPSs requirements\nare generally presented in domain-specific documents that are normally\nexpressed in natural language. There is currently no effective way to extract\nproblem diagrams from natural language documents. CPSs requirements extraction\nand modeling are generally done manually, which is time-consuming,\nlabor-intensive, and error-prone. Large language models (LLMs) have shown\nexcellent performance in natural language understanding. It can be interesting\nto explore the abilities of LLMs to understand domain-specific documents and\nidentify modeling elements, which this paper is working on. To achieve this\ngoal, we first formulate two tasks (i.e., entity recognition and interaction\nextraction) and propose a benchmark called CPSBench. Based on this benchmark,\nextensive experiments are conducted to evaluate the abilities and limitations\nof seven advanced LLMs. We find some interesting insights. Finally, we\nestablish a taxonomy of LLMs hallucinations in CPSs requirements modeling using\nproblem diagrams. These results will inspire research on the use of LLMs for\nautomated CPSs requirements modeling.", "categories": "cs.SE", "created": "2024-08-05", "doi": null, "arxiv_id": "2408.02450"}
{"title": "An investigation on the use of Large Language Models for hyperparameter\n  tuning in Evolutionary Algorithms", "authors": [], "abstract": "Hyperparameter optimization is a crucial problem in Evolutionary Computation.\nIn fact, the values of the hyperparameters directly impact the trajectory taken\nby the optimization process, and their choice requires extensive reasoning by\nhuman operators. Although a variety of self-adaptive Evolutionary Algorithms\nhave been proposed in the literature, no definitive solution has been found. In\nthis work, we perform a preliminary investigation to automate the reasoning\nprocess that leads to the choice of hyperparameter values. We employ two\nopen-source Large Language Models (LLMs), namely Llama2-70b and Mixtral, to\nanalyze the optimization logs online and provide novel real-time hyperparameter\nrecommendations. We study our approach in the context of step-size adaptation\nfor (1+1)-ES. The results suggest that LLMs can be an effective method for\noptimizing hyperparameters in Evolution Strategies, encouraging further\nresearch in this direction.", "categories": "cs.NE", "created": "2024-08-05", "doi": "10.1145/3638530.3664163", "arxiv_id": "2408.02451"}
{"title": "A Surprisingly Efficient Representation for Multi-Finger Grasping", "authors": [], "abstract": "The problem of grasping objects using a multi-finger hand has received\nsignificant attention in recent years. However, it remains challenging to\nhandle a large number of unfamiliar objects in real and cluttered environments.\nIn this work, we propose a representation that can be effectively mapped to the\nmulti-finger grasp space. Based on this representation, we develop a simple\ndecision model that generates accurate grasp quality scores for different\nmulti-finger grasp poses using only hundreds to thousands of training samples.\nWe demonstrate that our representation performs well on a real robot and\nachieves a success rate of 78.64% after training with only 500 real-world grasp\nattempts and 87% with 4500 grasp attempts. Additionally, we achieve a success\nrate of 84.51% in a dynamic human-robot handover scenario using a multi-finger\nhand.", "categories": "cs.RO", "created": "2024-08-05", "doi": null, "arxiv_id": "2408.02455"}
{"title": "Enhancing Heterogeneous Knowledge Graph Completion with a Novel\n  GAT-based Approach", "authors": [], "abstract": "Knowledge graphs (KGs) play a vital role in enhancing search results and\nrecommendation systems. With the rapid increase in the size of the KGs, they\nare becoming inaccuracy and incomplete. This problem can be solved by the\nknowledge graph completion methods, of which graph attention network\n(GAT)-based methods stand out since their superior performance. However,\nexisting GAT-based knowledge graph completion methods often suffer from\noverfitting issues when dealing with heterogeneous knowledge graphs, primarily\ndue to the unbalanced number of samples. Additionally, these methods\ndemonstrate poor performance in predicting the tail (head) entity that shares\nthe same relation and head (tail) entity with others. To solve these problems,\nwe propose GATH, a novel GAT-based method designed for Heterogeneous KGs. GATH\nincorporates two separate attention network modules that work synergistically\nto predict the missing entities. We also introduce novel encoding and feature\ntransformation approaches, enabling the robust performance of GATH in scenarios\nwith imbalanced samples. Comprehensive experiments are conducted to evaluate\nthe GATH's performance. Compared with the existing SOTA GAT-based model on\nHits@10 and MRR metrics, our model improves performance by 5.2% and 5.2% on the\nFB15K-237 dataset, and by 4.5% and 14.6% on the WN18RR dataset, respectively.", "categories": "cs.LG cs.AI", "created": "2024-08-05", "doi": "10.1145/3639472", "arxiv_id": "2408.02456"}
{"title": "Fast Robust Monitoring for Signal Temporal Logic with Value Freezing\n  Operators (STL*)", "authors": [], "abstract": "Researchers have previously proposed augmenting Signal Temporal Logic (STL)\nwith the value freezing operator in order to express engineering properties\nthat cannot be expressed in STL. This augmented logic is known as STL*. The\nprevious algorithms for STL* monitoring were intractable, and did not scale\nformulae with nested freeze variables. We present offline discrete-time\nmonitoring algorithms with an acceleration heuristic, both for Boolean\nmonitoring as well as for quantitative robustness monitoring. The acceleration\nheuristic operates over time intervals where subformulae hold true, rather than\nover the original trace sample-points. We present experimental validation of\nour algorithms, the results show that our algorithms can monitor over long\ntraces for formulae with two or three nested freeze variables.\n  Our work is the first work with monitoring algorithm implementations for STL*\nformulae with nested freeze variables.", "categories": "cs.LO cs.SY eess.SY", "created": "2024-08-05", "doi": null, "arxiv_id": "2408.02460"}
{"title": "Performance analysis of a RIS-assisted communications", "authors": [], "abstract": "Reconfigurable Intelligent Surfaces (RIS) are currently considered for\nadoption in future 6G stantards. ETSI and 3GPP have started feasibility and\nperformance investigations of such a technology. This work proposes an\nanalytical model to analyze RIS performance. It relies on a simple street model\nwhere obstacles and mobile units are all aligned. RIS is positioned onto a\nbuilding parallel to the road. The coverage probability in presence of\nobstacles and concurrent communications is then computed as a performance\ncriteria.", "categories": "cs.NI math.PR", "created": "2024-08-05", "doi": null, "arxiv_id": "2408.02461"}
{"title": "An investigation into the causes of race bias in AI-based cine CMR\n  segmentation", "authors": [], "abstract": "Artificial intelligence (AI) methods are being used increasingly for the\nautomated segmentation of cine cardiac magnetic resonance (CMR) imaging.\nHowever, these methods have been shown to be subject to race bias, i.e. they\nexhibit different levels of performance for different races depending on the\n(im)balance of the data used to train the AI model. In this paper we\ninvestigate the source of this bias, seeking to understand its root cause(s) so\nthat it can be effectively mitigated. We perform a series of classification and\nsegmentation experiments on short-axis cine CMR images acquired from Black and\nWhite subjects from the UK Biobank and apply AI interpretability methods to\nunderstand the results. In the classification experiments, we found that race\ncan be predicted with high accuracy from the images alone, but less accurately\nfrom ground truth segmentations, suggesting that the distributional shift\nbetween races, which is often the cause of AI bias, is mostly image-based\nrather than segmentation-based. The interpretability methods showed that most\nattention in the classification models was focused on non-heart regions, such\nas subcutaneous fat. Cropping the images tightly around the heart reduced\nclassification accuracy to around chance level. Similarly, race can be\npredicted from the latent representations of a biased segmentation model,\nsuggesting that race information is encoded in the model. Cropping images\ntightly around the heart reduced but did not eliminate segmentation bias. We\nalso investigate the influence of possible confounders on the bias observed.", "categories": "eess.IV cs.AI cs.CV", "created": "2024-08-05", "doi": null, "arxiv_id": "2408.02462"}
{"title": "Fairness and Bias Mitigation in Computer Vision: A Survey", "authors": [], "abstract": "Computer vision systems have witnessed rapid progress over the past two\ndecades due to multiple advances in the field. As these systems are\nincreasingly being deployed in high-stakes real-world applications, there is a\ndire need to ensure that they do not propagate or amplify any discriminatory\ntendencies in historical or human-curated data or inadvertently learn biases\nfrom spurious correlations. This paper presents a comprehensive survey on\nfairness that summarizes and sheds light on ongoing trends and successes in the\ncontext of computer vision. The topics we discuss include 1) The origin and\ntechnical definitions of fairness drawn from the wider fair machine learning\nliterature and adjacent disciplines. 2) Work that sought to discover and\nanalyze biases in computer vision systems. 3) A summary of methods proposed to\nmitigate bias in computer vision systems in recent years. 4) A comprehensive\nsummary of resources and datasets produced by researchers to measure, analyze,\nand mitigate bias and enhance fairness. 5) Discussion of the field's success,\ncontinuing trends in the context of multimodal foundation and generative\nmodels, and gaps that still need to be addressed. The presented\ncharacterization should help researchers understand the importance of\nidentifying and mitigating bias in computer vision and the state of the field\nand identify potential directions for future research.", "categories": "cs.CV", "created": "2024-08-05", "doi": null, "arxiv_id": "2408.02464"}
{"title": "Stability in Isolated Grids: Implementation and Analysis of the\n  Dead-Zone Virtual Oscillator Control in Simulink and Typhoon HIL", "authors": [], "abstract": "This paper explores the analysis and implementation of the Virtual Oscillator\nControl (VOC) strategy for inverters aiming to enhance stability amidst the\never-increasing generation of renewable energy sources like solar PV. Key\nobjectives include implementation and analysis of a Dead-Zone VOC (DZVOC)\nthree-phase battery-inverter system with an additional voltage control loop,\nstudy of its stability and performance in an isolated micro-grid and\nexploration of their use alongside widely used grid following PV-inverter\nsystem. By modeling independent microgrids under various cases with scenarios:\nVOC inverters of varying capacities and VOC inverters in conjunction with PV\ninverters, this research addresses critical aspects of power-sharing,\ncompatibility, response times, and fault ride-through potential, as well as\nimproving the voltage droop profile of a general DZVOC control. The simulation\nis executed in MATLAB SIMULINK and validated with real-time simulation using\nthe Typhoon-HIL 404.", "categories": "eess.SY cs.SY", "created": "2024-08-05", "doi": null, "arxiv_id": "2408.02468"}
{"title": "Toward Attention-based TinyML: A Heterogeneous Accelerated Architecture\n  and Automated Deployment Flow", "authors": [], "abstract": "One of the challenges for Tiny Machine Learning (tinyML) is keeping up with\nthe evolution of Machine Learning models from Convolutional Neural Networks to\nTransformers. We address this by leveraging a heterogeneous architectural\ntemplate coupling RISC-V processors with hardwired accelerators supported by an\nautomated deployment flow. We demonstrate an Attention-based model in a tinyML\npower envelope with an octa-core cluster coupled with an accelerator for\nquantized Attention. Our deployment flow enables an end-to-end 8-bit\nMobileBERT, achieving leading-edge energy efficiency and throughput of 2960\nGOp/J and 154 GOp/s at 32.5 Inf/s consuming 52.0 mW (0.65 V, 22 nm FD-SOI\ntechnology).", "categories": "cs.AR cs.LG", "created": "2024-08-05", "doi": null, "arxiv_id": "2408.02473"}
{"title": "From LLMs to LLM-based Agents for Software Engineering: A Survey of\n  Current, Challenges and Future", "authors": [], "abstract": "With the rise of large language models (LLMs), researchers are increasingly\nexploring their applications in var ious vertical domains, such as software\nengineering. LLMs have achieved remarkable success in areas including code\ngeneration and vulnerability detection. However, they also exhibit numerous\nlimitations and shortcomings. LLM-based agents, a novel tech nology with the\npotential for Artificial General Intelligence (AGI), combine LLMs as the core\nfor decision-making and action-taking, addressing some of the inherent\nlimitations of LLMs such as lack of autonomy and self-improvement. Despite\nnumerous studies and surveys exploring the possibility of using LLMs in\nsoftware engineering, it lacks a clear distinction between LLMs and LLM based\nagents. It is still in its early stage for a unified standard and benchmarking\nto qualify an LLM solution as an LLM-based agent in its domain. In this survey,\nwe broadly investigate the current practice and solutions for LLMs and\nLLM-based agents for software engineering. In particular we summarise six key\ntopics: requirement engineering, code generation, autonomous decision-making,\nsoftware design, test generation, and software maintenance. We review and\ndifferentiate the work of LLMs and LLM-based agents from these six topics,\nexamining their differences and similarities in tasks, benchmarks, and\nevaluation metrics. Finally, we discuss the models and benchmarks used,\nproviding a comprehensive analysis of their applications and effectiveness in\nsoftware engineering. We anticipate this work will shed some lights on pushing\nthe boundaries of LLM-based agents in software engineering for future research.", "categories": "cs.SE cs.AI cs.CL", "created": "2024-08-05", "doi": null, "arxiv_id": "2408.02479"}
{"title": "Gender differences in collaboration and career progression in physics", "authors": [], "abstract": "We examine gender differences in collaboration networks and academic career\nprogression in physics. We use the likelihood and time to become a principal\ninvestigator (PI) and the length of an author's career to measure career\nprogression. Utilising logistic regression and accelerated failure time models,\nwe examine whether the effect of collaboration behaviour varies by gender. We\nfind that, controlling for the number of publications, the relationship between\ncollaborative behaviour and career progression is almost the same for men and\nwomen. Specifically, we find that those who eventually reach principal\ninvestigator (PI) status, tend to have published with more unique\ncollaborators. In contrast, publishing repeatedly with the same highly\ninterconnected collaborators and/or larger number of coauthors per publication\nis characteristic of shorter career lengths and those that do not attain PI\nstatus. We observe that the tie strength is stronger for women than men, and\nwomen tend to collaborate in more tightly connected and larger groups than men.\nFinally, we observe that women are less likely to attain the status of PI\nthroughout their careers and have a lower survival probability compared to men,\nwhich calls for policies to close this crucial gap.", "categories": "physics.soc-ph cs.SI", "created": "2024-08-05", "doi": null, "arxiv_id": "2408.02482"}
{"title": "Exploring Conditional Multi-Modal Prompts for Zero-shot HOI Detection", "authors": [], "abstract": "Zero-shot Human-Object Interaction (HOI) detection has emerged as a frontier\ntopic due to its capability to detect HOIs beyond a predefined set of\ncategories. This task entails not only identifying the interactiveness of\nhuman-object pairs and localizing them but also recognizing both seen and\nunseen interaction categories. In this paper, we introduce a novel framework\nfor zero-shot HOI detection using Conditional Multi-Modal Prompts, namely CMMP.\nThis approach enhances the generalization of large foundation models, such as\nCLIP, when fine-tuned for HOI detection. Unlike traditional prompt-learning\nmethods, we propose learning decoupled vision and language prompts for\ninteractiveness-aware visual feature extraction and generalizable interaction\nclassification, respectively. Specifically, we integrate prior knowledge of\ndifferent granularity into conditional vision prompts, including an\ninput-conditioned instance prior and a global spatial pattern prior. The former\nencourages the image encoder to treat instances belonging to seen or\npotentially unseen HOI concepts equally while the latter provides\nrepresentative plausible spatial configuration of the human and object under\ninteraction. Besides, we employ language-aware prompt learning with a\nconsistency constraint to preserve the knowledge of the large foundation model\nto enable better generalization in the text branch. Extensive experiments\ndemonstrate the efficacy of our detector with conditional multi-modal prompts,\noutperforming previous state-of-the-art on unseen classes of various zero-shot\nsettings. The code and models are available at\n\\url{https://github.com/ltttpku/CMMP}.", "categories": "cs.CV", "created": "2024-08-05", "doi": null, "arxiv_id": "2408.02484"}
{"title": "A First Look at License Compliance Capability of LLMs in Code Generation", "authors": [], "abstract": "Recent advances in Large Language Models (LLMs) have revolutionized code\ngeneration, leading to widespread adoption of AI coding tools by developers.\nHowever, LLMs can generate license-protected code without providing the\nnecessary license information, leading to potential intellectual property\nviolations during software production. This paper addresses the critical, yet\nunderexplored, issue of license compliance in LLM-generated code by\nestablishing a benchmark to evaluate the ability of LLMs to provide accurate\nlicense information for their generated code. To establish this benchmark, we\nconduct an empirical study to identify a reasonable standard for \"striking\nsimilarity\" that excludes the possibility of independent creation, indicating a\ncopy relationship between the LLM output and certain open-source code. Based on\nthis standard, we propose an evaluation benchmark LiCoEval, to evaluate the\nlicense compliance capabilities of LLMs. Using LiCoEval, we evaluate 14 popular\nLLMs, finding that even top-performing LLMs produce a non-negligible proportion\n(0.88% to 2.01%) of code strikingly similar to existing open-source\nimplementations. Notably, most LLMs fail to provide accurate license\ninformation, particularly for code under copyleft licenses. These findings\nunderscore the urgent need to enhance LLM compliance capabilities in code\ngeneration tasks. Our study provides a foundation for future research and\ndevelopment to improve license compliance in AI-assisted software development,\ncontributing to both the protection of open-source software copyrights and the\nmitigation of legal risks for LLM users.", "categories": "cs.SE cs.AI cs.LG", "created": "2024-08-05", "doi": null, "arxiv_id": "2408.02487"}
{"title": "HyperSpaceX: Radial and Angular Exploration of HyperSpherical Dimensions", "authors": [], "abstract": "Traditional deep learning models rely on methods such as softmax\ncross-entropy and ArcFace loss for tasks like classification and face\nrecognition. These methods mainly explore angular features in a hyperspherical\nspace, often resulting in entangled inter-class features due to dense angular\ndata across many classes. In this paper, a new field of feature exploration is\nproposed known as HyperSpaceX which enhances class discrimination by exploring\nboth angular and radial dimensions in multi-hyperspherical spaces, facilitated\nby a novel DistArc loss. The proposed DistArc loss encompasses three feature\narrangement components: two angular and one radial, enforcing intra-class\nbinding and inter-class separation in multi-radial arrangement, improving\nfeature discriminability. Evaluation of HyperSpaceX framework for the novel\nrepresentation utilizes a proposed predictive measure that accounts for both\nangular and radial elements, providing a more comprehensive assessment of model\naccuracy beyond standard metrics. Experiments across seven object\nclassification and six face recognition datasets demonstrate state-of-the-art\n(SoTA) results obtained from HyperSpaceX, achieving up to a 20% performance\nimprovement on large-scale object datasets in lower dimensions and up to 6%\ngain in higher dimensions.", "categories": "cs.CV", "created": "2024-08-05", "doi": null, "arxiv_id": "2408.02494"}
{"title": "Automatic rating of incomplete hippocampal inversions evaluated across\n  multiple cohorts", "authors": [], "abstract": "Incomplete Hippocampal Inversion (IHI), sometimes called hippocampal\nmalrotation, is an atypical anatomical pattern of the hippocampus found in\nabout 20% of the general population. IHI can be visually assessed on coronal\nslices of T1 weighted MR images, using a composite score that combines four\nanatomical criteria. IHI has been associated with several brain disorders\n(epilepsy, schizophrenia). However, these studies were based on small samples.\nFurthermore, the factors (genetic or environmental) that contribute to the\ngenesis of IHI are largely unknown. Large-scale studies are thus needed to\nfurther understand IHI and their potential relationships to neurological and\npsychiatric disorders. However, visual evaluation is long and tedious,\njustifying the need for an automatic method. In this paper, we propose, for the\nfirst time, to automatically rate IHI. We proceed by predicting four anatomical\ncriteria, which are then summed up to form the IHI score, providing the\nadvantage of an interpretable score. We provided an extensive experimental\ninvestigation of different machine learning methods and training strategies. We\nperformed automatic rating using a variety of deep learning models (conv5-FC3,\nResNet and SECNN) as well as a ridge regression. We studied the generalization\nof our models using different cohorts and performed multi-cohort learning. We\nrelied on a large population of 2,008 participants from the IMAGEN study, 993\nand 403 participants from the QTIM/QTAB studies as well as 985 subjects from\nthe UKBiobank. We showed that deep learning models outperformed a ridge\nregression. We demonstrated that the performances of the conv5-FC3 network were\nat least as good as more complex networks while maintaining a low complexity\nand computation time. We showed that training on a single cohort may lack in\nvariability while training on several cohorts improves generalization.", "categories": "eess.IV cs.CV cs.LG q-bio.NC", "created": "2024-08-05", "doi": "10.59275/j.melba.2024-3d4e", "arxiv_id": "2408.02496"}
{"title": "Hybrid Surrogate Models: Circumventing Gibbs Phenomenon for Partial\n  Differential Equations with Finite Shock-Type Discontinuities", "authors": [], "abstract": "We introduce the concept of Hybrid Surrogate Models (HSMs) -- combining\nmultivariate polynomials with Heavyside functions -- as approximates of\nfunctions with finitely many jump discontinuities. We exploit the HSMs for\nformulating a variational optimization approach, solving non-regular partial\ndifferential equations (PDEs) with non-continuous shock-type solutions. The HSM\ntechnique simultaneously obtains a parametrization of the position and the\nheight of the shocks as well as the solution of the PDE. We show that the HSM\ntechnique circumvents the notorious Gibbs phenomenon, which limits the accuracy\nthat classic numerical methods reach. Numerical experiments, addressing linear\nand non-linearly propagating shocks, demonstrate the strong approximation power\nof the HSM technique.", "categories": "math.NA cs.NA", "created": "2024-08-05", "doi": null, "arxiv_id": "2408.02497"}
{"title": "Flow with FlorDB: Incremental Context Maintenance for the Machine\n  Learning Lifecycle", "authors": [], "abstract": "The metadata involved in integrating code, data, configuration, and feedback\ninto predictive models is varied and complex. This complexity is further\ncompounded by the agile development practices favored by data scientists and\nmachine learning engineers. These practices emphasize high experimentation\nvelocity and frequent deployments, which can make it challenging to keep track\nof all the relevant metadata. The iterative nature of agile methods means that\nmodels, datasets, and configurations are constantly evolving. Each experiment\nmight involve tweaks to the data preprocessing steps, changes in model\nhyperparameters, or updates to the deployment environment. The need for rapid\niteration can lead to shortcuts or oversights in documentation and metadata\nmanagement. Effective metadata management requires robust yet flexible tools\nand practices that can integrate and organize this information without slowing\ndown the development process. Traditional context management often emphasizes a\n``metadata first'' approach, which can introduce significant friction for\ndevelopers. FlorDB reduces this friction through multiversion hindsight logging\nand incremental context maintenance, allowing developers to add and refine\nmetadata after the fact. This ``metadata later'' approach enables a more\nflexible and incremental development process, allowing data scientists to focus\non model creation and refinement without the burden of documentation upfront.\nAs shown in a demo, FlorDB can be used to build AI/ML applications with\nintegrated train-infer pipelines and managed feedback loops. Ultimately, the\ngoal of FlorDB is to ensure that critical metadata is maintained accurately and\nefficiently, even in fast-paced agile workflows.", "categories": "cs.DB cs.SE", "created": "2024-08-05", "doi": null, "arxiv_id": "2408.02498"}
{"title": "Fair Resource Allocation For Hierarchical Federated Edge Learning in\n  Space-Air-Ground Integrated Networks via Deep Reinforcement Learning with\n  Hybrid Control", "authors": [], "abstract": "The space-air-ground integrated network (SAGIN) has become a crucial research\ndirection in future wireless communications due to its ubiquitous coverage,\nrapid and flexible deployment, and multi-layer cooperation capabilities.\nHowever, integrating hierarchical federated learning (HFL) with edge computing\nand SAGINs remains a complex open issue to be resolved. This paper proposes a\nnovel framework for applying HFL in SAGINs, utilizing aerial platforms and low\nEarth orbit (LEO) satellites as edge servers and cloud servers, respectively,\nto provide multi-layer aggregation capabilities for HFL. The proposed system\nalso considers the presence of inter-satellite links (ISLs), enabling\nsatellites to exchange federated learning models with each other. Furthermore,\nwe consider multiple different computational tasks that need to be completed\nwithin a limited satellite service time. To maximize the convergence\nperformance of all tasks while ensuring fairness, we propose the use of the\ndistributional soft-actor-critic (DSAC) algorithm to optimize resource\nallocation in the SAGIN and aggregation weights in HFL. Moreover, we address\nthe efficiency issue of hybrid action spaces in deep reinforcement learning\n(DRL) through a decoupling and recoupling approach, and design a new dynamic\nadjusting reward function to ensure fairness among multiple tasks in federated\nlearning. Simulation results demonstrate the superiority of our proposed\nalgorithm, consistently outperforming baseline approaches and offering a\npromising solution for addressing highly complex optimization problems in\nSAGINs.", "categories": "cs.IT eess.SP math.IT", "created": "2024-08-05", "doi": null, "arxiv_id": "2408.02501"}
{"title": "Context Conquers Parameters: Outperforming Proprietary LLM in Commit\n  Message Generation", "authors": [], "abstract": "Commit messages provide descriptions of the modifications made in a commit\nusing natural language, making them crucial for software maintenance and\nevolution. Recent developments in Large Language Models (LLMs) have led to\ntheir use in generating high-quality commit messages, such as the Omniscient\nMessage Generator (OMG). This method employs GPT-4 to produce state-of-the-art\ncommit messages. However, the use of proprietary LLMs like GPT-4 in coding\ntasks raises privacy and sustainability concerns, which may hinder their\nindustrial adoption. Considering that open-source LLMs have achieved\ncompetitive performance in developer tasks such as compiler validation, this\nstudy investigates whether they can be used to generate commit messages that\nare comparable with OMG. Our experiments show that an open-source LLM can\ngenerate commit messages that are comparable to those produced by OMG. In\naddition, through a series of contextual refinements, we propose lOcal MessagE\nGenerAtor (OMEGA) , a CMG approach that uses a 4-bit quantized 8B open-source\nLLM. OMEGA produces state-of-the-art commit messages, surpassing the\nperformance of GPT-4 in practitioners' preference.", "categories": "cs.SE", "created": "2024-08-05", "doi": null, "arxiv_id": "2408.02502"}
{"title": "UnifiedMLLM: Enabling Unified Representation for Multi-modal Multi-tasks\n  With Large Language Model", "authors": [], "abstract": "Significant advancements has recently been achieved in the field of\nmulti-modal large language models (MLLMs), demonstrating their remarkable\ncapabilities in understanding and reasoning across diverse tasks. However,\nthese models are often trained for specific tasks and rely on task-specific\ninput-output formats, limiting their applicability to a broader range of tasks.\nThis raises a fundamental question: Can we develop a unified approach to\nrepresent and handle different multi-modal tasks to maximize the\ngeneralizability of MLLMs? In this paper, we propose UnifiedMLLM, a\ncomprehensive model designed to represent various tasks using a unified\nrepresentation. Our model exhibits strong capabilities in comprehending the\nimplicit intent of user instructions and preforming reasoning. In addition to\ngenerating textual responses, our model also outputs task tokens and grounding\ntokens, serving as indicators of task types and task granularity. These outputs\nare subsequently routed through the task router and directed to specific expert\nmodels for task completion. To train our model, we construct a task-specific\ndataset and an 100k multi-task dataset encompassing complex scenarios.\nEmploying a three-stage training strategy, we equip our model with robust\nreasoning and task processing capabilities while preserving its generalization\ncapacity and knowledge reservoir. Extensive experiments showcase the impressive\nperformance of our unified representation approach across various tasks,\nsurpassing existing methodologies. Furthermore, our approach exhibits\nexceptional scalability and generality. Our code, model, and dataset will be\navailable at \\url{https://github.com/lzw-lzw/UnifiedMLLM}.", "categories": "cs.CL", "created": "2024-08-05", "doi": null, "arxiv_id": "2408.02503"}
{"title": "Estimating Pore Location of PBF-LB/M Processes with Segmentation Models", "authors": [], "abstract": "Reliably manufacturing defect free products is still an open challenge for\nLaser Powder Bed Fusion processes. Particularly, pores that occur frequently\nhave a negative impact on mechanical properties like fatigue performance.\nTherefore, an accurate localisation of pores is mandatory for quality\nassurance, but requires time-consuming post-processing steps like computer\ntomography scans. Although existing solutions using in-situ monitoring data can\ndetect pore occurrence within a layer, they are limited in their localisation\nprecision. Therefore, we propose a pore localisation approach that estimates\ntheir position within a single layer using a Gaussian kernel density\nestimation. This allows segmentation models to learn the correlation between\nin-situ monitoring data and the derived probability distribution of pore\noccurrence. Within our experiments, we compare the prediction performance of\ndifferent segmentation models depending on machine parameter configuration and\ngeometry features. From our results, we conclude that our approach allows a\nprecise localisation of pores that requires minimal data preprocessing. Our\nresearch extends the literature by providing a foundation for more precise pore\ndetection systems.", "categories": "cs.CV", "created": "2024-08-05", "doi": null, "arxiv_id": "2408.02507"}
{"title": "PUREsuggest: Citation-based Literature Search and Visual Exploration\n  with Keyword-controlled Rankings", "authors": [], "abstract": "Citations allow quickly identifying related research. If multiple\npublications are selected as seeds, specific suggestions for related literature\ncan be made based on the number of incoming and outgoing citation links to this\nselection. Interactively adding recommended publications to the selection\nrefines the next suggestion and incrementally builds a relevant collection of\npublications. Following this approach, the paper presents a search and foraging\napproach, PUREsuggest, which combines citation-based suggestions with augmented\nvisualizations of the citation network. The focus and novelty of the approach\nis, first, the transparency of how the rankings are explained visually and,\nsecond, that the process can be steered through user-defined keywords, which\nreflect topics of interests. The system can be used to build new literature\ncollections, to update and assess existing ones, as well as to use the\ncollected literature for identifying relevant experts in the field. We\nevaluated the recommendation approach through simulated sessions and performed\na user study investigating search strategies and usage patterns supported by\nthe interface.", "categories": "cs.HC cs.DL", "created": "2024-08-05", "doi": null, "arxiv_id": "2408.02508"}
{"title": "Practical Attacks against Black-box Code Completion Engines", "authors": [], "abstract": "Modern code completion engines, powered by large language models, have\ndemonstrated impressive capabilities to generate functionally correct code\nbased on surrounding context. As these tools are extensively used by millions\nof developers, it is crucial to investigate their security implications. In\nthis work, we present INSEC, a novel attack that directs code completion\nengines towards generating vulnerable code. In line with most commercial\ncompletion engines, such as GitHub Copilot, INSEC assumes only black-box query\naccess to the targeted engine, without requiring any knowledge of the engine's\ninternals. Our attack works by inserting a malicious attack string as a short\ncomment in the completion input. To derive the attack string, we design a\nseries of specialized initialization schemes and an optimization procedure for\nfurther refinement. We demonstrate the strength of INSEC not only on\nstate-of-the-art open-source models but also on black-box commercial services\nsuch as the OpenAI API and GitHub Copilot. On a comprehensive set of\nsecurity-critical test cases covering 16 CWEs across 5 programming languages,\nINSEC significantly increases the likelihood of the considered completion\nengines in generating unsafe code by >50% in absolute, while maintaining the\nability in producing functionally correct code. At the same time, our attack\nhas low resource requirements, and can be developed for a cost of well under\nten USD on commodity hardware.", "categories": "cs.CR cs.LG cs.PL cs.SE", "created": "2024-08-05", "doi": null, "arxiv_id": "2408.02509"}
{"title": "Stem-JEPA: A Joint-Embedding Predictive Architecture for Musical Stem\n  Compatibility Estimation", "authors": [], "abstract": "This paper explores the automated process of determining stem compatibility\nby identifying audio recordings of single instruments that blend well with a\ngiven musical context. To tackle this challenge, we present Stem-JEPA, a novel\nJoint-Embedding Predictive Architecture (JEPA) trained on a multi-track dataset\nusing a self-supervised learning approach.\n  Our model comprises two networks: an encoder and a predictor, which are\njointly trained to predict the embeddings of compatible stems from the\nembeddings of a given context, typically a mix of several instruments. Training\na model in this manner allows its use in estimating stem compatibility -\nretrieving, aligning, or generating a stem to match a given mix - or for\ndownstream tasks such as genre or key estimation, as the training paradigm\nrequires the model to learn information related to timbre, harmony, and rhythm.\n  We evaluate our model's performance on a retrieval task on the MUSDB18\ndataset, testing its ability to find the missing stem from a mix and through a\nsubjective user study. We also show that the learned embeddings capture\ntemporal alignment information and, finally, evaluate the representations\nlearned by our model on several downstream tasks, highlighting that they\neffectively capture meaningful musical features.", "categories": "cs.SD cs.LG eess.AS", "created": "2024-08-05", "doi": null, "arxiv_id": "2408.02514"}
{"title": "OneLove beyond the field -- A few-shot pipeline for topic and sentiment\n  analysis during the FIFA World Cup in Qatar", "authors": [], "abstract": "The FIFA World Cup in Qatar was discussed extensively in the news and on\nsocial media. Due to news reports with allegations of human rights violations,\nthere were calls to boycott it. Wearing a OneLove armband was part of a planned\nprotest activity. Controversy around the armband arose when FIFA threatened to\nsanction captains who wear it. To understand what topics Twitter users Tweeted\nabout and what the opinion of German Twitter users was towards the OneLove\narmband, we performed an analysis of German Tweets published during the World\nCup using in-context learning with LLMs. We validated the labels on human\nannotations. We found that Twitter users initially discussed the armband's\nimpact, LGBT rights, and politics; after the ban, the conversation shifted\ntowards politics in sports in general, accompanied by a subtle shift in\nsentiment towards neutrality. Our evaluation serves as a framework for future\nresearch to explore the impact of sports activism and evolving public\nsentiment. This is especially useful in settings where labeling datasets for\nspecific opinions is unfeasible, such as when events are unfolding.", "categories": "cs.CL", "created": "2024-08-05", "doi": null, "arxiv_id": "2408.02520"}
{"title": "Introducing a Comprehensive, Continuous, and Collaborative Survey of\n  Intrusion Detection Datasets", "authors": [], "abstract": "Researchers in the highly active field of intrusion detection largely rely on\npublic datasets for their experimental evaluations. However, the large number\nof existing datasets, the discovery of previously unknown flaws therein, and\nthe frequent publication of new datasets make it hard to select suitable\noptions and sufficiently understand their respective limitations. Hence, there\nis a great risk of drawing invalid conclusions from experimental results with\nrespect to detection performance of novel methods in the real world. While\nthere exist various surveys on intrusion detection datasets, they have\ndeficiencies in providing researchers with a profound decision basis since they\nlack comprehensiveness, actionable details, and up-to-dateness. In this paper,\nwe present COMIDDS, an ongoing effort to comprehensively survey intrusion\ndetection datasets with an unprecedented level of detail, implemented as a\nwebsite backed by a public GitHub repository. COMIDDS allows researchers to\nquickly identify suitable datasets depending on their requirements and provides\nstructured and critical information on each dataset, including actual data\nsamples and links to relevant publications. COMIDDS is freely accessible,\nregularly updated, and open to contributions.", "categories": "cs.CR", "created": "2024-08-05", "doi": "10.1145/3675741.3675754", "arxiv_id": "2408.02521"}
{"title": "Single-tap Latency Reduction with Single- or Double- tap Prediction", "authors": [], "abstract": "Touch surfaces are widely utilized for smartphones, tablet PCs, and laptops\n(touchpad), and single and double taps are the most basic and common operations\non them. The detection of single or double taps causes the single-tap latency\nproblem, which creates a bottleneck in terms of the sensitivity of touch\ninputs. To reduce the single-tap latency, we propose a novel\nmachine-learning-based tap prediction method called PredicTaps. Our method\npredicts whether a detected tap is a single tap or the first contact of a\ndouble tap without having to wait for the hundreds of milliseconds\nconventionally required. We present three evaluations and one user evaluation\nthat demonstrate its broad applicability and usability for various tap\nsituations on two form factors (touchpad and smartphone). The results showed\nPredicTaps reduces the single-tap latency from 150-500 ms to 12 ms on laptops\nand to 17.6 ms on smartphones without reducing usability.", "categories": "cs.HC cs.AI cs.LG", "created": "2024-08-05", "doi": "10.1145/3604271", "arxiv_id": "2408.02525"}
{"title": "Online Deterministic Minimum Cost Bipartite Matching with Delays on a\n  Line", "authors": [], "abstract": "We study the online minimum cost bipartite perfect matching with delays\nproblem. In this problem, $m$ servers and $m$ requests arrive over time, and an\nonline algorithm can delay the matching between servers and requests by paying\nthe delay cost. The objective is to minimize the total distance and delay cost.\nWhen servers and requests lie in a known metric space, there is a randomized\n$O(\\log n)$-competitive algorithm, where $n$ is the size of the metric space.\nWhen the metric space is unknown a priori, Azar and Jacob-Fanani proposed a\ndeterministic\n$O\\left(\\frac{1}{\\epsilon}m^{\\log\\left(\\frac{3+\\epsilon}{2}\\right)}\\right)$-competitive\nalgorithm for any fixed $\\epsilon > 0$. This competitive ratio is tight when $n\n= 1$ and becomes $O(m^{0.59})$ for sufficiently small $\\epsilon$.\n  In this paper, we improve upon the result of Azar and Jacob-Fanani for the\ncase where servers and requests are on the real line, providing a deterministic\n$\\tilde{O}(m^{0.5})$-competitive algorithm. Our algorithm is based on the\nRobust Matching (RM) algorithm proposed by Raghvendra for the minimum cost\nbipartite perfect matching problem. In this problem, delay is not allowed, and\nall servers arrive in the beginning. When a request arrives, the RM algorithm\nimmediately matches the request to a free server based on the request's minimum\n$t$-net-cost augmenting path, where $t > 1$ is a constant. In our algorithm, we\ndelay the matching of a request until its waiting time exceeds its minimum\n$t$-net-cost divided by $t$.", "categories": "cs.DS", "created": "2024-08-05", "doi": null, "arxiv_id": "2408.02526"}
{"title": "Explaining Reinforcement Learning: A Counterfactual Shapley Values\n  Approach", "authors": [], "abstract": "This paper introduces a novel approach Counterfactual Shapley Values (CSV),\nwhich enhances explainability in reinforcement learning (RL) by integrating\ncounterfactual analysis with Shapley Values. The approach aims to quantify and\ncompare the contributions of different state dimensions to various action\nchoices. To more accurately analyze these impacts, we introduce new\ncharacteristic value functions, the ``Counterfactual Difference Characteristic\nValue\" and the ``Average Counterfactual Difference Characteristic Value.\" These\nfunctions help calculate the Shapley values to evaluate the differences in\ncontributions between optimal and non-optimal actions. Experiments across\nseveral RL domains, such as GridWorld, FrozenLake, and Taxi, demonstrate the\neffectiveness of the CSV method. The results show that this method not only\nimproves transparency in complex RL systems but also quantifies the differences\nacross various decisions.", "categories": "cs.AI", "created": "2024-08-05", "doi": null, "arxiv_id": "2408.02529"}
{"title": "The Immersed Boundary Conformal Method for Kirchhoff-Love and\n  Reissner-Mindlin shells", "authors": [], "abstract": "This work utilizes the Immersed Boundary Conformal Method (IBCM) to analyze\nKirchhoff-Love and Reissner-Mindlin shell structures within an immersed domain\nframework. Immersed boundary methods involve embedding complex geometries\nwithin a background grid, which allows for great flexibility in modeling\nintricate shapes and features despite the simplicity of the approach. The IBCM\nmethod introduces additional layers conformal to the boundaries, allowing for\nthe strong imposition of Dirichlet boundary conditions and facilitating local\nrefinement. In this study, the construction of boundary layers is combined with\nhigh-degree spline-based approximation spaces to further increase efficiency.\nThe Nitsche method, employing non-symmetric average operators, is used to\ncouple the boundary layers with the inner patch, while stabilizing the\nformulation with minimal penalty parameters. High-order quadrature rules are\napplied for integration over cut elements and patch interfaces. Numerical\nexperiments demonstrate the efficiency and accuracy of the proposed\nformulation, highlighting its potential for complex shell structures modeled\nthrough Kirchhoff-Love and Reissner-Mindlin theories. These tests include the\ngeneration of conformal interfaces, the coupling of Kirchhoff-Love and\nReissner-Mindlin theories, and the simulation of a damaged shell.", "categories": "math.NA cs.NA", "created": "2024-08-05", "doi": null, "arxiv_id": "2408.02530"}
{"title": "LMEMs for post-hoc analysis of HPO Benchmarking", "authors": [], "abstract": "The importance of tuning hyperparameters in Machine Learning (ML) and Deep\nLearning (DL) is established through empirical research and applications,\nevident from the increase in new hyperparameter optimization (HPO) algorithms\nand benchmarks steadily added by the community. However, current benchmarking\npractices using averaged performance across many datasets may obscure key\ndifferences between HPO methods, especially for pairwise comparisons. In this\nwork, we apply Linear Mixed-Effect Models-based (LMEMs) significance testing\nfor post-hoc analysis of HPO benchmarking runs. LMEMs allow flexible and\nexpressive modeling on the entire experiment data, including information such\nas benchmark meta-features, offering deeper insights than current analysis\npractices. We demonstrate this through a case study on the PriorBand paper's\nexperiment data to find insights not reported in the original work.", "categories": "cs.LG", "created": "2024-08-05", "doi": null, "arxiv_id": "2408.02533"}
{"title": "Towards Coarse-grained Visual Language Navigation Task Planning Enhanced\n  by Event Knowledge Graph", "authors": [], "abstract": "Visual language navigation (VLN) is one of the important research in embodied\nAI. It aims to enable an agent to understand the surrounding environment and\ncomplete navigation tasks. VLN instructions could be categorized into\ncoarse-grained and fine-grained commands. Fine-grained command describes a\nwhole task with subtasks step-by-step. In contrast, coarse-grained command\ngives an abstract task description, which more suites human habits. Most\nexisting work focuses on the former kind of instruction in VLN tasks, ignoring\nthe latter abstract instructions belonging to daily life scenarios. To overcome\nthe above challenge in abstract instruction, we attempt to consider\ncoarse-grained instruction in VLN by event knowledge enhancement. Specifically,\nwe first propose a prompt-based framework to extract an event knowledge graph\n(named VLN-EventKG) for VLN integrally over multiple mainstream benchmark\ndatasets. Through small and large language model collaboration, we realize\nknowledge-enhanced navigation planning (named EventNav) for VLN tasks with\ncoarse-grained instruction input. Additionally, we design a novel dynamic\nhistory backtracking module to correct potential error action planning in real\ntime. Experimental results in various public benchmarks show our\nknowledge-enhanced method has superiority in coarse-grained-instruction VLN\nusing our proposed VLN-EventKG with over $5\\%$ improvement in success rate. Our\nproject is available at https://sites.google.com/view/vln-eventkg", "categories": "cs.IR cs.HC cs.RO", "created": "2024-08-05", "doi": null, "arxiv_id": "2408.02535"}
{"title": "Caution for the Environment: Multimodal Agents are Susceptible to\n  Environmental Distractions", "authors": [], "abstract": "This paper investigates the faithfulness of multimodal large language model\n(MLLM) agents in the graphical user interface (GUI) environment, aiming to\naddress the research question of whether multimodal GUI agents can be\ndistracted by environmental context. A general setting is proposed where both\nthe user and the agent are benign, and the environment, while not malicious,\ncontains unrelated content. A wide range of MLLMs are evaluated as GUI agents\nusing our simulated dataset, following three working patterns with different\nlevels of perception. Experimental results reveal that even the most powerful\nmodels, whether generalist agents or specialist GUI agents, are susceptible to\ndistractions. While recent studies predominantly focus on the helpfulness\n(i.e., action accuracy) of multimodal agents, our findings indicate that these\nagents are prone to environmental distractions, resulting in unfaithful\nbehaviors. Furthermore, we switch to the adversarial perspective and implement\nenvironment injection, demonstrating that such unfaithfulness can be exploited,\nleading to unexpected risks.", "categories": "cs.CL", "created": "2024-08-05", "doi": null, "arxiv_id": "2408.02544"}
{"title": "RAG Foundry: A Framework for Enhancing LLMs for Retrieval Augmented\n  Generation", "authors": [], "abstract": "Implementing Retrieval-Augmented Generation (RAG) systems is inherently\ncomplex, requiring deep understanding of data, use cases, and intricate design\ndecisions. Additionally, evaluating these systems presents significant\nchallenges, necessitating assessment of both retrieval accuracy and generative\nquality through a multi-faceted approach. We introduce RAG Foundry, an\nopen-source framework for augmenting large language models for RAG use cases.\nRAG Foundry integrates data creation, training, inference and evaluation into a\nsingle workflow, facilitating the creation of data-augmented datasets for\ntraining and evaluating large language models in RAG settings. This integration\nenables rapid prototyping and experimentation with various RAG techniques,\nallowing users to easily generate datasets and train RAG models using internal\nor specialized knowledge sources. We demonstrate the framework effectiveness by\naugmenting and fine-tuning Llama-3 and Phi-3 models with diverse RAG\nconfigurations, showcasing consistent improvements across three\nknowledge-intensive datasets. Code is released as open-source in\nhttps://github.com/IntelLabs/RAGFoundry.", "categories": "cs.CL cs.AI cs.IR cs.LG", "created": "2024-08-05", "doi": null, "arxiv_id": "2408.02545"}
{"title": "The Role of Functional Muscle Networks in Improving Hand Gesture\n  Perception for Human-Machine Interfaces", "authors": [], "abstract": "Developing accurate hand gesture perception models is critical for various\nrobotic applications, enabling effective communication between humans and\nmachines and directly impacting neurorobotics and interactive robots. Recently,\nsurface electromyography (sEMG) has been explored for its rich informational\ncontext and accessibility when combined with advanced machine learning\napproaches and wearable systems. The literature presents numerous approaches to\nboost performance while ensuring robustness for neurorobots using sEMG, often\nresulting in models requiring high processing power, large datasets, and less\nscalable solutions. This paper addresses this challenge by proposing the\ndecoding of muscle synchronization rather than individual muscle activation. We\nstudy coherence-based functional muscle networks as the core of our perception\nmodel, proposing that functional synchronization between muscles and the\ngraph-based network of muscle connectivity encode contextual information about\nintended hand gestures. This can be decoded using shallow machine learning\napproaches without the need for deep temporal networks. Our technique could\nimpact myoelectric control of neurorobots by reducing computational burdens and\nenhancing efficiency. The approach is benchmarked on the Ninapro database,\nwhich contains 12 EMG signals from 40 subjects performing 17 hand gestures. It\nachieves an accuracy of 85.1%, demonstrating improved performance compared to\nexisting methods while requiring much less computational power. The results\nsupport the hypothesis that a coherence-based functional muscle network encodes\ncritical information related to gesture execution, significantly enhancing hand\ngesture perception with potential applications for neurorobotic systems and\ninteractive machines.", "categories": "cs.RO cs.AI cs.LG eess.SP", "created": "2024-08-05", "doi": null, "arxiv_id": "2408.02547"}
{"title": "Higher weight spectra and Betti numbers of Reed-Muller codes $RM_2(2,2)$", "authors": [], "abstract": "We determine the higher weight spectra of $q$-ary Reed-Muller codes\n$C_q=RM_q(2,2)$ for all prime powers $q$. This is equivalent to finding the\nusual weight distributions of all extension codes of $C_q$ over every field\nextension of $F_q$ of finite degree. To obtain our results we will utilize\nwell-known connections between these weights and properties of the\nStanley-Reisner rings of a series of matroids associated to each code $C_q$. In\nthe process, we are able to explicitly determine all the graded Betti numbers\nof matroids associated to $C_q$ and its elongations.", "categories": "math.CO cs.IT math.IT", "created": "2024-08-05", "doi": null, "arxiv_id": "2408.02548"}
{"title": "Generative AI as a Service in 6G Edge-Cloud: Generation Task Offloading\n  by In-context Learning", "authors": [], "abstract": "Generative artificial intelligence (GAI) is a promising technique towards 6G\nnetworks, and generative foundation models such as large language models (LLMs)\nhave attracted considerable interest from academia and telecom industry. This\nwork considers a novel edge-cloud deployment of foundation models in 6G\nnetworks. Specifically, it aims to minimize the service delay of foundation\nmodels by radio resource allocation and task offloading, i.e., offloading\ndiverse content generation tasks to proper LLMs at the network edge or cloud.\nIn particular, we first introduce the communication system model, i.e.,\nallocating radio resources and calculating link capacity to support generated\ncontent transmission, and then we present the LLM inference model to calculate\nthe delay of content generation. After that, we propose a novel in-context\nlearning method to optimize the task offloading decisions. It utilizes LLM's\ninference capabilities, and avoids the difficulty of dedicated model training\nor fine-tuning as in conventional machine learning algorithms. Finally, the\nsimulations demonstrate that the proposed edge-cloud deployment and in-context\nlearning task offloading method can achieve satisfactory generation service\nquality without dedicated model training or fine-tuning.", "categories": "eess.SY cs.SY", "created": "2024-08-05", "doi": null, "arxiv_id": "2408.02549"}
{"title": "On the Complexity of the Conditional Independence Implication Problem\n  With Bounded Cardinalities", "authors": [], "abstract": "We show that the conditional independence (CI) implication problem with\nbounded cardinalities, which asks whether a given CI implication holds for all\ndiscrete random variables with given cardinalities, is co-NEXPTIME-hard. The\nproblem remains co-NEXPTIME-hard if all variables are binary. The reduction\ngoes from a variant of the tiling problem and is based on a prior construction\nused by Cheuk Ting Li to show the undecidability of a related problem where the\ncardinality of some variables remains unbounded. The CI implication problem\nwith bounded cardinalities is known to be in EXPSPACE, as its negation can be\nstated as an existential first-order logic formula over the reals of size\nexponential with regard to the size of the input.", "categories": "cs.CC cs.IT math.IT", "created": "2024-08-05", "doi": null, "arxiv_id": "2408.02550"}
{"title": "Process-constrained batch Bayesian approaches for yield optimization in\n  multi-reactor systems", "authors": [], "abstract": "The optimization of yields in multi-reactor systems, which are advanced tools\nin heterogeneous catalysis research, presents a significant challenge due to\nhierarchical technical constraints. To this respect, this work introduces a\nnovel approach called process-constrained batch Bayesian optimization via\nThompson sampling (pc-BO-TS) and its generalized hierarchical extension\n(hpc-BO-TS). This method, tailored for the efficiency demands in multi-reactor\nsystems, integrates experimental constraints and balances between exploration\nand exploitation in a sequential batch optimization strategy. It offers an\nimprovement over other Bayesian optimization methods. The performance of\npc-BO-TS and hpc-BO-TS is validated in synthetic cases as well as in a\nrealistic scenario based on data obtained from high-throughput experiments done\non a multi-reactor system available in the REALCAT platform. The proposed\nmethods often outperform other sequential Bayesian optimizations and existing\nprocess-constrained batch Bayesian optimization methods. This work proposes a\nnovel approach to optimize the yield of a reaction in a multi-reactor system,\nmarking a significant step forward in digital catalysis and generally in\noptimization methods for chemical engineering.", "categories": "cs.LG", "created": "2024-08-05", "doi": "10.1016/j.compchemeng.2024.108779", "arxiv_id": "2408.02551"}
{"title": "MeshAnything V2: Artist-Created Mesh Generation With Adjacent Mesh\n  Tokenization", "authors": [], "abstract": "We introduce MeshAnything V2, an autoregressive transformer that generates\nArtist-Created Meshes (AM) aligned to given shapes. It can be integrated with\nvarious 3D asset production pipelines to achieve high-quality, highly\ncontrollable AM generation. MeshAnything V2 surpasses previous methods in both\nefficiency and performance using models of the same size. These improvements\nare due to our newly proposed mesh tokenization method: Adjacent Mesh\nTokenization (AMT). Different from previous methods that represent each face\nwith three vertices, AMT uses a single vertex whenever possible. Compared to\nprevious methods, AMT requires about half the token sequence length to\nrepresent the same mesh in average. Furthermore, the token sequences from AMT\nare more compact and well-structured, fundamentally benefiting AM generation.\nOur extensive experiments show that AMT significantly improves the efficiency\nand performance of AM generation. Project Page:\nhttps://buaacyw.github.io/meshanything-v2/", "categories": "cs.CV cs.AI cs.GR", "created": "2024-08-05", "doi": null, "arxiv_id": "2408.02555"}
{"title": "AutoFL: A Tool for Automatic Multi-granular Labelling of Software\n  Repositories", "authors": [], "abstract": "Software comprehension, especially of new code bases, is time consuming for\ndevelopers, especially in large projects with multiple functionalities spanning\nvarious domains. One strategy to reduce this effort involves annotating files\nwith meaningful labels that describe the functionalities contained. However,\nprior research has so far focused on classifying the whole project using README\nfiles as a proxy, resulting in little information gained for the developers.\n  Our objective is to streamline the labelling of files with the correct\napplication domains using source code as input. To achieve this, in prior work,\nwe evaluated the ability to annotate files automatically using a weak labelling\napproach.\n  This paper presents AutoFL, a tool for automatically labelling software\nrepositories from source code. AutoFL allows multi-granular annotations\nincluding: \\textit{file}, \\textit{package}, and \\textit{project} -level.\n  We provide an overview of the tool's internals, present an example analysis\nfor which AutoFL can be used, and discuss limitations and future work.", "categories": "cs.SE", "created": "2024-08-05", "doi": null, "arxiv_id": "2408.02557"}
{"title": "Peer-induced Fairness: A Causal Approach to Reveal Algorithmic\n  Unfairness in Credit Approval", "authors": [], "abstract": "This paper introduces a novel framework, \"peer-induced fairness\", to\nscientifically audit algorithmic fairness. It addresses a critical but often\noverlooked issue: distinguishing between adverse outcomes due to algorithmic\ndiscrimination and those resulting from individuals' insufficient capabilities.\nBy utilizing counterfactual fairness and advanced causal inference techniques,\nsuch as the Single World Intervention Graph, this model-agnostic approach\nevaluates fairness at the individual level through peer comparisons and\nhypothesis testing. It also tackles challenges like data scarcity and\nimbalance, offering a flexible, plug-and-play self-audit tool for stakeholders\nand an external audit tool for regulators, while providing explainable feedback\nfor those affected by unfavorable decisions.", "categories": "stat.AP cs.CY q-fin.CP q-fin.ST stat.ML", "created": "2024-08-05", "doi": null, "arxiv_id": "2408.02558"}
{"title": "Evaluating and Enhancing LLMs Agent based on Theory of Mind in Guandan:\n  A Multi-Player Cooperative Game under Imperfect Information", "authors": [], "abstract": "Large language models (LLMs) have shown success in handling simple games with\nimperfect information and enabling multi-agent coordination, but their ability\nto facilitate practical collaboration against other agents in complex,\nimperfect information environments, especially in a non-English environment,\nstill needs to be explored. This study investigates the applicability of\nknowledge acquired by open-source and API-based LLMs to sophisticated\ntext-based games requiring agent collaboration under imperfect information,\ncomparing their performance to established baselines using other types of\nagents. We propose a Theory of Mind (ToM) planning technique that allows LLM\nagents to adapt their strategy against various adversaries using only game\nrules, current state, and historical context as input. An external tool was\nincorporated to mitigate the challenge of dynamic and extensive action spaces\nin this card game. Our results show that although a performance gap exists\nbetween current LLMs and state-of-the-art reinforcement learning (RL) models,\nLLMs demonstrate ToM capabilities in this game setting. It consistently\nimproves their performance against opposing agents, suggesting their ability to\nunderstand the actions of allies and adversaries and establish collaboration\nwith allies. To encourage further research and understanding, we have made our\ncodebase openly accessible.", "categories": "cs.CL cs.AI", "created": "2024-08-05", "doi": null, "arxiv_id": "2408.02559"}
{"title": "HQOD: Harmonious Quantization for Object Detection", "authors": [], "abstract": "Task inharmony problem commonly occurs in modern object detectors, leading to\ninconsistent qualities between classification and regression tasks. The\npredicted boxes with high classification scores but poor localization positions\nor low classification scores but accurate localization positions will worsen\nthe performance of detectors after Non-Maximum Suppression. Furthermore, when\nobject detectors collaborate with Quantization-Aware Training (QAT), we observe\nthat the task inharmony problem will be further exacerbated, which is\nconsidered one of the main causes of the performance degradation of quantized\ndetectors. To tackle this issue, we propose the Harmonious Quantization for\nObject Detection (HQOD) framework, which consists of two components. Firstly,\nwe propose a task-correlated loss to encourage detectors to focus on improving\nsamples with lower task harmony quality during QAT. Secondly, a harmonious\nIntersection over Union (IoU) loss is incorporated to balance the optimization\nof the regression branch across different IoU levels. The proposed HQOD can be\neasily integrated into different QAT algorithms and detectors. Remarkably, on\nthe MS COCO dataset, our 4-bit ATSS with ResNet-50 backbone achieves a\nstate-of-the-art mAP of 39.6%, even surpassing the full-precision one.", "categories": "cs.CV", "created": "2024-08-05", "doi": null, "arxiv_id": "2408.02561"}
{"title": "Asynchronous Latency and Fast Atomic Snapshot", "authors": [], "abstract": "The original goal of this paper was a novel, fast atomic-snapshot protocol\nfor asynchronous message-passing systems. In the process of defining what fast\nmeans exactly, we faced a number of interesting issues that arise when\nconventional time metrics are applied to asynchronous implementations. We\ndiscovered some gaps in latency claims made in earlier work on snapshot\nalgorithms, which hampers their comparative time-complexity analysis. We then\ncame up with a new unifying time-complexity analysis that captures the latency\nof an operation in an asynchronous, long-lived implementation, which allowed us\nto formally grasp latency improvements of our solution with respect to the\nstate-of-the-art protocols: optimal latency in fault-free runs without\ncontention, short constant latency in fault-free runs with contention, the\nworst-case latency proportional to the number of failures, and constant, close\nto optimal amortized latency.", "categories": "cs.DC", "created": "2024-08-05", "doi": null, "arxiv_id": "2408.02562"}
{"title": "Reasons to Doubt the Impact of AI Risk Evaluations", "authors": [], "abstract": "AI safety practitioners invest considerable resources in AI system\nevaluations, but these investments may be wasted if evaluations fail to realize\ntheir impact. This paper questions the core value proposition of evaluations:\nthat they significantly improve our understanding of AI risks and,\nconsequently, our ability to mitigate those risks. Evaluations may fail to\nimprove understanding in six ways, such as risks manifesting beyond the AI\nsystem or insignificant returns from evaluations compared to real-world\nobservations. Improved understanding may also not lead to better risk\nmitigation in four ways, including challenges in upholding and enforcing\ncommitments. Evaluations could even be harmful, for example, by triggering the\nweaponization of dual-use capabilities or invoking high opportunity costs for\nAI safety. This paper concludes with considerations for improving evaluation\npractices and 12 recommendations for AI labs, external evaluators, regulators,\nand academic researchers to encourage a more strategic and impactful approach\nto AI risk assessment and mitigation.", "categories": "cs.CY", "created": "2024-08-05", "doi": null, "arxiv_id": "2408.02565"}
{"title": "Cross-Modality Clustering-based Self-Labeling for Multimodal Data\n  Classification", "authors": [], "abstract": "Technological advances facilitate the ability to acquire multimodal data,\nposing a challenge for recognition systems while also providing an opportunity\nto use the heterogeneous nature of the information to increase the\ngeneralization capability of models. An often overlooked issue is the cost of\nthe labeling process, which is typically high due to the need for a significant\ninvestment in time and money associated with human experts. Existing\nsemi-supervised learning methods often focus on operating in the feature space\ncreated by the fusion of available modalities, neglecting the potential for\ncross-utilizing complementary information available in each modality. To\naddress this problem, we propose Cross-Modality Clustering-based Self-Labeling\n(CMCSL). Based on a small set of pre-labeled data, CMCSL groups instances\nbelonging to each modality in the deep feature space and then propagates known\nlabels within the resulting clusters. Next, information about the instances'\nclass membership in each modality is exchanged based on the Euclidean distance\nto ensure more accurate labeling. Experimental evaluation conducted on 20\ndatasets derived from the MM-IMDb dataset indicates that cross-propagation of\nlabels between modalities -- especially when the number of pre-labeled\ninstances is small -- can allow for more reliable labeling and thus increase\nthe classification performance in each modality.", "categories": "cs.LG cs.CV", "created": "2024-08-05", "doi": null, "arxiv_id": "2408.02568"}
{"title": "Whittle's index-based age-of-information minimization in multi-energy\n  harvesting source networks", "authors": [], "abstract": "We consider the problem of source sampling and transmission scheduling for\nage-of-information minimization in a system consisting of multiple energy\nharvesting (EH) sources and a sink node. At each time, one of the sources is\nselected by the scheduler and the quality of its channel to the sink is\nmeasured. This probed channel quality is then used to decide whether a source\nwill sample an observation and transmit the packet to the sink in that time\nslot. We formulate this problem as a constrained Markov decision process (CMDP)\nassuming i.i.d. energy arrival and channel fading processes, and relax it using\na Lagrange multiplier. We apply a near optimal Whittle's index policy to decide\nthe node to be probed. Next, for the probed node, we derive an optimal\nthreshold policy, which recommends source sampling and observation transmission\nfrom the probed source only when the measured channel quality is above a\nthreshold. Our proposed policy is called Whittle's index and threshold based\nsource scheduling and sampling (WITS3) policy. However, in order to calculate\nWhittle's indices, one must be aware of the underlying processes' transition\nmatrices, which are occasionally concealed from the scheduler. Therefore, we\nfurther propose a variant Q-WITS3 of WITS3 based on Q-learning assisted by two\ntimescale asynchronous stochastic approximation, which seeks to learn Whittle's\nindices and optimal policies for the case with unknown channel states and EH\ncharacteristics. Numerical results demonstrate the efficacy of our algorithms\nover two baseline policies.", "categories": "eess.SY cs.SY", "created": "2024-08-05", "doi": null, "arxiv_id": "2408.02570"}
{"title": "Contrastive Learning-based Multi Modal Architecture for Emoticon\n  Prediction by Employing Image-Text Pairs", "authors": [], "abstract": "The emoticons are symbolic representations that generally accompany the\ntextual content to visually enhance or summarize the true intention of a\nwritten message. Although widely utilized in the realm of social media, the\ncore semantics of these emoticons have not been extensively explored based on\nmultiple modalities. Incorporating textual and visual information within a\nsingle message develops an advanced way of conveying information. Hence, this\nresearch aims to analyze the relationship among sentences, visuals, and\nemoticons. For an orderly exposition, this paper initially provides a detailed\nexamination of the various techniques for extracting multimodal features,\nemphasizing the pros and cons of each method. Through conducting a\ncomprehensive examination of several multimodal algorithms, with specific\nemphasis on the fusion approaches, we have proposed a novel contrastive\nlearning based multimodal architecture. The proposed model employs the joint\ntraining of dual-branch encoder along with the contrastive learning to\naccurately map text and images into a common latent space. Our key finding is\nthat by integrating the principle of contrastive learning with that of the\nother two branches yields superior results. The experimental results\ndemonstrate that our suggested methodology surpasses existing multimodal\napproaches in terms of accuracy and robustness. The proposed model attained an\naccuracy of 91% and an MCC-score of 90% while assessing emoticons using the\nMultimodal-Twitter Emoticon dataset acquired from Twitter. We provide evidence\nthat deep features acquired by contrastive learning are more efficient,\nsuggesting that the proposed fusion technique also possesses strong\ngeneralisation capabilities for recognising emoticons across several modes.", "categories": "cs.CV cs.AI", "created": "2024-08-05", "doi": null, "arxiv_id": "2408.02571"}
{"title": "Artificial Intelligence for Public Health Surveillance in Africa:\n  Applications and Opportunities", "authors": [], "abstract": "Artificial Intelligence (AI) is revolutionizing various fields, including\npublic health surveillance. In Africa, where health systems frequently\nencounter challenges such as limited resources, inadequate infrastructure,\nfailed health information systems and a shortage of skilled health\nprofessionals, AI offers a transformative opportunity. This paper investigates\nthe applications of AI in public health surveillance across the continent,\npresenting successful case studies and examining the benefits, opportunities,\nand challenges of implementing AI technologies in African healthcare settings.\nOur paper highlights AI's potential to enhance disease monitoring and health\noutcomes, and support effective public health interventions. The findings\npresented in the paper demonstrate that AI can significantly improve the\naccuracy and timeliness of disease detection and prediction, optimize resource\nallocation, and facilitate targeted public health strategies. Additionally, our\npaper identified key barriers to the widespread adoption of AI in African\npublic health systems and proposed actionable recommendations to overcome these\nchallenges.", "categories": "cs.LG cs.CL", "created": "2024-08-05", "doi": null, "arxiv_id": "2408.02575"}
{"title": "Operational range bounding of spectroscopy models with anomaly detection", "authors": [], "abstract": "Safe operation of machine learning models requires architectures that\nexplicitly delimit their operational ranges. We evaluate the ability of anomaly\ndetection algorithms to provide indicators correlated with degraded model\nperformance. By placing acceptance thresholds over such indicators, hard\nboundaries are formed that define the model's coverage. As a use case, we\nconsider the extraction of exoplanetary spectra from transit light curves,\nspecifically within the context of ESA's upcoming Ariel mission. Isolation\nForests are shown to effectively identify contexts where prediction models are\nlikely to fail. Coverage/error trade-offs are evaluated under conditions of\ndata and concept drift. The best performance is seen when Isolation Forests\nmodel projections of the prediction model's explainability SHAP values.", "categories": "cs.LG astro-ph.IM", "created": "2024-08-05", "doi": null, "arxiv_id": "2408.02581"}
{"title": "Clustering and Mining Accented Speech for Inclusive and Fair Speech\n  Recognition", "authors": [], "abstract": "Modern automatic speech recognition (ASR) systems are typically trained on\nmore than tens of thousands hours of speech data, which is one of the main\nfactors for their great success. However, the distribution of such data is\ntypically biased towards common accents or typical speech patterns. As a\nresult, those systems often poorly perform on atypical accented speech. In this\npaper, we present accent clustering and mining schemes for fair speech\nrecognition systems which can perform equally well on under-represented\naccented speech. For accent recognition, we applied three schemes to overcome\nlimited size of supervised accent data: supervised or unsupervised\npre-training, distributionally robust optimization (DRO) and unsupervised\nclustering. Three schemes can significantly improve the accent recognition\nmodel especially for unbalanced and small accented speech. Fine-tuning ASR on\nthe mined Indian accent speech using the proposed supervised or unsupervised\nclustering schemes showed 10.0% and 5.3% relative improvements compared to\nfine-tuning on the randomly sampled speech, respectively.", "categories": "cs.SD cs.AI eess.AS", "created": "2024-08-05", "doi": null, "arxiv_id": "2408.02582"}
{"title": "Leveraging the Power of LLMs: A Fine-Tuning Approach for High-Quality\n  Aspect-Based Summarization", "authors": [], "abstract": "The ever-increasing volume of digital information necessitates efficient\nmethods for users to extract key insights from lengthy documents. Aspect-based\nsummarization offers a targeted approach, generating summaries focused on\nspecific aspects within a document. Despite advancements in aspect-based\nsummarization research, there is a continuous quest for improved model\nperformance. Given that large language models (LLMs) have demonstrated the\npotential to revolutionize diverse tasks within natural language processing,\nparticularly in the problem of summarization, this paper explores the potential\nof fine-tuning LLMs for the aspect-based summarization task. We evaluate the\nimpact of fine-tuning open-source foundation LLMs, including Llama2, Mistral,\nGemma and Aya, on a publicly available domain-specific aspect based summary\ndataset. We hypothesize that this approach will enable these models to\neffectively identify and extract aspect-related information, leading to\nsuperior quality aspect-based summaries compared to the state-of-the-art. We\nestablish a comprehensive evaluation framework to compare the performance of\nfine-tuned LLMs against competing aspect-based summarization methods and\nvanilla counterparts of the fine-tuned LLMs. Our work contributes to the field\nof aspect-based summarization by demonstrating the efficacy of fine-tuning LLMs\nfor generating high-quality aspect-based summaries. Furthermore, it opens doors\nfor further exploration of using LLMs for targeted information extraction tasks\nacross various NLP domains.", "categories": "cs.CL cs.AI cs.IR", "created": "2024-08-05", "doi": null, "arxiv_id": "2408.02584"}
{"title": "Massive MIMO-OTFS-Based Random Access for Cooperative LEO Satellite\n  Constellations", "authors": [], "abstract": "This paper investigates joint device identification, channel estimation, and\nsymbol detection for cooperative multi-satellite-enhanced random access, where\northogonal time-frequency space modulation with the large antenna array is\nutilized to combat the dynamics of the terrestrial-satellite links (TSLs). We\nintroduce the generalized complex exponential basis expansion model to\nparameterize TSLs, thereby reducing the pilot overhead. By exploiting the block\nsparsity of the TSLs in the angular domain, a message passing algorithm is\ndesigned for initial channel estimation. Subsequently, we examine two\ncooperative modes to leverage the spatial diversity within satellite\nconstellations: the centralized mode, where computations are performed at a\nhigh-power central server, and the distributed mode, where computations are\noffloaded to edge satellites with minimal signaling overhead. Specifically, in\nthe centralized mode, device identification is achieved by aggregating backhaul\ninformation from edge satellites, and channel estimation and symbol detection\nare jointly enhanced through a structured approximate expectation propagation\n(AEP) algorithm. In the distributed mode, edge satellites share channel\ninformation and exchange soft information about data symbols, leading to a\ndistributed version of AEP. The introduced basis expansion model for TSLs\nenables the efficient implementation of both centralized and distributed\nalgorithms via fast Fourier transform. Simulation results demonstrate that\nproposed schemes significantly outperform conventional algorithms in terms of\nthe activity error rate, the normalized mean squared error, and the symbol\nerror rate. Notably, the distributed mode achieves performance comparable to\nthe centralized mode with only two exchanges of soft information about data\nsymbols within the constellation.", "categories": "cs.IT eess.SP math.IT", "created": "2024-08-05", "doi": null, "arxiv_id": "2408.02586"}
{"title": "Modelling Visual Semantics via Image Captioning to extract Enhanced\n  Multi-Level Cross-Modal Semantic Incongruity Representation with Attention\n  for Multimodal Sarcasm Detection", "authors": [], "abstract": "Sarcasm is a type of irony, characterized by an inherent mismatch between the\nliteral interpretation and the intended connotation. Though sarcasm detection\nin text has been extensively studied, there are situations in which textual\ninput alone might be insufficient to perceive sarcasm. The inclusion of\nadditional contextual cues, such as images, is essential to recognize sarcasm\nin social media data effectively. This study presents a novel framework for\nmultimodal sarcasm detection that can process input triplets. Two components of\nthese triplets comprise the input text and its associated image, as provided in\nthe datasets. Additionally, a supplementary modality is introduced in the form\nof descriptive image captions. The motivation behind incorporating this visual\nsemantic representation is to more accurately capture the discrepancies between\nthe textual and visual content, which are fundamental to the sarcasm detection\ntask. The primary contributions of this study are: (1) a robust textual feature\nextraction branch that utilizes a cross-lingual language model; (2) a visual\nfeature extraction branch that incorporates a self-regulated residual ConvNet\nintegrated with a lightweight spatially aware attention module; (3) an\nadditional modality in the form of image captions generated using an\nencoder-decoder architecture capable of reading text embedded in images; (4)\ndistinct attention modules to effectively identify the incongruities between\nthe text and two levels of image representations; (5) multi-level cross-domain\nsemantic incongruity representation achieved through feature fusion. Compared\nwith cutting-edge baselines, the proposed model achieves the best accuracy of\n92.89% and 64.48%, respectively, on the Twitter multimodal sarcasm and\nMultiBully datasets.", "categories": "cs.CV cs.AI", "created": "2024-08-05", "doi": null, "arxiv_id": "2408.02595"}
{"title": "AI-Driven Strategies for Reducing Student Withdrawal -- A Study of EMU\n  Student Stopout", "authors": [], "abstract": "Not everyone who enrolls in college will leave with a certificate or degree,\nbut the number of people who drop out or take a break is much higher than\nexperts previously believed. In December 2013, there were 29 million people\nwith some college education but no degree. That number jumped to 36 million by\nDecember of 2018, according to a new report from the National Student\nClearinghouse Research Center[1]. It is imperative to understand the underlying\nfactors contributing to student withdrawal and to assist decision-makers to\nidentify effective strategies to prevent it. By analyzing the characteristics\nand educational pathways of the stopout student population, our aim is to\nprovide actionable insights that can benefit institutions facing similar\nchallenges. Eastern Michigan University (EMU) faces significant challenges in\nstudent retention, with approximately 55% of its undergraduate students not\ncompleting their degrees within six years. As an institution committed to\nstudent success, EMU conducted a comprehensive study of student withdrawals to\nunderstand the influencing factors. And the paper revealed a high correlation\nbetween certain factors and withdrawals, even in the early stages of university\nattendance. Based on these findings, we developed a predictive model that\nemploys artificial intelligence techniques to assess the potential risk that\nstudents abandon their studies. These models enable universities to implement\nearly intervention strategies, support at-risk students, and improve overall\nhigher education success.", "categories": "cs.LG cs.CY", "created": "2024-08-05", "doi": null, "arxiv_id": "2408.02598"}
{"title": "Progressively Selective Label Enhancement for Language Model Alignment", "authors": [], "abstract": "Large Language Models have demonstrated impressive capabilities in various\nlanguage tasks but may produce content that misaligns with human expectations,\nraising ethical and legal concerns. Therefore, it is important to explore the\nlimitations and implement restrictions on the models to ensure safety and\ncompliance, with Reinforcement Learning from Human Feedback (RLHF) being the\nprimary method. Due to challenges in stability and scalability with the RLHF\nstages, researchers are exploring alternative methods to achieve effects\ncomparable to those of RLHF. However, these methods often depend on large\nhigh-quality datasets and inefficiently utilize generated data. To deal with\nthis problem, we propose PSLE, i.e., Progressively Selective Label Enhancement\nfor Language Model Alignment, a framework that fully utilizes all generated\ndata by guiding the model with principles to align outputs with human\nexpectations. Using a dynamically updated threshold, our approach ensures\nefficient data utilization by incorporating all generated responses and\nweighting them based on their corresponding reward scores. Experimental results\non multiple datasets demonstrate the effectiveness of PSLE compared to existing\nlanguage model alignment methods.", "categories": "cs.CL cs.AI", "created": "2024-08-05", "doi": null, "arxiv_id": "2408.02599"}
{"title": "BioMamba: A Pre-trained Biomedical Language Representation Model\n  Leveraging Mamba", "authors": [], "abstract": "The advancement of natural language processing (NLP) in biology hinges on\nmodels' ability to interpret intricate biomedical literature. Traditional\nmodels often struggle with the complex and domain-specific language in this\nfield. In this paper, we present BioMamba, a pre-trained model specifically\ndesigned for biomedical text mining. BioMamba builds upon the Mamba\narchitecture and is pre-trained on an extensive corpus of biomedical\nliterature. Our empirical studies demonstrate that BioMamba significantly\noutperforms models like BioBERT and general-domain Mamba across various\nbiomedical tasks. For instance, BioMamba achieves a 100 times reduction in\nperplexity and a 4 times reduction in cross-entropy loss on the BioASQ test\nset. We provide an overview of the model architecture, pre-training process,\nand fine-tuning techniques. Additionally, we release the code and trained model\nto facilitate further research.", "categories": "cs.CL", "created": "2024-08-05", "doi": null, "arxiv_id": "2408.02600"}
{"title": "Learning rheological parameters of non-Newtonian fluids from velocimetry\n  data", "authors": [], "abstract": "We solve a Bayesian inverse Navier-Stokes (N-S) problem that assimilates\nvelocimetry data in order to jointly reconstruct the flow field and learn the\nunknown N-S parameters. By incorporating a Carreau shear-thinning viscosity\nmodel into the N-S problem, we devise an algorithm that learns the most likely\nCarreau parameters of a shear-thinning fluid, and estimates their\nuncertainties, from velocimetry data alone. We then conduct a flow-MRI\nexperiment to obtain velocimetry data of an axisymmetric laminar jet through an\nidealised medical device (FDA nozzle) for a blood analogue fluid. We show that\nthe algorithm can successfully reconstruct the flow field by learning the most\nlikely Carreau parameters, and that the learned parameters are in very good\nagreement with rheometry measurements. The algorithm accepts any algebraic\neffective viscosity model, as long as the model is differentiable, and it can\nbe extended to more complicated non-Newtonian fluids (e.g. Oldroyd-B fluid) if\na viscoelastic model is incorporated into the N-S problem.", "categories": "physics.flu-dyn cs.LG math.OC", "created": "2024-08-05", "doi": null, "arxiv_id": "2408.02604"}
{"title": "Trade-offs of Dynamic Control Structure in Human-swarm Systems", "authors": [], "abstract": "Swarm robotics is a study of simple robots that exhibit complex behaviour\nonly by interacting locally with other robots and their environment. The\ncontrol in swarm robotics is mainly distributed whereas centralised control is\nwidely used in other fields of robotics. Centralised and decentralised control\nstrategies both pose a unique set of benefits and drawbacks for the control of\nmulti-robot systems. While decentralised systems are more scalable and\nresilient, they are less efficient compared to the centralised systems and they\nlead to excessive data transmissions to the human operators causing cognitive\noverload. We examine the trade-offs of each of these approaches in a\nhuman-swarm system to perform an environmental monitoring task and propose a\nflexible hybrid approach, which combines elements of hierarchical and\ndecentralised systems. We find that a flexible hybrid system can outperform a\ncentralised system (in our environmental monitoring task by 19.2%) while\nreducing the number of messages sent to a human operator (here by 23.1%). We\nconclude that establishing centralisation for a system is not always optimal\nfor performance and that utilising aspects of centralised and decentralised\nsystems can keep the swarm from hindering its performance.", "categories": "cs.RO", "created": "2024-08-05", "doi": null, "arxiv_id": "2408.02605"}
{"title": "Backward explanations via redefinition of predicates", "authors": [], "abstract": "History eXplanation based on Predicates (HXP), studies the behavior of a\nReinforcement Learning (RL) agent in a sequence of agent's interactions with\nthe environment (a history), through the prism of an arbitrary predicate. To\nthis end, an action importance score is computed for each action in the\nhistory. The explanation consists in displaying the most important actions to\nthe user. As the calculation of an action's importance is #W[1]-hard, it is\nnecessary for long histories to approximate the scores, at the expense of their\nquality. We therefore propose a new HXP method, called Backward-HXP, to provide\nexplanations for these histories without having to approximate scores.\nExperiments show the ability of B-HXP to summarise long histories.", "categories": "cs.AI cs.CC", "created": "2024-08-05", "doi": null, "arxiv_id": "2408.02606"}
{"title": "Comparison of Code Quality and Best Practices in IoT and non-IoT\n  Software", "authors": [], "abstract": "Context: IoT systems, networks of connected devices powered by software,\nrequire studying software quality for maintenance. Despite extensive studies on\nnon-IoT software quality, research on IoT software quality is lacking. It is\nuncertain if IoT and non-IoT systems software are comparable, hindering the\nconfident application of results and best practices gained on non-IoT systems.\n  Objective: Therefore, we compare the code quality of two equivalent sets of\nIoT and non-IoT systems to determine whether there are similarities and\ndifferences. We also collect and revisit software-engineering best practices in\nnon-IoT contexts to apply them to IoT.\n  Method: We design and apply a systematic method to select two sets of 94\nnon-IoT and IoT systems software from GitHub with comparable characteristics.\nWe compute quality metrics on the systems in these two sets and then analyse\nand compare the metric values. We analyse in depth and provide specific\nexamples of IoT system's complexity and how it manifests in the codebases.\nAfter the comparison, We systematically select and present a list of best\npractices to address the observed difference between IoT and non-IoT code.\n  Results: Through a comparison of metrics, we conclude that software for IoT\nsystems is more complex, coupled, larger, less maintainable, and cohesive than\nnon-IoT systems. Several factors, such as integrating multiple hardware and\nsoftware components and managing data communication between them, contribute to\nthese differences. Considering these differences, we present a revisited best\npractices list with approaches, tools, or techniques for developing IoT\nsystems. As example, applying modularity, and refactoring are best practices\nfor lowering the complexity.\n  Conclusion: Based on our work, researchers can now make an informed decision\nusing existing studies on the quality of non-IoT systems for IoT systems.", "categories": "cs.SE", "created": "2024-08-05", "doi": null, "arxiv_id": "2408.02614"}
{"title": "LaMamba-Diff: Linear-Time High-Fidelity Diffusion Models Based on Local\n  Attention and Mamba", "authors": [], "abstract": "Recent Transformer-based diffusion models have shown remarkable performance,\nlargely attributed to the ability of the self-attention mechanism to accurately\ncapture both global and local contexts by computing all-pair interactions among\ninput tokens. However, their quadratic complexity poses significant\ncomputational challenges for long-sequence inputs. Conversely, a recent state\nspace model called Mamba offers linear complexity by compressing a filtered\nglobal context into a hidden state. Despite its efficiency, compression\ninevitably leads to information loss of fine-grained local dependencies among\ntokens, which are crucial for effective visual generative modeling. Motivated\nby these observations, we introduce Local Attentional Mamba (LaMamba) blocks\nthat combine the strengths of self-attention and Mamba, capturing both global\ncontexts and local details with linear complexity. Leveraging the efficient\nU-Net architecture, our model exhibits exceptional scalability and surpasses\nthe performance of DiT across various model scales on ImageNet at 256x256\nresolution, all while utilizing substantially fewer GFLOPs and a comparable\nnumber of parameters. Compared to state-of-the-art diffusion models on ImageNet\n256x256 and 512x512, our largest model presents notable advantages, such as a\nreduction of up to 62\\% GFLOPs compared to DiT-XL/2, while achieving superior\nperformance with comparable or fewer parameters.", "categories": "cs.CV", "created": "2024-08-05", "doi": null, "arxiv_id": "2408.02615"}
{"title": "Mastering Agile Jumping Skills from Simple Practices with Iterative\n  Learning Control", "authors": [], "abstract": "Achieving precise target jumping with legged robots poses a significant\nchallenge due to the long flight phase and the uncertainties inherent in\ncontact dynamics and hardware. Forcefully attempting these agile motions on\nhardware could result in severe failures and potential damage. Motivated by\nthese challenging problems, we propose an Iterative Learning Control (ILC)\napproach that aims to learn and refine jumping skills from easy to difficult,\ninstead of directly learning these challenging tasks. We verify that learning\nfrom simplicity can enhance safety and target jumping accuracy over trials.\nCompared to other ILC approaches for legged locomotion, our method can tackle\nthe problem of a long flight phase where control input is not available. In\naddition, our approach allows the robot to apply what it learns from a simple\njumping task to accomplish more challenging tasks within a few trials directly\nin hardware, instead of learning from scratch. We validate the method via\nextensive experiments in the A1 model and hardware for various jumping tasks.\nStarting from a small jump (e.g., a forward leap of 40cm), our learning\napproach empowers the robot to accomplish a variety of challenging targets,\nincluding jumping onto a 20cm high box, jumping to a greater distance of up to\n60cm, as well as performing jumps while carrying an unknown payload of 2kg. Our\nframework can allow the robot to reach the desired position and orientation\ntargets with approximate errors of 1cm and 1 degree within a few trials.", "categories": "cs.RO", "created": "2024-08-05", "doi": null, "arxiv_id": "2408.02619"}
{"title": "Language Model Can Listen While Speaking", "authors": [], "abstract": "Dialogue serves as the most natural manner of human-computer interaction\n(HCI). Recent advancements in speech language models (SLM) have significantly\nenhanced speech-based conversational AI. However, these models are limited to\nturn-based conversation, lacking the ability to interact with humans in\nreal-time spoken scenarios, for example, being interrupted when the generated\ncontent is not satisfactory. To address these limitations, we explore full\nduplex modeling (FDM) in interactive speech language models (iSLM), focusing on\nenhancing real-time interaction and, more explicitly, exploring the\nquintessential ability of interruption. We introduce a novel model design,\nnamely listening-while-speaking language model (LSLM), an end-to-end system\nequipped with both listening and speaking channels. Our LSLM employs a\ntoken-based decoder-only TTS for speech generation and a streaming\nself-supervised learning (SSL) encoder for real-time audio input. LSLM fuses\nboth channels for autoregressive generation and detects turn-taking in real\ntime. Three fusion strategies -- early fusion, middle fusion, and late fusion\n-- are explored, with middle fusion achieving an optimal balance between speech\ngeneration and real-time interaction. Two experimental settings, command-based\nFDM and voice-based FDM, demonstrate LSLM's robustness to noise and sensitivity\nto diverse instructions. Our results highlight LSLM's capability to achieve\nduplex communication with minimal impact on existing systems. This study aims\nto advance the development of interactive speech dialogue systems, enhancing\ntheir applicability in real-world contexts.", "categories": "cs.CL cs.AI cs.HC cs.SD eess.AS", "created": "2024-08-05", "doi": null, "arxiv_id": "2408.02622"}
{"title": "VidGen-1M: A Large-Scale Dataset for Text-to-video Generation", "authors": [], "abstract": "The quality of video-text pairs fundamentally determines the upper bound of\ntext-to-video models. Currently, the datasets used for training these models\nsuffer from significant shortcomings, including low temporal consistency,\npoor-quality captions, substandard video quality, and imbalanced data\ndistribution. The prevailing video curation process, which depends on image\nmodels for tagging and manual rule-based curation, leads to a high\ncomputational load and leaves behind unclean data. As a result, there is a lack\nof appropriate training datasets for text-to-video models. To address this\nproblem, we present VidGen-1M, a superior training dataset for text-to-video\nmodels. Produced through a coarse-to-fine curation strategy, this dataset\nguarantees high-quality videos and detailed captions with excellent temporal\nconsistency. When used to train the video generation model, this dataset has\nled to experimental results that surpass those obtained with other models.", "categories": "cs.CV", "created": "2024-08-05", "doi": null, "arxiv_id": "2408.02629"}
{"title": "Learning the Latent dynamics of Fluid flows from High-Fidelity Numerical\n  Simulations using Parsimonious Diffusion Maps", "authors": [], "abstract": "We use parsimonious diffusion maps (PDMs) to discover the latent dynamics of\nhigh-fidelity Navier-Stokes simulations with a focus on the 2D fluidic pinball\nproblem. By varying the Reynolds number, different flow regimes emerge, ranging\nfrom steady symmetric flows to quasi-periodic asymmetric and turbulence. We\nshow, that the proposed non-linear manifold learning scheme, identifies in a\ncrisp manner the expected intrinsic dimension of the underlying emerging\ndynamics over the parameter space. In particular, PDMs, estimate that the\nemergent dynamics in the oscillatory regime can be captured by just two\nvariables, while in the chaotic regime, the dominant modes are three as\nanticipated by the normal form theory. On the other hand, proper orthogonal\ndecomposition (POD)/PCA, most commonly used for dimensionality reduction in\nfluid mechanics, does not provide such a crisp separation between the dominant\nmodes. To validate the performance of PDMs, we also computed the reconstruction\nerror, by constructing a decoder using Geometric Harmonics. We show that the\nproposed scheme outperforms the POD/PCA over the whole Reynolds number range.\nThus, we believe that the proposed scheme will allow for the development of\nmore accurate reduced order models for high-fidelity fluid dynamics simulators,\nthus relaxing the curse of dimensionality in numerical analysis tasks such as\nbifurcation analysis, optimization and control.", "categories": "physics.flu-dyn cs.NA math.NA nlin.CD", "created": "2024-08-05", "doi": null, "arxiv_id": "2408.02630"}
{"title": "SEAS: Self-Evolving Adversarial Safety Optimization for Large Language\n  Models", "authors": [], "abstract": "As large language models (LLMs) continue to advance in capability and\ninfluence, ensuring their security and preventing harmful outputs has become\ncrucial. A promising approach to address these concerns involves training\nmodels to automatically generate adversarial prompts for red teaming. However,\nthe evolving subtlety of vulnerabilities in LLMs challenges the effectiveness\nof current adversarial methods, which struggle to specifically target and\nexplore the weaknesses of these models. To tackle these challenges, we\nintroduce the $\\mathbf{S}\\text{elf-}\\mathbf{E}\\text{volving\n}\\mathbf{A}\\text{dversarial }\\mathbf{S}\\text{afety }\\mathbf{(SEAS)}$\noptimization framework, which enhances security by leveraging data generated by\nthe model itself. SEAS operates through three iterative stages: Initialization,\nAttack, and Adversarial Optimization, refining both the Red Team and Target\nmodels to improve robustness and safety. This framework reduces reliance on\nmanual testing and significantly enhances the security capabilities of LLMs.\nOur contributions include a novel adversarial framework, a comprehensive safety\ndataset, and after three iterations, the Target model achieves a security level\ncomparable to GPT-4, while the Red Team model shows a marked increase in attack\nsuccess rate (ASR) against advanced models.", "categories": "cs.CL cs.AI", "created": "2024-08-05", "doi": null, "arxiv_id": "2408.02632"}
{"title": "CLVR Ordering of Transactions on AMMs", "authors": [], "abstract": "Trading on decentralized exchanges via an Automated Market Maker (AMM)\nmechanism has been massively adopted, with a daily trading volume reaching $1B.\nThis trading method has also received close attention from researchers, central\nbanks, and financial firms, who have the potential to adopt it to traditional\nfinancial markets such as foreign exchanges and stock markets. A critical\nchallenge of AMM-powered trading is that transaction order has high financial\nvalue, so a policy or method to order transactions in a \"good\" (optimal) manner\nis vital. We offer economic measures of both price stability (low volatility)\nand inequality that inform how a \"social planner\" should pick an optimal\nordering. We show that there is a trade-off between achieving price stability\nand reducing inequality, and that policymakers must choose which to prioritize.\nIn addition, picking the optimal order can often be costly, especially when\nperforming an exhaustive search over trade orderings (permutations). As an\nalternative we provide a simple algorithm, Clever Look-ahead Volatility\nReduction (CLVR). This algorithm constructs an ordering which approximately\nminimizes price volatility with a small computation cost. We also provide\ninsight into the strategy changes that may occur if traders are subject to this\nsequencing algorithm.", "categories": "cs.GT q-fin.MF q-fin.TR", "created": "2024-08-05", "doi": null, "arxiv_id": "2408.02634"}
{"title": "Interactive 3D Medical Image Segmentation with SAM 2", "authors": [], "abstract": "Interactive medical image segmentation (IMIS) has shown significant potential\nin enhancing segmentation accuracy by integrating iterative feedback from\nmedical professionals. However, the limited availability of enough 3D medical\ndata restricts the generalization and robustness of most IMIS methods. The\nSegment Anything Model (SAM), though effective for 2D images, requires\nexpensive semi-auto slice-by-slice annotations for 3D medical images. In this\npaper, we explore the zero-shot capabilities of SAM 2, the next-generation Meta\nSAM model trained on videos, for 3D medical image segmentation. By treating\nsequential 2D slices of 3D images as video frames, SAM 2 can fully\nautomatically propagate annotations from a single frame to the entire 3D\nvolume. We propose a practical pipeline for using SAM 2 in 3D medical image\nsegmentation and present key findings highlighting its efficiency and potential\nfor further optimization. Concretely, numerical experiments on the BraTS2020\nand the medical segmentation decathlon datasets demonstrate that SAM 2 still\nhas a gap with supervised methods but can narrow the gap in specific settings\nand organ types, significantly reducing the annotation burden on medical\nprofessionals. Our code will be open-sourced and available at\nhttps://github.com/Chuyun-Shen/SAM_2_Medical_3D.", "categories": "cs.CV", "created": "2024-08-05", "doi": null, "arxiv_id": "2408.02635"}
{"title": "Command-line Obfuscation Detection using Small Language Models", "authors": [], "abstract": "To avoid detection, adversaries often use command-line obfuscation. There are\nnumerous techniques of the command-line obfuscation, all designed to alter the\ncommand-line syntax without affecting its original functionality. This\nvariability forces most security solutions to create an exhaustive enumeration\nof signatures for even a single pattern. In contrast to using signatures, we\nhave implemented a scalable NLP-based detection method that leverages a\ncustom-trained, small transformer language model that can be applied to any\nsource of execution logs. The evaluation on top of real-world telemetry\ndemonstrates that our approach yields high-precision detections even on\nhigh-volume telemetry from a diverse set of environments spanning from\nuniversities and businesses to healthcare or finance. The practical value is\ndemonstrated in a case study of real-world samples detected by our model. We\nshow the model's superiority to signatures on established malware known to\nemploy obfuscation and showcase previously unseen obfuscated samples detected\nby our model.", "categories": "cs.CR cs.LG", "created": "2024-08-05", "doi": null, "arxiv_id": "2408.02637"}
{"title": "Detection of Compromised Functions in a Serverless Cloud Environment", "authors": [], "abstract": "Serverless computing is an emerging cloud paradigm with serverless functions\nat its core. While serverless environments enable software developers to focus\non developing applications without the need to actively manage the underlying\nruntime infrastructure, they open the door to a wide variety of security\nthreats that can be challenging to mitigate with existing methods. Existing\nsecurity solutions do not apply to all serverless architectures, since they\nrequire significant modifications to the serverless infrastructure or rely on\nthird-party services for the collection of more detailed data. In this paper,\nwe present an extendable serverless security threat detection model that\nleverages cloud providers' native monitoring tools to detect anomalous behavior\nin serverless applications. Our model aims to detect compromised serverless\nfunctions by identifying post-exploitation abnormal behavior related to\ndifferent types of attacks on serverless functions, and therefore, it is a last\nline of defense. Our approach is not tied to any specific serverless\napplication, is agnostic to the type of threats, and is adaptable through model\nadjustments. To evaluate our model's performance, we developed a serverless\ncybersecurity testbed in an AWS cloud environment, which includes two different\nserverless applications and simulates a variety of attack scenarios that cover\nthe main security threats faced by serverless functions. Our evaluation\ndemonstrates our model's ability to detect all implemented attacks while\nmaintaining a negligible false alarm rate.", "categories": "cs.CR cs.LG", "created": "2024-08-05", "doi": null, "arxiv_id": "2408.02641"}
{"title": "Can Reinforcement Learning Unlock the Hidden Dangers in Aligned Large\n  Language Models?", "authors": [], "abstract": "Large Language Models (LLMs) have demonstrated impressive capabilities in\nnatural language tasks, but their safety and morality remain contentious due to\ntheir training on internet text corpora. To address these concerns, alignment\ntechniques have been developed to improve the public usability and safety of\nLLMs. Yet, the potential for generating harmful content through these models\nseems to persist. This paper explores the concept of jailbreaking\nLLMs-reversing their alignment through adversarial triggers. Previous methods,\nsuch as soft embedding prompts, manually crafted prompts, and gradient-based\nautomatic prompts, have had limited success on black-box models due to their\nrequirements for model access and for producing a low variety of manually\ncrafted prompts, making them susceptible to being blocked. This paper\nintroduces a novel approach using reinforcement learning to optimize\nadversarial triggers, requiring only inference API access to the target model\nand a small surrogate model. Our method, which leverages a BERTScore-based\nreward function, enhances the transferability and effectiveness of adversarial\ntriggers on new black-box models. We demonstrate that this approach improves\nthe performance of adversarial triggers on a previously untested language\nmodel.", "categories": "cs.CL cs.AI cs.CR", "created": "2024-08-05", "doi": null, "arxiv_id": "2408.02651"}
{"title": "On Using Quasirandom Sequences in Machine Learning for Model Weight\n  Initialization", "authors": [], "abstract": "The effectiveness of training neural networks directly impacts computational\ncosts, resource allocation, and model development timelines in machine learning\napplications. An optimizer's ability to train the model adequately (in terms of\ntrained model performance) depends on the model's initial weights. Model weight\ninitialization schemes use pseudorandom number generators (PRNGs) as a source\nof randomness.\n  We investigate whether substituting PRNGs for low-discrepancy quasirandom\nnumber generators (QRNGs) -- namely Sobol' sequences -- as a source of\nrandomness for initializers can improve model performance. We examine\nMulti-Layer Perceptrons (MLP), Convolutional Neural Networks (CNN), Long\nShort-Term Memory (LSTM), and Transformer architectures trained on MNIST,\nCIFAR-10, and IMDB datasets using SGD and Adam optimizers. Our analysis uses\nten initialization schemes: Glorot, He, Lecun (both Uniform and Normal);\nOrthogonal, Random Normal, Truncated Normal, and Random Uniform. Models with\nweights set using PRNG- and QRNG-based initializers are compared pairwise for\neach combination of dataset, architecture, optimizer, and initialization\nscheme.\n  Our findings indicate that QRNG-based neural network initializers either\nreach a higher accuracy or achieve the same accuracy more quickly than\nPRNG-based initializers in 60% of the 120 experiments conducted. Thus, using\nQRNG-based initializers instead of PRNG-based initializers can speed up and\nimprove model training.", "categories": "cs.LG cs.CV", "created": "2024-08-05", "doi": null, "arxiv_id": "2408.02654"}
{"title": "Lumina-mGPT: Illuminate Flexible Photorealistic Text-to-Image Generation\n  with Multimodal Generative Pretraining", "authors": [], "abstract": "We present Lumina-mGPT, a family of multimodal autoregressive models capable\nof various vision and language tasks, particularly excelling in generating\nflexible photorealistic images from text descriptions. Unlike existing\nautoregressive image generation approaches, Lumina-mGPT employs a pretrained\ndecoder-only transformer as a unified framework for modeling multimodal token\nsequences. Our key insight is that a simple decoder-only transformer with\nmultimodal Generative PreTraining (mGPT), utilizing the next-token prediction\nobjective on massive interleaved text-image sequences, can learn broad and\ngeneral multimodal capabilities, thereby illuminating photorealistic\ntext-to-image generation. Building on these pretrained models, we propose\nFlexible Progressive Supervised Finetuning (FP-SFT) on high-quality image-text\npairs to fully unlock their potential for high-aesthetic image synthesis at any\nresolution while maintaining their general multimodal capabilities.\nFurthermore, we introduce Ominiponent Supervised Finetuning (Omni-SFT),\ntransforming Lumina-mGPT into a foundation model that seamlessly achieves\nomnipotent task unification. The resulting model demonstrates versatile\nmultimodal capabilities, including visual generation tasks like flexible\ntext-to-image generation and controllable generation, visual recognition tasks\nlike segmentation and depth estimation, and vision-language tasks like\nmultiturn visual question answering. Additionally, we analyze the differences\nand similarities between diffusion-based and autoregressive methods in a direct\ncomparison.", "categories": "cs.CV", "created": "2024-08-05", "doi": null, "arxiv_id": "2408.02657"}
{"title": "Context-aware Mamba-based Reinforcement Learning for social robot\n  navigation", "authors": [], "abstract": "Social robot navigation (SRN) is a relevant problem that involves navigating\na pedestrian-rich environment in a socially acceptable manner. It is an\nessential part of making social robots effective in pedestrian-rich settings.\nThe use cases of such robots could vary from companion robots to warehouse\nrobots to autonomous wheelchairs. In recent years, deep reinforcement learning\nhas been increasingly used in research on social robot navigation. Our work\nintroduces CAMRL (Context-Aware Mamba-based Reinforcement Learning). Mamba is a\nnew deep learning-based State Space Model (SSM) that has achieved results\ncomparable to transformers in sequencing tasks. CAMRL uses Mamba to determine\nthe robot's next action, which maximizes the value of the next state predicted\nby the neural network, enabling the robot to navigate effectively based on the\nrewards assigned. We evaluate CAMRL alongside existing solutions (CADRL,\nLSTM-RL, SARL) using a rigorous testing dataset which involves a variety of\ndensities and environment behaviors based on ORCA and SFM, thus, demonstrating\nthat CAMRL achieves higher success rates, minimizes collisions, and maintains\nsafer distances from pedestrians. This work introduces a new SRN planner,\nshowcasing the potential for deep-state space models for robot navigation.", "categories": "cs.RO cs.SY eess.SY", "created": "2024-08-05", "doi": null, "arxiv_id": "2408.02661"}
{"title": "Integrating Model-Based Footstep Planning with Model-Free Reinforcement\n  Learning for Dynamic Legged Locomotion", "authors": [], "abstract": "In this work, we introduce a control framework that combines model-based\nfootstep planning with Reinforcement Learning (RL), leveraging desired footstep\npatterns derived from the Linear Inverted Pendulum (LIP) dynamics. Utilizing\nthe LIP model, our method forward predicts robot states and determines the\ndesired foot placement given the velocity commands. We then train an RL policy\nto track the foot placements without following the full reference motions\nderived from the LIP model. This partial guidance from the physics model allows\nthe RL policy to integrate the predictive capabilities of the physics-informed\ndynamics and the adaptability characteristics of the RL controller without\noverfitting the policy to the template model. Our approach is validated on the\nMIT Humanoid, demonstrating that our policy can achieve stable yet dynamic\nlocomotion for walking and turning. We further validate the adaptability and\ngeneralizability of our policy by extending the locomotion task to unseen,\nuneven terrain. During the hardware deployment, we have achieved forward\nwalking speeds of up to 1.5 m/s on a treadmill and have successfully performed\ndynamic locomotion maneuvers such as 90-degree and 180-degree turns.", "categories": "cs.RO cs.SY eess.SY", "created": "2024-08-05", "doi": null, "arxiv_id": "2408.02662"}
{"title": "Latent-INR: A Flexible Framework for Implicit Representations of Videos\n  with Discriminative Semantics", "authors": [], "abstract": "Implicit Neural Networks (INRs) have emerged as powerful representations to\nencode all forms of data, including images, videos, audios, and scenes. With\nvideo, many INRs for video have been proposed for the compression task, and\nrecent methods feature significant improvements with respect to encoding time,\nstorage, and reconstruction quality. However, these encoded representations\nlack semantic meaning, so they cannot be used for any downstream tasks that\nrequire such properties, such as retrieval. This can act as a barrier for\nadoption of video INRs over traditional codecs as they do not offer any\nsignificant edge apart from compression. To alleviate this, we propose a\nflexible framework that decouples the spatial and temporal aspects of the video\nINR. We accomplish this with a dictionary of per-frame latents that are learned\njointly with a set of video specific hypernetworks, such that given a latent,\nthese hypernetworks can predict the INR weights to reconstruct the given frame.\nThis framework not only retains the compression efficiency, but the learned\nlatents can be aligned with features from large vision models, which grants\nthem discriminative properties. We align these latents with CLIP and show good\nperformance for both compression and video retrieval tasks. By aligning with\nVideoLlama, we are able to perform open-ended chat with our learned latents as\nthe visual inputs. Additionally, the learned latents serve as a proxy for the\nunderlying weights, allowing us perform tasks like video interpolation. These\nsemantic properties and applications, existing simultaneously with ability to\nperform compression, interpolation, and superresolution properties, are a first\nin this field of work.", "categories": "cs.CV", "created": "2024-08-05", "doi": null, "arxiv_id": "2408.02672"}
{"title": "Spatial-temporal Graph Convolutional Networks with Diversified\n  Transformation for Dynamic Graph Representation Learning", "authors": [], "abstract": "Dynamic graphs (DG) are often used to describe evolving interactions between\nnodes in real-world applications. Temporal patterns are a natural feature of\nDGs and are also key to representation learning. However, existing dynamic GCN\nmodels are mostly composed of static GCNs and sequence modules, which results\nin the separation of spatiotemporal information and cannot effectively capture\ncomplex temporal patterns in DGs. To address this problem, this study proposes\na spatial-temporal graph convolutional networks with diversified transformation\n(STGCNDT), which includes three aspects: a) constructing a unified graph tensor\nconvolutional network (GTCN) using tensor M-products without the need to\nrepresent spatiotemporal information separately; b) introducing three\ntransformation schemes in GTCN to model complex temporal patterns to aggregate\ntemporal information; and c) constructing an ensemble of diversified\ntransformation schemes to obtain higher representation capabilities. Empirical\nstudies on four DGs that appear in communication networks show that the\nproposed STGCNDT significantly outperforms state-of-the-art models in solving\nlink weight estimation tasks due to the diversified transformations.", "categories": "cs.LG cs.AI", "created": "2024-08-05", "doi": null, "arxiv_id": "2408.02704"}
{"title": "PSNE: Efficient Spectral Sparsification Algorithms for Scaling Network\n  Embedding", "authors": [], "abstract": "Network embedding has numerous practical applications and has received\nextensive attention in graph learning, which aims at mapping vertices into a\nlow-dimensional and continuous dense vector space by preserving the underlying\nstructural properties of the graph. Many network embedding methods have been\nproposed, among which factorization of the Personalized PageRank (PPR for\nshort) matrix has been empirically and theoretically well supported recently.\nHowever, several fundamental issues cannot be addressed. (1) Existing methods\ninvoke a seminal Local Push subroutine to approximate \\textit{a single} row or\ncolumn of the PPR matrix. Thus, they have to execute $n$ ($n$ is the number of\nnodes) Local Push subroutines to obtain a provable PPR matrix, resulting in\nprohibitively high computational costs for large $n$. (2) The PPR matrix has\nlimited power in capturing the structural similarity between vertices, leading\nto performance degradation. To overcome these dilemmas, we propose PSNE, an\nefficient spectral s\\textbf{P}arsification method for \\textbf{S}caling\n\\textbf{N}etwork \\textbf{E}mbedding, which can fast obtain the embedding\nvectors that retain strong structural similarities. Specifically, PSNE first\ndesigns a matrix polynomial sparser to accelerate the calculation of the PPR\nmatrix, which has a theoretical guarantee in terms of the Frobenius norm.\nSubsequently, PSNE proposes a simple but effective multiple-perspective\nstrategy to enhance further the representation power of the obtained\napproximate PPR matrix. Finally, PSNE applies a randomized singular value\ndecomposition algorithm on the sparse and multiple-perspective PPR matrix to\nget the target embedding vectors. Experimental evaluation of real-world and\nsynthetic datasets shows that our solutions are indeed more efficient,\neffective, and scalable compared with ten competitors.", "categories": "cs.LG cs.AI", "created": "2024-08-05", "doi": null, "arxiv_id": "2408.02705"}
{"title": "Bayesian Kolmogorov Arnold Networks (Bayesian_KANs): A Probabilistic\n  Approach to Enhance Accuracy and Interpretability", "authors": [], "abstract": "Because of its strong predictive skills, deep learning has emerged as an\nessential tool in many industries, including healthcare. Traditional deep\nlearning models, on the other hand, frequently lack interpretability and omit\nto take prediction uncertainty into account two crucial components of clinical\ndecision making. In order to produce explainable and uncertainty aware\npredictions, this study presents a novel framework called Bayesian Kolmogorov\nArnold Networks (BKANs), which combines the expressive capacity of Kolmogorov\nArnold Networks with Bayesian inference. We employ BKANs on two medical\ndatasets, which are widely used benchmarks for assessing machine learning\nmodels in medical diagnostics: the Pima Indians Diabetes dataset and the\nCleveland Heart Disease dataset. Our method provides useful insights into\nprediction confidence and decision boundaries and outperforms traditional deep\nlearning models in terms of prediction accuracy. Moreover, BKANs' capacity to\nrepresent aleatoric and epistemic uncertainty guarantees doctors receive more\nsolid and trustworthy decision support. Our Bayesian strategy improves the\ninterpretability of the model and considerably minimises overfitting, which is\nimportant for tiny and imbalanced medical datasets, according to experimental\nresults. We present possible expansions to further use BKANs in more\ncomplicated multimodal datasets and address the significance of these\ndiscoveries for future research in building reliable AI systems for healthcare.\nThis work paves the way for a new paradigm in deep learning model deployment in\nvital sectors where transparency and reliability are crucial.", "categories": "cs.LG cs.AI", "created": "2024-08-05", "doi": null, "arxiv_id": "2408.02706"}
{"title": "SnapE -- Training Snapshot Ensembles of Link Prediction Models", "authors": [], "abstract": "Snapshot ensembles have been widely used in various fields of prediction.\nThey allow for training an ensemble of prediction models at the cost of\ntraining a single one. They are known to yield more robust predictions by\ncreating a set of diverse base models. In this paper, we introduce an approach\nto transfer the idea of snapshot ensembles to link prediction models in\nknowledge graphs. Moreover, since link prediction in knowledge graphs is a\nsetup without explicit negative examples, we propose a novel training loop that\niteratively creates negative examples using previous snapshot models. An\nevaluation with four base models across four datasets shows that this approach\nconstantly outperforms the single model approach, while keeping the training\ntime constant.", "categories": "cs.LG cs.AI", "created": "2024-08-05", "doi": null, "arxiv_id": "2408.02707"}
{"title": "Scribble-Based Interactive Segmentation of Medical Hyperspectral Images", "authors": [], "abstract": "Hyperspectral imaging (HSI) is an advanced medical imaging modality that\ncaptures optical data across a broad spectral range, providing novel insights\ninto the biochemical composition of tissues. HSI may enable precise\ndifferentiation between various tissue types and pathologies, making it\nparticularly valuable for tumour detection, tissue classification, and disease\ndiagnosis.\n  Deep learning-based segmentation methods have shown considerable\nadvancements, offering automated and accurate results. However, these methods\nface challenges with HSI datasets due to limited annotated data and\ndiscrepancies from hardware and acquisition\ntechniques~\\cite{clancy2020surgical,studier2023heiporspectral}. Variability in\nclinical protocols also leads to different definitions of structure boundaries.\nInteractive segmentation methods, utilizing user knowledge and clinical\ninsights, can overcome these issues and achieve precise segmentation results\n\\cite{zhao2013overview}.\n  This work introduces a scribble-based interactive segmentation framework for\nmedical hyperspectral images. The proposed method utilizes deep learning for\nfeature extraction and a geodesic distance map generated from user-provided\nscribbles to obtain the segmentation results. The experiment results show that\nutilising the geodesic distance maps based on deep learning-extracted features\nachieved better segmentation results than geodesic distance maps directly\ngenerated from hyperspectral images, reconstructed RGB images, or Euclidean\ndistance maps.", "categories": "eess.IV cs.CV", "created": "2024-08-05", "doi": null, "arxiv_id": "2408.02708"}
{"title": "Enhancing Medical Learning and Reasoning Systems: A Boxology-Based\n  Comparative Analysis of Design Patterns", "authors": [], "abstract": "This study analyzes hybrid AI systems' design patterns and their\neffectiveness in clinical decision-making using the boxology framework. It\ncategorizes and copares various architectures combining machine learning and\nrule-based reasoning to provide insights into their structural foundations and\nhealthcare applications. Addressing two main questions, how to categorize these\nsystems againts established design patterns and how to extract insights through\ncomparative analysis, the study uses design patterns from software engineering\nto understand and optimize healthcare AI systems. Boxology helps identify\ncommonalities and create reusable solutions, enhancing these systems'\nscalability, reliability, and performance. Five primary architectures are\nexamined: REML, MLRB, RBML, RMLT, and PERML. Each has unique strengths and\nweaknesses, highlighting the need for tailored approaches in clinical tasks.\nREML excels in high-accuracy prediction for datasets with limited data; MLRB in\nhandling large datasets and complex data integration; RBML in explainability\nand trustworthiness; RMLT in managing high-dimensional data; and PERML, though\nlimited in analysis, shows promise in urgent care scenarios. The study\nintroduces four new patterns, creates five abstract categorization patterns,\nand refines those five further to specific systems. These contributions enhance\nBoxlogy's taxonomical organization and offer novel approaches to integrating\nexpert knowledge with machine learning. Boxology's structured, modular apporach\noffers significant advantages in developing and analyzing hybrid AI systems,\nrevealing commonalities, and promoting reusable solutions. In conclusion, this\nstudy underscores hybrid AI systems' crucial role in advancing healthcare and\nBoxology's potential to drive further innovation in AI integration, ultimately\nimproving clinical decision support and patient outcomes.", "categories": "cs.SE cs.AI", "created": "2024-08-05", "doi": null, "arxiv_id": "2408.02709"}
{"title": "RCDM: Enabling Robustness for Conditional Diffusion Model", "authors": [], "abstract": "The conditional diffusion model (CDM) enhances the standard diffusion model\nby providing more control, improving the quality and relevance of the outputs,\nand making the model adaptable to a wider range of complex tasks. However,\ninaccurate conditional inputs in the inverse process of CDM can easily lead to\ngenerating fixed errors in the neural network, which diminishes the\nadaptability of a well-trained model. The existing methods like data\naugmentation, adversarial training, robust optimization can improve the\nrobustness, while they often face challenges such as high computational\ncomplexity, limited applicability to unknown perturbations, and increased\ntraining difficulty. In this paper, we propose a lightweight solution, the\nRobust Conditional Diffusion Model (RCDM), based on control theory to\ndynamically reduce the impact of noise and significantly enhance the model's\nrobustness. RCDM leverages the collaborative interaction between two neural\nnetworks, along with optimal control strategies derived from control theory, to\noptimize the weights of two networks during the sampling process. Unlike\nconventional techniques, RCDM establishes a mathematical relationship between\nfixed errors and the weights of the two neural networks without incurring\nadditional computational overhead. Extensive experiments were conducted on\nMNIST and CIFAR-10 datasets, and the results demonstrate the effectiveness and\nadaptability of our proposed model.", "categories": "cs.LG cs.CV", "created": "2024-08-05", "doi": null, "arxiv_id": "2408.02710"}
{"title": "Text Conditioned Symbolic Drumbeat Generation using Latent Diffusion\n  Models", "authors": [], "abstract": "This study introduces a text-conditioned approach to generating drumbeats\nwith Latent Diffusion Models (LDMs). It uses informative conditioning text\nextracted from training data filenames. By pretraining a text and drumbeat\nencoder through contrastive learning within a multimodal network, aligned\nfollowing CLIP, we align the modalities of text and music closely.\nAdditionally, we examine an alternative text encoder based on multihot text\nencodings. Inspired by musics multi-resolution nature, we propose a novel LSTM\nvariant, MultiResolutionLSTM, designed to operate at various resolutions\nindependently. In common with recent LDMs in the image space, it speeds up the\ngeneration process by running diffusion in a latent space provided by a\npretrained unconditional autoencoder. We demonstrate the originality and\nvariety of the generated drumbeats by measuring distance (both over binary\npianorolls and in the latent space) versus the training dataset and among the\ngenerated drumbeats. We also assess the generated drumbeats through a listening\ntest focused on questions of quality, aptness for the prompt text, and novelty.\nWe show that the generated drumbeats are novel and apt to the prompt text, and\ncomparable in quality to those created by human musicians.", "categories": "cs.SD cs.AI cs.LG eess.AS", "created": "2024-08-05", "doi": null, "arxiv_id": "2408.02711"}
{"title": "Automatic Voice Identification after Speech Resynthesis using PPG", "authors": [], "abstract": "Speech resynthesis is a generic task for which we want to synthesize audio\nwith another audio as input, which finds applications for media monitors and\njournalists.Among different tasks addressed by speech resynthesis, voice\nconversion preserves the linguistic information while modifying the identity of\nthe speaker, and speech edition preserves the identity of the speaker but some\nwords are modified.In both cases, we need to disentangle speaker and phonetic\ncontents in intermediate representations.Phonetic PosteriorGrams (PPG) are a\nframe-level probabilistic representation of phonemes, and are usually\nconsidered speaker-independent.This paper presents a PPG-based speech\nresynthesis system.A perceptive evaluation assesses that it produces correct\naudio quality.Then, we demonstrate that an automatic speaker verification model\nis not able to recover the source speaker after re-synthesis with PPG, even\nwhen the model is trained on synthetic data.", "categories": "cs.SD cs.AI cs.NE eess.AS eess.SP", "created": "2024-08-05", "doi": null, "arxiv_id": "2408.02712"}
{"title": "A Review on Organ Deformation Modeling Approaches for Reliable Surgical\n  Navigation using Augmented Reality", "authors": [], "abstract": "Augmented Reality (AR) holds the potential to revolutionize surgical\nprocedures by allowing surgeons to visualize critical structures within the\npatient's body. This is achieved through superimposing preoperative organ\nmodels onto the actual anatomy. Challenges arise from dynamic deformations of\norgans during surgery, making preoperative models inadequate for faithfully\nrepresenting intraoperative anatomy. To enable reliable navigation in augmented\nsurgery, modeling of intraoperative deformation to obtain an accurate alignment\nof the preoperative organ model with the intraoperative anatomy is\nindispensable. Despite the existence of various methods proposed to model\nintraoperative organ deformation, there are still few literature reviews that\nsystematically categorize and summarize these approaches. This review aims to\nfill this gap by providing a comprehensive and technical-oriented overview of\nmodeling methods for intraoperative organ deformation in augmented reality in\nsurgery. Through a systematic search and screening process, 112 closely\nrelevant papers were included in this review. By presenting the current status\nof organ deformation modeling methods and their clinical applications, this\nreview seeks to enhance the understanding of organ deformation modeling in\nAR-guided surgery, and discuss the potential topics for future advancements.", "categories": "physics.med-ph cs.AI cs.HC eess.IV", "created": "2024-08-05", "doi": "10.1080/24699322.2024.2357164", "arxiv_id": "2408.02713"}
{"title": "MDM: Advancing Multi-Domain Distribution Matching for Automatic\n  Modulation Recognition Dataset Synthesis", "authors": [], "abstract": "Recently, deep learning technology has been successfully introduced into\nAutomatic Modulation Recognition (AMR) tasks. However, the success of deep\nlearning is all attributed to the training on large-scale datasets. Such a\nlarge amount of data brings huge pressure on storage, transmission and model\ntraining. In order to solve the problem of large amount of data, some\nresearchers put forward the method of data distillation, which aims to compress\nlarge training data into smaller synthetic datasets to maintain its\nperformance. While numerous data distillation techniques have been developed\nwithin the realm of image processing, the unique characteristics of signals set\nthem apart. Signals exhibit distinct features across various domains,\nnecessitating specialized approaches for their analysis and processing. To this\nend, a novel dataset distillation method--Multi-domain Distribution Matching\n(MDM) is proposed. MDM employs the Discrete Fourier Transform (DFT) to\ntranslate timedomain signals into the frequency domain, and then uses a model\nto compute distribution matching losses between the synthetic and real\ndatasets, considering both the time and frequency domains. Ultimately, these\ntwo losses are integrated to update the synthetic dataset. We conduct extensive\nexperiments on three AMR datasets. Experimental results show that, compared\nwith baseline methods, our method achieves better performance under the same\ncompression ratio. Furthermore, we conduct crossarchitecture generalization\nexperiments on several models, and the experimental results show that our\nsynthetic datasets can generalize well on other unseen models.", "categories": "cs.LG cs.AI", "created": "2024-08-05", "doi": null, "arxiv_id": "2408.02714"}
{"title": "MMIU: Multimodal Multi-image Understanding for Evaluating Large\n  Vision-Language Models", "authors": [], "abstract": "The capability to process multiple images is crucial for Large\nVision-Language Models (LVLMs) to develop a more thorough and nuanced\nunderstanding of a scene. Recent multi-image LVLMs have begun to address this\nneed. However, their evaluation has not kept pace with their development. To\nfill this gap, we introduce the Multimodal Multi-image Understanding (MMIU)\nbenchmark, a comprehensive evaluation suite designed to assess LVLMs across a\nwide range of multi-image tasks. MMIU encompasses 7 types of multi-image\nrelationships, 52 tasks, 77K images, and 11K meticulously curated\nmultiple-choice questions, making it the most extensive benchmark of its kind.\nOur evaluation of 24 popular LVLMs, including both open-source and proprietary\nmodels, reveals significant challenges in multi-image comprehension,\nparticularly in tasks involving spatial understanding. Even the most advanced\nmodels, such as GPT-4o, achieve only 55.7% accuracy on MMIU. Through\nmulti-faceted analytical experiments, we identify key performance gaps and\nlimitations, providing valuable insights for future model and data\nimprovements. We aim for MMIU to advance the frontier of LVLM research and\ndevelopment, moving us toward achieving sophisticated multimodal multi-image\nuser interactions.", "categories": "cs.CV", "created": "2024-08-05", "doi": null, "arxiv_id": "2408.02718"}
{"title": "KAN we improve on HEP classification tasks? Kolmogorov-Arnold Networks\n  applied to an LHC physics example", "authors": [], "abstract": "Recently, Kolmogorov-Arnold Networks (KANs) have been proposed as an\nalternative to multilayer perceptrons, suggesting advantages in performance and\ninterpretability. We study a typical binary event classification task in\nhigh-energy physics including high-level features and comment on the\nperformance and interpretability of KANs in this context. We find that the\nlearned activation functions of a one-layer KAN resemble the log-likelihood\nratio of the input features. In deeper KANs, the activations in the first KAN\nlayer differ from those in the one-layer KAN, which indicates that the deeper\nKANs learn more complex representations of the data. We study KANs with\ndifferent depths and widths and we compare them to multilayer perceptrons in\nterms of performance and number of trainable parameters. For the chosen\nclassification task, we do not find that KANs are more parameter efficient.\nHowever, small KANs may offer advantages in terms of interpretability that come\nat the cost of only a moderate loss in performance.", "categories": "hep-ph cs.LG hep-ex physics.data-an", "created": "2024-08-05", "doi": null, "arxiv_id": "2408.02743"}
{"title": "Decoupling methods for fluid-structure interaction with local\n  time-stepping", "authors": [], "abstract": "We introduce two global-in-time domain decomposition methods, namely the\nSteklov-Poincare method and the Robin method, for solving a fluid-structure\ninteraction system. These methods allow us to formulate the coupled system as a\nspace-time interface problem and apply iterative algorithms directly to the\nevolutionary problem. Each time-dependent subdomain problem is solved\nindependently, which enables the use of different time discretization schemes\nand time step sizes in the subsystems. This leads to an efficient way of\nsimulating time-dependent phenomena. We present numerical tests for both\nnon-physical and physical problems, with various mesh sizes and time step sizes\nto demonstrate the accuracy and efficiency of the proposed methods.", "categories": "math.NA cs.NA", "created": "2024-08-05", "doi": null, "arxiv_id": "2408.02746"}
{"title": "Privacy-Safe Iris Presentation Attack Detection", "authors": [], "abstract": "This paper proposes a framework for a privacy-safe iris presentation attack\ndetection (PAD) method, designed solely with synthetically-generated,\nidentity-leakage-free iris images. Once trained, the method is evaluated in a\nclassical way using state-of-the-art iris PAD benchmarks. We designed two\ngenerative models for the synthesis of ISO/IEC 19794-6-compliant iris images.\nThe first model synthesizes bona fide-looking samples. To avoid ``identity\nleakage,'' the generated samples that accidentally matched those used in the\nmodel's training were excluded. The second model synthesizes images of irises\nwith textured contact lenses and is conditioned by a given contact lens brand\nto have better control over textured contact lens appearance when forming the\ntraining set. Our experiments demonstrate that models trained solely on\nsynthetic data achieve a lower but still reasonable performance when compared\nto solutions trained with iris images collected from human subjects. This is\nthe first-of-its-kind attempt to use solely synthetic data to train a\nfully-functional iris PAD solution, and despite the performance gap between\nregular and the proposed methods, this study demonstrates that with the\nincreasing fidelity of generative models, creating such privacy-safe iris PAD\nmethods may be possible. The source codes and generative models trained for\nthis work are offered along with the paper.", "categories": "cs.CV eess.IV", "created": "2024-08-05", "doi": null, "arxiv_id": "2408.02750"}
{"title": "A Novel Hybrid Approach for Tornado Prediction in the United States:\n  Kalman-Convolutional BiLSTM with Multi-Head Attention", "authors": [], "abstract": "Tornadoes are among the most intense atmospheric vortex phenomena and pose\nsignificant challenges for detection and forecasting. Conventional methods,\nwhich heavily depend on ground-based observations and radar data, are limited\nby issues such as decreased accuracy over greater distances and a high rate of\nfalse positives. To address these challenges, this study utilizes the Seamless\nHybrid Scan Reflectivity (SHSR) dataset from the Multi-Radar Multi-Sensor\n(MRMS) system, which integrates data from multiple radar sources to enhance\naccuracy. A novel hybrid model, the Kalman-Convolutional BiLSTM with Multi-Head\nAttention, is introduced to improve dynamic state estimation and capture both\nspatial and temporal dependencies within the data. This model demonstrates\nsuperior performance in precision, recall, F1-Score, and accuracy compared to\nmethods such as K-Nearest Neighbors (KNN) and LightGBM. The results highlight\nthe considerable potential of advanced machine learning techniques to improve\ntornado prediction and reduce false alarm rates. Future research will focus on\nexpanding datasets, exploring innovative model architectures, and incorporating\nlarge language models (LLMs) to provide deeper insights. This research\nintroduces a novel model for tornado prediction, offering a robust framework\nfor enhancing forecasting accuracy and public safety.", "categories": "cs.LG", "created": "2024-08-05", "doi": null, "arxiv_id": "2408.02751"}
{"title": "Symmetric powers: structure, smoothability, and applications", "authors": [], "abstract": "We investigate border ranks of twisted powers of polynomials and\nsmoothability of symmetric powers of algebras. We prove that the latter are\nsmoothable. For the former, we obtain upper bounds for the border rank in\ngeneral and prove that they are optimal under mild conditions. We give\napplications to complexity theory.", "categories": "math.AG cs.CC math.AC", "created": "2024-08-05", "doi": null, "arxiv_id": "2408.02754"}
{"title": "Finite-Time Lyapunov Exponent Calculation on FPGA using High-Level\n  Synthesis Tools", "authors": [], "abstract": "As Field Programmable Gate Arrays (FPGAs) computing capabilities continue to\ngrow, also does the interest on building scientific accelerators around them.\nTools like Xilinx's High-Level Synthesis (HLS) help to bridge the gap between\ntraditional high-level languages such as C and C++, and low-level hardware\ndescription languages such as VHDL and Verilog. In this report, we study the\nimplementation of a fluid dynamics application, the Finite-Time Lyapunov\nExponent (FTLE) calculation, on FPGA using HLS. We provide speed and\nresource-consumption results for 2- and 3-dimensional cases.", "categories": "cs.AR", "created": "2024-08-05", "doi": null, "arxiv_id": "2408.02758"}
{"title": "Classification of Raw MEG/EEG Data with Detach-Rocket Ensemble: An\n  Improved ROCKET Algorithm for Multivariate Time Series Analysis", "authors": [], "abstract": "Multivariate Time Series Classification (MTSC) is a ubiquitous problem in\nscience and engineering, particularly in neuroscience, where most data\nacquisition modalities involve the simultaneous time-dependent recording of\nbrain activity in multiple brain regions. In recent years, Random Convolutional\nKernel models such as ROCKET and MiniRocket have emerged as highly effective\ntime series classification algorithms, capable of achieving state-of-the-art\naccuracy results with low computational load. Despite their success, these\ntypes of models face two major challenges when employed in neuroscience: 1)\nthey struggle to deal with high-dimensional data such as EEG and MEG, and 2)\nthey are difficult to interpret. In this work, we present a novel ROCKET-based\nalgorithm, named Detach-Rocket Ensemble, that is specifically designed to\naddress these two problems in MTSC. Our algorithm leverages pruning to provide\nan integrated estimation of channel importance, and ensembles to achieve better\naccuracy and provide a label probability. Using a synthetic multivariate time\nseries classification dataset in which we control the amount of information\ncarried by each of the channels, we first show that our algorithm is able to\ncorrectly recover the channel importance for classification. Then, using two\nreal-world datasets, a MEG dataset and an EEG dataset, we show that\nDetach-Rocket Ensemble is able to provide both interpretable channel relevance\nand competitive classification accuracy, even when applied directly to the raw\nbrain data, without the need for feature engineering.", "categories": "cs.LG cs.CE q-bio.NC stat.ML", "created": "2024-08-05", "doi": null, "arxiv_id": "2408.02760"}
{"title": "Dimensionality Reduction and Nearest Neighbors for Improving\n  Out-of-Distribution Detection in Medical Image Segmentation", "authors": [], "abstract": "Clinically deployed deep learning-based segmentation models are known to fail\non data outside of their training distributions. While clinicians review the\nsegmentations, these models tend to perform well in most instances, which could\nexacerbate automation bias. Therefore, detecting out-of-distribution images at\ninference is critical to warn the clinicians that the model likely failed. This\nwork applied the Mahalanobis distance (MD) post hoc to the bottleneck features\nof four Swin UNETR and nnU-net models that segmented the liver on T1-weighted\nmagnetic resonance imaging and computed tomography. By reducing the dimensions\nof the bottleneck features with either principal component analysis or uniform\nmanifold approximation and projection, images the models failed on were\ndetected with high performance and minimal computational load. In addition,\nthis work explored a non-parametric alternative to the MD, a k-th nearest\nneighbors distance (KNN). KNN drastically improved scalability and performance\nover MD when both were applied to raw and average-pooled bottleneck features.", "categories": "cs.CV cs.LG", "created": "2024-08-05", "doi": null, "arxiv_id": "2408.02761"}
{"title": "Learning with Adaptive Conservativeness for Distributionally Robust\n  Optimization: Incentive Design for Voltage Regulation", "authors": [], "abstract": "Information asymmetry between the Distribution System Operator (DSO) and\nDistributed Energy Resource Aggregators (DERAs) obstructs designing effective\nincentives for voltage regulation. To capture this effect, we employ a\nStackelberg game-theoretic framework, where the DSO seeks to overcome the\ninformation asymmetry and refine its incentive strategies by learning from DERA\nbehavior over multiple iterations. We introduce a model-based online learning\nalgorithm for the DSO, aimed at inferring the relationship between incentives\nand DERA responses. Given the uncertain nature of these responses, we also\npropose a distributionally robust incentive design model to control the\nprobability of voltage regulation failure and then reformulate it into a convex\nproblem. This model allows the DSO to periodically revise distribution\nassumptions on uncertain parameters in the decision model of the DERA. Finally,\nwe present a gradient-based method that permits the DSO to adaptively modify\nits conservativeness level, measured by the size of a Wasserstein metric-based\nambiguity set, according to historical voltage regulation performance. The\neffectiveness of our proposed method is demonstrated through numerical\nexperiments.", "categories": "eess.SY cs.SY", "created": "2024-08-05", "doi": null, "arxiv_id": "2408.02765"}
{"title": "ConDL: Detector-Free Dense Image Matching", "authors": [], "abstract": "In this work, we introduce a deep-learning framework designed for estimating\ndense image correspondences. Our fully convolutional model generates dense\nfeature maps for images, where each pixel is associated with a descriptor that\ncan be matched across multiple images. Unlike previous methods, our model is\ntrained on synthetic data that includes significant distortions, such as\nperspective changes, illumination variations, shadows, and specular highlights.\nUtilizing contrastive learning, our feature maps achieve greater invariance to\nthese distortions, enabling robust matching. Notably, our method eliminates the\nneed for a keypoint detector, setting it apart from many existing\nimage-matching techniques.", "categories": "cs.CV cs.LG", "created": "2024-08-05", "doi": null, "arxiv_id": "2408.02766"}
{"title": "4D-Var using Hessian approximation and backpropagation applied to\n  automatically-differentiable numerical and machine learning models", "authors": [], "abstract": "Constraining a numerical weather prediction (NWP) model with observations via\n4D variational (4D-Var) data assimilation is often difficult to implement in\npractice due to the need to develop and maintain a software-based tangent\nlinear model and adjoint model. One of the most common 4D-Var algorithms uses\nan incremental update procedure, which has been shown to be an approximation of\nthe Gauss-Newton method. Here we demonstrate that when using a forecast model\nthat supports automatic differentiation, an efficient and in some cases more\naccurate alternative approximation of the Gauss-Newton method can be applied by\ncombining backpropagation of errors with Hessian approximation. This approach\ncan be used with either a conventional numerical model implemented within a\nsoftware framework that supports automatic differentiation, or a machine\nlearning (ML) based surrogate model. We test the new approach on a variety of\nLorenz-96 and quasi-geostrophic models. The results indicate potential for a\ndeeper integration of modeling, data assimilation, and new technologies in a\nnext-generation of operational forecast systems that leverage weather models\ndesigned to support automatic differentiation.", "categories": "cs.LG math.DS physics.geo-ph", "created": "2024-08-05", "doi": null, "arxiv_id": "2408.02767"}
{"title": "Assessing the Effects of Container Handling Strategies on Enhancing\n  Freight Throughput", "authors": [], "abstract": "As global supply chains and freight volumes grow, the U.S. faces escalating\ntransportation demands. The heavy reliance on road transport, coupled with the\nunderutilization of the railway system, results in congested highways,\nprolonged transportation times, higher costs, and increased carbon emissions.\nCalifornia's San Pedro Port Complex (SPPC), the nation's busiest, incurs a\nsignificant share of these challenges. We utilize an agent-based simulation to\nreplicate real-world scenarios, focusing on the intricacies of interactions in\na modified intermodal inbound freight system for the SPPC. This involves\nrelocating container classification to potential warehouses in California,\nUtah, Arizona, and Nevada, rather than exclusively at port areas. Our primary\naim is to evaluate the proposed system's efficiency, considering cost and\nfreight throughput, while also examining the effects of workforce shortages.\nComputational analysis suggests that strategically installing intermodal\ncapabilities in select warehouses can reduce transportation costs, boost\nthroughput, and foster resour", "categories": "cs.MA cs.CY", "created": "2024-08-05", "doi": null, "arxiv_id": "2408.02768"}
{"title": "From Recognition to Prediction: Leveraging Sequence Reasoning for Action\n  Anticipation", "authors": [], "abstract": "The action anticipation task refers to predicting what action will happen\nbased on observed videos, which requires the model to have a strong ability to\nsummarize the present and then reason about the future. Experience and common\nsense suggest that there is a significant correlation between different\nactions, which provides valuable prior knowledge for the action anticipation\ntask. However, previous methods have not effectively modeled this underlying\nstatistical relationship. To address this issue, we propose a novel end-to-end\nvideo modeling architecture that utilizes attention mechanisms, named\nAnticipation via Recognition and Reasoning (ARR). ARR decomposes the action\nanticipation task into action recognition and sequence reasoning tasks, and\neffectively learns the statistical relationship between actions by next action\nprediction (NAP). In comparison to existing temporal aggregation strategies,\nARR is able to extract more effective features from observable videos to make\nmore reasonable predictions. In addition, to address the challenge of\nrelationship modeling that requires extensive training data, we propose an\ninnovative approach for the unsupervised pre-training of the decoder, which\nleverages the inherent temporal dynamics of video to enhance the reasoning\ncapabilities of the network. Extensive experiments on the Epic-kitchen-100,\nEGTEA Gaze+, and 50salads datasets demonstrate the efficacy of the proposed\nmethods. The code is available at https://github.com/linuxsino/ARR.", "categories": "cs.CV", "created": "2024-08-05", "doi": null, "arxiv_id": "2408.02769"}
{"title": "Refined Infrared Small Target Detection Scheme with Single-Point\n  Supervision", "authors": [], "abstract": "Recently, infrared small target detection with single-point supervision has\nattracted extensive attention. However, the detection accuracy of existing\nmethods has difficulty meeting actual needs. Therefore, we propose an\ninnovative refined infrared small target detection scheme with single-point\nsupervision, which has excellent segmentation accuracy and detection rate.\nSpecifically, we introduce label evolution with single point supervision\n(LESPS) framework and explore the performance of various excellent infrared\nsmall target detection networks based on this framework. Meanwhile, to improve\nthe comprehensive performance, we construct a complete post-processing\nstrategy. On the one hand, to improve the segmentation accuracy, we use a\ncombination of test-time augmentation (TTA) and conditional random field (CRF)\nfor post-processing. On the other hand, to improve the detection rate, we\nintroduce an adjustable sensitivity (AS) strategy for post-processing, which\nfully considers the advantages of multiple detection results and reasonably\nadds some areas with low confidence to the fine segmentation image in the form\nof centroid points. In addition, to further improve the performance and explore\nthe characteristics of this task, on the one hand, we construct and find that a\nmulti-stage loss is helpful for fine-grained detection. On the other hand, we\nfind that a reasonable sliding window cropping strategy for test samples has\nbetter performance for actual multi-size samples. Extensive experimental\nresults show that the proposed scheme achieves state-of-the-art (SOTA)\nperformance. Notably, the proposed scheme won the third place in the \"ICPR 2024\nResource-Limited Infrared Small Target Detection Challenge Track 1: Weakly\nSupervised Infrared Small Target Detection\".", "categories": "cs.CV", "created": "2024-08-05", "doi": null, "arxiv_id": "2408.02773"}
{"title": "DUST: A Framework for Data-Driven Density Steering", "authors": [], "abstract": "We consider the problem of data-driven stochastic optimal control of an\nunknown LTI dynamical system. Assuming the process noise is normally\ndistributed, we pose the problem of steering the state's mean and covariance to\na target normal distribution, under noisy data collected from the underlying\nsystem, a problem commonly referred to as covariance steering (CS). A novel\nframework for Data-driven Uncertainty quantification and density STeering\n(DUST) is presented that simultaneously characterizes the noise affecting the\nmeasured data and designs an optimal affine-feedback controller to steer the\ndensity of the state to a prescribed terminal value. We use both indirect and\ndirect data-driven design approaches based on the notions of persistency of\nexcitation and subspace predictors to exactly represent the mean and covariance\ndynamics of the state in terms of the data and noise realizations. Since both\nthe mean and the covariance steering sub-problems are plagued with\ndistributional uncertainty arising from noisy data collection, we first\nestimate the noise realization from this dataset and subsequently compute\ntractable upper bounds on the estimation errors. The moment steering problems\nare then solved to optimality using techniques from robust control and robust\noptimization. Lastly, we present an alternative control design approach based\non the certainty equivalence principle and interpret the problem as one of CS\nunder multiplicative uncertainties. We analyze the performance and efficacy of\neach of these data-driven approaches using a case study and compare them with\ntheir model-based counterparts.", "categories": "eess.SY cs.SY math.OC", "created": "2024-08-05", "doi": null, "arxiv_id": "2408.02777"}
{"title": "LR-Net: A Lightweight and Robust Network for Infrared Small Target\n  Detection", "authors": [], "abstract": "Limited by equipment limitations and the lack of target intrinsic features,\nexisting infrared small target detection methods have difficulty meeting actual\ncomprehensive performance requirements. Therefore, we propose an innovative\nlightweight and robust network (LR-Net), which abandons the complex structure\nand achieves an effective balance between detection accuracy and resource\nconsumption. Specifically, to ensure the lightweight and robustness, on the one\nhand, we construct a lightweight feature extraction attention (LFEA) module,\nwhich can fully extract target features and strengthen information interaction\nacross channels. On the other hand, we construct a simple refined feature\ntransfer (RFT) module. Compared with direct cross-layer connections, the RFT\nmodule can improve the network's feature refinement extraction capability with\nlittle resource consumption. Meanwhile, to solve the problem of small target\nloss in high-level feature maps, on the one hand, we propose a low-level\nfeature distribution (LFD) strategy to use low-level features to supplement the\ninformation of high-level features. On the other hand, we introduce an\nefficient simplified bilinear interpolation attention module (SBAM) to promote\nthe guidance constraints of low-level features on high-level features and the\nfusion of the two. In addition, We abandon the traditional resizing method and\nadopt a new training and inference cropping strategy, which is more robust to\ndatasets with multi-scale samples. Extensive experimental results show that our\nLR-Net achieves state-of-the-art (SOTA) performance. Notably, on the basis of\nthe proposed LR-Net, we achieve 3rd place in the \"ICPR 2024 Resource-Limited\nInfrared Small Target Detection Challenge Track 2: Lightweight Infrared Small\nTarget Detection\".", "categories": "cs.CV", "created": "2024-08-05", "doi": null, "arxiv_id": "2408.02780"}
{"title": "LLM economicus? Mapping the Behavioral Biases of LLMs via Utility Theory", "authors": [], "abstract": "Humans are not homo economicus (i.e., rational economic beings). As humans,\nwe exhibit systematic behavioral biases such as loss aversion, anchoring,\nframing, etc., which lead us to make suboptimal economic decisions. Insofar as\nsuch biases may be embedded in text data on which large language models (LLMs)\nare trained, to what extent are LLMs prone to the same behavioral biases?\nUnderstanding these biases in LLMs is crucial for deploying LLMs to support\nhuman decision-making. We propose utility theory-a paradigm at the core of\nmodern economic theory-as an approach to evaluate the economic biases of LLMs.\nUtility theory enables the quantification and comparison of economic behavior\nagainst benchmarks such as perfect rationality or human behavior. To\ndemonstrate our approach, we quantify and compare the economic behavior of a\nvariety of open- and closed-source LLMs. We find that the economic behavior of\ncurrent LLMs is neither entirely human-like nor entirely economicus-like. We\nalso find that most current LLMs struggle to maintain consistent economic\nbehavior across settings. Finally, we illustrate how our approach can measure\nthe effect of interventions such as prompting on economic biases.", "categories": "cs.CL", "created": "2024-08-05", "doi": null, "arxiv_id": "2408.02784"}
{"title": "Multi-Scale Cell Decomposition for Path Planning using Restrictive\n  Routing Potential Fields", "authors": [], "abstract": "In burgeoning domains, like urban goods distribution, the advent of aerial\ncargo transportation necessitates the development of routing solutions that\nprioritize safety. This paper introduces Larp, a novel path planning framework\nthat leverages the concept of restrictive potential fields to forge routes\ndemonstrably safer than those derived from existing methods. The algorithm\nachieves it by segmenting a potential field into a hierarchy of cells, each\nwith a designated restriction zone determined by obstacle proximity. While the\nprimary impetus behind Larp is to enhance the safety of aerial pathways for\ncargo-carrying Unmanned Aerial Vehicles (UAVs), its utility extends to a wide\narray of path planning scenarios. Comparative analyses with both established\nand contemporary potential field-based methods reveal Larp's proficiency in\nmaintaining a safe distance from restrictions and its adeptness in\ncircumventing local minima.", "categories": "cs.RO cs.SY eess.SY", "created": "2024-08-05", "doi": null, "arxiv_id": "2408.02786"}
{"title": "Segmentation Style Discovery: Application to Skin Lesion Images", "authors": [], "abstract": "Variability in medical image segmentation, arising from annotator\npreferences, expertise, and their choice of tools, has been well documented.\nWhile the majority of multi-annotator segmentation approaches focus on modeling\nannotator-specific preferences, they require annotator-segmentation\ncorrespondence. In this work, we introduce the problem of segmentation style\ndiscovery, and propose StyleSeg, a segmentation method that learns plausible,\ndiverse, and semantically consistent segmentation styles from a corpus of\nimage-mask pairs without any knowledge of annotator correspondence. StyleSeg\nconsistently outperforms competing methods on four publicly available skin\nlesion segmentation (SLS) datasets. We also curate ISIC-MultiAnnot, the largest\nmulti-annotator SLS dataset with annotator correspondence, and our results show\na strong alignment, using our newly proposed measure AS2, between the predicted\nstyles and annotator preferences. The code and the dataset are available at\nhttps://github.com/sfu-mial/StyleSeg.", "categories": "cs.CV", "created": "2024-08-05", "doi": null, "arxiv_id": "2408.02787"}
{"title": "GazeXplain: Learning to Predict Natural Language Explanations of Visual\n  Scanpaths", "authors": [], "abstract": "While exploring visual scenes, humans' scanpaths are driven by their\nunderlying attention processes. Understanding visual scanpaths is essential for\nvarious applications. Traditional scanpath models predict the where and when of\ngaze shifts without providing explanations, creating a gap in understanding the\nrationale behind fixations. To bridge this gap, we introduce GazeXplain, a\nnovel study of visual scanpath prediction and explanation. This involves\nannotating natural-language explanations for fixations across eye-tracking\ndatasets and proposing a general model with an attention-language decoder that\njointly predicts scanpaths and generates explanations. It integrates a unique\nsemantic alignment mechanism to enhance the consistency between fixations and\nexplanations, alongside a cross-dataset co-training approach for\ngeneralization. These novelties present a comprehensive and adaptable solution\nfor explainable human visual scanpath prediction. Extensive experiments on\ndiverse eye-tracking datasets demonstrate the effectiveness of GazeXplain in\nboth scanpath prediction and explanation, offering valuable insights into human\nvisual attention and cognitive processes.", "categories": "cs.CV", "created": "2024-08-05", "doi": null, "arxiv_id": "2408.02788"}
{"title": "Inferring Accumulative Effects of Higher Order Programs", "authors": [], "abstract": "Many temporal safety properties of higher-order programs go beyond simple\nevent sequencing and require an automaton register (or \"accumulator\") to\nexpress, such as input-dependency, event summation, resource usage, ensuring\nequal event magnitude, computation cost, etc. Some steps have been made towards\nverifying more basic temporal event sequences via reductions to fair\ntermination [Murase et al. 2016] or some input-dependent properties through\ndeductive proof systems [Nanjo et al. 2018]. However, there are currently no\nautomated techniques to verify the more general class of register-automaton\nsafety properties of higher-order programs.\n  We introduce an abstract interpretation-based analysis to compute dependent,\nregister-automata effects of recursive, higher-order programs. We capture\nproperties of a program's effects in terms of automata that summarizes the\nhistory of observed effects using an accumulator register. The key novelty is a\nnew abstract domain for context-dependent effects, capable of abstracting\nrelations between the program environment, the automaton control state, and the\naccumulator value. The upshot is a dataflow type and effect system that\ncomputes context-sensitive effect summaries. We demonstrate our work via a\nprototype implementation that computes dependent effect summaries (and\nvalidates assertions) for OCaml-like recursive higher order programs. As a\nbasis of comparison, we describe reductions to assertion checking for\neffect-free programs, and demonstrate that our approach outperforms prior tools\nDrift and RCaml/PCSat. Overall, across a set of 21 new benchmarks, RCaml/PCSat\ncould not verify any, Drift verified 9 benchmarks, and evDrift verified 19;\nevDrift also had a 30.5x over Drift on those benchmarks that both tools could\nsolve.", "categories": "cs.PL", "created": "2024-08-05", "doi": null, "arxiv_id": "2408.02791"}
{"title": "Lesion Elevation Prediction from Skin Images Improves Diagnosis", "authors": [], "abstract": "While deep learning-based computer-aided diagnosis for skin lesion image\nanalysis is approaching dermatologists' performance levels, there are several\nworks showing that incorporating additional features such as shape priors,\ntexture, color constancy, and illumination further improves the lesion\ndiagnosis performance. In this work, we look at another clinically useful\nfeature, skin lesion elevation, and investigate the feasibility of predicting\nand leveraging skin lesion elevation labels. Specifically, we use a deep\nlearning model to predict image-level lesion elevation labels from 2D skin\nlesion images. We test the elevation prediction accuracy on the derm7pt\ndataset, and use the elevation prediction model to estimate elevation labels\nfor images from five other datasets: ISIC 2016, 2017, and 2018 Challenge\ndatasets, MSK, and DermoFit. We evaluate cross-domain generalization by using\nthese estimated elevation labels as auxiliary inputs to diagnosis models, and\nshow that these improve the classification performance, with AUROC improvements\nof up to 6.29% and 2.69% for dermoscopic and clinical images, respectively. The\ncode is publicly available at https://github.com/sfu-mial/LesionElevation.", "categories": "cs.CV", "created": "2024-08-05", "doi": null, "arxiv_id": "2408.02792"}
{"title": "Evaluating Large Language Models for Automatic Register Transfer Logic\n  Generation via High-Level Synthesis", "authors": [], "abstract": "The ever-growing popularity of large language models (LLMs) has resulted in\ntheir increasing adoption for hardware design and verification. Prior research\nhas attempted to assess the capability of LLMs to automate digital hardware\ndesign by producing superior-quality Register Transfer Logic (RTL)\ndescriptions, particularly in Verilog. However, these tests have revealed that\nVerilog code production using LLMs at current state-of-the-art lack sufficient\nfunctional correctness to be practically viable, compared to automatic\ngeneration of programs in general-purpose programming languages such as C, C++,\nPython, etc. With this as the key insight, in this paper we assess the\nperformance of a two-stage software pipeline for automated Verilog RTL\ngeneration: LLM based automatic generation of annotated C++ code suitable for\nhigh-level synthesis (HLS), followed by HLS to generate Verilog RTL. We have\nbenchmarked the performance of our proposed scheme using the open-source\nVerilogEval dataset, for four different industry-scale LLMs, and the Vitis HLS\ntool. Our experimental results demonstrate that our two-step technique\nsubstantially outperforms previous proposed techniques of direct Verilog RTL\ngeneration by LLMs in terms of average functional correctness rates, reaching\nscore of 0.86 in pass@1 metric.", "categories": "cs.AR", "created": "2024-08-05", "doi": null, "arxiv_id": "2408.02793"}
{"title": "Entity Retrieval for Answering Entity-Centric Questions", "authors": [], "abstract": "The similarity between the question and indexed documents is a crucial factor\nin document retrieval for retrieval-augmented question answering. Although this\nis typically the only method for obtaining the relevant documents, it is not\nthe sole approach when dealing with entity-centric questions. In this study, we\npropose Entity Retrieval, a novel retrieval method which rather than relying on\nquestion-document similarity, depends on the salient entities within the\nquestion to identify the retrieval documents. We conduct an in-depth analysis\nof the performance of both dense and sparse retrieval methods in comparison to\nEntity Retrieval. Our findings reveal that our method not only leads to more\naccurate answers to entity-centric questions but also operates more\nefficiently.", "categories": "cs.IR cs.CL", "created": "2024-08-05", "doi": null, "arxiv_id": "2408.02795"}
{"title": "Gaussian Mixture based Evidential Learning for Stereo Matching", "authors": [], "abstract": "In this paper, we introduce a novel Gaussian mixture based evidential\nlearning solution for robust stereo matching. Diverging from previous\nevidential deep learning approaches that rely on a single Gaussian\ndistribution, our framework posits that individual image data adheres to a\nmixture-of-Gaussian distribution in stereo matching. This assumption yields\nmore precise pixel-level predictions and more accurately mirrors the real-world\nimage distribution. By further employing the inverse-Gamma distribution as an\nintermediary prior for each mixture component, our probabilistic model achieves\nimproved depth estimation compared to its counterpart with the single Gaussian\nand effectively captures the model uncertainty, which enables a strong\ncross-domain generation ability. We evaluated our method for stereo matching by\ntraining the model using the Scene Flow dataset and testing it on KITTI 2015\nand Middlebury 2014. The experiment results consistently show that our method\nbrings improvements over the baseline methods in a trustworthy manner. Notably,\nour approach achieved new state-of-the-art results on both the in-domain\nvalidated data and the cross-domain datasets, demonstrating its effectiveness\nand robustness in stereo matching tasks.", "categories": "cs.CV", "created": "2024-08-05", "doi": null, "arxiv_id": "2408.02796"}
{"title": "Algorithm-Informed Graph Neural Networks for Leakage Detection and\n  Localization in Water Distribution Networks", "authors": [], "abstract": "Detecting and localizing leakages is a significant challenge for the\nefficient and sustainable management of water distribution networks (WDN).\nLeveraging the inherent graph structure of WDNs, recent approaches have used\ngraph-based data-driven methods. However, these methods often learn shortcuts\nthat work well with in-distribution data but fail to generalize to\nout-of-distribution data. To address this limitation and inspired by the\nperfect generalization ability of classical algorithms, we propose an\nalgorithm-informed graph neural network (AIGNN). Recognizing that WDNs function\nas flow networks, incorporating max-flow information can be beneficial for\ninferring pressures. In the proposed framework, we first train AIGNN to emulate\nthe Ford-Fulkerson algorithm for solving max-flow problems. This algorithmic\nknowledge is then transferred to address the pressure estimation problem in\nWDNs. Two AIGNNs are deployed, one to reconstruct pressure based on the current\nmeasurements, and another to predict pressure based on previous measurements.\nLeakages are detected and localized by comparing the outputs of the\nreconstructor and the predictor. By pretraining AIGNNs to reason like\nalgorithms, they are expected to extract more task-relevant and generalizable\nfeatures. Experimental results demonstrate that the proposed algorithm-informed\napproach achieves superior results with better generalization ability compared\nto GNNs that do not incorporate algorithmic knowledge.", "categories": "cs.LG", "created": "2024-08-05", "doi": null, "arxiv_id": "2408.02797"}
{"title": "Examining Gender and Power on Wikipedia Through Face and Politeness", "authors": [], "abstract": "We propose a framework for analyzing discourse by combining two\ninterdependent concepts from sociolinguistic theory: face acts and politeness.\nWhile politeness has robust existing tools and data, face acts are less\nresourced. We introduce a new corpus created by annotating Wikipedia talk pages\nwith face acts and we use this to train a face act tagger. We then employ our\nframework to study how face and politeness interact with gender and power in\ndiscussions between Wikipedia editors. Among other findings, we observe that\nfemale Wikipedians are not only more polite, which is consistent with prior\nstudies, but that this difference corresponds with significantly more language\ndirected at humbling aspects of their own face. Interestingly, the distinction\nnearly vanishes once limiting to editors with administrative power.", "categories": "cs.CL cs.AI cs.LG", "created": "2024-08-05", "doi": null, "arxiv_id": "2408.02798"}
{"title": "On Galois duality, self-orthogonality, and dual-containment of matrix\n  product codes", "authors": [], "abstract": "In recent literature, matrix product (MP) codes and their duals have gained\nsignificant attention due to their application in the construction of quantum\nstabilizer codes. In this paper, we begin with providing a formula that\ncharacterizes the Galois dual of MP codes. Using this formula, we establish the\nconditions under which MP codes are self-orthogonal and dual-containing.\nAlthough similar results may exist in the literature, the novelty and\nsuperiority of our results can be identified in the following points. Previous\nresults that characterize the duals of MP codes only apply to MP codes with an\ninvertible square defining matrix $\\mathcal{A}$. However, our characterization\napplies to MP code with any defining matrix, whether $\\mathcal{A}$ is not\nsquare or not of full row rank. Previous studies on the conditions for\nself-orthogonality or dual-containment of MP codes have assumed certain\nstructures for the product $\\mathcal{A}\\mathcal{A}^T$ or\n$\\mathcal{A}\\mathcal{A}^{\\dagger}$, such as being diagonal, anti-diagonal,\nmonomial, or partitioned Hermitian orthogonal. However, our conditions do not\nnecessitate such specific structures. Previous studies investigated MP code\nduality in the context of Euclidean and Hermitian duals; however, we\ninvestigate MP code duality in the broader context of Galois dual, with\nEuclidean and Hermitian duals acting as special cases. Finally, it is worth\nnoting that the proposed conditions for Galois self-orthogonality or\ndual-containment are both necessary and sufficient. To demonstrate the\ntheoretical results, several numerical examples with best-known parameters MP\ncodes are provided.", "categories": "cs.IT math.IT", "created": "2024-08-05", "doi": null, "arxiv_id": "2408.02799"}
{"title": "Sparse Deep Learning Models with the $\\ell_1$ Regularization", "authors": [], "abstract": "Sparse neural networks are highly desirable in deep learning in reducing its\ncomplexity. The goal of this paper is to study how choices of regularization\nparameters influence the sparsity level of learned neural networks. We first\nderive the $\\ell_1$-norm sparsity-promoting deep learning models including\nsingle and multiple regularization parameters models, from a statistical\nviewpoint. We then characterize the sparsity level of a regularized neural\nnetwork in terms of the choice of the regularization parameters. Based on the\ncharacterizations, we develop iterative algorithms for selecting regularization\nparameters so that the weight parameters of the resulting deep neural network\nenjoy prescribed sparsity levels. Numerical experiments are presented to\ndemonstrate the effectiveness of the proposed algorithms in choosing desirable\nregularization parameters and obtaining corresponding neural networks having\nboth of predetermined sparsity levels and satisfactory approximation accuracy.", "categories": "cs.LG math.OC stat.ML", "created": "2024-08-05", "doi": null, "arxiv_id": "2408.02801"}
{"title": "Deciphering Air Travel Disruptions: A Machine Learning Approach", "authors": [], "abstract": "This research investigates flight delay trends by examining factors such as\ndeparture time, airline, and airport. It employs regression machine learning\nmethods to predict the contributions of various sources to delays. Time-series\nmodels, including LSTM, Hybrid LSTM, and Bi-LSTM, are compared with baseline\nregression models such as Multiple Regression, Decision Tree Regression, Random\nForest Regression, and Neural Network. Despite considerable errors in the\nbaseline models, the study aims to identify influential features in delay\nprediction, potentially informing flight planning strategies. Unlike previous\nwork, this research focuses on regression tasks and explores the use of\ntime-series models for predicting flight delays. It offers insights into\naviation operations by independently analyzing each delay component (e.g.,\nsecurity, weather).", "categories": "cs.LG", "created": "2024-08-05", "doi": null, "arxiv_id": "2408.02802"}
{"title": "SiCo: A Size-Controllable Virtual Try-On Approach for Informed\n  Decision-Making", "authors": [], "abstract": "Virtual try-on (VTO) applications aim to improve the online shopping\nexperience by allowing users to preview garments, before making purchase\ndecisions. However, many VTO tools fail to consider the crucial relationship\nbetween a garment's size and the user's body size, often employing a\none-size-fits-all approach when visualizing a clothing item. This results in\npoor size recommendations and purchase decisions leading to increased return\nrates. To address this limitation, we introduce SiCo, an online VTO system,\nwhere users can upload images of themselves and visualize how different sizes\nof clothing would look on their body to help make better-informed purchase\ndecisions. Our user study shows SiCo's superiority over baseline VTO. The\nresults indicate that our approach significantly enhances user ability to gauge\nthe appearance of outfits on their bodies and boosts their confidence in\nselecting clothing sizes that match desired goals. Based on our evaluation, we\nbelieve our VTO design has the potential to reduce return rates and enhance the\nonline clothes shopping experience. Our code is available at\nhttps://github.com/SherryXTChen/SiCo.", "categories": "cs.HC cs.CV", "created": "2024-08-05", "doi": null, "arxiv_id": "2408.02803"}
{"title": "Numerical Instability of Algebraic Rootfinding Methods", "authors": [], "abstract": "We demonstrate that the most popular variants of all common algebraic\nmultidimensional rootfinding algorithms are unstable by analyzing the\nconditioning of subproblems that are constructed at intermediate steps. In\nparticular, we give multidimensional polynomial systems for which the\nconditioning of a subproblem can be worse than the conditioning of the original\nproblem by a factor that grows exponentially with the number of variables.", "categories": "math.NA cs.NA math.AG", "created": "2024-08-05", "doi": null, "arxiv_id": "2408.02805"}
{"title": "Optimal Gaussian Strategies for Vector-valued Witsenhausen\n  Counterexample with Non-causal State Estimator", "authors": [], "abstract": "In this study, we investigate a vector-valued Witsenhausen model where the\nsecond decision maker (DM) acquires a vector of observations before selecting a\nvector of estimations. Here, the first DM acts causally whereas the second DM\nestimates non-causally. When the vector length grows, we characterize, via a\nsingle-letter expression, the optimal trade-off between the power cost at the\nfirst DM and the estimation cost at the second DM. In this paper, we show that\nthe best linear scheme is achieved by using the time-sharing method between two\naffine strategies, which coincides with the convex envelope of the solution of\nWitsenhausen in 1968. Here also, Witsenhausen's two-point strategy and the\nscheme of Grover and Sahai in 2010 where both devices operate non-causally,\noutperform our best linear scheme. Therefore, gains obtained with block-coding\nschemes are only attainable if all DMs operate non-causally.", "categories": "math.OC cs.IT math.IT", "created": "2024-08-05", "doi": null, "arxiv_id": "2408.02807"}
{"title": "Development of REGAI: Rubric Enabled Generative Artificial Intelligence", "authors": [], "abstract": "This paper presents and evaluates a new retrieval augmented generation (RAG)\nand large language model (LLM)-based artificial intelligence (AI) technique:\nrubric enabled generative artificial intelligence (REGAI). REGAI uses rubrics,\nwhich can be created manually or automatically by the system, to enhance the\nperformance of LLMs for evaluation purposes. REGAI improves on the performance\nof both classical LLMs and RAG-based LLM techniques. This paper describes\nREGAI, presents data regarding its performance and discusses several possible\napplication areas for the technology.", "categories": "cs.AI", "created": "2024-08-05", "doi": null, "arxiv_id": "2408.02811"}
{"title": "Mitigating Malicious Attacks in Federated Learning via Confidence-aware\n  Defense", "authors": [], "abstract": "Federated Learning (FL) is an emerging distributed machine learning paradigm\nthat allows multiple clients to collaboratively train a global model without\nsharing private local data. However, FL systems are vulnerable to attacks from\nmalicious clients, who can degrade the global model performance through data\npoisoning and model poisoning. Existing defense methods typically focus on a\nsingle type of attack, such as Byzantine attacks or backdoor attacks, and are\noften ineffective against potential data poisoning attacks like label flipping\nand label shuffling. Additionally, these methods often lack accuracy and\nrobustness in detecting and handling malicious updates. To address these\nissues, we propose a novel method based on model confidence scores, which\nevaluates the uncertainty of client model updates to detect and defend against\nmalicious clients. Our approach is comprehensively effective for both model\npoisoning and data poisoning attacks and is capable of accurately identifying\nand mitigating potential malicious updates from being aggregated. Experimental\nresults demonstrate that our method significantly improves the robustness of FL\nsystems against various types of attacks, also achieving higher model accuracy\nand stability across various scenarios.", "categories": "cs.LG cs.CR cs.CV cs.DC", "created": "2024-08-05", "doi": null, "arxiv_id": "2408.02813"}
{"title": "Pre-trained Encoder Inference: Revealing Upstream Encoders In Downstream\n  Machine Learning Services", "authors": [], "abstract": "Though pre-trained encoders can be easily accessed online to build downstream\nmachine learning (ML) services quickly, various attacks have been designed to\ncompromise the security and privacy of these encoders. While most attacks\ntarget encoders on the upstream side, it remains unknown how an encoder could\nbe threatened when deployed in a downstream ML service. This paper unveils a\nnew vulnerability: the Pre-trained Encoder Inference (PEI) attack, which posts\nprivacy threats toward encoders hidden behind downstream ML services. By only\nproviding API accesses to a targeted downstream service and a set of candidate\nencoders, the PEI attack can infer which encoder is secretly used by the\ntargeted service based on candidate ones. We evaluate the attack performance of\nPEI against real-world encoders on three downstream tasks: image\nclassification, text classification, and text-to-image generation. Experiments\nshow that the PEI attack succeeds in revealing the hidden encoder in most cases\nand seldom makes mistakes even when the hidden encoder is not in the candidate\nset. We also conducted a case study on one of the most recent vision-language\nmodels, LLaVA, to illustrate that the PEI attack is useful in assisting other\nML attacks such as adversarial attacks. The code is available at\nhttps://github.com/fshp971/encoder-inference.", "categories": "cs.LG cs.CR", "created": "2024-08-05", "doi": null, "arxiv_id": "2408.02814"}
{"title": "Continuous Monitoring via Repeated Significance", "authors": [], "abstract": "Requiring statistical significance at multiple interim analyses to declare a\nstatistically significant result for an AB test allows less stringent\nrequirements for significance at each interim analysis. Repeated repeated\nsignificance competes well with methods built on assumptions about the test --\nassumptions that may be impossible to evaluate a priori and may require extra\ndata to evaluate empirically.\n  Instead, requiring repeated significance allows the data itself to prove\ndirectly that the required results are not due to chance alone. We explain how\nto apply tests with repeated significance to continuously monitor unbounded\ntests -- tests that do not have an a priori bound on running time or number of\nobservations. We show that it is impossible to maintain a constant requirement\nfor significance for unbounded tests, but that we can come arbitrarily close to\nthat goal.", "categories": "stat.ME cs.LG", "created": "2024-08-05", "doi": null, "arxiv_id": "2408.02821"}
{"title": "Wave-RVFL: A Randomized Neural Network Based on Wave Loss Function", "authors": [], "abstract": "The random vector functional link (RVFL) network is well-regarded for its\nstrong generalization capabilities in the field of machine learning. However,\nits inherent dependencies on the square loss function make it susceptible to\nnoise and outliers. Furthermore, the calculation of RVFL's unknown parameters\nnecessitates matrix inversion of the entire training sample, which constrains\nits scalability. To address these challenges, we propose the Wave-RVFL, an RVFL\nmodel incorporating the wave loss function. We formulate and solve the proposed\noptimization problem of the Wave-RVFL using the adaptive moment estimation\n(Adam) algorithm in a way that successfully eliminates the requirement for\nmatrix inversion and significantly enhances scalability. The Wave-RVFL exhibits\nrobustness against noise and outliers by preventing over-penalization of\ndeviations, thereby maintaining a balanced approach to managing noise and\noutliers. The proposed Wave-RVFL model is evaluated on multiple UCI datasets,\nboth with and without the addition of noise and outliers, across various\ndomains and sizes. Empirical results affirm the superior performance and\nrobustness of the Wave-RVFL compared to baseline models, establishing it as a\nhighly effective and scalable classification solution.", "categories": "cs.LG", "created": "2024-08-05", "doi": null, "arxiv_id": "2408.02824"}
{"title": "On the Variability of AI-based Software Systems Due to Environment\n  Configurations", "authors": [], "abstract": "[Context] Nowadays, many software systems include Artificial Intelligence\n(AI) components and changes in the development environment have been known to\ninduce variability in an AI-based system. [Objective] However, how an\nenvironment configuration impacts the variability of these systems is yet to be\nexplored. Understanding and quantifying the degree of variability due to such\nconfigurations can help practitioners decide the best environment configuration\nfor the most stable AI products. [Method] To achieve this goal, we performed\nexperiments with eight different combinations of three key environment\nvariables (operating system, Python version, and CPU architecture) on 30\nopen-source AI-based systems using the Travis CI platform. We evaluate\nvariability using three metrics: the output of an AI component like an ML model\n(performance), the time required to build and run a system (processing time),\nand the cost associated with building and running a system (expense). [Results]\nOur results indicate that variability exists in all three metrics; however, it\nis observed more frequently with respect to processing time and expense than\nperformance. For example, between Linux and MacOS, variabilities are observed\nin 23%, 96.67%, and 100% of the studied projects in performance, processing\ntime, and expense, respectively. [Conclusion] Our findings underscore the\nimportance of identifying the optimal combination of configuration settings to\nmitigate performance drops and reduce retraining time and cost before deploying\nan AI-based system.", "categories": "cs.SE", "created": "2024-08-05", "doi": null, "arxiv_id": "2408.02825"}
{"title": "Efficient ECC-based authentication scheme for fog-based IoT environment", "authors": [], "abstract": "The rapid growth of cloud computing and Internet of Things (IoT) applications\nfaces several threats, such as latency, security, network failure, and\nperformance. These issues are solved with the development of fog computing,\nwhich brings storage and computation closer to IoT-devices. However, there are\nseveral challenges faced by security designers, engineers, and researchers to\nsecure this environment. To ensure the confidentiality of data that passes\nbetween the connected devices, digital signature protocols have been applied to\nthe authentication of identities and messages. However, in the traditional\nmethod, a user's private key is directly stored on IoTs, so the private key may\nbe disclosed under various malicious attacks. Furthermore, these methods\nrequire a lot of energy, which drains the resources of IoT-devices. A signature\nscheme based on the elliptic curve digital signature algorithm (ECDSA) is\nproposed in this paper to improve the security of the private key and the time\ntaken for key-pair generation. ECDSA security is based on the intractability of\nthe Elliptic Curve Discrete Logarithm Problem (ECDLP), which allows one to use\nmuch smaller groups. Smaller group sizes directly translate into shorter\nsignatures, which is a crucial feature in settings where communication\nbandwidth is limited, or data transfer consumes a large amount of energy. The\nefficiency and effectiveness of ECDSA in the IoT environment are validated by\nexperimental evaluation and comparison analysis. The results indicate that, in\ncomparison to the two-party ECDSA and RSA, the proposed ECDSA decreases\ncomputation time by 65% and 87%, respectively. Additionally, as compared to\ntwo-party ECDSA and RSA, respectively, it reduces energy consumption by 77% and\n82%.", "categories": "cs.CR", "created": "2024-08-05", "doi": "10.5121/ijcnc.2023.15404", "arxiv_id": "2408.02826"}
{"title": "An asymptotic-preserving semi-Lagrangian algorithm for the anisotropic\n  heat transport equation with arbitrary magnetic fields", "authors": [], "abstract": "We extend the recently proposed semi-Lagrangian algorithm for the extremely\nanisotropic heat transport equation [Chac\\'on et al., J. Comput. Phys., 272\n(2014)] to deal with arbitrary magnetic field topologies. The original scheme\n(which showed remarkable numerical properties) was valid for the so-called\ntokamak-ordering regime, in which the magnetic field magnitude was not allowed\nto vary much along field lines. The proposed extension maintains the attractive\nfeatures of the original scheme (including the analytical Green's function,\nwhich is critical for tractability) with minor modifications, while allowing\nfor completely general magnetic fields. The accuracy and generality of the\napproach are demonstrated by numerical experiment with an analytical\nmanufactured solution.", "categories": "math.NA cs.NA physics.plasm-ph", "created": "2024-08-05", "doi": null, "arxiv_id": "2408.02829"}
{"title": "Setting the duration of online A/B experiments", "authors": [], "abstract": "In designing an online A/B experiment, it is crucial to select a sample size\nand duration that ensure the resulting confidence interval (CI) for the\ntreatment effect is the right width to detect an effect of meaningful magnitude\nwith sufficient statistical power without wasting resources. While the\nrelationship between sample size and CI width is well understood, the effect of\nexperiment duration on CI width remains less clear. This paper provides an\nanalytical formula for the width of a CI based on a ratio treatment effect\nestimator as a function of both sample size (N) and duration (T). The formula\nis derived from a mixed effects model with two variance components. One\ncomponent, referred to as the temporal variance, persists over time for\nexperiments where the same users are kept in the same experiment arm across\ndifferent days. The remaining error variance component, by contrast, decays to\nzero as T gets large. The formula we derive introduces a key parameter that we\ncall the user-specific temporal correlation (UTC), which quantifies the\nrelative sizes of the two variance components and can be estimated from\nhistorical experiments. Higher UTC indicates a slower decay in CI width over\ntime. On the other hand, when the UTC is 0 -- as for experiments where users\nshuffle in and out of the experiment across days -- the CI width decays at the\nstandard parametric 1/T rate. We also study how access to pre-period data for\nthe users in the experiment affects the CI width decay. We show our formula\nclosely explains CI widths on real A/B experiments at YouTube.", "categories": "stat.ME cs.LG", "created": "2024-08-05", "doi": null, "arxiv_id": "2408.02830"}
{"title": "Adaptive Learning for Quantum Linear Regression", "authors": [], "abstract": "The recent availability of quantum annealers as cloud-based services has\nenabled new ways to handle machine learning problems, and several relevant\nalgorithms have been adapted to run on these devices. In a recent work, linear\nregression was formulated as a quadratic binary optimization problem that can\nbe solved via quantum annealing. Although this approach promises a\ncomputational time advantage for large datasets, the quality of the solution is\nlimited by the necessary use of a precision vector, used to approximate the\nreal-numbered regression coefficients in the quantum formulation. In this work,\nwe focus on the practical challenge of improving the precision vector encoding:\ninstead of setting an array of generic values equal for all coefficients, we\nallow each one to be expressed by its specific precision, which is tuned with a\nsimple adaptive algorithm. This approach is evaluated on synthetic datasets of\nincreasing size, and linear regression is solved using the D-Wave Advantage\nquantum annealer, as well as classical solvers. To the best of our knowledge,\nthis is the largest dataset ever evaluated for linear regression on a quantum\nannealer. The results show that our formulation is able to deliver improved\nsolution quality in all instances, and could better exploit the potential of\ncurrent quantum devices.", "categories": "quant-ph cs.LG", "created": "2024-08-05", "doi": null, "arxiv_id": "2408.02833"}
{"title": "DaCapo: a modular deep learning framework for scalable 3D image\n  segmentation", "authors": [], "abstract": "DaCapo is a specialized deep learning library tailored to expedite the\ntraining and application of existing machine learning approaches on large,\nnear-isotropic image data. In this correspondence, we introduce DaCapo's unique\nfeatures optimized for this specific domain, highlighting its modular\nstructure, efficient experiment management tools, and scalable deployment\ncapabilities. We discuss its potential to improve access to large-scale,\nisotropic image segmentation and invite the community to explore and contribute\nto this open-source initiative.", "categories": "cs.CV cs.LG eess.IV q-bio.QM", "created": "2024-08-05", "doi": null, "arxiv_id": "2408.02834"}
{"title": "Interpretation of the Intent Detection Problem as Dynamics in a\n  Low-dimensional Space", "authors": [], "abstract": "Intent detection is a text classification task whose aim is to recognize and\nlabel the semantics behind a users query. It plays a critical role in various\nbusiness applications. The output of the intent detection module strongly\nconditions the behavior of the whole system. This sequence analysis task is\nmainly tackled using deep learning techniques. Despite the widespread use of\nthese techniques, the internal mechanisms used by networks to solve the problem\nare poorly understood. Recent lines of work have analyzed the computational\nmechanisms learned by RNNs from a dynamical systems perspective. In this work,\nwe investigate how different RNN architectures solve the SNIPS intent detection\nproblem. Sentences injected into trained networks can be interpreted as\ntrajectories traversing a hidden state space. This space is constrained to a\nlow-dimensional manifold whose dimensionality is related to the embedding and\nhidden layer sizes. To generate predictions, RNN steers the trajectories\ntowards concrete regions, spatially aligned with the output layer matrix rows\ndirections. Underlying the system dynamics, an unexpected fixed point topology\nhas been identified with a limited number of attractors. Our results provide\nnew insights into the inner workings of networks that solve the intent\ndetection task.", "categories": "cs.LG cs.CL stat.ML", "created": "2024-08-05", "doi": null, "arxiv_id": "2408.02838"}
{"title": "Optimizing Cox Models with Stochastic Gradient Descent: Theoretical\n  Foundations and Practical Guidances", "authors": [], "abstract": "Optimizing Cox regression and its neural network variants poses substantial\ncomputational challenges in large-scale studies. Stochastic gradient descent\n(SGD), known for its scalability in model optimization, has recently been\nadapted to optimize Cox models. Unlike its conventional application, which\ntypically targets a sum of independent individual loss, SGD for Cox models\nupdates parameters based on the partial likelihood of a subset of data. Despite\nits empirical success, the theoretical foundation for optimizing Cox partial\nlikelihood with SGD is largely underexplored. In this work, we demonstrate that\nthe SGD estimator targets an objective function that is batch-size-dependent.\nWe establish that the SGD estimator for the Cox neural network (Cox-NN) is\nconsistent and achieves the optimal minimax convergence rate up to a\npolylogarithmic factor. For Cox regression, we further prove the\n$\\sqrt{n}$-consistency and asymptotic normality of the SGD estimator, with\nvariance depending on the batch size. Furthermore, we quantify the impact of\nbatch size on Cox-NN training and its effect on the SGD estimator's asymptotic\nefficiency in Cox regression. These findings are validated by extensive\nnumerical experiments and provide guidance for selecting batch sizes in SGD\napplications. Finally, we demonstrate the effectiveness of SGD in a real-world\napplication where GD is unfeasible due to the large scale of data.", "categories": "stat.ML cs.LG", "created": "2024-08-05", "doi": null, "arxiv_id": "2408.02839"}
{"title": "GAReT: Cross-view Video Geolocalization with Adapters and\n  Auto-Regressive Transformers", "authors": [], "abstract": "Cross-view video geo-localization (CVGL) aims to derive GPS trajectories from\nstreet-view videos by aligning them with aerial-view images. Despite their\npromising performance, current CVGL methods face significant challenges. These\nmethods use camera and odometry data, typically absent in real-world scenarios.\nThey utilize multiple adjacent frames and various encoders for feature\nextraction, resulting in high computational costs. Moreover, these approaches\nindependently predict each street-view frame's location, resulting in\ntemporally inconsistent GPS trajectories. To address these challenges, in this\nwork, we propose GAReT, a fully transformer-based method for CVGL that does not\nrequire camera and odometry data. We introduce GeoAdapter, a\ntransformer-adapter module designed to efficiently aggregate image-level\nrepresentations and adapt them for video inputs. Specifically, we train a\ntransformer encoder on video frames and aerial images, then freeze the encoder\nto optimize the GeoAdapter module to obtain video-level representation. To\naddress temporally inconsistent trajectories, we introduce TransRetriever, an\nencoder-decoder transformer model that predicts GPS locations of street-view\nframes by encoding top-k nearest neighbor predictions per frame and\nauto-regressively decoding the best neighbor based on the previous frame's\npredictions. Our method's effectiveness is validated through extensive\nexperiments, demonstrating state-of-the-art performance on benchmark datasets.\nOur code is available at https://github.com/manupillai308/GAReT.", "categories": "cs.CV", "created": "2024-08-05", "doi": null, "arxiv_id": "2408.02840"}
{"title": "Evaluating Posterior Probabilities: Decision Theory, Proper Scoring\n  Rules, and Calibration", "authors": [], "abstract": "Most machine learning classifiers are designed to output posterior\nprobabilities for the classes given the input sample. These probabilities may\nbe used to make the categorical decision on the class of the sample; provided\nas input to a downstream system; or provided to a human for interpretation.\nEvaluating the quality of the posteriors generated by these system is an\nessential problem which was addressed decades ago with the invention of proper\nscoring rules (PSRs). Unfortunately, much of the recent machine learning\nliterature uses calibration metrics -- most commonly, the expected calibration\nerror (ECE) -- as a proxy to assess posterior performance. The problem with\nthis approach is that calibration metrics reflect only one aspect of the\nquality of the posteriors, ignoring the discrimination performance. For this\nreason, we argue that calibration metrics should play no role in the assessment\nof posterior quality. Expected PSRs should instead be used for this job,\npreferably normalized for ease of interpretation. In this work, we first give a\nbrief review of PSRs from a practical perspective, motivating their definition\nusing Bayes decision theory. We discuss why expected PSRs provide a principled\nmeasure of the quality of a system's posteriors and why calibration metrics are\nnot the right tool for this job. We argue that calibration metrics, while not\nuseful for performance assessment, may be used as diagnostic tools during\nsystem development. With this purpose in mind, we discuss a simple and\npractical calibration metric, called calibration loss, derived from a\ndecomposition of expected PSRs. We compare this metric with the ECE and with\nthe expected score divergence calibration metric from the PSR literature and\nargue, using theoretical and empirical evidence, that calibration loss is\nsuperior to these two metrics.", "categories": "stat.ML cs.LG", "created": "2024-08-05", "doi": null, "arxiv_id": "2408.02841"}
{"title": "Heterogeneous graph attention network improves cancer multiomics\n  integration", "authors": [], "abstract": "The increase in high-dimensional multiomics data demands advanced integration\nmodels to capture the complexity of human diseases. Graph-based deep learning\nintegration models, despite their promise, struggle with small patient cohorts\nand high-dimensional features, often applying independent feature selection\nwithout modeling relationships among omics. Furthermore, conventional\ngraph-based omics models focus on homogeneous graphs, lacking multiple types of\nnodes and edges to capture diverse structures. We introduce a Heterogeneous\nGraph ATtention network for omics integration (HeteroGATomics) to improve\ncancer diagnosis. HeteroGATomics performs joint feature selection through a\nmulti-agent system, creating dedicated networks of feature and patient\nsimilarity for each omic modality. These networks are then combined into one\nheterogeneous graph for learning holistic omic-specific representations and\nintegrating predictions across modalities. Experiments on three cancer\nmultiomics datasets demonstrate HeteroGATomics' superior performance in cancer\ndiagnosis. Moreover, HeteroGATomics enhances interpretability by identifying\nimportant biomarkers contributing to the diagnosis outcomes.", "categories": "cs.LG cs.MA q-bio.BM q-bio.GN", "created": "2024-08-05", "doi": null, "arxiv_id": "2408.02845"}
{"title": "Less Is More: A Mixed-Methods Study on Security-Sensitive API Calls in\n  Java for Better Dependency Selection", "authors": [], "abstract": "Security sensitive APIs provide access to security-sensitive resources, e.g.,\nthe filesystem or network resources. Including such API calls -- directly or\nthrough dependencies -- increases the application's attack surface. An example\nof such a phenomenon is Log4Shell, which rendered many applications vulnerable\ndue to network-related capabilities (JNDI lookup) in log4j package. Before the\nLog4Shell incident, alternate logging libraries to log4j were available that do\nnot make JNDI lookup calls. The impact of such an incident would be minimal if\ninformation about network-related API calls by logging libraries were available\nto the developers. And so the lack of visibility into the calls to these\nsecurity sensitive APIs by functionally similar open-source packages makes it\ndifficult for developers to use them as a dependency selection criterion. The\ngoal of this study is to aid developers in selecting their dependency by\nunderstanding security sensitive APIs in their dependency through call graph\nanalysis. We conducted a mixed-methods study with 45 Java packages and defined\na list of 219 security sensitive APIs. We then used call graph analysis to\nanalyze the prevalence of these APIs in our selected package versions, with and\nwithout their dependencies. Finally, we conducted a survey with open-source\ndevelopers (110 respondents) showing the comparison of functionally similar\npackages w.r.t. Security sensitive API calls to understand the usefulness of\nthis API information in the dependency selection process. The number of\nSecurity sensitive API calls of functionally similar packages can vary from 0\nto 368 in one API category and 0 to 429 in total. Our survey results show that\n73% developers agree that information about the number and type of\nsecurity-sensitive API calls of functionally similar packages would have been\nuseful in their dependency selection.", "categories": "cs.CR cs.SE", "created": "2024-08-05", "doi": null, "arxiv_id": "2408.02846"}
{"title": "Active Learning for WBAN-based Health Monitoring", "authors": [], "abstract": "We consider a novel active learning problem motivated by the need of learning\nmachine learning models for health monitoring in wireless body area network\n(WBAN). Due to the limited resources at body sensors, collecting each unlabeled\nsample in WBAN incurs a nontrivial cost. Moreover, training health monitoring\nmodels typically requires labels indicating the patient's health state that\nneed to be generated by healthcare professionals, which cannot be obtained at\nthe same pace as data collection. These challenges make our problem\nfundamentally different from classical active learning, where unlabeled samples\nare free and labels can be queried in real time. To handle these challenges, we\npropose a two-phased active learning method, consisting of an online phase\nwhere a coreset construction algorithm is proposed to select a subset of\nunlabeled samples based on their noisy predictions, and an offline phase where\nthe selected samples are labeled to train the target model. The samples\nselected by our algorithm are proved to yield a guaranteed error in\napproximating the full dataset in evaluating the loss function. Our evaluation\nbased on real health monitoring data and our own experimentation demonstrates\nthat our solution can drastically save the data curation cost without\nsacrificing the quality of the target model.", "categories": "cs.LG cs.NI", "created": "2024-08-05", "doi": null, "arxiv_id": "2408.02849"}
{"title": "Usability of back support, shoulder support and sit-stand passive\n  occupational exoskeletons: A heuristic evaluation of the designs", "authors": [], "abstract": "Occupational exoskeletons promise to alleviate musculoskeletal injuries among\nindustrial workers. Knowledge of the usability of the exoskeleton designs with\nrespect to the user device interaction points, and the problems in design\nfeatures, functions and parts, evaluated and rated using design principles is\nstill limited. Further, the usability of exoskeletons when assembling, donning,\ndoffing and disassembling them, tasks that can be considered pre and post use\ntasks are also critical to evaluate, especially from a device design\nstandpoint. We conducted a heuristic evaluation of the usability of three\npopular exoskeletons, a back support device, a shoulder support device, and a\nsit stand exoskeleton when assembling, donning, doffing and disassembling them.\nSeven evaluators used Nielsen and Shneiderman usability heuristics to evaluate\nthe devices. Results indicate that none of the three exoskeletons had any\ncatastrophic usability problems, but all three had major usability problems\nincluding accommodating diverse users, the assembly, donning and doffing being\na two person operation, poor documentation, a lack of sequence indicators\nduring assembly of the devices, presence of safety hazards while donning and\ndoffing the devices, and manual strength requirements. Further, the assembly\ntask is the most difficult task resulting in the most violations of usability\nheuristics. The exoskeleton human factors research community should include\ndiverse users in their evaluations and conduct usability, accessibility, and\nsafety evaluations of these devices to provide design feedback to device\ndesigners.", "categories": "cs.HC", "created": "2024-08-05", "doi": null, "arxiv_id": "2408.02852"}
{"title": "Analyzing Data Efficiency and Performance of Machine Learning Algorithms\n  for Assessing Low Back Pain Physical Rehabilitation Exercises", "authors": [], "abstract": "Analyzing human motion is an active research area, with various applications.\nIn this work, we focus on human motion analysis in the context of physical\nrehabilitation using a robot coach system. Computer-aided assessment of\nphysical rehabilitation entails evaluation of patient performance in completing\nprescribed rehabilitation exercises, based on processing movement data captured\nwith a sensory system, such as RGB and RGB-D cameras. As 2D and 3D human pose\nestimation from RGB images had made impressive improvements, we aim to compare\nthe assessment of physical rehabilitation exercises using movement data\nobtained from both RGB-D camera (Microsoft Kinect) and estimation from RGB\nvideos (OpenPose and BlazePose algorithms). A Gaussian Mixture Model (GMM) is\nemployed from position (and orientation) features, with performance metrics\ndefined based on the log-likelihood values from GMM. The evaluation is\nperformed on a medical database of clinical patients carrying out low back-pain\nrehabilitation exercises, previously coached by robot Poppy.", "categories": "cs.HC cs.CV", "created": "2024-08-05", "doi": "10.1145/3568294.3580153", "arxiv_id": "2408.02855"}
{"title": "Multistain Pretraining for Slide Representation Learning in Pathology", "authors": [], "abstract": "Developing self-supervised learning (SSL) models that can learn universal and\ntransferable representations of H&E gigapixel whole-slide images (WSIs) is\nbecoming increasingly valuable in computational pathology. These models hold\nthe potential to advance critical tasks such as few-shot classification, slide\nretrieval, and patient stratification. Existing approaches for slide\nrepresentation learning extend the principles of SSL from small images (e.g.,\n224 x 224 patches) to entire slides, usually by aligning two different\naugmentations (or views) of the slide. Yet the resulting representation remains\nconstrained by the limited clinical and biological diversity of the views.\nInstead, we postulate that slides stained with multiple markers, such as\nimmunohistochemistry, can be used as different views to form a rich\ntask-agnostic training signal. To this end, we introduce Madeleine, a\nmultimodal pretraining strategy for slide representation learning. Madeleine is\ntrained with a dual global-local cross-stain alignment objective on large\ncohorts of breast cancer samples (N=4,211 WSIs across five stains) and kidney\ntransplant samples (N=12,070 WSIs across four stains). We demonstrate the\nquality of slide representations learned by Madeleine on various downstream\nevaluations, ranging from morphological and molecular classification to\nprognostic prediction, comprising 21 tasks using 7,299 WSIs from multiple\nmedical centers. Code is available at https://github.com/mahmoodlab/MADELEINE.", "categories": "eess.IV cs.AI cs.CV", "created": "2024-08-05", "doi": null, "arxiv_id": "2408.02859"}
{"title": "A Framework for Fine-Tuning LLMs using Heterogeneous Feedback", "authors": [], "abstract": "Large language models (LLMs) have been applied to a wide range of tasks,\nincluding text summarization, web navigation, and chatbots. They have\nbenefitted from supervised fine-tuning (SFT) and reinforcement learning from\nhuman feedback (RLHF) following an unsupervised pretraining. These datasets can\nbe difficult to collect, limited in scope, and vary in sample quality.\nAdditionally, datasets can vary extensively in supervision format, from\nnumerical to binary as well as multi-dimensional with many different values. We\npresent a framework for fine-tuning LLMs using heterogeneous feedback, which\nhas two main components. First, we combine the heterogeneous feedback data into\na single supervision format, compatible with methods like SFT and RLHF. Next,\ngiven this unified feedback dataset, we extract a high-quality and diverse\nsubset to obtain performance increases potentially exceeding the full dataset.\nWe conduct extensive experiments to understand the effectiveness of these\ntechniques for incorporating heterogeneous feedback, and demonstrate\nimprovements from using a high-quality and diverse subset of the data. We find\nthat our framework is able to improve models in multiple areas simultaneously,\nsuch as in instruction following and bias reduction.", "categories": "cs.CL cs.LG", "created": "2024-08-05", "doi": null, "arxiv_id": "2408.02861"}
{"title": "On The Stability of Moral Preferences: A Problem with Computational\n  Elicitation Methods", "authors": [], "abstract": "Preference elicitation frameworks feature heavily in the research on\nparticipatory ethical AI tools and provide a viable mechanism to enquire and\nincorporate the moral values of various stakeholders. As part of the\nelicitation process, surveys about moral preferences, opinions, and judgments\nare typically administered only once to each participant. This methodological\npractice is reasonable if participants' responses are stable over time such\nthat, all other relevant factors being held constant, their responses today\nwill be the same as their responses to the same questions at a later time.\nHowever, we do not know how often that is the case. It is possible that\nparticipants' true moral preferences change, are subject to temporary moods or\nwhims, or are influenced by environmental factors we don't track. If\nparticipants' moral responses are unstable in such ways, it would raise\nimportant methodological and theoretical issues for how participants' true\nmoral preferences, opinions, and judgments can be ascertained. We address this\npossibility here by asking the same survey participants the same moral\nquestions about which patient should receive a kidney when only one is\navailable ten times in ten different sessions over two weeks, varying only\npresentation order across sessions. We measured how often participants gave\ndifferent responses to simple (Study One) and more complicated (Study Two)\nrepeated scenarios. On average, the fraction of times participants changed\ntheir responses to controversial scenarios was around 10-18% across studies,\nand this instability is observed to have positive associations with response\ntime and decision-making difficulty. We discuss the implications of these\nresults for the efficacy of moral preference elicitation, highlighting the role\nof response instability in causing value misalignment between stakeholders and\nAI tools trained on their moral judgments.", "categories": "cs.CY cs.AI cs.HC", "created": "2024-08-05", "doi": null, "arxiv_id": "2408.02862"}
{"title": "VisionUnite: A Vision-Language Foundation Model for Ophthalmology\n  Enhanced with Clinical Knowledge", "authors": [], "abstract": "The need for improved diagnostic methods in ophthalmology is acute,\nespecially in the less developed regions with limited access to specialists and\nadvanced equipment. Therefore, we introduce VisionUnite, a novel\nvision-language foundation model for ophthalmology enhanced with clinical\nknowledge. VisionUnite has been pretrained on an extensive dataset comprising\n1.24 million image-text pairs, and further refined using our proposed MMFundus\ndataset, which includes 296,379 high-quality fundus image-text pairs and\n889,137 simulated doctor-patient dialogue instances. Our experiments indicate\nthat VisionUnite outperforms existing generative foundation models such as\nGPT-4V and Gemini Pro. It also demonstrates diagnostic capabilities comparable\nto junior ophthalmologists. VisionUnite performs well in various clinical\nscenarios including open-ended multi-disease diagnosis, clinical explanation,\nand patient interaction, making it a highly versatile tool for initial\nophthalmic disease screening. VisionUnite can also serve as an educational aid\nfor junior ophthalmologists, accelerating their acquisition of knowledge\nregarding both common and rare ophthalmic conditions. VisionUnite represents a\nsignificant advancement in ophthalmology, with broad implications for\ndiagnostics, medical education, and understanding of disease mechanisms.", "categories": "eess.IV cs.AI cs.CL cs.CV", "created": "2024-08-05", "doi": null, "arxiv_id": "2408.02865"}
{"title": "Designing model predictive control strategies for grid-interactive water\n  heaters for load shifting applications", "authors": [], "abstract": "Model predictive control (MPC) strategies allow residential water heaters to\nshift load in response to dynamic price signals. Crucially, the performance of\nsuch strategies is sensitive to various algorithm design choices. In this work,\nwe develop a framework for implementing model predictive controls on\nresidential water heaters for load shifting applications. We use this framework\nto analyze how four different design factors affect control performance and\nthermal comfort: (i) control model fidelity, (ii) temperature sensor\nconfiguration, (iii) water draw estimation methodology, and (iv) water draw\nforecasting methodology. We propose new methods for estimating water draw\npatterns without the use of a flow meter. MPC strategies are compared under two\ndifferent time-varying price signals through simulations using a high-fidelity\ntank model and real-world draw data. Results show that control model fidelity\nand the number of temperature sensors have the largest impact on electricity\ncosts, while the water draw forecasting methodology has a significant impact on\nthermal comfort and the frequency of runout events. Results provide practical\ninsight into effective MPC design for water heaters in home energy management\nsystems.", "categories": "eess.SY cs.SY", "created": "2024-08-05", "doi": null, "arxiv_id": "2408.02868"}
{"title": "Enabling High-Throughput Parallel I/O in Particle-in-Cell Monte Carlo\n  Simulations with openPMD and Darshan I/O Monitoring", "authors": [], "abstract": "Large-scale HPC simulations of plasma dynamics in fusion devices require\nefficient parallel I/O to avoid slowing down the simulation and to enable the\npost-processing of critical information. Such complex simulations lacking\nparallel I/O capabilities may encounter performance bottlenecks, hindering\ntheir effectiveness in data-intensive computing tasks. In this work, we focus\non introducing and enhancing the efficiency of parallel I/O operations in\nParticle-in-Cell Monte Carlo simulations. We first evaluate the scalability of\nBIT1, a massively-parallel electrostatic PIC MC code, determining its initial\nwrite throughput capabilities and performance bottlenecks using an HPC I/O\nperformance monitoring tool, Darshan. We design and develop an adaptor to the\nopenPMD I/O interface that allows us to stream PIC particle and field\ninformation to I/O using the BP4 backend, aggressively optimized for I/O\nefficiency, including the highly efficient ADIOS2 interface. Next, we explore\nadvanced optimization techniques such as data compression, aggregation, and\nLustre file striping, achieving write throughput improvements while enhancing\ndata storage efficiency. Finally, we analyze the enhanced high-throughput\nparallel I/O and storage capabilities achieved through the integration of\nopenPMD with rapid metadata extraction in BP4 format. Our study demonstrates\nthat the integration of openPMD and advanced I/O optimizations significantly\nenhances BIT1's I/O performance and storage capabilities, successfully\nintroducing high throughput parallel I/O and surpassing the capabilities of\ntraditional file I/O.", "categories": "cs.DC cs.PF physics.plasm-ph", "created": "2024-08-05", "doi": null, "arxiv_id": "2408.02869"}
{"title": "Narrowband Electromagnetic Coupling Matrix in Coupled-Resonator\n  Microwave Circuits", "authors": [], "abstract": "A novel methodology to unleash electromagnetic coupling matrix information in\ncoupled-resonator microwave circuits has been recently proposed [1]. This\ninformation is derived from Maxwell's equations and the natural language of\nelectromagnetics is employed. As a result, the coupling matrix coefficients\nstand only for electromagnetics. In this work, we enhance this approach to\nreveal valuable design information for microwave engineering, showing the\nelectromagnetic (EM) coupling among all EM resonators and ports. By the same\ntoken, the similarities with the well-known classical coupling matrix theory\nare addressed. We bridge this gap since the classical theory is the\npreferential language among microwave engineers.\n  Classical coupling matrix theory is a narrowband model for electromagnetics.\nThus, we carry out a narrowband approximation in the electromagnetic coupling\nmatrix. This makes it possible to describe the EM coupling coefficients in the\nsame framework as classical circuits. As a result, proper comparison between\nboth coupling matrices is allowed.\n  Finally, both coupling matrix approaches have a common ground, namely, get\nphysical insight and valuable information for design purposes in\ncoupled-resonator microwave circuits. However, only the electromagnetic\ncoupling matrix details all EM behavior, including parasitic and leakage\ncouplings, and the higher-order mode influence in the microwave circuit.\nSeveral microwave circuits, such as filters and diplexers, will show the\npossibilities of this new technique and its relation to classical coupling\nmatrix theory.", "categories": "eess.SY cs.SY physics.comp-ph", "created": "2024-08-05", "doi": null, "arxiv_id": "2408.02870"}
{"title": "Hide and Seek: Fingerprinting Large Language Models with Evolutionary\n  Learning", "authors": [], "abstract": "As content generated by Large Language Model (LLM) has grown exponentially,\nthe ability to accurately identify and fingerprint such text has become\nincreasingly crucial. In this work, we introduce a novel black-box approach for\nfingerprinting LLMs, achieving an impressive 72% accuracy in identifying the\ncorrect family of models (Such as Llama, Mistral, Gemma, etc) among a lineup of\nLLMs. We present an evolutionary strategy that leverages the capabilities of\none LLM to discover the most salient features for identifying other LLMs. Our\nmethod employs a unique \"Hide and Seek\" algorithm, where an Auditor LLM\ngenerates discriminative prompts, and a Detective LLM analyzes the responses to\nfingerprint the target models. This approach not only demonstrates the\nfeasibility of LLM-driven model identification but also reveals insights into\nthe semantic manifolds of different LLM families. By iteratively refining\nprompts through in-context learning, our system uncovers subtle distinctions\nbetween model outputs, providing a powerful tool for LLM analysis and\nverification. This research opens new avenues for understanding LLM behavior\nand has significant implications for model attribution, security, and the\nbroader field of AI transparency.", "categories": "cs.CR cs.AI", "created": "2024-08-05", "doi": null, "arxiv_id": "2408.02871"}
{"title": "Rate-Splitting for Joint Unicast and Multicast Transmission in LEO\n  Satellite Networks with Non-Uniform Traffic Demand", "authors": [], "abstract": "Low Earth orbit (LEO) satellite communications (SATCOM) with ubiquitous\nglobal connectivity is deemed a pivotal catalyst in advancing wireless\ncommunication systems for 5G and beyond. LEO SATCOM excels in delivering\nversatile information services across expansive areas, facilitating both\nunicast and multicast transmissions via high-speed broadband capability.\nNonetheless, given the broadband coverage of LEO SATCOM, traffic demand\ndistribution within the service area is non-uniform, and the\ntime/frequency/power resources available at LEO satellites remain significantly\nlimited. Motivated by these challenges, we propose a rate-matching framework\nfor non-orthogonal unicast and multicast (NOUM) transmission. Our approach aims\nto minimize the difference between offered rates and traffic demands for both\nunicast and multicast messages. By multiplexing unicast and multicast\ntransmissions over the same radio resource, rate-splitting multiple access\n(RSMA) is employed to manage interference between unicast and multicast\nstreams, as well as inter-user interference under imperfect channel state\ninformation at the LEO satellite. To address the formulated problems\nnon-smoothness and non-convexity, the common rate is approximated using the\nLogSumExp technique. Thereafter, we represent the common rate portion as the\nratio of the approximated function, converting the problem into an\nunconstrained form. A generalized power iteration (GPI)-based algorithm, coined\nGPI-RS-NOUM, is proposed upon this reformulation. Through comprehensive\nnumerical analysis across diverse simulation setups, we demonstrate that the\nproposed framework outperforms various benchmarks for LEO SATCOM with uneven\ntraffic demands.", "categories": "cs.IT cs.NI math.IT", "created": "2024-08-05", "doi": null, "arxiv_id": "2408.02872"}
{"title": "Elevating Software Trust: Unveiling and Quantifying the Risk Landscape", "authors": [], "abstract": "Considering the ever-evolving threat landscape and rapid changes in software\ndevelopment, we propose a risk assessment framework SRiQT (Software Risk\nQuantification through Trust). This framework is based on the necessity of a\ndynamic, data-driven, and adaptable process to quantify risk in the software\nsupply chain. Usually, when formulating such frameworks, static pre-defined\nweights are assigned to reflect the impact of each contributing parameter while\naggregating these individual parameters to compute resulting risk scores. This\nleads to inflexibility, a lack of adaptability, and reduced accuracy, making\nthem unsuitable for the changing nature of the digital world. We adopt a novel\nperspective by examining risk through the lens of trust and incorporating the\nhuman aspect. Moreover, we quantify risk associated with individual software by\nassessing and formulating risk elements quantitatively and exploring dynamic\ndata-driven weight assignment. This enhances the sensitivity of the framework\nto cater to the evolving risk factors associated with software development and\nthe different actors involved in the entire process. The devised framework is\ntested through a dataset containing 9000 samples, comprehensive scenarios,\nassessments, and expert opinions. Furthermore, a comparison between scores\ncomputed by the OpenSSF scorecard, OWASP risk calculator, and the proposed\nSRiQT framework has also been presented. The results suggest that SRiQT\nmitigates subjectivity and yields dynamic data-driven weights as well as risk\nscores.", "categories": "cs.SE", "created": "2024-08-05", "doi": null, "arxiv_id": "2408.02876"}
{"title": "Body of Her: A Preliminary Study on End-to-End Humanoid Agent", "authors": [], "abstract": "Interactive virtual humanoid agent is a crucial interface with the physical\nworld. A relatively complete humanoid agent first needs to have face and body,\nthen possess both verbal and non-verbal (such as eye contact, facial\nexpression, lip motion, gesture, and manipulation) abilities, and finally, it\nis capable of real-time duplex communication, e.g., the ability to actively\ninterrupt conversations. Most prior systems typically only consider a subset of\nthese elements, leaving a gap from realistic humanoid agent. In this work, we\npropose a real-time, duplex, interactive end-to-end network capable of modeling\nrealistic agent behaviors, including speech, full-body movements for talking,\nresponding, idling, and manipulation. This system is a multimodal model\nintegrating audio and visual inputs, extended from a pre-trained large language\nmodel (LLM). We collect approximately 200,000 hours of audio, around 130,000\nhours of video data, and about 20,000 alignment samples to build the model. The\nfinal model demonstrates capabilities that are difficult to achieve in previous\nsystems, such as generalized object manipulation. This work performs a\npreliminary exploration of the end-to-end approach in this field, aiming to\ninspire further research towards scaling up.", "categories": "cs.CV", "created": "2024-08-05", "doi": null, "arxiv_id": "2408.02879"}
{"title": "On the construction of scattering matrices for irregular or elongated\n  enclosures using Green's representation formula", "authors": [], "abstract": "Multiple scattering methods are widely used to reduce the computational\ncomplexity of acoustic or electromagnetic scattering problems when waves\npropagate through media containing many identical inclusions. Historically,\nthis numerical technique has been limited to situations in which the inclusions\n(particles) can be covered by nonoverlapping disks in two dimensions or spheres\nin three dimensions. This allows for the use of separation of variables in\ncylindrical or spherical coordinates to represent the solution to the governing\npartial differential equation. Here, we provide a more flexible approach,\napplicable to a much larger class of geometries. We use a Green's\nrepresentation formula and the associated layer potentials to construct\nincoming and outgoing solutions on rectangular enclosures. The performance and\nflexibility of the resulting scattering operator formulation in two-dimensions\nis demonstrated via several numerical examples for multi-particle scattering in\nfree space as well as in layered media. The mathematical formalism extends\ndirectly to the three dimensional case as well, and can easily be coupled with\nseveral commercial numerical PDE software packages.", "categories": "math.NA cs.NA", "created": "2024-08-05", "doi": null, "arxiv_id": "2408.02881"}
{"title": "Compromising Embodied Agents with Contextual Backdoor Attacks", "authors": [], "abstract": "Large language models (LLMs) have transformed the development of embodied\nintelligence. By providing a few contextual demonstrations, developers can\nutilize the extensive internal knowledge of LLMs to effortlessly translate\ncomplex tasks described in abstract language into sequences of code snippets,\nwhich will serve as the execution logic for embodied agents. However, this\npaper uncovers a significant backdoor security threat within this process and\nintroduces a novel method called \\method{}. By poisoning just a few contextual\ndemonstrations, attackers can covertly compromise the contextual environment of\na black-box LLM, prompting it to generate programs with context-dependent\ndefects. These programs appear logically sound but contain defects that can\nactivate and induce unintended behaviors when the operational agent encounters\nspecific triggers in its interactive environment. To compromise the LLM's\ncontextual environment, we employ adversarial in-context generation to optimize\npoisoned demonstrations, where an LLM judge evaluates these poisoned prompts,\nreporting to an additional LLM that iteratively optimizes the demonstration in\na two-player adversarial game using chain-of-thought reasoning. To enable\ncontext-dependent behaviors in downstream agents, we implement a dual-modality\nactivation strategy that controls both the generation and execution of program\ndefects through textual and visual triggers. We expand the scope of our attack\nby developing five program defect modes that compromise key aspects of\nconfidentiality, integrity, and availability in embodied agents. To validate\nthe effectiveness of our approach, we conducted extensive experiments across\nvarious tasks, including robot planning, robot manipulation, and compositional\nvisual reasoning. Additionally, we demonstrate the potential impact of our\napproach by successfully attacking real-world autonomous driving systems.", "categories": "cs.AI cs.CR cs.LG", "created": "2024-08-05", "doi": null, "arxiv_id": "2408.02882"}
{"title": "\"Sharing, Not Showing Off\": How BeReal Approaches Authentic\n  Self-Presentation on Social Media Through Its Design", "authors": [], "abstract": "Adolescents are particularly vulnerable to the pressures created by social\nmedia, such as heightened self-consciousness and the need for extensive\nself-presentation. In this study, we investigate how BeReal, a social media\nplatform designed to counter some of these pressures, influences adolescents'\nself-presentation behaviors. We interviewed 29 users aged 13-18 to understand\ntheir experiences with BeReal. We found that BeReal's design focuses on\nspontaneous sharing, including randomly timed daily notifications and\nreciprocal posting, discourages staged posts, encourages careful curation of\nthe audience, and reduces pressure on self-presentation. The space created by\nBeReal offers benefits such as validating an unfiltered life and reframing\nsocial comparison, but its approach to self-presentation is sometimes perceived\nas limited or unappealing and, at times, even toxic. Drawing on this empirical\ndata, we distill a set of design guidelines for creating platforms that support\nauthentic self-presentation online, such as scaffolding reciprocity and\nexpanding beyond spontaneous photo-sharing to allow users to more accurately\nand comfortably portray themselves.", "categories": "cs.HC cs.SI", "created": "2024-08-05", "doi": "10.1145/3686909", "arxiv_id": "2408.02883"}
{"title": "VizECGNet: Visual ECG Image Network for Cardiovascular Diseases\n  Classification with Multi-Modal Training and Knowledge Distillation", "authors": [], "abstract": "An electrocardiogram (ECG) captures the heart's electrical signal to assess\nvarious heart conditions. In practice, ECG data is stored as either digitized\nsignals or printed images. Despite the emergence of numerous deep learning\nmodels for digitized signals, many hospitals prefer image storage due to cost\nconsiderations. Recognizing the unavailability of raw ECG signals in many\nclinical settings, we propose VizECGNet, which uses only printed ECG graphics\nto determine the prognosis of multiple cardiovascular diseases. During\ntraining, cross-modal attention modules (CMAM) are used to integrate\ninformation from two modalities - image and signal, while self-modality\nattention modules (SMAM) capture inherent long-range dependencies in ECG data\nof each modality. Additionally, we utilize knowledge distillation to improve\nthe similarity between two distinct predictions from each modality stream. This\ninnovative multi-modal deep learning architecture enables the utilization of\nonly ECG images during inference. VizECGNet with image input achieves higher\nperformance in precision, recall, and F1-Score compared to signal-based ECG\nclassification models, with improvements of 3.50%, 8.21%, and 7.38%,\nrespectively.", "categories": "cs.CV cs.AI", "created": "2024-08-05", "doi": null, "arxiv_id": "2408.02888"}
{"title": "Diverse Generation while Maintaining Semantic Coordination: A\n  Diffusion-Based Data Augmentation Method for Object Detection", "authors": [], "abstract": "Recent studies emphasize the crucial role of data augmentation in enhancing\nthe performance of object detection models. However,existing methodologies\noften struggle to effectively harmonize dataset diversity with semantic\ncoordination.To bridge this gap, we introduce an innovative augmentation\ntechnique leveraging pre-trained conditional diffusion models to mediate this\nbalance. Our approach encompasses the development of a Category Affinity\nMatrix, meticulously designed to enhance dataset diversity, and a Surrounding\nRegion Alignment strategy, which ensures the preservation of semantic\ncoordination in the augmented images. Extensive experimental evaluations\nconfirm the efficacy of our method in enriching dataset diversity while\nseamlessly maintaining semantic coordination. Our method yields substantial\naverage improvements of +1.4AP, +0.9AP, and +3.4AP over existing alternatives\non three distinct object detection models, respectively.", "categories": "cs.CV", "created": "2024-08-05", "doi": null, "arxiv_id": "2408.02891"}
{"title": "A Metric Driven Approach to Mixed Precision Training", "authors": [], "abstract": "As deep learning methodologies have developed, it has been generally agreed\nthat increasing neural network size improves model quality. However, this is at\nthe expense of memory and compute requirements, which also need to be\nincreased. Various efficiency techniques have been proposed to rein in hardware\ncosts, one being the use of low precision numerics. Recent accelerators have\nintroduced several different 8-bit data types to help accommodate DNNs in terms\nof numerics. In this paper, we identify a metric driven methodology to aid in\nthe choice of numerics. We demonstrate how such a methodology can help scale\ntraining of a language representation model. The technique can be generalized\nto other model architectures.", "categories": "cs.LG cs.AI", "created": "2024-08-05", "doi": null, "arxiv_id": "2408.02897"}
{"title": "SETN: Stock Embedding Enhanced with Textual and Network Information", "authors": [], "abstract": "Stock embedding is a method for vector representation of stocks. There is a\ngrowing demand for vector representations of stock, i.e., stock embedding, in\nwealth management sectors, and the method has been applied to various tasks\nsuch as stock price prediction, portfolio optimization, and similar fund\nidentifications. Stock embeddings have the advantage of enabling the\nquantification of relative relationships between stocks, and they can extract\nuseful information from unstructured data such as text and network data. In\nthis study, we propose stock embedding enhanced with textual and network\ninformation (SETN) using a domain-adaptive pre-trained transformer-based model\nto embed textual information and a graph neural network model to grasp network\ninformation. We evaluate the performance of our proposed model on related\ncompany information extraction tasks. We also demonstrate that stock embeddings\nobtained from the proposed model perform better in creating thematic funds than\nthose obtained from baseline methods, providing a promising pathway for various\napplications in the wealth management industry.", "categories": "cs.CL cs.CE", "created": "2024-08-05", "doi": "10.1109/BigData55660.2022.10020220", "arxiv_id": "2408.02899"}
{"title": "MedTrinity-25M: A Large-scale Multimodal Dataset with Multigranular\n  Annotations for Medicine", "authors": [], "abstract": "This paper introduces MedTrinity-25M, a comprehensive, large-scale multimodal\ndataset for medicine, covering over 25 million images across 10 modalities,\nwith multigranular annotations for more than 65 diseases. These enriched\nannotations encompass both global textual information, such as disease/lesion\ntype, modality, region-specific descriptions, and inter-regional relationships,\nas well as detailed local annotations for regions of interest (ROIs), including\nbounding boxes, segmentation masks. Unlike existing approach which is limited\nby the availability of image-text pairs, we have developed the first automated\npipeline that scales up multimodal data by generating multigranular visual and\ntexual annotations (in the form of image-ROI-description triplets) without the\nneed for any paired text descriptions. Specifically, data from over 90\ndifferent sources have been collected, preprocessed, and grounded using\ndomain-specific expert models to identify ROIs related to abnormal regions. We\nthen build a comprehensive knowledge base and prompt multimodal large language\nmodels to perform retrieval-augmented generation with the identified ROIs as\nguidance, resulting in multigranular texual descriptions. Compared to existing\ndatasets, MedTrinity-25M provides the most enriched annotations, supporting a\ncomprehensive range of multimodal tasks such as captioning and report\ngeneration, as well as vision-centric tasks like classification and\nsegmentation. Pretraining on MedTrinity-25M, our model achieves\nstate-of-the-art performance on VQA-RAD and PathVQA, surpassing both multimodal\nlarge language models and other representative SoTA approaches. This dataset\ncan also be utilized to support large-scale pre-training of multimodal medical\nAI models, contributing to the development of future foundation models in the\nmedical domain.", "categories": "cs.CV", "created": "2024-08-05", "doi": null, "arxiv_id": "2408.02900"}
{"title": "Lighthouse: A User-Friendly Library for Reproducible Video Moment\n  Retrieval and Highlight Detection", "authors": [], "abstract": "We propose Lighthouse, a user-friendly library for reproducible video moment\nretrieval and highlight detection (MR-HD). Although researchers proposed\nvarious MR-HD approaches, the research community holds two main issues. The\nfirst is a lack of comprehensive and reproducible experiments across various\nmethods, datasets, and video-text features. This is because no unified training\nand evaluation codebase covers multiple settings. The second is user-unfriendly\ndesign. Because previous works use different libraries, researchers set up\nindividual environments. In addition, most works release only the training\ncodes, requiring users to implement the whole inference process of MR-HD.\nLighthouse addresses these issues by implementing a unified reproducible\ncodebase that includes six models, three features, and five datasets. In\naddition, it provides an inference API and web demo to make these methods\neasily accessible for researchers and developers. Our experiments demonstrate\nthat Lighthouse generally reproduces the reported scores in the reference\npapers. The code is available at https://github.com/line/lighthouse.", "categories": "cs.CV cs.CL cs.MM", "created": "2024-08-05", "doi": null, "arxiv_id": "2408.02901"}
{"title": "Enabling Intelligent Traffic Systems: A Deep Learning Method for\n  Accurate Arabic License Plate Recognition", "authors": [], "abstract": "This paper introduces a novel two-stage framework for accurate Egyptian\nVehicle License Plate Recognition (EVLPR). The first stage employs image\nprocessing techniques to reliably localize license plates, while the second\nstage utilizes a custom-designed deep learning model for robust Arabic\ncharacter recognition. The proposed system achieves a remarkable 99.3% accuracy\non a diverse dataset, surpassing existing approaches. Its potential\napplications extend to intelligent traffic management, including traffic\nviolation detection and parking optimization. Future research will focus on\nenhancing the system's capabilities through architectural refinements, expanded\ndatasets, and addressing system dependencies.", "categories": "cs.CV cs.AI", "created": "2024-08-05", "doi": "10.69888/FTSIN.2024.000156", "arxiv_id": "2408.02904"}
{"title": "Dual-View Pyramid Pooling in Deep Neural Networks for Improved Medical\n  Image Classification and Confidence Calibration", "authors": [], "abstract": "Spatial pooling (SP) and cross-channel pooling (CCP) operators have been\napplied to aggregate spatial features and pixel-wise features from feature maps\nin deep neural networks (DNNs), respectively. Their main goal is to reduce\ncomputation and memory overhead without visibly weakening the performance of\nDNNs. However, SP often faces the problem of losing the subtle feature\nrepresentations, while CCP has a high possibility of ignoring salient feature\nrepresentations, which may lead to both miscalibration of confidence issues and\nsuboptimal medical classification results. To address these problems, we\npropose a novel dual-view framework, the first to systematically investigate\nthe relative roles of SP and CCP by analyzing the difference between spatial\nfeatures and pixel-wise features. Based on this framework, we propose a new\npooling method, termed dual-view pyramid pooling (DVPP), to aggregate\nmulti-scale dual-view features. DVPP aims to boost both medical image\nclassification and confidence calibration performance by fully leveraging the\nmerits of SP and CCP operators from a dual-axis perspective. Additionally, we\ndiscuss how to fulfill DVPP with five parameter-free implementations. Extensive\nexperiments on six 2D/3D medical image classification tasks show that our DVPP\nsurpasses state-of-the-art pooling methods in terms of medical image\nclassification results and confidence calibration across different DNNs.", "categories": "cs.CV", "created": "2024-08-05", "doi": null, "arxiv_id": "2408.02906"}
{"title": "Leveraging Inter-Chunk Interactions for Enhanced Retrieval in Large\n  Language Model-Based Question Answering", "authors": [], "abstract": "Retrieving external knowledge and prompting large language models with\nrelevant information is an effective paradigm to enhance the performance of\nquestion-answering tasks. Previous research typically handles paragraphs from\nexternal documents in isolation, resulting in a lack of context and ambiguous\nreferences, particularly in multi-document and complex tasks. To overcome these\nchallenges, we propose a new retrieval framework IIER, that leverages\nInter-chunk Interactions to Enhance Retrieval. This framework captures the\ninternal connections between document chunks by considering three types of\ninteractions: structural, keyword, and semantic. We then construct a unified\nChunk-Interaction Graph to represent all external documents comprehensively.\nAdditionally, we design a graph-based evidence chain retriever that utilizes\nprevious paths and chunk interactions to guide the retrieval process. It\nidentifies multiple seed nodes based on the target question and iteratively\nsearches for relevant chunks to gather supporting evidence. This retrieval\nprocess refines the context and reasoning chain, aiding the large language\nmodel in reasoning and answer generation. Extensive experiments demonstrate\nthat IIER outperforms strong baselines across four datasets, highlighting its\neffectiveness in improving retrieval and reasoning capabilities.", "categories": "cs.CL", "created": "2024-08-05", "doi": null, "arxiv_id": "2408.02907"}
{"title": "Dirichlet Logistic Gaussian Processes for Evaluation of Black-Box\n  Stochastic Systems under Complex Requirements", "authors": [], "abstract": "The requirement-driven performance evaluation of a black-box cyber-physical\nsystem (CPS) that utilizes machine learning methods has proven to be an\neffective way to assess the quality of the CPS. However, the distributional\nevaluation of the performance has been poorly considered. Although many\nuncertainty estimation methods have been advocated, they have not successfully\nestimated highly complex performance distributions under small data. In this\npaper, we propose a method to distributionally evaluate the performance under\ncomplex requirements using small input-trajectory data. To handle the unknown\ncomplex probability distributions under small data, we discretize the\ncorresponding performance measure, yielding a discrete random process over an\ninput region. Then, we propose a semiparametric Bayesian model of the discrete\nprocess based on a Dirichlet random field whose parameter function is\nrepresented by multiple logistic Gaussian processes (LGPs). The Dirichlet\nposterior parameter function is estimated through the LGP posteriors in a\nreasonable and conservative fashion. We show that the proposed Bayesian model\nconverges to the true discrete random process as the number of data becomes\nlarge enough. We also empirically demonstrate the effectiveness of the proposed\nmethod by simulation.", "categories": "eess.SY cs.SY", "created": "2024-08-05", "doi": null, "arxiv_id": "2408.02908"}
{"title": "NVPC: A Transparent NVM Page Cache", "authors": [], "abstract": "Towards a compatible utilization of NVM, NVM-specialized kernel file systems\nand NVM-based disk file system accelerators have been proposed. However, these\nstudies only focus on one or several characteristics of NVM, while failing to\nexploit its best practice by putting NVM in the proper position of the whole\nstorage stack. In this paper, we present NVPC, a transparent acceleration to\nexisting kernel file systems with an NVM-enhanced page cache. The acceleration\nlies in two aspects, respectively matching the desperate needs of existing disk\nfile systems: sync writes and cache-missed operations. Besides, the fast DRAM\npage cache is preserved for cache-hit operations. For sync writes, a\nhigh-performance log-based sync absorbing area is provided to redirect data\ndestination from the slow disk to the fast NVM. Meanwhile, the byte-addressable\nfeature of NVM is used to prevent write amplification. For cache-missed\noperations, NVPC makes use of the idle space on NVM to extend the DRAM page\ncache, so that more and larger workloads can fit into the cache. NVPC is\nentirely implemented as a page cache, thus can provide efficient speed-up to\ndisk file systems with full transparency to users and full compatibility to\nlower file systems.\n  In Filebench macro-benchmarks, NVPC achieves at most 3.55x, 2.84x, and 2.64x\nfaster than NOVA, Ext-4, and SPFS. In RocksDB workloads with working set larger\nthan DRAM, NVPC achieves 1.12x, 2.59x, and 2.11x faster than NOVA, Ext-4, and\nSPFS. Meanwhile, NVPC gains positive revenue from NOVA, Ext-4, and SPFS in\n62.5% of the tested cases in our read/write/sync mixed evaluation,\ndemonstrating that NVPC is more balanced and adaptive to complex real-world\nworkloads. Experimental results also show that NVPC is the only method that\naccelerates Ext-4 in particular cases for up to 15.19x, with no slow-down to\nany other use cases.", "categories": "cs.OS", "created": "2024-08-05", "doi": null, "arxiv_id": "2408.02911"}
{"title": "VirtualNexus: Enhancing 360-Degree Video AR/VR Collaboration with\n  Environment Cutouts and Virtual Replicas", "authors": [], "abstract": "Asymmetric AR/VR collaboration systems bring a remote VR user to a local AR\nuser's physical environment, allowing them to communicate and work within a\nshared virtual/physical space. Such systems often display the remote\nenvironment through 3D reconstructions or 360-degree videos. While 360-degree\ncameras stream an environment in higher quality, they lack spatial information,\nmaking them less interactable. We present VirtualNexus, an AR/VR collaboration\nsystem that enhances 360-degree video AR/VR collaboration with environment\ncutouts and virtual replicas. VR users can define cutouts of the remote\nenvironment to interact with as a world-in-miniature, and their interactions\nare synchronized to the local AR perspective. Furthermore, AR users can rapidly\nscan and share 3D virtual replicas of physical objects using neural rendering.\nWe demonstrated our system's utility through 3 example applications and\nevaluated our system in a dyadic usability test. VirtualNexus extends the\ninteraction space of 360-degree telepresence systems, offering improved\nphysical presence, versatility, and clarity in interactions.", "categories": "cs.HC", "created": "2024-08-05", "doi": null, "arxiv_id": "2408.02914"}
{"title": "Binary Triorthogonal and CSS-T Codes for Quantum Error Correction", "authors": [], "abstract": "In this paper, we study binary triorthogonal codes and their relation to\nCSS-T quantum codes. We characterize the binary triorthogonal codes that are\nminimal or maximal with respect to the CSS-T poset, and we also study how to\nderive new triorthogonal matrices from existing ones. Given a binary\ntriorthogonal matrix, we characterize which of its equivalent matrices are also\ntriorthogonal. As a consequence, we show that a binary triorthogonal matrix\nuniquely determines the parameters of the corresponding triorthogonal quantum\ncode, meaning that any other equivalent matrix that is also triorthogonal gives\nrise to a triorthogonal quantum code with the same parameters.", "categories": "cs.IT math.IT", "created": "2024-08-05", "doi": null, "arxiv_id": "2408.02916"}
{"title": "Data Checklist: On Unit-Testing Datasets with Usable Information", "authors": [], "abstract": "Model checklists (Ribeiro et al., 2020) have emerged as a useful tool for\nunderstanding the behavior of LLMs, analogous to unit-testing in software\nengineering. However, despite datasets being a key determinant of model\nbehavior, evaluating datasets, e.g., for the existence of annotation artifacts,\nis largely done ad hoc, once a problem in model behavior has already been found\ndownstream. In this work, we take a more principled approach to unit-testing\ndatasets by proposing a taxonomy based on the V-information literature. We call\na collection of such unit tests a data checklist. Using a checklist, not only\nare we able to recover known artifacts in well-known datasets such as SNLI, but\nwe also discover previously unknown artifacts in preference datasets for LLM\nalignment. Data checklists further enable a new kind of data filtering, which\nwe use to improve the efficacy and data efficiency of preference alignment.", "categories": "cs.CL", "created": "2024-08-05", "doi": null, "arxiv_id": "2408.02919"}
{"title": "A Taxonomy of Architecture Options for Foundation Model-based Agents:\n  Analysis and Decision Model", "authors": [], "abstract": "The rapid advancement of AI technology has led to widespread applications of\nagent systems across various domains. However, the need for detailed\narchitecture design poses significant challenges in designing and operating\nthese systems. This paper introduces a taxonomy focused on the architectures of\nfoundation-model-based agents, addressing critical aspects such as functional\ncapabilities and non-functional qualities. We also discuss the operations\ninvolved in both design-time and run-time phases, providing a comprehensive\nview of architectural design and operational characteristics. By unifying and\ndetailing these classifications, our taxonomy aims to improve the design of\nfoundation-model-based agents. Additionally, the paper establishes a decision\nmodel that guides critical design and runtime decisions, offering a structured\napproach to enhance the development of foundation-model-based agents. Our\ncontributions include providing a structured architecture design option and\nguiding the development process of foundation-model-based agents, thereby\naddressing current fragmentation in the field.", "categories": "cs.SE cs.AI", "created": "2024-08-05", "doi": null, "arxiv_id": "2408.02920"}
{"title": "Interoperability and Explicable AI-based Zero-Day Attacks Detection\n  Process in Smart Community", "authors": [], "abstract": "Systems, technologies, protocols, and infrastructures all face\ninteroperability challenges. It is among the most crucial parameters to give\nreal-world effectiveness. Organizations that achieve interoperability will be\nable to identify, prevent, and provide appropriate protection on an\ninternational scale, which can be relied upon. This paper aims to explain how\nfuture technologies such as 6G mobile communication, Internet of Everything\n(IoE), Artificial Intelligence (AI), and Smart Contract embedded WPA3\nprotocol-based WiFi-8 can work together to prevent known attack vectors and\nprovide protection against zero-day attacks, thus offering intelligent\nsolutions for smart cities. The phrase zero-day refers to an attack that occurs\non the day zero of the vulnerability's disclosure to the public or vendor.\nExisting systems require an extra layer of security. In the security world,\ninteroperability enables disparate security solutions and systems to\ncollaborate seamlessly. AI improves cybersecurity by enabling improved\ncapabilities for detecting, responding, and preventing zero-day attacks. When\ninteroperability and Explainable Artificial Intelligence (XAI) are integrated\ninto cybersecurity, they form a strong protection against zero-day assaults.\nAdditionally, we evaluate a couple of parameters based on the accuracy and time\nrequired for efficiently analyzing attack patterns and anomalies.", "categories": "cs.CR", "created": "2024-08-05", "doi": null, "arxiv_id": "2408.02921"}
{"title": "Intermediate direct preference optimization", "authors": [], "abstract": "We propose the intermediate direct preference optimization (DPO) method to\ncalculate the DPO loss at selected intermediate layers as an auxiliary loss for\nfinetuning large language models (LLMs). The conventional DPO method fine-tunes\na supervised fine-tuning (SFT) model by calculating the DPO loss using logits\nfrom the final layer. In our intermediate DPO approach, DPO losses are\ncalculated using the logits from K-selected intermediate layers and averaged to\nobtain the intermediate DPO loss. For training the intermediate DPO model, the\nfinal loss is obtained by calculating the weighted sum of the DPO and\nintermediate DPO losses. During inference, the intermediate DPO model decodes\nusing the final layer logits similarly to the conventional DPO model. In\nexperiments using the ultrafeedback dataset, the performance of the\nintermediate DPO model was evaluated using GPT-4. As a result, the intermediate\nDPO model trained using the intermediate DPO loss calculated at the 22nd layer\nof a 32-layer SFT model achieved win rates of 52.5% and 67.5% against the\nconventional DPO and SFT models, respectively, demonstrating the effectiveness\nof the proposed method. Furthermore, we report the relationships among the\nposition of the selected intermediate layers, the number of layers, and\nperformance.", "categories": "cs.CL", "created": "2024-08-05", "doi": null, "arxiv_id": "2408.02923"}
{"title": "Evaluation of Segment Anything Model 2: The Role of SAM2 in the\n  Underwater Environment", "authors": [], "abstract": "With breakthroughs in large-scale modeling, the Segment Anything Model (SAM)\nand its extensions have been attempted for applications in various underwater\nvisualization tasks in marine sciences, and have had a significant impact on\nthe academic community. Recently, Meta has further developed the Segment\nAnything Model 2 (SAM2), which significantly improves running speed and\nsegmentation accuracy compared to its predecessor. This report aims to explore\nthe potential of SAM2 in marine science by evaluating it on the underwater\ninstance segmentation benchmark datasets UIIS and USIS10K. The experiments show\nthat the performance of SAM2 is extremely dependent on the type of\nuser-provided prompts. When using the ground truth bounding box as prompt, SAM2\nperformed excellently in the underwater instance segmentation domain. However,\nwhen running in automatic mode, SAM2's ability with point prompts to sense and\nsegment underwater instances is significantly degraded. It is hoped that this\npaper will inspire researchers to further explore the SAM model family in the\nunderwater domain. The results and evaluation codes in this paper are available\nat https://github.com/LiamLian0727/UnderwaterSAM2Eval.", "categories": "cs.CV", "created": "2024-08-05", "doi": null, "arxiv_id": "2408.02924"}
{"title": "A Deep Reinforcement Learning Approach for Cost Optimized Workflow\n  Scheduling in Cloud Computing Environments", "authors": [], "abstract": "Cost optimization is a common goal of workflow schedulers operating in cloud\ncomputing environments. The use of spot instances is a potential means of\nachieving this goal, as they are offered by cloud providers at discounted\nprices compared to their on-demand counterparts in exchange for reduced\nreliability. This is due to the fact that spot instances are subjected to\ninterruptions when spare computing capacity used for provisioning them is\nneeded back owing to demand variations. Also, the prices of spot instances are\nnot fixed as pricing is dependent on long term supply and demand. The\npossibility of interruptions and pricing variations associated with spot\ninstances adds a layer of uncertainty to the general problem of workflow\nscheduling across cloud computing environments. These challenges need to be\nefficiently addressed for enjoying the cost savings achievable with the use of\nspot instances without compromising the underlying business requirements. To\nthis end, in this paper we use Deep Reinforcement Learning for developing an\nautonomous agent capable of scheduling workflows in a cost efficient manner by\nusing an intelligent mix of spot and on-demand instances. The proposed solution\nis implemented in the open source container native Argo workflow engine that is\nwidely used for executing industrial workflows. The results of the experiments\ndemonstrate that the proposed scheduling method is capable of outperforming the\ncurrent benchmarks.", "categories": "cs.DC", "created": "2024-08-05", "doi": null, "arxiv_id": "2408.02926"}
{"title": "HARMONIC: Harnessing LLMs for Tabular Data Synthesis and Privacy\n  Protection", "authors": [], "abstract": "Data serves as the fundamental foundation for advancing deep learning,\nparticularly tabular data presented in a structured format, which is highly\nconducive to modeling. However, even in the era of LLM, obtaining tabular data\nfrom sensitive domains remains a challenge due to privacy or copyright\nconcerns. Hence, exploring how to effectively use models like LLMs to generate\nrealistic and privacy-preserving synthetic tabular data is urgent. In this\npaper, we take a step forward to explore LLMs for tabular data synthesis and\nprivacy protection, by introducing a new framework HARMONIC for tabular data\ngeneration and evaluation. In the tabular data generation of our framework,\nunlike previous small-scale LLM-based methods that rely on continued\npre-training, we explore the larger-scale LLMs with fine-tuning to generate\ntabular data and enhance privacy. Based on idea of the k-nearest neighbors\nalgorithm, an instruction fine-tuning dataset is constructed to inspire LLMs to\ndiscover inter-row relationships. Then, with fine-tuning, LLMs are trained to\nremember the format and connections of the data rather than the data itself,\nwhich reduces the risk of privacy leakage. In the evaluation part of our\nframework, we develop specific privacy risk metrics DLT for LLM synthetic data\ngeneration, as well as performance evaluation metrics LLE for downstream LLM\ntasks. Our experiments find that this tabular data generation framework\nachieves equivalent performance to existing methods with better privacy, which\nalso demonstrates our evaluation framework for the effectiveness of synthetic\ndata and privacy risks in LLM scenarios.", "categories": "cs.LG cs.AI cs.CL cs.CR", "created": "2024-08-05", "doi": null, "arxiv_id": "2408.02927"}
{"title": "PGB: Benchmarking Differentially Private Synthetic Graph Generation\n  Algorithms", "authors": [], "abstract": "Differentially private graph analysis is a powerful tool for deriving\ninsights from diverse graph data while protecting individual information.\nDesigning private analytic algorithms for different graph queries often\nrequires starting from scratch. In contrast, differentially private synthetic\ngraph generation offers a general paradigm that supports one-time generation\nfor multiple queries. Although a rich set of differentially private graph\ngeneration algorithms has been proposed, comparing them effectively remains\nchallenging due to various factors, including differing privacy definitions,\ndiverse graph datasets, varied privacy requirements, and multiple utility\nmetrics.\n  To this end, we propose PGB (Private Graph Benchmark), a comprehensive\nbenchmark designed to enable researchers to compare differentially private\ngraph generation algorithms fairly. We begin by identifying four essential\nelements of existing works as a 4-tuple: mechanisms, graph datasets, privacy\nrequirements, and utility metrics. We discuss principles regarding these\nelements to ensure the comprehensiveness of a benchmark. Next, we present a\nbenchmark instantiation that adheres to all principles, establishing a new\nmethod to evaluate existing and newly proposed graph generation algorithms.\nThrough extensive theoretical and empirical analysis, we gain valuable insights\ninto the strengths and weaknesses of prior algorithms. Our results indicate\nthat there is no universal solution for all possible cases. Finally, we provide\nguidelines to help researchers select appropriate mechanisms for various\nscenarios.", "categories": "cs.DB", "created": "2024-08-05", "doi": null, "arxiv_id": "2408.02928"}
{"title": "Segmenting Small Stroke Lesions with Novel Labeling Strategies", "authors": [], "abstract": "Deep neural networks have demonstrated exceptional efficacy in stroke lesion\nsegmentation. However, the delineation of small lesions, critical for stroke\ndiagnosis, remains a challenge. In this study, we propose two straightforward\nyet powerful approaches that can be seamlessly integrated into a variety of\nnetworks: Multi-Size Labeling (MSL) and Distance-Based Labeling (DBL), with the\naim of enhancing the segmentation accuracy of small lesions. MSL divides lesion\nmasks into various categories based on lesion volume while DBL emphasizes the\nlesion boundaries. Experimental evaluations on the Anatomical Tracings of\nLesions After Stroke (ATLAS) v2.0 dataset showcase that an ensemble of MSL and\nDBL achieves consistently better or equal performance on recall (3.6% and\n3.7%), F1 (2.4% and 1.5%), and Dice scores (1.3% and 0.0%) compared to the\ntop-1 winner of the 2022 MICCAI ATLAS Challenge on both the subset only\ncontaining small lesions and the entire dataset, respectively. Notably, on the\nmini-lesion subset, a single MSL model surpasses the previous best ensemble\nstrategy, with enhancements of 1.0% and 0.3% on F1 and Dice scores,\nrespectively. Our code is available at:\nhttps://github.com/nadluru/StrokeLesSeg.", "categories": "cs.CV", "created": "2024-08-05", "doi": null, "arxiv_id": "2408.02929"}
{"title": "The Need for a Big World Simulator: A Scientific Challenge for Continual\n  Learning", "authors": [], "abstract": "The \"small agent, big world\" frame offers a conceptual view that motivates\nthe need for continual learning. The idea is that a small agent operating in a\nmuch bigger world cannot store all information that the world has to offer. To\nperform well, the agent must be carefully designed to ingest, retain, and eject\nthe right information. To enable the development of performant continual\nlearning agents, a number of synthetic environments have been proposed.\nHowever, these benchmarks suffer from limitations, including unnatural\ndistribution shifts and a lack of fidelity to the \"small agent, big world\"\nframing. This paper aims to formalize two desiderata for the design of future\nsimulated environments. These two criteria aim to reflect the objectives and\ncomplexity of continual learning in practical settings while enabling rapid\nprototyping of algorithms on a smaller scale.", "categories": "cs.LG cs.AI", "created": "2024-08-05", "doi": null, "arxiv_id": "2408.02930"}
{"title": "Learned Trimmed-Ridge Regression for Channel Estimation in\n  Millimeter-Wave Massive MIMO", "authors": [], "abstract": "Channel estimation poses significant challenges in millimeter-wave massive\nmultiple-input multiple-output systems, especially when the base station has\nfewer radio-frequency chains than antennas. To address this challenge, one\npromising solution exploits the beamspace channel sparsity to reconstruct\nfull-dimensional channels from incomplete measurements. This paper presents a\nmodel-based deep learning method to reconstruct sparse, as well as\napproximately sparse, vectors fast and accurately. To implement this method, we\npropose a trimmed-ridge regression that transforms the sparse-reconstruction\nproblem into a least-squares problem regularized by a nonconvex penalty term,\nand then derive an iterative solution. We then unfold the iterations into a\ndeep network that can be implemented in online applications to realize\nreal-time computations. To this end, an unfolded trimmed-ridge regression model\nis constructed using a structural configuration to reduce computational\ncomplexity and a model ensemble strategy to improve accuracy. Compared with\nother state-of-the-art deep learning models, the proposed learning scheme\nachieves better accuracy and supports higher downlink sum rates.", "categories": "cs.IT eess.SP math.IT", "created": "2024-08-05", "doi": null, "arxiv_id": "2408.02934"}
{"title": "Numerical Ergodicity of Stochastic Allen--Cahn Equation driven by\n  Multiplicative White Noise", "authors": [], "abstract": "We establish the unique ergodicity of a fully discrete scheme for monotone\nSPDEs with polynomial growth drift and bounded diffusion coefficients driven by\nmultiplicative white noise. The main ingredient of our method depends on the\nsatisfaction of a Lyapunov condition followed by a uniform moments' estimate,\ncombined with the irreducibility and the strong Feller property for full\ndiscretization. We transform the original stochastic equation into an\nequivalent random equation where the discrete stochastic convolutions are\nuniformly controlled to derive the desired uniform moments' estimate. Applying\nthe main result to the stochastic Allen--Cahn equation driven by multiplicative\nwhite noise indicates that this full discretization is uniquely ergodic for any\ninterface thickness. Numerical experiments validate our theoretical results.", "categories": "math.NA cs.NA math.PR", "created": "2024-08-05", "doi": null, "arxiv_id": "2408.02935"}
{"title": "A Real-Time Adaptive Multi-Stream GPU System for Online Approximate\n  Nearest Neighborhood Search", "authors": [], "abstract": "In recent years, Approximate Nearest Neighbor Search (ANNS) has played a\npivotal role in modern search and recommendation systems, especially in\nemerging LLM applications like Retrieval-Augmented Generation. There is a\ngrowing exploration into harnessing the parallel computing capabilities of GPUs\nto meet the substantial demands of ANNS. However, existing systems primarily\nfocus on offline scenarios, overlooking the distinct requirements of online\napplications that necessitate real-time insertion of new vectors. This\nlimitation renders such systems inefficient for real-world scenarios. Moreover,\nprevious architectures struggled to effectively support real-time insertion due\nto their reliance on serial execution streams. In this paper, we introduce a\nnovel Real-Time Adaptive Multi-Stream GPU ANNS System (RTAMS-GANNS). Our\narchitecture achieves its objectives through three key advancements: 1) We\ninitially examined the real-time insertion mechanisms in existing GPU ANNS\nsystems and discovered their reliance on repetitive copying and memory\nallocation, which significantly hinders real-time effectiveness on GPUs. As a\nsolution, we introduce a dynamic vector insertion algorithm based on memory\nblocks, which includes in-place rearrangement. 2) To enable real-time vector\ninsertion in parallel, we introduce a multi-stream parallel execution mode,\nwhich differs from existing systems that operate serially within a single\nstream. Our system utilizes a dynamic resource pool, allowing multiple streams\nto execute concurrently without additional execution blocking. 3) Through\nextensive experiments and comparisons, our approach effectively handles varying\nQPS levels across different datasets, reducing latency by up to 40%-80%. The\nproposed system has also been deployed in real-world industrial search and\nrecommendation systems, serving hundreds of millions of users daily, and has\nachieved good results.", "categories": "cs.IR", "created": "2024-08-05", "doi": null, "arxiv_id": "2408.02937"}
{"title": "Reinforcement Learning based Workflow Scheduling in Cloud and Edge\n  Computing Environments: A Taxonomy, Review and Future Directions", "authors": [], "abstract": "Deep Reinforcement Learning (DRL) techniques have been successfully applied\nfor solving complex decision-making and control tasks in multiple fields\nincluding robotics, autonomous driving, healthcare and natural language\nprocessing. The ability of DRL agents to learn from experience and utilize\nreal-time data for making decisions makes it an ideal candidate for dealing\nwith the complexities associated with the problem of workflow scheduling in\nhighly dynamic cloud and edge computing environments. Despite the benefits of\nDRL, there are multiple challenges associated with the application of DRL\ntechniques including multi-objectivity, curse of dimensionality, partial\nobservability and multi-agent coordination. In this paper, we comprehensively\nanalyze the challenges and opportunities associated with the design and\nimplementation of DRL oriented solutions for workflow scheduling in cloud and\nedge computing environments. Based on the identified characteristics, we\npropose a taxonomy of workflow scheduling with DRL. We map reviewed works with\nrespect to the taxonomy to identify their strengths and weaknesses. Based on\ntaxonomy driven analysis, we propose novel future research directions for the\nfield.", "categories": "cs.DC", "created": "2024-08-05", "doi": null, "arxiv_id": "2408.02938"}
{"title": "An Artificial Neural Network based approach for Harmonic Component\n  Prediction in a Distribution Line", "authors": [], "abstract": "With a growth in the use of nonlinear devices, in both generation and\nconsumption, it is imminent that we require accurate and quick control for\nactive filters to suppress harmonics. Time delays between input and output is\ncatastrophic for such filters, which rely on real-time operation. Artificial\nNeural Networks (ANNs) are capable of properly modelling complex nonlinear\nsystems through adjustments in their learned parameters. Once these networks\nare properly trained, they can produce highly accurate predictions at an\ninstantaneous time frame. Leveraging these qualities, various complex control\nsystems may be replaced by neural networks to provide quick and precise\nresponses. This paper proposes an ANN based approach for the prediction of\nindividual harmonic components. By extracting and analyzing the magnitudes of\nharmonic components obtained from the survey of a particular area through\nreal-time measurements, a sequential pattern in their occurrence is observed.\nVarious neural network architectures are trained using the collected data and\ntheir performance are evaluated. The best performing model, whose loss is\nminimum, is then used to observe the harmonic cancellation for a particular\ncase through a simplified simulation in hardware-in-the-loop. These neural\nnetwork structures, that produce instantaneous and accurate outputs, provide a\nbetter response time. On top of that, it can limit the required input\nmeasurements/parameters to basic ones like time, currents and a few other\npertaining to a particular locality, such as maximum demand and number of\nhouseholds.", "categories": "eess.SY cs.SY", "created": "2024-08-05", "doi": null, "arxiv_id": "2408.03161"}
