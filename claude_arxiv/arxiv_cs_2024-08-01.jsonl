{"title": "3D U-KAN Implementation for Multi-modal MRI Brain Tumor Segmentation", "authors": [], "abstract": "We explore the application of U-KAN, a U-Net based network enhanced with\nKolmogorov-Arnold Network (KAN) layers, for 3D brain tumor segmentation using\nmulti-modal MRI data. We adapt the original 2D U-KAN model to the 3D task, and\nintroduce a variant called UKAN-SE, which incorporates Squeeze-and-Excitation\nmodules for global attention. We compare the performance of U-KAN and UKAN-SE\nagainst existing methods such as U-Net, Attention U-Net, and Swin UNETR, using\nthe BraTS 2024 dataset. Our results show that U-KAN and UKAN-SE, with\napproximately 10.6 million parameters, achieve exceptional efficiency,\nrequiring only about 1/4 of the training time of U-Net and Attention U-Net, and\n1/6 that of Swin UNETR, while surpassing these models across most evaluation\nmetrics. Notably, UKAN-SE slightly outperforms U-KAN.", "categories": "eess.IV cs.CV", "created": "2024-08-01", "doi": null, "arxiv_id": "2408.00273"}
{"title": "QUITO: Accelerating Long-Context Reasoning through Query-Guided Context\n  Compression", "authors": [], "abstract": "In-context learning (ICL) capabilities are foundational to the success of\nlarge language models (LLMs). Recently, context compression has attracted\ngrowing interest since it can largely reduce reasoning complexities and\ncomputation costs of LLMs. In this paper, we introduce a novel Query-gUIded\naTtention cOmpression (QUITO) method, which leverages attention of the question\nover the contexts to filter useless information. Specifically, we take a\ntrigger token to calculate the attention distribution of the context in\nresponse to the question. Based on the distribution, we propose three different\nfiltering methods to satisfy the budget constraints of the context length. We\nevaluate the QUITO using two widely-used datasets, namely, NaturalQuestions and\nASQA. Experimental results demonstrate that QUITO significantly outperforms\nestablished baselines across various datasets and downstream LLMs, underscoring\nits effectiveness. Our code is available at\nhttps://github.com/Wenshansilvia/attention_compressor.", "categories": "cs.CL cs.AI", "created": "2024-08-01", "doi": null, "arxiv_id": "2408.00274"}
{"title": "High Performance Im2win and Direct Convolutions using Three Tensor\n  Layouts on SIMD Architectures", "authors": [], "abstract": "Convolution is the core component within deep neural networks and it is\ncomputationally intensive and time consuming. Tensor data layouts significantly\nimpact convolution operations in terms of memory access and computational\nefficiency. Yet, there is still a lack of comprehensive performance\ncharacterization on data layouts on SIMD architectures concerning convolution\nmethods. This paper proposes three novel data layouts for im2win convolution:\nNHWC, CHWN, and CHWN8, and introduces a set of general optimization techniques\nfor both direct and im2win convolutions. We compare the optimized im2win\nconvolution with the direct convolution and PyTorch's im2col-based convolution\nacross the aforementioned layouts on SIMD machines. The experiments\ndemonstrated that the im2win convolution with the new NHWC layout achieved up\nto 355% performance speedup over NCHW layout. Our optimizations also\nsignificantly improve the performance of both im2win and direct convolutions.\nOur optimized im2win and direct convolutions achieved up to 95% and 94% of\nmachine's theoretical peak performance, respectively.", "categories": "cs.LG cs.AI cs.NE", "created": "2024-08-01", "doi": null, "arxiv_id": "2408.00278"}
{"title": "DMESA: Densely Matching Everything by Segmenting Anything", "authors": [], "abstract": "We propose MESA and DMESA as novel feature matching methods, which utilize\nSegment Anything Model (SAM) to effectively mitigate matching redundancy. The\nkey insight of our methods is to establish implicit-semantic area matching\nprior to point matching, based on advanced image understanding of SAM. Then,\ninformative area matches with consistent internal semantic are able to undergo\ndense feature comparison, facilitating precise inside-area point matching.\nSpecifically, MESA adopts a sparse matching framework and first obtains\ncandidate areas from SAM results through a novel Area Graph (AG). Then, area\nmatching among the candidates is formulated as graph energy minimization and\nsolved by graphical models derived from AG. To address the efficiency issue of\nMESA, we further propose DMESA as its dense counterpart, applying a dense\nmatching framework. After candidate areas are identified by AG, DMESA\nestablishes area matches through generating dense matching distributions. The\ndistributions are produced from off-the-shelf patch matching utilizing the\nGaussian Mixture Model and refined via the Expectation Maximization. With less\nrepetitive computation, DMESA showcases a speed improvement of nearly five\ntimes compared to MESA, while maintaining competitive accuracy. Our methods are\nextensively evaluated on five datasets encompassing indoor and outdoor scenes.\nThe results illustrate consistent performance improvements from our methods for\nfive distinct point matching baselines across all datasets. Furthermore, our\nmethods exhibit promise generalization and improved robustness against image\nresolution variations. The code is publicly available at\nhttps://github.com/Easonyesheng/A2PM-MESA.", "categories": "cs.CV", "created": "2024-08-01", "doi": null, "arxiv_id": "2408.00279"}
{"title": "Towards Scalable GPU-Accelerated SNN Training via Temporal Fusion", "authors": [], "abstract": "Drawing on the intricate structures of the brain, Spiking Neural Networks\n(SNNs) emerge as a transformative development in artificial intelligence,\nclosely emulating the complex dynamics of biological neural networks. While\nSNNs show promising efficiency on specialized sparse-computational hardware,\ntheir practical training often relies on conventional GPUs. This reliance\nfrequently leads to extended computation times when contrasted with traditional\nArtificial Neural Networks (ANNs), presenting significant hurdles for advancing\nSNN research. To navigate this challenge, we present a novel temporal fusion\nmethod, specifically designed to expedite the propagation dynamics of SNNs on\nGPU platforms, which serves as an enhancement to the current significant\napproaches for handling deep learning tasks with SNNs. This method underwent\nthorough validation through extensive experiments in both authentic training\nscenarios and idealized conditions, confirming its efficacy and adaptability\nfor single and multi-GPU systems. Benchmarked against various existing SNN\nlibraries/implementations, our method achieved accelerations ranging from\n$5\\times$ to $40\\times$ on NVIDIA A100 GPUs. Publicly available experimental\ncodes can be found at https://github.com/EMI-Group/snn-temporal-fusion.", "categories": "cs.AI cs.DC", "created": "2024-08-01", "doi": null, "arxiv_id": "2408.00280"}
{"title": "Navigating Text-to-Image Generative Bias across Indic Languages", "authors": [], "abstract": "This research investigates biases in text-to-image (TTI) models for the Indic\nlanguages widely spoken across India. It evaluates and compares the generative\nperformance and cultural relevance of leading TTI models in these languages\nagainst their performance in English. Using the proposed IndicTTI benchmark, we\ncomprehensively assess the performance of 30 Indic languages with two\nopen-source diffusion models and two commercial generation APIs. The primary\nobjective of this benchmark is to evaluate the support for Indic languages in\nthese models and identify areas needing improvement. Given the linguistic\ndiversity of 30 languages spoken by over 1.4 billion people, this benchmark\naims to provide a detailed and insightful analysis of TTI models' effectiveness\nwithin the Indic linguistic landscape. The data and code for the IndicTTI\nbenchmark can be accessed at\nhttps://iab-rubric.org/resources/other-databases/indictti.", "categories": "cs.CL cs.CV", "created": "2024-08-01", "doi": null, "arxiv_id": "2408.00283"}
{"title": "Bailing-TTS: Chinese Dialectal Speech Synthesis Towards Human-like\n  Spontaneous Representation", "authors": [], "abstract": "Large-scale text-to-speech (TTS) models have made significant progress\nrecently.However, they still fall short in the generation of Chinese dialectal\nspeech. Toaddress this, we propose Bailing-TTS, a family of large-scale TTS\nmodels capable of generating high-quality Chinese dialectal speech. Bailing-TTS\nserves as a foundation model for Chinese dialectal speech generation. First,\ncontinual semi-supervised learning is proposed to facilitate the alignment of\ntext tokens and speech tokens. Second, the Chinese dialectal representation\nlearning is developed using a specific transformer architecture and multi-stage\ntraining processes. With the proposed design of novel network architecture and\ncorresponding strategy, Bailing-TTS is able to generate Chinese dialectal\nspeech from text effectively and efficiently. Experiments demonstrate that\nBailing-TTS generates Chinese dialectal speech towards human-like spontaneous\nrepresentation. Readers are encouraged to listen to demos at\n\\url{https://c9412600.github.io/bltts_tech_report/index.html}.", "categories": "cs.CL cs.SD eess.AS", "created": "2024-08-01", "doi": null, "arxiv_id": "2408.00284"}
{"title": "Diff3DETR:Agent-based Diffusion Model for Semi-supervised 3D Object\n  Detection", "authors": [], "abstract": "3D object detection is essential for understanding 3D scenes. Contemporary\ntechniques often require extensive annotated training data, yet obtaining\npoint-wise annotations for point clouds is time-consuming and laborious. Recent\ndevelopments in semi-supervised methods seek to mitigate this problem by\nemploying a teacher-student framework to generate pseudo-labels for unlabeled\npoint clouds. However, these pseudo-labels frequently suffer from insufficient\ndiversity and inferior quality. To overcome these hurdles, we introduce an\nAgent-based Diffusion Model for Semi-supervised 3D Object Detection\n(Diff3DETR). Specifically, an agent-based object query generator is designed to\nproduce object queries that effectively adapt to dynamic scenes while striking\na balance between sampling locations and content embedding. Additionally, a\nbox-aware denoising module utilizes the DDIM denoising process and the\nlong-range attention in the transformer decoder to refine bounding boxes\nincrementally. Extensive experiments on ScanNet and SUN RGB-D datasets\ndemonstrate that Diff3DETR outperforms state-of-the-art semi-supervised 3D\nobject detection methods.", "categories": "cs.CV", "created": "2024-08-01", "doi": null, "arxiv_id": "2408.00286"}
{"title": "Gradient Harmonization in Unsupervised Domain Adaptation", "authors": [], "abstract": "Unsupervised domain adaptation (UDA) intends to transfer knowledge from a\nlabeled source domain to an unlabeled target domain. Many current methods focus\non learning feature representations that are both discriminative for\nclassification and invariant across domains by simultaneously optimizing domain\nalignment and classification tasks. However, these methods often overlook a\ncrucial challenge: the inherent conflict between these two tasks during\ngradient-based optimization. In this paper, we delve into this issue and\nintroduce two effective solutions known as Gradient Harmonization, including GH\nand GH++, to mitigate the conflict between domain alignment and classification\ntasks. GH operates by altering the gradient angle between different tasks from\nan obtuse angle to an acute angle, thus resolving the conflict and trade-offing\nthe two tasks in a coordinated manner. Yet, this would cause both tasks to\ndeviate from their original optimization directions. We thus further propose an\nimproved version, GH++, which adjusts the gradient angle between tasks from an\nobtuse angle to a vertical angle. This not only eliminates the conflict but\nalso minimizes deviation from the original gradient directions. Finally, for\noptimization convenience and efficiency, we evolve the gradient harmonization\nstrategies into a dynamically weighted loss function using an integral operator\non the harmonized gradient. Notably, GH/GH++ are orthogonal to UDA and can be\nseamlessly integrated into most existing UDA models. Theoretical insights and\nexperimental analyses demonstrate that the proposed approaches not only enhance\npopular UDA baselines but also improve recent state-of-the-art models.", "categories": "cs.CV cs.AI cs.LG", "created": "2024-08-01", "doi": null, "arxiv_id": "2408.00288"}
{"title": "Multi-Modal Parameter-Efficient Fine-tuning via Graph Neural Network", "authors": [], "abstract": "With the advent of the era of foundation models, pre-training and fine-tuning\nhave become common paradigms. Recently, parameter-efficient fine-tuning has\ngarnered widespread attention due to its better balance between the number of\nlearnable parameters and performance. However, some current parameter-efficient\nfine-tuning methods only model a single modality and lack the utilization of\nstructural knowledge in downstream tasks. To address this issue, this paper\nproposes a multi-modal parameter-efficient fine-tuning method based on graph\nnetworks. Each image is fed into a multi-modal large language model (MLLM) to\ngenerate a text description. The image and its corresponding text description\nare then processed by a frozen image encoder and text encoder to generate image\nfeatures and text features, respectively. A graph is constructed based on the\nsimilarity of the multi-modal feature nodes, and knowledge and relationships\nrelevant to these features are extracted from each node. Additionally, Elastic\nWeight Consolidation (EWC) regularization is incorporated into the loss\nfunction to mitigate the problem of forgetting during task learning. The\nproposed model achieves test accuracies on the OxfordPets, Flowers102, and\nFood101 datasets that improve by 4.45%, 2.92%, and 0.23%, respectively. The\ncode is available at https://github.com/yunche0/GA-Net/tree/master.", "categories": "cs.CV cs.AI", "created": "2024-08-01", "doi": null, "arxiv_id": "2408.00290"}
{"title": "Everything We Hear: Towards Tackling Misinformation in Podcasts", "authors": [], "abstract": "Advances in generative AI, the proliferation of large multimodal models\n(LMMs), and democratized open access to these technologies have direct\nimplications for the production and diffusion of misinformation. In this\nprequel, we address tackling misinformation in the unique and increasingly\npopular context of podcasts. The rise of podcasts as a popular medium for\ndisseminating information across diverse topics necessitates a proactive\nstrategy to combat the spread of misinformation. Inspired by the proven\neffectiveness of \\textit{auditory alerts} in contexts like collision alerts for\ndrivers and error pings in mobile phones, our work envisions the application of\nauditory alerts as an effective tool to tackle misinformation in podcasts. We\npropose the integration of suitable auditory alerts to notify listeners of\npotential misinformation within the podcasts they are listening to, in\nreal-time and without hampering listening experiences. We identify several\nopportunities and challenges in this path and aim to provoke novel\nconversations around instruments, methods, and measures to tackle\nmisinformation in podcasts.", "categories": "cs.HC", "created": "2024-08-01", "doi": "10.1145/3678957.3678959", "arxiv_id": "2408.00292"}
{"title": "Gradient Flow Decoding", "authors": [], "abstract": "This paper presents the Gradient Flow (GF) decoding for LDPC codes. GF\ndecoding, a continuous-time methodology based on gradient flow, employs a\npotential energy function associated with bipolar codewords of LDPC codes. The\ndecoding process of the GF decoding is concisely defined by an ordinary\ndifferential equation and thus it is well suited to an analog circuit\nimplementation. We experimentally demonstrate that the decoding performance of\nthe GF decoding for AWGN channels is comparable to that of the multi-bit mode\ngradient descent bit flipping algorithm. We further introduce the negative\nlog-likelihood function of the channel for generalizing the GF decoding. The\nproposed method is shown to be tensor-computable, which means that the gradient\nof the objective function can be evaluated with the combination of basic tensor\ncomputations. This characteristic is well-suited to emerging AI accelerators,\npotentially applicable in wireless signal processing. The paper assesses the\ndecoding performance of the generalized GF decoding in LDPC-coded MIMO\nchannels. Our numerical experiments reveal that the decoding performance rivals\nthat of established techniques like MMSE + BP. Furthermore, an exploration of\nscore-based channel learning for capturing statistical properties is also\nprovided.", "categories": "cs.IT math.IT", "created": "2024-08-01", "doi": null, "arxiv_id": "2408.00293"}
{"title": "RDP: Ranked Differential Privacy for Facial Feature Protection in\n  Multiscale Sparsified Subspace", "authors": [], "abstract": "With the widespread sharing of personal face images in applications' public\ndatabases, face recognition systems faces real threat of being breached by\npotential adversaries who are able to access users' face images and use them to\nintrude the face recognition systems. In this paper, we propose a novel privacy\nprotection method in the multiscale sparsified feature subspaces to protect\nsensitive facial features, by taking care of the influence or weight ranked\nfeature coefficients on the privacy budget, named \"Ranked Differential Privacy\n(RDP)\". After the multiscale feature decomposition, the lightweight Laplacian\nnoise is added to the dimension-reduced sparsified feature coefficients\naccording to the geometric superposition method. Then, we rigorously prove that\nthe RDP satisfies Differential Privacy. After that, the nonlinear Lagrange\nMultiplier (LM) method is formulated for the constraint optimization problem of\nmaximizing the utility of the visualization quality protected face images with\nsanitizing noise, under a given facial features privacy budget. Then, two\nmethods are proposed to solve the nonlinear LM problem and obtain the optimal\nnoise scale parameters: 1) the analytical Normalization Approximation (NA)\nmethod with identical average noise scale parameter for real-time online\napplications; and 2) the LM optimization Gradient Descent (LMGD) numerical\nmethod to obtain the nonlinear solution through iterative updating for more\naccurate offline applications. Experimental results on two real-world datasets\nshow that our proposed RDP outperforms other state-of-the-art methods: at a\nprivacy budget of 0.2, the PSNR (Peak Signal-to-Noise Ratio) of the RDP is\nabout ~10 dB higher than (10 times as high as) the highest PSNR of all compared\nmethods.", "categories": "cs.CV cs.IR", "created": "2024-08-01", "doi": null, "arxiv_id": "2408.00294"}
{"title": "Contrastive Graph Representation Learning with Adversarial Cross-view\n  Reconstruction and Information Bottleneck", "authors": [], "abstract": "Graph Neural Networks (GNNs) have received extensive research attention due\nto their powerful information aggregation capabilities. Despite the success of\nGNNs, most of them suffer from the popularity bias issue in a graph caused by a\nsmall number of popular categories. Additionally, real graph datasets always\ncontain incorrect node labels, which hinders GNNs from learning effective node\nrepresentations. Graph contrastive learning (GCL) has been shown to be\neffective in solving the above problems for node classification tasks. Most\nexisting GCL methods are implemented by randomly removing edges and nodes to\ncreate multiple contrasting views, and then maximizing the mutual information\n(MI) between these contrasting views to improve the node feature\nrepresentation. However, maximizing the mutual information between multiple\ncontrasting views may lead the model to learn some redundant information\nirrelevant to the node classification task. To tackle this issue, we propose an\neffective Contrastive Graph Representation Learning with Adversarial Cross-view\nReconstruction and Information Bottleneck (CGRL) for node classification, which\ncan adaptively learn to mask the nodes and edges in the graph to obtain the\noptimal graph structure representation. Furthermore, we innovatively introduce\nthe information bottleneck theory into GCLs to remove redundant information in\nmultiple contrasting views while retaining as much information as possible\nabout node classification. Moreover, we add noise perturbations to the original\nviews and reconstruct the augmented views by constructing adversarial views to\nimprove the robustness of node feature representation. Extensive experiments on\nreal-world public datasets demonstrate that our method significantly\noutperforms existing state-of-the-art algorithms.", "categories": "cs.LG cs.AI", "created": "2024-08-01", "doi": null, "arxiv_id": "2408.00295"}
{"title": "Head360: Learning a Parametric 3D Full-Head for Free-View Synthesis in\n  360{\\deg}", "authors": [], "abstract": "Creating a 360{\\deg} parametric model of a human head is a very challenging\ntask. While recent advancements have demonstrated the efficacy of leveraging\nsynthetic data for building such parametric head models, their performance\nremains inadequate in crucial areas such as expression-driven animation,\nhairstyle editing, and text-based modifications. In this paper, we build a\ndataset of artist-designed high-fidelity human heads and propose to create a\nnovel parametric 360{\\deg} renderable parametric head model from it. Our scheme\ndecouples the facial motion/shape and facial appearance, which are represented\nby a classic parametric 3D mesh model and an attached neural texture,\nrespectively. We further propose a training method for decompositing hairstyle\nand facial appearance, allowing free-swapping of the hairstyle. A novel\ninversion fitting method is presented based on single image input with high\ngeneralization and fidelity. To the best of our knowledge, our model is the\nfirst parametric 3D full-head that achieves 360{\\deg} free-view synthesis,\nimage-based fitting, appearance editing, and animation within a single model.\nExperiments show that facial motions and appearances are well disentangled in\nthe parametric space, leading to SOTA performance in rendering and animating\nquality. The code and SynHead100 dataset are released at\nhttps://nju-3dv.github.io/projects/Head360.", "categories": "cs.CV", "created": "2024-08-01", "doi": null, "arxiv_id": "2408.00296"}
{"title": "EmoTalk3D: High-Fidelity Free-View Synthesis of Emotional 3D Talking\n  Head", "authors": [], "abstract": "We present a novel approach for synthesizing 3D talking heads with\ncontrollable emotion, featuring enhanced lip synchronization and rendering\nquality. Despite significant progress in the field, prior methods still suffer\nfrom multi-view consistency and a lack of emotional expressiveness. To address\nthese issues, we collect EmoTalk3D dataset with calibrated multi-view videos,\nemotional annotations, and per-frame 3D geometry. By training on the EmoTalk3D\ndataset, we propose a \\textit{`Speech-to-Geometry-to-Appearance'} mapping\nframework that first predicts faithful 3D geometry sequence from the audio\nfeatures, then the appearance of a 3D talking head represented by 4D Gaussians\nis synthesized from the predicted geometry. The appearance is further\ndisentangled into canonical and dynamic Gaussians, learned from multi-view\nvideos, and fused to render free-view talking head animation. Moreover, our\nmodel enables controllable emotion in the generated talking heads and can be\nrendered in wide-range views. Our method exhibits improved rendering quality\nand stability in lip motion generation while capturing dynamic facial details\nsuch as wrinkles and subtle expressions. Experiments demonstrate the\neffectiveness of our approach in generating high-fidelity and\nemotion-controllable 3D talking heads. The code and EmoTalk3D dataset are\nreleased at https://nju-3dv.github.io/projects/EmoTalk3D.", "categories": "cs.CV", "created": "2024-08-01", "doi": null, "arxiv_id": "2408.00297"}
{"title": "Tails Tell Tales: Chapter-Wide Manga Transcriptions with Character Names", "authors": [], "abstract": "Enabling engagement of manga by visually impaired individuals presents a\nsignificant challenge due to its inherently visual nature. With the goal of\nfostering accessibility, this paper aims to generate a dialogue transcript of a\ncomplete manga chapter, entirely automatically, with a particular emphasis on\nensuring narrative consistency. This entails identifying (i) what is being\nsaid, i.e., detecting the texts on each page and classifying them into\nessential vs non-essential, and (ii) who is saying it, i.e., attributing each\ndialogue to its speaker, while ensuring the same characters are named\nconsistently throughout the chapter.\n  To this end, we introduce: (i) Magiv2, a model that is capable of generating\nhigh-quality chapter-wide manga transcripts with named characters and\nsignificantly higher precision in speaker diarisation over prior works; (ii) an\nextension of the PopManga evaluation dataset, which now includes annotations\nfor speech-bubble tail boxes, associations of text to corresponding tails,\nclassifications of text as essential or non-essential, and the identity for\neach character box; and (iii) a new character bank dataset, which comprises\nover 11K characters from 76 manga series, featuring 11.5K exemplar character\nimages in total, as well as a list of chapters in which they appear. The code,\ntrained model, and both datasets can be found at:\nhttps://github.com/ragavsachdeva/magi", "categories": "cs.CV", "created": "2024-08-01", "doi": null, "arxiv_id": "2408.00298"}
{"title": "Towards Flexible Evaluation for Generative Visual Question Answering", "authors": [], "abstract": "Throughout rapid development of multimodal large language models, a crucial\ningredient is a fair and accurate evaluation of their multimodal comprehension\nabilities. Although Visual Question Answering (VQA) could serve as a developed\ntest field, limitations of VQA evaluation, like the inflexible pattern of Exact\nMatch, have hindered MLLMs from demonstrating their real capability and\ndiscourage rich responses. Therefore, this paper proposes the use of\nsemantics-based evaluators for assessing unconstrained open-ended responses on\nVQA datasets. As characteristics of VQA have made such evaluation significantly\ndifferent than the traditional Semantic Textual Similarity (STS) task, to\nsystematically analyze the behaviour and compare the performance of various\nevaluators including LLM-based ones, we proposes three key properties, i.e.,\nAlignment, Consistency and Generalization, and a corresponding dataset\nAssessing VQA Evaluators (AVE) to facilitate analysis. In addition, this paper\nproposes a Semantically Flexible VQA Evaluator (SFVE) with meticulous design\nbased on the unique features of VQA evaluation. Experimental results verify the\nfeasibility of model-based VQA evaluation and effectiveness of the proposed\nevaluator that surpasses existing semantic evaluators by a large margin. The\nproposed training scheme generalizes to both the BERT-like encoders and\ndecoder-only LLM.", "categories": "cs.CV cs.MM", "created": "2024-08-01", "doi": null, "arxiv_id": "2408.00300"}
{"title": "Neural Octahedral Field: Octahedral prior for simultaneous smoothing and\n  sharp edge regularization", "authors": [], "abstract": "Neural implicit representation, the parameterization of distance function as\na coordinate neural field, has emerged as a promising lead in tackling surface\nreconstruction from unoriented point clouds. To enforce consistent orientation,\nexisting methods focus on regularizing the gradient of the distance function,\nsuch as constraining it to be of the unit norm, minimizing its divergence, or\naligning it with the eigenvector of Hessian that corresponds to zero\neigenvalue. However, under the presence of large scanning noise, they tend to\neither overfit the noise input or produce an excessively smooth reconstruction.\nIn this work, we propose to guide the surface reconstruction under a new\nvariant of neural field, the octahedral field, leveraging the spherical\nharmonics representation of octahedral frames originated in the hexahedral\nmeshing. Such field automatically snaps to geometry features when constrained\nto be smooth, and naturally preserves sharp angles when interpolated over\ncreases. By simultaneously fitting and smoothing the octahedral field alongside\nthe implicit geometry, it behaves analogously to bilateral filtering, resulting\nin smooth reconstruction while preserving sharp edges. Despite being operated\npurely pointwise, our method outperforms various traditional and neural\napproaches across extensive experiments, and is very competitive with methods\nthat require normal and data priors. Our full implementation is available at:\nhttps://github.com/Ankbzpx/frame-field.", "categories": "cs.CV cs.GR", "created": "2024-08-01", "doi": null, "arxiv_id": "2408.00303"}
{"title": "Constraint Energy Minimizing Generalized Multiscale Finite Element\n  Method for Convection Diffusion Equations with Inhomogeneous Boundary\n  Conditions", "authors": [], "abstract": "In this paper, we develop the constraint energy minimizing generalized\nmultiscale finite element method (CEM-GMsFEM) for convection-diffusion\nequations with inhomogeneous Dirichlet, Neumann and Robin boundary conditions,\nalong with high-contrast coefficients. For time independent problems, boundary\ncorrectors $\\mathcal{D}^m$ and $\\mathcal{N}^{m}$ for Dirichlet, Neumann, and\nRobin conditions are designed. For time dependent problems, a scheme to update\nthe boundary correctors is formulated. Error analysis in both cases is given to\nshow the first-order convergence in energy norm with respect to the coarse mesh\nsize $H$ and second-order convergence in $L^2-$norm, as verified by numerical\nexamples, with which different finite difference schemes are compared for\ntemporal discretization. Nonlinear problems are also demonstrated in\ncombination with Strang splitting.", "categories": "math.NA cs.NA", "created": "2024-08-01", "doi": null, "arxiv_id": "2408.00304"}
{"title": "Leveraging Weak Cross-Modal Guidance for Coherence Modelling via\n  Iterative Learning", "authors": [], "abstract": "Cross-modal coherence modeling is essential for intelligent systems to help\nthem organize and structure information, thereby understanding and creating\ncontent of the physical world coherently like human-beings. Previous work on\ncross-modal coherence modeling attempted to leverage the order information from\nanother modality to assist the coherence recovering of the target modality.\nDespite of the effectiveness, labeled associated coherency information is not\nalways available and might be costly to acquire, making the cross-modal\nguidance hard to leverage. To tackle this challenge, this paper explores a new\nway to take advantage of cross-modal guidance without gold labels on coherency,\nand proposes the Weak Cross-Modal Guided Ordering (WeGO) model. More\nspecifically, it leverages high-confidence predicted pairwise order in one\nmodality as reference information to guide the coherence modeling in another.\nAn iterative learning paradigm is further designed to jointly optimize the\ncoherence modeling in two modalities with selected guidance from each other.\nThe iterative cross-modal boosting also functions in inference to further\nenhance coherence prediction in each modality. Experimental results on two\npublic datasets have demonstrated that the proposed method outperforms existing\nmethods for cross-modal coherence modeling tasks. Major technical modules have\nbeen evaluated effective through ablation studies. Codes are available at:\n\\url{https://github.com/scvready123/IterWeGO}.", "categories": "cs.MM cs.IR", "created": "2024-08-01", "doi": "10.1145/3664647.3681677", "arxiv_id": "2408.00305"}
{"title": "ABC Align: Large Language Model Alignment for Safety & Accuracy", "authors": [], "abstract": "Alignment of Large Language Models (LLMs) remains an unsolved problem. Human\npreferences are highly distributed and can be captured at multiple levels of\nabstraction, from the individual to diverse populations. Organisational\npreferences, represented by standards and principles, are defined to mitigate\nreputational risk or meet legislative obligations. In this paper, we present\nABC Align, a novel alignment methodology for LLMs that enables integration of\nthe standards and preferences of a large media organisation into the LLM\nitself. We combine a set of data and methods that build on recent breakthroughs\nin synthetic data generation, preference optimisation, and post-training model\nquantisation. Our unified approach mitigates bias and improves accuracy, while\npreserving reasoning capability, as measured against standard benchmarks.", "categories": "cs.LG cs.AI cs.CL", "created": "2024-08-01", "doi": null, "arxiv_id": "2408.00307"}
{"title": "Online Computation of String Net Frequency", "authors": [], "abstract": "The net frequency (NF) of a string, of length $m$, in a text, of length $n$,\nis the number of occurrences of the string in the text with unique left and\nright extensions. Recently, Guo et al. [CPM 2024] showed that NF is\ncombinatorially interesting and how two key questions can be computed\nefficiently in the offline setting. First, SINGLE-NF: reporting the NF of a\nquery string in an input text. Second, ALL-NF: reporting an occurrence and the\nNF of each string of positive NF in an input text. For many applications,\nhowever, facilitating these computations in an online manner is highly\ndesirable. We are the first to solve the above two problems in the online\nsetting, and we do so in optimal time, assuming, as is common, a constant-size\nalphabet: SINGLE-NF in $O(m)$ time and ALL-NF in $O(n)$ time. Our results are\nachieved by first designing new and simpler offline algorithms using suffix\ntrees, proving additional properties of NF, and exploiting Ukkonen's online\nsuffix tree construction algorithm and results on implicit node maintenance in\nan implicit suffix tree by Breslauer and Italiano.", "categories": "cs.DS", "created": "2024-08-01", "doi": null, "arxiv_id": "2408.00308"}
{"title": "Discretizing Continuous Action Space with Unimodal Probability\n  Distributions for On-Policy Reinforcement Learning", "authors": [], "abstract": "For on-policy reinforcement learning, discretizing action space for\ncontinuous control can easily express multiple modes and is straightforward to\noptimize. However, without considering the inherent ordering between the\ndiscrete atomic actions, the explosion in the number of discrete actions can\npossess undesired properties and induce a higher variance for the policy\ngradient estimator. In this paper, we introduce a straightforward architecture\nthat addresses this issue by constraining the discrete policy to be unimodal\nusing Poisson probability distributions. This unimodal architecture can better\nleverage the continuity in the underlying continuous action space using\nexplicit unimodal probability distributions. We conduct extensive experiments\nto show that the discrete policy with the unimodal probability distribution\nprovides significantly faster convergence and higher performance for on-policy\nreinforcement learning algorithms in challenging control tasks, especially in\nhighly complex tasks such as Humanoid. We provide theoretical analysis on the\nvariance of the policy gradient estimator, which suggests that our attentively\ndesigned unimodal discrete policy can retain a lower variance and yield a\nstable learning process.", "categories": "cs.LG cs.AI", "created": "2024-08-01", "doi": null, "arxiv_id": "2408.00309"}
{"title": "Online Linear Programming with Batching", "authors": [], "abstract": "We study Online Linear Programming (OLP) with batching. The planning horizon\nis cut into $K$ batches, and the decisions on customers arriving within a batch\ncan be delayed to the end of their associated batch. Compared with OLP without\nbatching, the ability to delay decisions brings better operational performance,\nas measured by regret. Two research questions of interest are: (1) What is a\nlower bound of the regret as a function of $K$? (2) What algorithms can achieve\nthe regret lower bound? These questions have been analyzed in the literature\nwhen the distribution of the reward and the resource consumption of the\ncustomers have finite support. By contrast, this paper analyzes these questions\nwhen the conditional distribution of the reward given the resource consumption\nis continuous, and we show the answers are different under this setting. When\nthere is only a single type of resource and the decision maker knows the total\nnumber of customers, we propose an algorithm with a $O(\\log K)$ regret upper\nbound and provide a $\\Omega(\\log K)$ regret lower bound. We also propose\nalgorithms with $O(\\log K)$ regret upper bound for the setting in which there\nare multiple types of resource and the setting in which customers arrive\nfollowing a Poisson process. All these regret upper and lower bounds are\nindependent of the length of the planning horizon, and all the proposed\nalgorithms delay decisions on customers arriving in only the first and the last\nbatch. We also take customer impatience into consideration and establish a way\nof selecting an appropriate batch size.", "categories": "cs.LG math.OC", "created": "2024-08-01", "doi": null, "arxiv_id": "2408.00310"}
{"title": "Translating Imaging to Genomics: Leveraging Transformers for Predictive\n  Modeling", "authors": [], "abstract": "In this study, we present a novel approach for predicting genomic information\nfrom medical imaging modalities using a transformer-based model. We aim to\nbridge the gap between imaging and genomics data by leveraging transformer\nnetworks, allowing for accurate genomic profile predictions from CT/MRI images.\nPresently most studies rely on the use of whole slide images (WSI) for the\nassociation, which are obtained via invasive methodologies. We propose using\nonly available CT/MRI images to predict genomic sequences. Our transformer\nbased approach is able to efficiently generate associations between multiple\nsequences based on CT/MRI images alone. This work paves the way for the use of\nnon-invasive imaging modalities for precise and personalized healthcare,\nallowing for a better understanding of diseases and treatment.", "categories": "cs.CV", "created": "2024-08-01", "doi": null, "arxiv_id": "2408.00311"}
{"title": "Adversarial Text Rewriting for Text-aware Recommender Systems", "authors": [], "abstract": "Text-aware recommender systems incorporate rich textual features, such as\ntitles and descriptions, to generate item recommendations for users. The use of\ntextual features helps mitigate cold-start problems, and thus, such recommender\nsystems have attracted increased attention. However, we argue that the\ndependency on item descriptions makes the recommender system vulnerable to\nmanipulation by adversarial sellers on e-commerce platforms. In this paper, we\nexplore the possibility of such manipulation by proposing a new text rewriting\nframework to attack text-aware recommender systems. We show that the rewriting\nattack can be exploited by sellers to unfairly uprank their products, even\nthough the adversarially rewritten descriptions are perceived as realistic by\nhuman evaluators. Methodologically, we investigate two different variations to\ncarry out text rewriting attacks: (1) two-phase fine-tuning for greater attack\nperformance, and (2) in-context learning for higher text rewriting quality.\nExperiments spanning 3 different datasets and 4 existing approaches demonstrate\nthat recommender systems exhibit vulnerability against the proposed text\nrewriting attack. Our work adds to the existing literature around the\nrobustness of recommender systems, while highlighting a new dimension of\nvulnerability in the age of large-scale automated text generation.", "categories": "cs.IR cs.CR cs.LG cs.SI", "created": "2024-08-01", "doi": "10.1145/3627673.3679592", "arxiv_id": "2408.00312"}
{"title": "ADBM: Adversarial diffusion bridge model for reliable adversarial\n  purification", "authors": [], "abstract": "Recently Diffusion-based Purification (DiffPure) has been recognized as an\neffective defense method against adversarial examples. However, we find\nDiffPure which directly employs the original pre-trained diffusion models for\nadversarial purification, to be suboptimal. This is due to an inherent\ntrade-off between noise purification performance and data recovery quality.\nAdditionally, the reliability of existing evaluations for DiffPure is\nquestionable, as they rely on weak adaptive attacks. In this work, we propose a\nnovel Adversarial Diffusion Bridge Model, termed ADBM. ADBM directly constructs\na reverse bridge from the diffused adversarial data back to its original clean\nexamples, enhancing the purification capabilities of the original diffusion\nmodels. Through theoretical analysis and experimental validation across various\nscenarios, ADBM has proven to be a superior and robust defense mechanism,\noffering significant promise for practical applications.", "categories": "cs.LG cs.AI cs.CV", "created": "2024-08-01", "doi": null, "arxiv_id": "2408.00315"}
{"title": "Condorcet's Jury Theorem with Abstention", "authors": [], "abstract": "The well-known Condorcet's Jury theorem posits that the majority rule selects\nthe best alternative among two available options with probability one, as the\npopulation size increases to infinity. We study this result under an asymmetric\ntwo-candidate setup, where supporters of both candidates may have different\nparticipation costs.\n  When the decision to abstain is fully rational i.e., when the vote pivotality\nis the probability of a tie, the only equilibrium outcome is a trivial\nequilibrium where all voters except those with zero voting cost, abstain. We\npropose and analyze a more practical, boundedly rational model where voters\noverestimate their pivotality, and show that under this model, non-trivial\nequilibria emerge where the winning probability of both candidates is bounded\naway from one.\n  We show that when the pivotality estimate strongly depends on the margin of\nvictory, victory is not assured to any candidate in any non-trivial\nequilibrium, regardless of population size and in contrast to Condorcet's\nassertion. Whereas, under a weak dependence on margin, Condorcet's Jury theorem\nis restored.", "categories": "cs.GT cs.MA", "created": "2024-08-01", "doi": null, "arxiv_id": "2408.00317"}
{"title": "A Novel Edge Laplacian-based Approach for Adaptive Formation Control of\n  Uncertain Multi-agent Systems with Unified Relative Error Performance", "authors": [], "abstract": "For most existing prescribed performance formation control methods,\nperformance requirements are not directly imposed on the relative states\nbetween agents but on the consensus error, which lacks a clear physical\ninterpretation of their solution. In this paper, we propose a novel adaptive\nprescribed performance formation control strategy, capable of guaranteeing\nprescribed performance on the relative errors, for uncertain high-order\nmulti-agent systems under a class of directed graphs. Due to the consideration\nof performance constraints for relative errors, a coupled nonlinear interaction\nterm that contains global graphic information among agents is involved in the\nerror dynamics, leading to a fully distributed control design more difficult\nand challenging. Here by proposing a series of nonlinear mappings and utilizing\nthe edge Laplacian along with Lyapunov stability theory, the presented\nformation control scheme exhibits the following appealing features when\ncompared to existing results: 1) different performance requirements can be\nguaranteed in a unified way by solely tuning the design parameters a priori,\nwithout the need for control redesign and stability reanalysis under the\nproposed fixed control protocol, making the design more user-friendly and the\nimplementation less demanding; 2) the complex and burdensome verification\nprocess for the initial constraint, often encountered in existing prescribed\nperformance controls, is completely obviated if the performance requirements\nare global; and 3) nonlinear interaction is completely decoupled and the\nasymptotic stability of the formation manifold is ensured via using the\nadaptive parameter estimate technique. Finally, simulations of various\nperformance behaviors are performed to show the efficiency of the theoretical\nresults.", "categories": "eess.SY cs.SY", "created": "2024-08-01", "doi": null, "arxiv_id": "2408.00323"}
{"title": "Iterative Prototype Refinement for Ambiguous Speech Emotion Recognition", "authors": [], "abstract": "Recognizing emotions from speech is a daunting task due to the subtlety and\nambiguity of expressions. Traditional speech emotion recognition (SER) systems,\nwhich typically rely on a singular, precise emotion label, struggle with this\ncomplexity. Therefore, modeling the inherent ambiguity of emotions is an urgent\nproblem. In this paper, we propose an iterative prototype refinement framework\n(IPR) for ambiguous SER. IPR comprises two interlinked components: contrastive\nlearning and class prototypes. The former provides an efficient way to obtain\nhigh-quality representations of ambiguous samples. The latter are dynamically\nupdated based on ambiguous labels -- the similarity of the ambiguous data to\nall prototypes. These refined embeddings yield precise pseudo labels, thus\nreinforcing representation quality. Experimental evaluations conducted on the\nIEMOCAP dataset validate the superior performance of IPR over state-of-the-art\nmethods, thus proving the effectiveness of our proposed method.", "categories": "cs.SD eess.AS", "created": "2024-08-01", "doi": null, "arxiv_id": "2408.00325"}
{"title": "Exploiting Preferences in Loss Functions for Sequential Recommendation\n  via Weak Transitivity", "authors": [], "abstract": "A choice of optimization objective is immensely pivotal in the design of a\nrecommender system as it affects the general modeling process of a user's\nintent from previous interactions. Existing approaches mainly adhere to three\ncategories of loss functions: pairwise, pointwise, and setwise loss functions.\nDespite their effectiveness, a critical and common drawback of such objectives\nis viewing the next observed item as a unique positive while considering all\nremaining items equally negative. Such a binary label assignment is generally\nlimited to assuring a higher recommendation score of the positive item,\nneglecting potential structures induced by varying preferences between other\nunobserved items. To alleviate this issue, we propose a novel method that\nextends original objectives to explicitly leverage the different levels of\npreferences as relative orders between their scores. Finally, we demonstrate\nthe superior performance of our method compared to baseline objectives.", "categories": "cs.LG cs.IR", "created": "2024-08-01", "doi": "10.1145/3627673.3679920", "arxiv_id": "2408.00326"}
{"title": "Leveraging Virtual Reality Simulation to Engage Non-Disabled People in\n  Reflection on Access Barriers for Disabled People", "authors": [], "abstract": "Disabled people experience many barriers in daily life, but non-disabled\npeople rarely pause to reflect and engage in joint action to advocate for\naccess. In this demo, we explore the potential of Virtual Reality (VR) to\nsensitize non-disabled people to barriers in the built environment. We\ncontribute a VR simulation of a major traffic hub in Karlsruhe, Germany, and we\nemploy visual embellishments and animations to showcase barriers and potential\nremoval strategies. Through our work, we seek to engage users in conversation\non what kind of environment is accessible to whom, and what equitable\nparticipation in society requires. Additionally, we aim to expand the\nunderstanding of how VR technology can promote reflection through interactive\nexploration.", "categories": "cs.HC", "created": "2024-08-01", "doi": "10.18420/muc2024-mci-demo-303", "arxiv_id": "2408.00328"}
{"title": "OTAD: An Optimal Transport-Induced Robust Model for Agnostic Adversarial\n  Attack", "authors": [], "abstract": "Deep neural networks (DNNs) are vulnerable to small adversarial perturbations\nof the inputs, posing a significant challenge to their reliability and\nrobustness. Empirical methods such as adversarial training can defend against\nparticular attacks but remain vulnerable to more powerful attacks.\nAlternatively, Lipschitz networks provide certified robustness to unseen\nperturbations but lack sufficient expressive power. To harness the advantages\nof both approaches, we design a novel two-step Optimal Transport induced\nAdversarial Defense (OTAD) model that can fit the training data accurately\nwhile preserving the local Lipschitz continuity. First, we train a DNN with a\nregularizer derived from optimal transport theory, yielding a discrete optimal\ntransport map linking data to its features. By leveraging the map's inherent\nregularity, we interpolate the map by solving the convex integration problem\n(CIP) to guarantee the local Lipschitz property. OTAD is extensible to diverse\narchitectures of ResNet and Transformer, making it suitable for complex data.\nFor efficient computation, the CIP can be solved through training neural\nnetworks. OTAD opens a novel avenue for developing reliable and secure deep\nlearning systems through the regularity of optimal transport maps. Empirical\nresults demonstrate that OTAD can outperform other robust models on diverse\ndatasets.", "categories": "cs.LG cs.AI math.OC stat.ML", "created": "2024-08-01", "doi": null, "arxiv_id": "2408.00329"}
{"title": "\"Patriarchy Hurts Men Too.\" Does Your Model Agree? A Discussion on\n  Fairness Assumptions", "authors": [], "abstract": "The pipeline of a fair ML practitioner is generally divided into three\nphases: 1) Selecting a fairness measure. 2) Choosing a model that minimizes\nthis measure. 3) Maximizing the model's performance on the data. In the context\nof group fairness, this approach often obscures implicit assumptions about how\nbias is introduced into the data. For instance, in binary classification, it is\noften assumed that the best model, with equal fairness, is the one with better\nperformance. However, this belief already imposes specific properties on the\nprocess that introduced bias. More precisely, we are already assuming that the\nbiasing process is a monotonic function of the fair scores, dependent solely on\nthe sensitive attribute. We formally prove this claim regarding several\nimplicit fairness assumptions. This leads, in our view, to two possible\nconclusions: either the behavior of the biasing process is more complex than\nmere monotonicity, which means we need to identify and reject our implicit\nassumptions in order to develop models capable of tackling more complex\nsituations; or the bias introduced in the data behaves predictably, implying\nthat many of the developed models are superfluous.", "categories": "cs.LG", "created": "2024-08-01", "doi": null, "arxiv_id": "2408.00330"}
{"title": "DECIDER: Leveraging Foundation Model Priors for Improved Model Failure\n  Detection and Explanation", "authors": [], "abstract": "Reliably detecting when a deployed machine learning model is likely to fail\non a given input is crucial for ensuring safe operation. In this work, we\npropose DECIDER (Debiasing Classifiers to Identify Errors Reliably), a novel\napproach that leverages priors from large language models (LLMs) and\nvision-language models (VLMs) to detect failures in image classification\nmodels. DECIDER utilizes LLMs to specify task-relevant core attributes and\nconstructs a ``debiased'' version of the classifier by aligning its visual\nfeatures to these core attributes using a VLM, and detects potential failure by\nmeasuring disagreement between the original and debiased models. In addition to\nproactively identifying samples on which the model would fail, DECIDER also\nprovides human-interpretable explanations for failure through a novel\nattribute-ablation strategy. Through extensive experiments across diverse\nbenchmarks spanning subpopulation shifts (spurious correlations, class\nimbalance) and covariate shifts (synthetic corruptions, domain shifts), DECIDER\nconsistently achieves state-of-the-art failure detection performance,\nsignificantly outperforming baselines in terms of the overall Matthews\ncorrelation coefficient as well as failure and success recall. Our codes can be\naccessed at~\\url{https://github.com/kowshikthopalli/DECIDER/}", "categories": "cs.CV", "created": "2024-08-01", "doi": null, "arxiv_id": "2408.00331"}
{"title": "Vision-based Wearable Steering Assistance for People with Impaired\n  Vision in Jogging", "authors": [], "abstract": "Outdoor sports pose a challenge for people with impaired vision. The demand\nfor higher-speed mobility inspired us to develop a vision-based wearable\nsteering assistance. To ensure broad applicability, we focused on a\nrepresentative sports environment, the athletics track. Our efforts centered on\nimproving the speed and accuracy of perception, enhancing planning adaptability\nfor the real world, and providing swift and safe assistance for people with\nimpaired vision. In perception, we engineered a lightweight multitask network\ncapable of simultaneously detecting track lines and obstacles. Additionally,\ndue to the limitations of existing datasets for supporting multi-task detection\nin athletics tracks, we diligently collected and annotated a new dataset (MAT)\ncontaining 1000 images. In planning, we integrated the methods of sampling and\nspline curves, addressing the planning challenges of curves. Meanwhile, we\nutilized the positions of the track lines and obstacles as constraints to guide\npeople with impaired vision safely along the current track. Our system is\ndeployed on an embedded device, Jetson Orin NX. Through outdoor experiments, it\ndemonstrated adaptability in different sports scenarios, assisting users in\nachieving free movement of 400-meter at an average speed of 1.34 m/s, meeting\nthe level of normal people in jogging. Our MAT dataset is publicly available\nfrom https://github.com/snoopy-l/MAT", "categories": "cs.CV cs.RO", "created": "2024-08-01", "doi": null, "arxiv_id": "2408.00332"}
{"title": "DistillGrasp: Integrating Features Correlation with Knowledge\n  Distillation for Depth Completion of Transparent Objects", "authors": [], "abstract": "Due to the visual properties of reflection and refraction, RGB-D cameras\ncannot accurately capture the depth of transparent objects, leading to\nincomplete depth maps. To fill in the missing points, recent studies tend to\nexplore new visual features and design complex networks to reconstruct the\ndepth, however, these approaches tremendously increase computation, and the\ncorrelation of different visual features remains a problem. To this end, we\npropose an efficient depth completion network named DistillGrasp which\ndistillates knowledge from the teacher branch to the student branch.\nSpecifically, in the teacher branch, we design a position correlation block\n(PCB) that leverages RGB images as the query and key to search for the\ncorresponding values, guiding the model to establish correct correspondence\nbetween two features and transfer it to the transparent areas. For the student\nbranch, we propose a consistent feature correlation module (CFCM) that retains\nthe reliable regions of RGB images and depth maps respectively according to the\nconsistency and adopts a CNN to capture the pairwise relationship for depth\ncompletion. To avoid the student branch only learning regional features from\nthe teacher branch, we devise a distillation loss that not only considers the\ndistance loss but also the object structure and edge information. Extensive\nexperiments conducted on the ClearGrasp dataset manifest that our teacher\nnetwork outperforms state-of-the-art methods in terms of accuracy and\ngeneralization, and the student network achieves competitive results with a\nhigher speed of 48 FPS. In addition, the significant improvement in a\nreal-world robotic grasping system illustrates the effectiveness and robustness\nof our proposed system.", "categories": "cs.CV cs.IR", "created": "2024-08-01", "doi": null, "arxiv_id": "2408.00337"}
{"title": "MAARS: Multi-Rate Attack-Aware Randomized Scheduling for Securing\n  Real-time Systems", "authors": [], "abstract": "Modern Cyber-Physical Systems (CPSs) consist of numerous control units\ninterconnected by communication networks. Each control unit executes multiple\nsafety-critical and non-critical tasks in real-time. Most of the\nsafety-critical tasks are executed with a fixed sampling period to ensure\ndeterministic timing behaviour that helps in its safety and performance\nanalysis. However, adversaries can exploit this deterministic behaviour of\nsafety-critical tasks to launch inference-based-based attacks on them. This\npaper aims to prevent and minimize the possibility of such timing inference or\nschedule-based attacks to compromise the control units. This is done by\nswitching between strategically chosen execution rates of the safety-critical\ncontrol tasks such that their performance remains unhampered. Thereafter, we\npresent a novel schedule vulnerability analysis methodology to switch between\nvalid schedules generated for these multiple periodicities of the control tasks\nin run time. Utilizing these strategies, we introduce a novel Multi-Rate\nAttack-Aware Randomized Scheduling (MAARS) framework for preemptive\nfixed-priority schedulers that minimize the success rate of\ntiming-inference-based attacks on safety-critical real-time systems. To our\nknowledge, this is the first work to propose a schedule randomization method\nwith attack awareness that preserves both the control and scheduling aspects.\nThe efficacy of the framework in terms of attack prevention is finally\nevaluated on several automotive benchmarks in a Hardware-in-loop (HiL)\nenvironment.", "categories": "eess.SY cs.CR cs.OS cs.SY", "created": "2024-08-01", "doi": null, "arxiv_id": "2408.00341"}
{"title": "MuJoCo MPC for Humanoid Control: Evaluation on HumanoidBench", "authors": [], "abstract": "We tackle the recently introduced benchmark for whole-body humanoid control\nHumanoidBench using MuJoCo MPC. We find that sparse reward functions of\nHumanoidBench yield undesirable and unrealistic behaviors when optimized;\ntherefore, we propose a set of regularization terms that stabilize the robot\nbehavior across tasks. Current evaluations on a subset of tasks demonstrate\nthat our proposed reward function allows achieving the highest HumanoidBench\nscores while maintaining realistic posture and smooth control signals. Our code\nis publicly available and will become a part of MuJoCo MPC, enabling rapid\nprototyping of robot behaviors.", "categories": "cs.RO cs.AI cs.LG", "created": "2024-08-01", "doi": null, "arxiv_id": "2408.00342"}
{"title": "Interaural time difference loss for binaural target sound extraction", "authors": [], "abstract": "Binaural target sound extraction (TSE) aims to extract a desired sound from a\nbinaural mixture of arbitrary sounds while preserving the spatial cues of the\ndesired sound. Indeed, for many applications, the target sound signal and its\nspatial cues carry important information about the sound source. Binaural TSE\ncan be realized with a neural network trained to output only the desired sound\ngiven a binaural mixture and an embedding characterizing the desired sound\nclass as inputs. Conventional TSE systems are trained using signal-level\nlosses, which measure the difference between the extracted and reference\nsignals for the left and right channels. In this paper, we propose adding\nexplicit spatial losses to better preserve the spatial cues of the target\nsound. In particular, we explore losses aiming at preserving the interaural\nlevel (ILD), phase (IPD), and time differences (ITD). We show experimentally\nthat adding such spatial losses, particularly our newly proposed ITD loss,\nhelps preserve better spatial cues while maintaining the signal-level metrics.", "categories": "cs.SD eess.AS", "created": "2024-08-01", "doi": null, "arxiv_id": "2408.00344"}
{"title": "Neural Graph Matching for Video Retrieval in Large-Scale Video-driven\n  E-commerce", "authors": [], "abstract": "With the rapid development of the short video industry, traditional\ne-commerce has encountered a new paradigm, video-driven e-commerce, which\nleverages attractive videos for product showcases and provides both video and\nitem services for users. Benefitting from the dynamic and visualized\nintroduction of items,video-driven e-commerce has shown huge potential in\nstimulating consumer confidence and promoting sales. In this paper, we focus on\nthe video retrieval task, facing the following challenges: (1) Howto handle the\nheterogeneities among users, items, and videos? (2)How to mine the\ncomplementarity between items and videos for better user understanding? In this\npaper, we first leverage the dual graph to model the co-existing of user-video\nand user-item interactions in video-driven e-commerce and innovatively reduce\nuser preference understanding to a graph matching problem. To solve it, we\nfurther propose a novel bi-level Graph Matching Network(GMN), which mainly\nconsists of node- and preference-level graph matching. Given a user, node-level\ngraph matching aims to match videos and items, while preference-level graph\nmatching aims to match multiple user preferences extracted from both videos and\nitems. Then the proposed GMN can generate and improve user embedding by\naggregating matched nodes or preferences from the dual graph in a bi-level\nmanner. Comprehensive experiments show the superiority of the proposed GMN with\nsignificant improvements over state-of-the-art approaches (e.g., AUC+1.9% and\nCTR+7.15%). We have developed it on a well-known video-driven e-commerce\nplatform, serving hundreds of millions of users every day", "categories": "cs.LG cs.AI", "created": "2024-08-01", "doi": null, "arxiv_id": "2408.00346"}
{"title": "Advancing Medical Image Segmentation: Morphology-Driven Learning with\n  Diffusion Transformer", "authors": [], "abstract": "Understanding the morphological structure of medical images and precisely\nsegmenting the region of interest or abnormality is an important task that can\nassist in diagnosis. However, the unique properties of medical imaging make\nclear segmentation difficult, and the high cost and time-consuming task of\nlabeling leads to a coarse-grained representation of ground truth. Facing with\nthese problems, we propose a novel Diffusion Transformer Segmentation (DTS)\nmodel for robust segmentation in the presence of noise. We propose an\nalternative to the dominant Denoising U-Net encoder through experiments\napplying a transformer architecture, which captures global dependency through\nself-attention. Additionally, we propose k-neighbor label smoothing, reverse\nboundary attention, and self-supervised learning with morphology-driven\nlearning to improve the ability to identify complex structures. Our model,\nwhich analyzes the morphological representation of images, shows better results\nthan the previous models in various medical imaging modalities, including CT,\nMRI, and lesion images.", "categories": "cs.CV cs.AI", "created": "2024-08-01", "doi": null, "arxiv_id": "2408.00347"}
{"title": "Securing the Diagnosis of Medical Imaging: An In-depth Analysis of\n  AI-Resistant Attacks", "authors": [], "abstract": "Machine learning (ML) is a rapidly developing area of medicine that uses\nsignificant resources to apply computer science and statistics to medical\nissues. ML's proponents laud its capacity to handle vast, complicated, and\nerratic medical data. It's common knowledge that attackers might cause\nmisclassification by deliberately creating inputs for machine learning\nclassifiers. Research on adversarial examples has been extensively conducted in\nthe field of computer vision applications. Healthcare systems are thought to be\nhighly difficult because of the security and life-or-death considerations they\ninclude, and performance accuracy is very important. Recent arguments have\nsuggested that adversarial attacks could be made against medical image analysis\n(MedIA) technologies because of the accompanying technology infrastructure and\npowerful financial incentives. Since the diagnosis will be the basis for\nimportant decisions, it is essential to assess how strong medical DNN tasks are\nagainst adversarial attacks. Simple adversarial attacks have been taken into\naccount in several earlier studies. However, DNNs are susceptible to more risky\nand realistic attacks. The present paper covers recent proposed adversarial\nattack strategies against DNNs for medical imaging as well as countermeasures.\nIn this study, we review current techniques for adversarial imaging attacks,\ndetections. It also encompasses various facets of these techniques and offers\nsuggestions for the robustness of neural networks to be improved in the future.", "categories": "cs.CR cs.AI eess.IV", "created": "2024-08-01", "doi": null, "arxiv_id": "2408.00348"}
{"title": "A Simple Background Augmentation Method for Object Detection with\n  Diffusion Model", "authors": [], "abstract": "In computer vision, it is well-known that a lack of data diversity will\nimpair model performance. In this study, we address the challenges of enhancing\nthe dataset diversity problem in order to benefit various downstream tasks such\nas object detection and instance segmentation. We propose a simple yet\neffective data augmentation approach by leveraging advancements in generative\nmodels, specifically text-to-image synthesis technologies like Stable\nDiffusion. Our method focuses on generating variations of labeled real images,\nutilizing generative object and background augmentation via inpainting to\naugment existing training data without the need for additional annotations. We\nfind that background augmentation, in particular, significantly improves the\nmodels' robustness and generalization capabilities. We also investigate how to\nadjust the prompt and mask to ensure the generated content comply with the\nexisting annotations. The efficacy of our augmentation techniques is validated\nthrough comprehensive evaluations of the COCO dataset and several other key\nobject detection benchmarks, demonstrating notable enhancements in model\nperformance across diverse scenarios. This approach offers a promising solution\nto the challenges of dataset enhancement, contributing to the development of\nmore accurate and robust computer vision models.", "categories": "cs.CV cs.AI", "created": "2024-08-01", "doi": null, "arxiv_id": "2408.00350"}
{"title": "Hierarchically Structured Neural Bones for Reconstructing Animatable\n  Objects from Casual Videos", "authors": [], "abstract": "We propose a new framework for creating and easily manipulating 3D models of\narbitrary objects using casually captured videos. Our core ingredient is a\nnovel hierarchy deformation model, which captures motions of objects with a\ntree-structured bones. Our hierarchy system decomposes motions based on the\ngranularity and reveals the correlations between parts without exploiting any\nprior structural knowledge. We further propose to regularize the bones to be\npositioned at the basis of motions, centers of parts, sufficiently covering\nrelated surfaces of the part. This is achieved by our bone occupancy function,\nwhich identifies whether a given 3D point is placed within the bone. Coupling\nthe proposed components, our framework offers several clear advantages: (1)\nusers can obtain animatable 3D models of the arbitrary objects in improved\nquality from their casual videos, (2) users can manipulate 3D models in an\nintuitive manner with minimal costs, and (3) users can interactively add or\ndelete control points as necessary. The experimental results demonstrate the\nefficacy of our framework on diverse instances, in reconstruction quality,\ninterpretability and easier manipulation. Our code is available at\nhttps://github.com/subin6/HSNB.", "categories": "cs.CV", "created": "2024-08-01", "doi": null, "arxiv_id": "2408.00351"}
{"title": "Autonomous LLM-Enhanced Adversarial Attack for Text-to-Motion", "authors": [], "abstract": "Human motion generation driven by deep generative models has enabled\ncompelling applications, but the ability of text-to-motion (T2M) models to\nproduce realistic motions from text prompts raises security concerns if\nexploited maliciously. Despite growing interest in T2M, few methods focus on\nsafeguarding these models against adversarial attacks, with existing work on\ntext-to-image models proving insufficient for the unique motion domain. In the\npaper, we propose ALERT-Motion, an autonomous framework leveraging large\nlanguage models (LLMs) to craft targeted adversarial attacks against black-box\nT2M models. Unlike prior methods modifying prompts through predefined rules,\nALERT-Motion uses LLMs' knowledge of human motion to autonomously generate\nsubtle yet powerful adversarial text descriptions. It comprises two key\nmodules: an adaptive dispatching module that constructs an LLM-based agent to\niteratively refine and search for adversarial prompts; and a multimodal\ninformation contrastive module that extracts semantically relevant motion\ninformation to guide the agent's search. Through this LLM-driven approach,\nALERT-Motion crafts adversarial prompts querying victim models to produce\noutputs closely matching targeted motions, while avoiding obvious\nperturbations. Evaluations across popular T2M models demonstrate ALERT-Motion's\nsuperiority over previous methods, achieving higher attack success rates with\nstealthier adversarial prompts. This pioneering work on T2M adversarial attacks\nhighlights the urgency of developing defensive measures as motion generation\ntechnology advances, urging further research into safe and responsible\ndeployment.", "categories": "cs.CV", "created": "2024-08-01", "doi": null, "arxiv_id": "2408.00352"}
{"title": "Redefining Lexicographical Ordering: Optimizing Pauli String\n  Decompositions for Quantum Compiling", "authors": [], "abstract": "In quantum computing, the efficient optimization of Pauli string\ndecompositions is a crucial aspect for the compilation of quantum circuits for\nmany applications, such as chemistry simulations and quantum machine learning.\nIn this paper, we propose a novel algorithm for the synthesis of trotterized\ntime-evolution operators that results in circuits with significantly fewer\ngates than previous solutions. Our synthesis procedure takes the qubit\nconnectivity of a target quantum computer into account. As a result, the\ngenerated quantum circuit does not require routing, and no additional CNOT\ngates are needed to run the resulting circuit on a target device. We compare\nour algorithm against Paulihedral and TKET, and show a significant improvement\nfor randomized circuits and different molecular ansatzes. We also investigate\nthe Trotter error introduced by our ordering of the terms in the Hamiltonian\nversus default ordering and the ordering from the baseline methods and conclude\nthat our method on average does not increase the Trotter error.", "categories": "quant-ph cs.DS cs.PL", "created": "2024-08-01", "doi": null, "arxiv_id": "2408.00354"}
{"title": "DNTextSpotter: Arbitrary-Shaped Scene Text Spotting via Improved\n  Denoising Training", "authors": [], "abstract": "More and more end-to-end text spotting methods based on Transformer\narchitecture have demonstrated superior performance. These methods utilize a\nbipartite graph matching algorithm to perform one-to-one optimal matching\nbetween predicted objects and actual objects. However, the instability of\nbipartite graph matching can lead to inconsistent optimization targets, thereby\naffecting the training performance of the model. Existing literature applies\ndenoising training to solve the problem of bipartite graph matching instability\nin object detection tasks. Unfortunately, this denoising training method cannot\nbe directly applied to text spotting tasks, as these tasks need to perform\nirregular shape detection tasks and more complex text recognition tasks than\nclassification. To address this issue, we propose a novel denoising training\nmethod (DNTextSpotter) for arbitrary-shaped text spotting. Specifically, we\ndecompose the queries of the denoising part into noised positional queries and\nnoised content queries. We use the four Bezier control points of the Bezier\ncenter curve to generate the noised positional queries. For the noised content\nqueries, considering that the output of the text in a fixed positional order is\nnot conducive to aligning position with content, we employ a masked character\nsliding method to initialize noised content queries, thereby assisting in the\nalignment of text content and position. To improve the model's perception of\nthe background, we further utilize an additional loss function for background\ncharacters classification in the denoising training part.Although DNTextSpotter\nis conceptually simple, it outperforms the state-of-the-art methods on four\nbenchmarks (Total-Text, SCUT-CTW1500, ICDAR15, and Inverse-Text), especially\nyielding an improvement of 11.3% against the best approach in Inverse-Text\ndataset.", "categories": "cs.CV cs.AI", "created": "2024-08-01", "doi": null, "arxiv_id": "2408.00355"}
{"title": "DeliLaw: A Chinese Legal Counselling System Based on a Large Language\n  Model", "authors": [], "abstract": "Traditional legal retrieval systems designed to retrieve legal documents,\nstatutes, precedents, and other legal information are unable to give\nsatisfactory answers due to lack of semantic understanding of specific\nquestions. Large Language Models (LLMs) have achieved excellent results in a\nvariety of natural language processing tasks, which inspired us that we train a\nLLM in the legal domain to help legal retrieval. However, in the Chinese legal\ndomain, due to the complexity of legal questions and the rigour of legal\narticles, there is no legal large model with satisfactory practical application\nyet. In this paper, we present DeliLaw, a Chinese legal counselling system\nbased on a large language model. DeliLaw integrates a legal retrieval module\nand a case retrieval module to overcome the model hallucination. Users can\nconsult professional legal questions, search for legal articles and relevant\njudgement cases, etc. on the DeliLaw system in a dialogue mode. In addition,\nDeliLaw supports the use of English for counseling. we provide the address of\nthe system: https://data.delilegal.com/lawQuestion.", "categories": "cs.CL", "created": "2024-08-01", "doi": "10.1145/3627673.3679219", "arxiv_id": "2408.00357"}
{"title": "Memorization Capacity for Additive Fine-Tuning with Small ReLU Networks", "authors": [], "abstract": "Fine-tuning large pre-trained models is a common practice in machine learning\napplications, yet its mathematical analysis remains largely unexplored. In this\npaper, we study fine-tuning through the lens of memorization capacity. Our new\nmeasure, the Fine-Tuning Capacity (FTC), is defined as the maximum number of\nsamples a neural network can fine-tune, or equivalently, as the minimum number\nof neurons ($m$) needed to arbitrarily change $N$ labels among $K$ samples\nconsidered in the fine-tuning process. In essence, FTC extends the memorization\ncapacity concept to the fine-tuning scenario. We analyze FTC for the additive\nfine-tuning scenario where the fine-tuned network is defined as the summation\nof the frozen pre-trained network $f$ and a neural network $g$ (with $m$\nneurons) designed for fine-tuning. When $g$ is a ReLU network with either 2 or\n3 layers, we obtain tight upper and lower bounds on FTC; we show that $N$\nsamples can be fine-tuned with $m=\\Theta(N)$ neurons for 2-layer networks, and\nwith $m=\\Theta(\\sqrt{N})$ neurons for 3-layer networks, no matter how large $K$\nis. Our results recover the known memorization capacity results when $N = K$ as\na special case.", "categories": "cs.LG stat.ML", "created": "2024-08-01", "doi": null, "arxiv_id": "2408.00359"}
{"title": "High-Precision Self-Supervised Monocular Depth Estimation with\n  Rich-Resource Prior", "authors": [], "abstract": "In the area of self-supervised monocular depth estimation, models that\nutilize rich-resource inputs, such as high-resolution and multi-frame inputs,\ntypically achieve better performance than models that use ordinary single image\ninput. However, these rich-resource inputs may not always be available,\nlimiting the applicability of these methods in general scenarios. In this\npaper, we propose Rich-resource Prior Depth estimator (RPrDepth), which only\nrequires single input image during the inference phase but can still produce\nhighly accurate depth estimations comparable to rich resource based methods.\nSpecifically, we treat rich-resource data as prior information and extract\nfeatures from it as reference features in an offline manner. When estimating\nthe depth for a single-image image, we search for similar pixels from the\nrich-resource features and use them as prior information to estimate the depth.\nExperimental results demonstrate that our model outperform other single-image\nmodel and can achieve comparable or even better performance than models with\nrich-resource inputs, only using low-resolution single-image input.", "categories": "cs.CV", "created": "2024-08-01", "doi": null, "arxiv_id": "2408.00361"}
{"title": "Multimodal Fusion and Coherence Modeling for Video Topic Segmentation", "authors": [], "abstract": "The video topic segmentation (VTS) task segments videos into intelligible,\nnon-overlapping topics, facilitating efficient comprehension of video content\nand quick access to specific content. VTS is also critical to various\ndownstream video understanding tasks. Traditional VTS methods using shallow\nfeatures or unsupervised approaches struggle to accurately discern the nuances\nof topical transitions. Recently, supervised approaches have achieved superior\nperformance on video action or scene segmentation over unsupervised approaches.\nIn this work, we improve supervised VTS by thoroughly exploring multimodal\nfusion and multimodal coherence modeling. Specifically, (1) we enhance\nmultimodal fusion by exploring different architectures using cross-attention\nand mixture of experts. (2) To generally strengthen multimodality alignment and\nfusion, we pre-train and fine-tune the model with multimodal contrastive\nlearning. (3) We propose a new pre-training task tailored for the VTS task, and\na novel fine-tuning task for enhancing multimodal coherence modeling for VTS.\nWe evaluate the proposed approaches on educational videos, in the form of\nlectures, due to the vital role of topic segmentation of educational videos in\nboosting learning experiences. Additionally, we introduce a large-scale Chinese\nlecture video dataset to augment the existing English corpus, promoting further\nresearch in VTS. Experiments on both English and Chinese lecture datasets\ndemonstrate that our model achieves superior VTS performance compared to\ncompetitive unsupervised and supervised baselines.", "categories": "cs.AI cs.CV eess.IV", "created": "2024-08-01", "doi": null, "arxiv_id": "2408.00365"}
{"title": "DiM-Gesture: Co-Speech Gesture Generation with Adaptive Layer\n  Normalization Mamba-2 framework", "authors": [], "abstract": "Speech-driven gesture generation is an emerging domain within virtual human\ncreation, where current methods predominantly utilize Transformer-based\narchitectures that necessitate extensive memory and are characterized by slow\ninference speeds. In response to these limitations, we propose\n\\textit{DiM-Gestures}, a novel end-to-end generative model crafted to create\nhighly personalized 3D full-body gestures solely from raw speech audio,\nemploying Mamba-based architectures. This model integrates a Mamba-based fuzzy\nfeature extractor with a non-autoregressive Adaptive Layer Normalization\n(AdaLN) Mamba-2 diffusion architecture. The extractor, leveraging a Mamba\nframework and a WavLM pre-trained model, autonomously derives implicit,\ncontinuous fuzzy features, which are then unified into a singular latent\nfeature. This feature is processed by the AdaLN Mamba-2, which implements a\nuniform conditional mechanism across all tokens to robustly model the interplay\nbetween the fuzzy features and the resultant gesture sequence. This innovative\napproach guarantees high fidelity in gesture-speech synchronization while\nmaintaining the naturalness of the gestures. Employing a diffusion model for\ntraining and inference, our framework has undergone extensive subjective and\nobjective evaluations on the ZEGGS and BEAT datasets. These assessments\nsubstantiate our model's enhanced performance relative to contemporary\nstate-of-the-art methods, demonstrating competitive outcomes with the DiTs\narchitecture (Persona-Gestors) while optimizing memory usage and accelerating\ninference speed.", "categories": "cs.GR cs.AI cs.RO cs.SD", "created": "2024-08-01", "doi": null, "arxiv_id": "2408.00370"}
{"title": "Few-shot Defect Image Generation based on Consistency Modeling", "authors": [], "abstract": "Image generation can solve insufficient labeled data issues in defect\ndetection. Most defect generation methods are only trained on a single product\nwithout considering the consistencies among multiple products, leading to poor\nquality and diversity of generated results. To address these issues, we propose\nDefectDiffu, a novel text-guided diffusion method to model both intra-product\nbackground consistency and inter-product defect consistency across multiple\nproducts and modulate the consistency perturbation directions to control\nproduct type and defect strength, achieving diversified defect image\ngeneration. Firstly, we leverage a text encoder to separately provide\nconsistency prompts for background, defect, and fusion parts of the\ndisentangled integrated architecture, thereby disentangling defects and normal\nbackgrounds. Secondly, we propose the double-free strategy to generate defect\nimages through two-stage perturbation of consistency direction, thereby\ncontrolling product type and defect strength by adjusting the perturbation\nscale. Besides, DefectDiffu can generate defect mask annotations utilizing\ncross-attention maps from the defect part. Finally, to improve the generation\nquality of small defects and masks, we propose the adaptive attention-enhance\nloss to increase the attention to defects. Experimental results demonstrate\nthat DefectDiffu surpasses state-of-the-art methods in terms of generation\nquality and diversity, thus effectively improving downstream defection\nperformance. Moreover, defect perturbation directions can be transferred among\nvarious products to achieve zero-shot defect generation, which is highly\nbeneficial for addressing insufficient data issues. The code are available at\nhttps://github.com/FFDD-diffusion/DefectDiffu.", "categories": "cs.CV", "created": "2024-08-01", "doi": null, "arxiv_id": "2408.00372"}
{"title": "On the Limitations and Prospects of Machine Unlearning for Generative AI", "authors": [], "abstract": "Generative AI (GenAI), which aims to synthesize realistic and diverse data\nsamples from latent variables or other data modalities, has achieved remarkable\nresults in various domains, such as natural language, images, audio, and\ngraphs. However, they also pose challenges and risks to data privacy, security,\nand ethics. Machine unlearning is the process of removing or weakening the\ninfluence of specific data samples or features from a trained model, without\naffecting its performance on other data or tasks. While machine unlearning has\nshown significant efficacy in traditional machine learning tasks, it is still\nunclear if it could help GenAI become safer and aligned with human desire. To\nthis end, this position paper provides an in-depth discussion of the machine\nunlearning approaches for GenAI. Firstly, we formulate the problem of machine\nunlearning tasks on GenAI and introduce the background. Subsequently, we\nsystematically examine the limitations of machine unlearning on GenAI models by\nfocusing on the two representative branches: LLMs and image generative\n(diffusion) models. Finally, we provide our prospects mainly from three\naspects: benchmark, evaluation metrics, and utility-unlearning trade-off, and\nconscientiously advocate for the future development of this field.", "categories": "cs.LG cs.AI", "created": "2024-08-01", "doi": null, "arxiv_id": "2408.00376"}
{"title": "A deep spatio-temporal attention model of dynamic functional network\n  connectivity shows sensitivity to Alzheimer's in asymptomatic individuals", "authors": [], "abstract": "Alzheimer's disease (AD) progresses from asymptomatic changes to clinical\nsymptoms, emphasizing the importance of early detection for proper treatment.\nFunctional magnetic resonance imaging (fMRI), particularly dynamic functional\nnetwork connectivity (dFNC), has emerged as an important biomarker for AD.\nNevertheless, studies probing at-risk subjects in the pre-symptomatic stage\nusing dFNC are limited. To identify at-risk subjects and understand alterations\nof dFNC in different stages, we leverage deep learning advancements and\nintroduce a transformer-convolution framework for predicting at-risk subjects\nbased on dFNC, incorporating spatial-temporal self-attention to capture brain\nnetwork dependencies and temporal dynamics. Our model significantly outperforms\nother popular machine learning methods. By analyzing individuals with diagnosed\nAD and mild cognitive impairment (MCI), we studied the AD progression and\nobserved a higher similarity between MCI and asymptomatic AD. The interpretable\nanalysis highlights the cognitive-control network's diagnostic importance, with\nthe model focusing on intra-visual domain dFNC when predicting asymptomatic AD\nsubjects.", "categories": "cs.CE", "created": "2024-08-01", "doi": null, "arxiv_id": "2408.00378"}
{"title": "Finding Defective Elements in Intelligent Reflecting Surface via\n  Over-the-Air Measurements", "authors": [], "abstract": "Due to circuit failures, defective elements that cannot adaptively adjust the\nphase shifts of their impinging signals in a desired manner may exist on an\nintelligent reflecting surface (IRS). Traditional way to find these defective\nIRS elements requires a thorough diagnosis of all the circuits belonging to a\nhuge number of IRS elements, which is practically challenging. In this paper,\nwe will devise a novel approach under which a transmitter sends known pilot\nsignals and a receiver localizes all the defective IRS elements just based on\nits over-the-air measurements reflected from the IRS. The key lies in the fact\nthat the over-the-air measurements at the receiver side are functions of the\nset of defective IRS elements. Based on this observation, we propose a\nbisection based method to localize all the defective IRS elements.\nSpecifically, at each time slot, we properly control the desired phase shifts\nof all the IRS elements such that half of the considered regime that is not\nuseful to localize the defective elements can be found based on the received\nsignals and removed. Via numerical results, it is shown that our proposed\nbisection method can exploit the over-the-air measurements to localize all the\ndefective IRS elements quickly and accurately.", "categories": "eess.SP cs.IT math.IT", "created": "2024-08-01", "doi": null, "arxiv_id": "2408.00379"}
{"title": "Statistical AoI Guarantee Optimization for Supporting xURLLC in\n  ISAC-enabled V2I Networks", "authors": [], "abstract": "This paper addresses the critical challenge of supporting next-generation\nultra-reliable and low-latency communication (xURLLC) within integrated sensing\nand communication (ISAC)-enabled vehicle-to-infrastructure (V2I) networks. We\nincorporate channel evaluation and retransmission mechanisms for real-time\nreliability enhancement. Using stochastic network calculus (SNC), we establish\na theoretical framework to derive upper bounds for the peak age of information\nviolation probability (PAVP) via characterized sensing and communication moment\ngeneration functions (MGFs). By optimizing these bounds, we develop power\nallocation schemes that significantly reduce the statistical PAVP of sensory\npackets in such networks. Simulations validate our theoretical derivations and\ndemonstrate the effectiveness of our proposed schemes.", "categories": "cs.IT cs.SY eess.SY math.IT", "created": "2024-08-01", "doi": null, "arxiv_id": "2408.00381"}
{"title": "Quantitative Group Testing and Pooled Data in the Linear Regime with\n  Sublinear Tests", "authors": [], "abstract": "In the pooled data problem, the goal is to identify the categories associated\nwith a large collection of items via a sequence of pooled tests. Each pooled\ntest reveals the number of items in the pool belonging to each category. A\nprominent special case is quantitative group testing (QGT), which is the case\nof pooled data with two categories. We consider these problems in the\nnon-adaptive and linear regime, where the fraction of items in each category is\nof constant order. We propose a scheme with a spatially coupled Bernoulli test\nmatrix and an efficient approximate message passing (AMP) algorithm for\nrecovery. We rigorously characterize its asymptotic performance in both the\nnoiseless and noisy settings, and prove that in the noiseless case, the AMP\nalgorithm achieves almost-exact recovery with a number of tests sublinear in\nthe number of items. For both QGT and pooled data, this is the first efficient\nscheme that provably achieves recovery in the linear regime with a sublinear\nnumber of tests, with performance degrading gracefully in the presence of\nnoise. Numerical simulations illustrate the benefits of the spatially coupled\nscheme at finite dimensions, showing that it outperforms i.i.d. test designs as\nwell as other recovery algorithms based on convex programming.", "categories": "cs.IT eess.SP math.IT", "created": "2024-08-01", "doi": null, "arxiv_id": "2408.00385"}
{"title": "What comes after transformers? -- A selective survey connecting ideas in\n  deep learning", "authors": [], "abstract": "Transformers have become the de-facto standard model in artificial\nintelligence since 2017 despite numerous shortcomings ranging from energy\ninefficiency to hallucinations. Research has made a lot of progress in\nimproving elements of transformers, and, more generally, deep learning\nmanifesting in many proposals for architectures, layers, optimization\nobjectives, and optimization techniques. For researchers it is difficult to\nkeep track of such developments on a broader level. We provide a comprehensive\noverview of the many important, recent works in these areas to those who\nalready have a basic understanding of deep learning. Our focus differs from\nother works, as we target specifically novel, alternative potentially\ndisruptive approaches to transformers as well as successful ideas of recent\ndeep learning. We hope that such a holistic and unified treatment of\ninfluential, recent works and novel ideas helps researchers to form new\nconnections between diverse areas of deep learning. We identify and discuss\nmultiple patterns that summarize the key strategies for successful innovations\nover the last decade as well as works that can be seen as rising stars.\nEspecially, we discuss attempts on how to improve on transformers covering\n(partially) proven methods such as state space models but also including\nfar-out ideas in deep learning that seem promising despite not achieving\nstate-of-the-art results. We also cover a discussion on recent state-of-the-art\nmodels such as OpenAI's GPT series and Meta's LLama models and, Google's Gemini\nmodel family.", "categories": "cs.LG", "created": "2024-08-01", "doi": null, "arxiv_id": "2408.00386"}
{"title": "Deepfake Media Forensics: State of the Art and Challenges Ahead", "authors": [], "abstract": "AI-generated synthetic media, also called Deepfakes, have significantly\ninfluenced so many domains, from entertainment to cybersecurity. Generative\nAdversarial Networks (GANs) and Diffusion Models (DMs) are the main frameworks\nused to create Deepfakes, producing highly realistic yet fabricated content.\nWhile these technologies open up new creative possibilities, they also bring\nsubstantial ethical and security risks due to their potential misuse. The rise\nof such advanced media has led to the development of a cognitive bias known as\nImpostor Bias, where individuals doubt the authenticity of multimedia due to\nthe awareness of AI's capabilities. As a result, Deepfake detection has become\na vital area of research, focusing on identifying subtle inconsistencies and\nartifacts with machine learning techniques, especially Convolutional Neural\nNetworks (CNNs). Research in forensic Deepfake technology encompasses five main\nareas: detection, attribution and recognition, passive authentication,\ndetection in realistic scenarios, and active authentication. Each area tackles\nspecific challenges, from tracing the origins of synthetic media and examining\nits inherent characteristics for authenticity. This paper reviews the primary\nalgorithms that address these challenges, examining their advantages,\nlimitations, and future prospects.", "categories": "cs.CV", "created": "2024-08-01", "doi": null, "arxiv_id": "2408.00388"}
{"title": "Polynomial quasi-Trefftz DG for PDEs with smooth coefficients: elliptic\n  problems", "authors": [], "abstract": "Trefftz schemes are high-order Galerkin methods whose discrete spaces are\nmade of elementwise exact solutions of the underlying PDE. Trefftz basis\nfunctions can be easily computed for many PDEs that are linear, homogeneous,\nand have piecewise-constant coefficients. However, if the equation has variable\ncoefficients, exact solutions are generally unavailable. Quasi-Trefftz methods\novercome this limitation relying on elementwise \"approximate solutions\" of the\nPDE, in the sense of Taylor polynomials.\n  We define polynomial quasi-Trefftz spaces for general linear PDEs with smooth\ncoefficients and source term, describe their approximation properties and,\nunder a non-degeneracy condition, provide a simple algorithm to compute a\nbasis. We then focus on a quasi-Trefftz DG method for variable-coefficient\nelliptic diffusion-advection-reaction problems, showing stability and\nhigh-order convergence of the scheme. The main advantage over standard DG\nschemes is the higher accuracy for comparable numbers of degrees of freedom.\nFor non-homogeneous problems with piecewise-smooth source term we propose to\nconstruct a local quasi-Trefftz particular solution and then solve for the\ndifference. Numerical experiments in 2 and 3 space dimensions show the\nexcellent properties of the method both in diffusion-dominated and\nadvection-dominated problems.", "categories": "math.NA cs.NA", "created": "2024-08-01", "doi": null, "arxiv_id": "2408.00392"}
{"title": "A Zero-Knowledge Proof of Knowledge for Subgroup Distance Problem", "authors": [], "abstract": "In this study, we introduce a novel zero-knowledge identification scheme\nbased on the hardness of the subgroup distance problem in the Hamming metric.\nThe proposed protocol, named Subgroup Distance Zero Knowledge Proof (SDZKP),\nemploys a cryptographically secure pseudorandom number generator to mask\nsecrets and utilizes a Stern-type algorithm to ensure robust security\nproperties.", "categories": "cs.CR math.GR", "created": "2024-08-01", "doi": null, "arxiv_id": "2408.00395"}
{"title": "Analysis of continuous data assimilation with large (or even infinite)\n  nudging parameters", "authors": [], "abstract": "This paper considers continuous data assimilation (CDA) in partial\ndifferential equation (PDE) discretizations where nudging parameters can be\ntaken arbitrarily large. We prove that long-time optimally accurate solutions\nare obtained for such parameters for the heat and Navier-Stokes equations\n(using implicit time stepping methods), with error bounds that do not grow as\nthe nudging parameter gets large. Existing theoretical results either prove\noptimal accuracy but with the error scaled by the nudging parameter, or\nsuboptimal accuracy that is independent of it. The key idea to the improved\nanalysis is to decompose the error based on a weighted inner product that\nincorporates the (symmetric by construction) nudging term, and prove that the\nprojection error from this weighted inner product is optimal and independent of\nthe nudging parameter. We apply the idea to BDF2 - finite element\ndiscretizations of the heat equation and Navier-Stokes equations to show that\nwith CDA, they will admit optimal long-time accurate solutions independent of\nthe nudging parameter, for nudging parameters large enough. Several numerical\ntests are given for the heat equation, fluid transport equation, Navier-Stokes,\nand Cahn-Hilliard that illustrate the theory.", "categories": "math.NA cs.NA", "created": "2024-08-01", "doi": null, "arxiv_id": "2408.00396"}
{"title": "In-Context Example Selection via Similarity Search Improves Low-Resource\n  Machine Translation", "authors": [], "abstract": "The ability of generative large language models (LLMs) to perform in-context\nlearning has given rise to a large body of research into how best to prompt\nmodels for various natural language processing tasks. In this paper, we focus\non machine translation (MT), a task that has been shown to benefit from\nin-context translation examples. However no systematic studies have been\npublished on how best to select examples, and mixed results have been reported\non the usefulness of similarity-based selection over random selection. We\nprovide a study covering multiple LLMs and multiple in-context example\nretrieval strategies, comparing multilingual sentence embeddings. We cover\nseveral language directions, representing different levels of language\nresourcedness (English into French, German, Swahili and Wolof). Contrarily to\npreviously published results, we find that sentence embedding similarity can\nimprove MT, especially for low-resource language directions, and discuss the\nbalance between selection pool diversity and quality. We also highlight\npotential problems with the evaluation of LLM-based MT and suggest a more\nappropriate evaluation protocol, adapting the COMET metric to the evaluation of\nLLMs. Code and outputs are freely available at\nhttps://github.com/ArmelRandy/ICL-MT.", "categories": "cs.CL", "created": "2024-08-01", "doi": null, "arxiv_id": "2408.00397"}
{"title": "Log Diameter Rounds MST Verification and Sensitivity in MPC", "authors": [], "abstract": "We consider two natural variants of the problem of minimum spanning tree\n(MST) of a graph in the parallel setting: MST verification (verifying if a\ngiven tree is an MST) and the sensitivity analysis of an MST (finding the\nlowest cost replacement edge for each edge of the MST). These two problems have\nbeen studied extensively for sequential algorithms and for parallel algorithms\nin the PRAM model of computation. In this paper, we extend the study to the\nstandard model of Massive Parallel Computation (MPC).\n  It is known that for graphs of diameter $D$, the connectivity problem can be\nsolved in $O(\\log D + \\log\\log n)$ rounds on an MPC with low local memory (each\nmachine can store only $O(n^{\\delta})$ words for an arbitrary constant $\\delta\n> 0$) and with linear global memory, that is, with optimal utilization.\nHowever, for the related task of finding an MST, we need $\\Omega(\\log\nD_{\\text{MST}})$ rounds, where $D_{\\text{MST}}$ denotes the diameter of the\nminimum spanning tree. The state of the art upper bound for MST is $O(\\log n)$\nrounds; the result follows by simulating existing PRAM algorithms. While this\nbound may be optimal for general graphs, the benchmark of connectivity and\nlower bound for MST suggest the target bound of $O(\\log D_{\\text{MST}})$\nrounds, or possibly $O(\\log D_{\\text{MST}} + \\log\\log n)$ rounds. As for now,\nwe do not know if this bound is achievable for the MST problem on an MPC with\nlow local memory and linear global memory. In this paper, we show that two\nnatural variants of the MST problem: MST verification and sensitivity analysis\nof an MST, can be completed in $O(\\log D_T)$ rounds on an MPC with low local\nmemory and with linear global memory; here $D_T$ is the diameter of the input\n``candidate MST'' $T$. The algorithms asymptotically match our lower bound,\nconditioned on the 1-vs-2-cycle conjecture.", "categories": "cs.DS", "created": "2024-08-01", "doi": null, "arxiv_id": "2408.00398"}
{"title": "Unsupervised Pairwise Causal Discovery on Heterogeneous Data using\n  Mutual Information Measures", "authors": [], "abstract": "A fundamental task in science is to determine the underlying causal relations\nbecause it is the knowledge of this functional structure what leads to the\ncorrect interpretation of an effect given the apparent associations in the\nobserved data. In this sense, Causal Discovery is a technique that tackles this\nchallenge by analyzing the statistical properties of the constituent variables.\nIn this work, we target the generalizability of the discovery method by\nfollowing a reductionist approach that only involves two variables, i.e., the\npairwise or bi-variate setting. We question the current (possibly misleading)\nbaseline results on the basis that they were obtained through supervised\nlearning, which is arguably contrary to this genuinely exploratory endeavor. In\nconsequence, we approach this problem in an unsupervised way, using robust\nMutual Information measures, and observing the impact of the different variable\ntypes, which is oftentimes ignored in the design of solutions. Thus, we provide\na novel set of standard unbiased results that can serve as a reference to guide\nfuture discovery tasks in completely unknown environments.", "categories": "cs.AI cs.LG stat.ME", "created": "2024-08-01", "doi": null, "arxiv_id": "2408.00399"}
{"title": "Micro frequency hopping spread spectrum modulation and encryption\n  technology", "authors": [], "abstract": "By combining traditional frequency hopping ideas with the concepts of\nsubcarriers and sampling points in OFDM baseband systems, this paper proposes a\nfrequency hopping technology within the baseband called micro frequency\nhopping. Based on the concept of micro frequency hopping, this paper proposes a\nmicro frequency hopping spread spectrum modulation method based on cyclic\nfrequency shift and cyclic time shift, as well as a micro frequency hopping\nencryption method based on phase scrambling of baseband signals. Specifically,\nthis paper reveals a linear micro frequency hopping symbol with good\nauto-correlation and cross-correlation feature in both time domain and\nfrequency domain. Linear micro frequency hopping symbols with different root\n$R$ have good cross-correlation feature, which can be used in multi-user\ncommunication at same time and same frequency. Moreover, there is a linear\nrelationship between the time delay and frequency offset of this linear micro\nfrequency hopping symbol, making it suitable for time delay and frequency\noffset estimation, also for ranging, and speed measurement. Finally, this paper\nalso verifies the advantages of micro frequency hopping technology through an\nexample of a linear micro frequency hopping spread spectrum multiple access\ncommunication system. The author believes that micro frequency hopping\ntechnology will be widely used in fields such as the Internet of Things,\nmilitary communication, satellite communication, satellite positioning, and\nradar etc.", "categories": "cs.IT math.IT", "created": "2024-08-01", "doi": null, "arxiv_id": "2408.00400"}
{"title": "Task-oriented and Semantics-aware Communications for Augmented Reality", "authors": [], "abstract": "Upon the advent of the emerging metaverse and its related applications in\nAugmented Reality (AR), the current bit-oriented network struggles to support\nreal-time changes for the vast amount of associated information, creating a\nsignificant bottleneck in its development. To address the above problem, we\npresent a novel task-oriented and semantics-aware communication framework for\naugmented reality (TSAR) to enhance communication efficiency and effectiveness\nsignificantly. We first present an analysis of the traditional wireless AR\npoint cloud communication framework, followed by a detailed summary of our\nproposed semantic information extraction within the end-to-end communication.\nThen, we detail the components of the TSAR framework, incorporating semantics\nextraction with deep learning, task-oriented base knowledge selection, and\navatar pose recovery. Through rigorous experimentation, we demonstrate that our\nproposed TSAR framework considerably outperforms traditional point cloud\ncommunication framework, reducing wireless AR application transmission latency\nby 95.6% and improving communication effectiveness in geometry and color\naspects by up to 82.4% and 20.4%, respectively.", "categories": "eess.SY cs.SY", "created": "2024-08-01", "doi": null, "arxiv_id": "2408.00407"}
{"title": "Low-level I/O Monitoring for Scientific Workflows", "authors": [], "abstract": "While detailed resource usage monitoring is possible on the low-level using\nproper tools, associating such usage with higher-level abstractions in the\napplication layer that actually cause the resource usage in the first place\npresents a number of challenges. Suppose a large-scale scientific data analysis\nworkflow is run using a distributed execution environment such as a compute\ncluster or cloud environment and we want to analyze the I/O behaviour of it to\nfind and alleviate potential bottlenecks. Different tasks of the workflow can\nbe assigned to arbitrary compute nodes and may even share the same compute\nnodes. Thus, locally observed resource usage is not directly associated with\nthe individual workflow tasks. By acquiring resource usage profiles of the\ninvolved nodes, we seek to correlate the trace data to the workflow and its\nindividual tasks. To accomplish that, we select the proper set of metadata\nassociated with low-level traces that let us associate them with higher-level\ntask information obtained from log files of the workflow execution as well as\nthe job management using a task orchestrator such as Kubernetes with its\ncontainer management. Ensuring a proper information chain allows the\nclassification of observed I/O on a logical task level and may reveal the most\ncostly or inefficient tasks of a scientific workflow that are most promising\nfor optimization.", "categories": "cs.DC", "created": "2024-08-01", "doi": null, "arxiv_id": "2408.00411"}
{"title": "DriveArena: A Closed-loop Generative Simulation Platform for Autonomous\n  Driving", "authors": [], "abstract": "This paper presented DriveArena, the first high-fidelity closed-loop\nsimulation system designed for driving agents navigating in real scenarios.\nDriveArena features a flexible, modular architecture, allowing for the seamless\ninterchange of its core components: Traffic Manager, a traffic simulator\ncapable of generating realistic traffic flow on any worldwide street map, and\nWorld Dreamer, a high-fidelity conditional generative model with infinite\nautoregression. This powerful synergy empowers any driving agent capable of\nprocessing real-world images to navigate in DriveArena's simulated environment.\nThe agent perceives its surroundings through images generated by World Dreamer\nand output trajectories. These trajectories are fed into Traffic Manager,\nachieving realistic interactions with other vehicles and producing a new scene\nlayout. Finally, the latest scene layout is relayed back into World Dreamer,\nperpetuating the simulation cycle. This iterative process fosters closed-loop\nexploration within a highly realistic environment, providing a valuable\nplatform for developing and evaluating driving agents across diverse and\nchallenging scenarios. DriveArena signifies a substantial leap forward in\nleveraging generative image data for the driving simulation platform, opening\ninsights for closed-loop autonomous driving. Code will be available soon on\nGitHub: https://github.com/PJLab-ADG/DriveArena", "categories": "cs.RO cs.AI cs.CV", "created": "2024-08-01", "doi": null, "arxiv_id": "2408.00415"}
{"title": "A Batch Update Using Multiplicative Noise Modelling for Extended Object\n  Tracking", "authors": [], "abstract": "While the tracking of multiple extended targets demands for sophisticated\nalgorithms to handle the high complexity inherent to the task, it also requires\nlow runtime for online execution in real-world scenarios. In this work, we\nderive a batch update for the recently introduced elliptical-target tracker\ncalled MEM-EKF*. The MEM-EKF* is based on the same likelihood as the\nwell-established random matrix approach but is derived from the multiplicative\nerror model (MEM) and uses an extended Kalman filter (EKF) to update the target\nstate sequentially, i.e., measurement-by-measurement. Our batch variant updates\nthe target state in a single step based on straightforward sums over all\nmeasurements and the MEM-specific pseudo-measurements. This drastically reduces\nthe scaling constant for typical implementations and indeed we find a speedup\nof roughly 100x in our numerical experiments. At the same time, the estimation\nerror which we measure using the Gaussian Wasserstein distance stays\nsignificantly below that of the random matrix approach in coordinated turn\nscenarios while being comparable otherwise.", "categories": "eess.SY cs.SY", "created": "2024-08-01", "doi": null, "arxiv_id": "2408.00417"}
{"title": "Towards Reliable Advertising Image Generation Using Human Feedback", "authors": [], "abstract": "In the e-commerce realm, compelling advertising images are pivotal for\nattracting customer attention. While generative models automate image\ngeneration, they often produce substandard images that may mislead customers\nand require significant labor costs to inspect. This paper delves into\nincreasing the rate of available generated images. We first introduce a\nmulti-modal Reliable Feedback Network (RFNet) to automatically inspect the\ngenerated images. Combining the RFNet into a recurrent process, Recurrent\nGeneration, results in a higher number of available advertising images. To\nfurther enhance production efficiency, we fine-tune diffusion models with an\ninnovative Consistent Condition regularization utilizing the feedback from\nRFNet (RFFT). This results in a remarkable increase in the available rate of\ngenerated images, reducing the number of attempts in Recurrent Generation, and\nproviding a highly efficient production process without sacrificing visual\nappeal. We also construct a Reliable Feedback 1 Million (RF1M) dataset which\ncomprises over one million generated advertising images annotated by human,\nwhich helps to train RFNet to accurately assess the availability of generated\nimages and faithfully reflect the human feedback. Generally speaking, our\napproach offers a reliable solution for advertising image generation.", "categories": "cs.CV", "created": "2024-08-01", "doi": null, "arxiv_id": "2408.00418"}
{"title": "MPT-PAR:Mix-Parameters Transformer for Panoramic Activity Recognition", "authors": [], "abstract": "The objective of the panoramic activity recognition task is to identify\nbehaviors at various granularities within crowded and complex environments,\nencompassing individual actions, social group activities, and global\nactivities. Existing methods generally use either parameter-independent modules\nto capture task-specific features or parameter-sharing modules to obtain common\nfeatures across all tasks. However, there is often a strong interrelatedness\nand complementary effect between tasks of different granularities that previous\nmethods have yet to notice. In this paper, we propose a model called MPT-PAR\nthat considers both the unique characteristics of each task and the synergies\nbetween different tasks simultaneously, thereby maximizing the utilization of\nfeatures across multi-granularity activity recognition. Furthermore, we\nemphasize the significance of temporal and spatial information by introducing a\nspatio-temporal relation-enhanced module and a scene representation learning\nmodule, which integrate the the spatio-temporal context of action and global\nscene into the feature map of each granularity. Our method achieved an overall\nF1 score of 47.5\\% on the JRDB-PAR dataset, significantly outperforming all the\nstate-of-the-art methods.", "categories": "cs.CV cs.AI", "created": "2024-08-01", "doi": null, "arxiv_id": "2408.00420"}
{"title": "Towards Evolutionary-based Automated Machine Learning for Small Molecule\n  Pharmacokinetic Prediction", "authors": [], "abstract": "Machine learning (ML) is revolutionising drug discovery by expediting the\nprediction of small molecule properties essential for developing new drugs.\nThese properties -- including absorption, distribution, metabolism and\nexcretion (ADME)-- are crucial in the early stages of drug development since\nthey provide an understanding of the course of the drug in the organism, i.e.,\nthe drug's pharmacokinetics. However, existing methods lack personalisation and\nrely on manually crafted ML algorithms or pipelines, which can introduce\ninefficiencies and biases into the process. To address these challenges, we\npropose a novel evolutionary-based automated ML method (AutoML) specifically\ndesigned for predicting small molecule properties, with a particular focus on\npharmacokinetics. Leveraging the advantages of grammar-based genetic\nprogramming, our AutoML method streamlines the process by automatically\nselecting algorithms and designing predictive pipelines tailored to the\nparticular characteristics of input molecular data. Results demonstrate\nAutoML's effectiveness in selecting diverse ML algorithms, resulting in\ncomparable or even improved predictive performances compared to conventional\napproaches. By offering personalised ML-driven pipelines, our method promises\nto enhance small molecule research in drug discovery, providing researchers\nwith a valuable tool for accelerating the development of novel therapeutic\ndrugs.", "categories": "cs.LG cs.AI", "created": "2024-08-01", "doi": null, "arxiv_id": "2408.00421"}
{"title": "A Cross-Domain Benchmark for Active Learning", "authors": [], "abstract": "Active Learning (AL) deals with identifying the most informative samples for\nlabeling to reduce data annotation costs for supervised learning tasks. AL\nresearch suffers from the fact that lifts from literature generalize poorly and\nthat only a small number of repetitions of experiments are conducted. To\novercome these obstacles, we propose \\emph{CDALBench}, the first active\nlearning benchmark which includes tasks in computer vision, natural language\nprocessing and tabular learning. Furthermore, by providing an efficient, greedy\noracle, \\emph{CDALBench} can be evaluated with 50 runs for each experiment. We\nshow, that both the cross-domain character and a large amount of repetitions\nare crucial for sophisticated evaluation of AL research. Concretely, we show\nthat the superiority of specific methods varies over the different domains,\nmaking it important to evaluate Active Learning with a cross-domain benchmark.\nAdditionally, we show that having a large amount of runs is crucial. With only\nconducting three runs as often done in the literature, the superiority of\nspecific methods can strongly vary with the specific runs. This effect is so\nstrong, that, depending on the seed, even a well-established method's\nperformance can be significantly better and significantly worse than random for\nthe same dataset.", "categories": "cs.LG", "created": "2024-08-01", "doi": null, "arxiv_id": "2408.00426"}
{"title": "Augmenting Channel Simulator and Semi- Supervised Learning for Efficient\n  Indoor Positioning", "authors": [], "abstract": "This work aims to tackle the labor-intensive and resource-consuming task of\nindoor positioning by proposing an efficient approach. The proposed approach\ninvolves the introduction of a semi-supervised learning (SSL) with a biased\nteacher (SSLB) algorithm, which effectively utilizes both labeled and unlabeled\nchannel data. To reduce measurement expenses, unlabeled data is generated using\nan updated channel simulator (UCHS), and then weighted by adaptive confidence\nvalues to simplify the tuning of hyperparameters. Simulation results\ndemonstrate that the proposed strategy achieves superior performance while\nminimizing measurement overhead and training expense compared to existing\nbenchmarks, offering a valuable and practical solution for indoor positioning.", "categories": "eess.SP cs.AI", "created": "2024-08-01", "doi": null, "arxiv_id": "2408.00429"}
{"title": "ShellFuzzer: Grammar-based Fuzzing of Shell Interpreters", "authors": [], "abstract": "Despite its long-standing popularity and fundamental role in an operating\nsystem, the Unix shell has rarely been a subject of academic research. In\nparticular, regardless of the significant progress in compiler testing, there\nhas been hardly any work applying automated testing techniques to detect faults\nand vulnerabilities in shell interpreters.\n  To address this important shortcoming, we present ShellFuzzer: a technique to\ntest Unix shell interpreters by automatically generating a large number of\nshell scripts. ShellFuzzer combines grammar-based generation with selected\nrandom mutations, so as to produce a diverse range of shell programs with\npredictable characteristics (e.g., valid according to the language standard,\nand free from destructive behavior).\n  In our experimental evaluation, ShellFuzzer generated shell programs that\nexposed 8 previously unknown issues that affected a recent version of the mksh\nPOSIX-compliant shell; the shell maintainers confirmed 7 of these issues, and\naddressed them in the latest revisions of the shell's open-source\nimplementation.", "categories": "cs.SE", "created": "2024-08-01", "doi": null, "arxiv_id": "2408.00433"}
{"title": "A Qualitative Study on Using ChatGPT for Software Security: Perception\n  vs. Practicality", "authors": [], "abstract": "Artificial Intelligence (AI) advancements have enabled the development of\nLarge Language Models (LLMs) that can perform a variety of tasks with\nremarkable semantic understanding and accuracy. ChatGPT is one such LLM that\nhas gained significant attention due to its impressive capabilities for\nassisting in various knowledge-intensive tasks. Due to the knowledge-intensive\nnature of engineering secure software, ChatGPT's assistance is expected to be\nexplored for security-related tasks during the development/evolution of\nsoftware. To gain an understanding of the potential of ChatGPT as an emerging\ntechnology for supporting software security, we adopted a two-fold approach.\nInitially, we performed an empirical study to analyse the perceptions of those\nwho had explored the use of ChatGPT for security tasks and shared their views\non Twitter. It was determined that security practitioners view ChatGPT as\nbeneficial for various software security tasks, including vulnerability\ndetection, information retrieval, and penetration testing. Secondly, we\ndesigned an experiment aimed at investigating the practicality of this\ntechnology when deployed as an oracle in real-world settings. In particular, we\nfocused on vulnerability detection and qualitatively examined ChatGPT outputs\nfor given prompts within this prominent software security task. Based on our\nanalysis, responses from ChatGPT in this task are largely filled with generic\nsecurity information and may not be appropriate for industry use. To prevent\ndata leakage, we performed this analysis on a vulnerability dataset compiled\nafter the OpenAI data cut-off date from real-world projects covering 40\ndistinct vulnerability types and 12 programming languages. We assert that the\nfindings from this study would contribute to future research aimed at\ndeveloping and evaluating LLMs dedicated to software security.", "categories": "cs.SE cs.AI cs.CR", "created": "2024-08-01", "doi": null, "arxiv_id": "2408.00435"}
{"title": "A Search for High-Threshold Qutrit Magic State Distillation Routines", "authors": [], "abstract": "Determining the best attainable threshold for qudit magic state distillation\nis directly related to the question of whether or not contextuality is\nsufficient for universal quantum computation. We carry out a search for\nhigh-threshold magic state distillation routines for a highly-symmetric qutrit\nmagic state known as the strange state. Our search covers a large class of\n$[[n,1]]_3$ qutrit stabilizer codes with up to 23 qutrits, and is facilitated\nby a theorem that relates the distillation performance of a qudit stabilizer\ncode to its weight-enumerators. We could not find any code with $n<23$ qutrits\nthat distills the strange state with better than linear noise suppression,\nother than the 11-qutrit Golay code. However, for $n=23$, we find over 600 CSS\ncodes that can distill the qutrit strange state with cubic noise suppression.\nWhile none of these codes surpass the threshold of the 11-qutrit Golay code,\ntheir existence suggests that, for large codes, the ability to distill the\nqutrit strange state is somewhat generic.", "categories": "quant-ph cs.IT math.CO math.IT", "created": "2024-08-01", "doi": null, "arxiv_id": "2408.00436"}
{"title": "Efficient Patient Fine-Tuned Seizure Detection with a Tensor Kernel\n  Machine", "authors": [], "abstract": "Recent developments in wearable devices have made accurate and efficient\nseizure detection more important than ever. A challenge in seizure detection is\nthat patient-specific models typically outperform patient-independent models.\nHowever, in a wearable device one typically starts with a patient-independent\nmodel, until such patient-specific data is available. To avoid having to\nconstruct a new classifier with this data, as required in conventional kernel\nmachines, we propose a transfer learning approach with a tensor kernel machine.\nThis method learns the primal weights in a compressed form using the canonical\npolyadic decomposition, making it possible to efficiently update the weights of\nthe patient-independent model with patient-specific data. The results show that\nthis patient fine-tuned model reaches as high a performance as a\npatient-specific SVM model with a model size that is twice as small as the\npatient-specific model and ten times as small as the patient-independent model.", "categories": "eess.SP cs.LG stat.ML", "created": "2024-08-01", "doi": null, "arxiv_id": "2408.00437"}
{"title": "MonoMM: A Multi-scale Mamba-Enhanced Network for Real-time Monocular 3D\n  Object Detection", "authors": [], "abstract": "Recent advancements in transformer-based monocular 3D object detection\ntechniques have exhibited exceptional performance in inferring 3D attributes\nfrom single 2D images. However, most existing methods rely on\nresource-intensive transformer architectures, which often lead to significant\ndrops in computational efficiency and performance when handling long sequence\ndata. To address these challenges and advance monocular 3D object detection\ntechnology, we propose an innovative network architecture, MonoMM, a\nMulti-scale \\textbf{M}amba-Enhanced network for real-time Monocular 3D object\ndetection. This well-designed architecture primarily includes the following two\ncore modules: Focused Multi-Scale Fusion (FMF) Module, which focuses on\neffectively preserving and fusing image information from different scales with\nlower computational resource consumption. By precisely regulating the\ninformation flow, the FMF module enhances the model adaptability and robustness\nto scale variations while maintaining image details. Depth-Aware Feature\nEnhancement Mamba (DMB) Module: It utilizes the fused features from image\ncharacteristics as input and employs a novel adaptive strategy to globally\nintegrate depth information and visual information. This depth fusion strategy\nnot only improves the accuracy of depth estimation but also enhances the model\nperformance under different viewing angles and environmental conditions.\nMoreover, the modular design of MonoMM provides high flexibility and\nscalability, facilitating adjustments and optimizations according to specific\napplication needs. Extensive experiments conducted on the KITTI dataset show\nthat our method outperforms previous monocular methods and achieves real-time\ndetection.", "categories": "cs.CV", "created": "2024-08-01", "doi": null, "arxiv_id": "2408.00438"}
{"title": "Rapid and Power-Aware Learned Optimization for Modular Receive\n  Beamforming", "authors": [], "abstract": "Multiple-input multiple-output (MIMO) systems play a key role in wireless\ncommunication technologies. A widely considered approach to realize scalable\nMIMO systems involves architectures comprised of multiple separate modules,\neach with its own beamforming capability. Such models accommodate cell-free\nmassive MIMO and partially connected hybrid MIMO architectures. A core issue\nwith the implementation of modular MIMO arises from the need to rapidly set the\nbeampatterns of the modules, while maintaining their power efficiency. This\nleads to challenging constrained optimization that should be repeatedly solved\non each coherence duration. In this work, we propose a power-oriented\noptimization algorithm for beamforming in uplink modular hybrid MIMO systems,\nwhich learns from data to operate rapidly. We derive our learned optimizer by\ntackling the rate maximization objective using projected gradient ascent steps\nwith momentum. We then leverage data to tune the hyperparameters of the\noptimizer, allowing it to operate reliably in a fixed and small number of\niterations while completely preserving its interpretable operation. We show how\npower efficient beamforming can be encouraged by the learned optimizer, via\nboosting architectures with low-resolution phase shifts and with deactivated\nanalog components. Numerical results show that our learn-to-optimize method\nnotably reduces the number of iterations and computation latency required to\nreliably tune modular MIMO receivers, and that it allows obtaining desirable\nbalances between power efficient designs and throughput.", "categories": "eess.SP cs.IT cs.LG math.IT", "created": "2024-08-01", "doi": null, "arxiv_id": "2408.00439"}
{"title": "An Empirical Study on Challenges of Event Management in Microservice\n  Architectures", "authors": [], "abstract": "Microservices emerged as a popular architectural style over the last decade.\nAlthough microservices are designed to be self-contained, they must communicate\nto realize business capabilities, creating dependencies among their data and\nfunctionalities. Developers then resort to asynchronous, event-based\ncommunication to fulfill such dependencies while reducing coupling. However,\ndevelopers are often oblivious to the inherent challenges of the asynchronous\nand event-based paradigm, leading to frustrations and ultimately making them\nreconsider the adoption of microservices. To make matters worse, there is a\nscarcity of literature on the practices and challenges of designing,\nimplementing, testing, monitoring, and troubleshooting event-based\nmicroservices.\n  To fill this gap, this paper provides the first comprehensive\ncharacterization of event management practices and challenges in microservices\nbased on a repository mining study of over 8000 Stack Overflow questions.\nMoreover, 628 relevant questions were randomly sampled for an in-depth manual\ninvestigation of challenges. We find that developers encounter many problems,\nincluding large event payloads, modeling event schemas, auditing event flows,\nand ordering constraints in processing events. This suggests that developers\nare not sufficiently served by state-of-the-practice technologies. We provide\nactionable implications to developers, technology providers, and researchers to\nadvance event management in microservices.", "categories": "cs.SE cs.DB", "created": "2024-08-01", "doi": null, "arxiv_id": "2408.00440"}
{"title": "Focus, Distinguish, and Prompt: Unleashing CLIP for Efficient and\n  Flexible Scene Text Retrieval", "authors": [], "abstract": "Scene text retrieval aims to find all images containing the query text from\nan image gallery. Current efforts tend to adopt an Optical Character\nRecognition (OCR) pipeline, which requires complicated text detection and/or\nrecognition processes, resulting in inefficient and inflexible retrieval.\nDifferent from them, in this work we propose to explore the intrinsic potential\nof Contrastive Language-Image Pre-training (CLIP) for OCR-free scene text\nretrieval. Through empirical analysis, we observe that the main challenges of\nCLIP as a text retriever are: 1) limited text perceptual scale, and 2)\nentangled visual-semantic concepts. To this end, a novel model termed FDP\n(Focus, Distinguish, and Prompt) is developed. FDP first focuses on scene text\nvia shifting the attention to the text area and probing the hidden text\nknowledge, and then divides the query text into content word and function word\nfor processing, in which a semantic-aware prompting scheme and a distracted\nqueries assistance module are utilized. Extensive experiments show that FDP\nsignificantly enhances the inference speed while achieving better or\ncompetitive retrieval accuracy compared to existing methods. Notably, on the\nIIIT-STR benchmark, FDP surpasses the state-of-the-art model by 4.37% with a 4\ntimes faster speed. Furthermore, additional experiments under phrase-level and\nattribute-aware scene text retrieval settings validate FDP's particular\nadvantages in handling diverse forms of query text. The source code will be\npublicly available at https://github.com/Gyann-z/FDP.", "categories": "cs.CV cs.AI", "created": "2024-08-01", "doi": null, "arxiv_id": "2408.00441"}
{"title": "An Experimental Evaluation of TEE technology Evolution: Benchmarking\n  Transparent Approaches based on SGX, SEV, and TDX", "authors": [], "abstract": "Protection of data-in-use is a key priority, for which Trusted Execution\nEnvironment (TEE) technology has unarguably emerged as a, possibly the most,\npromising solution. Multiple server-side TEE offerings have been released over\nthe years, exhibiting substantial differences with respect to several aspects.\nThe first comer was Intel SGX, which featured Process-based TEE protection, an\nefficient yet difficult to use approach. Some SGX limitations were (partially)\novercome by runtimes, notably: Gramine, Scone, and Occlum. A major paradigm\nshift was later brought by AMD SEV, with VM-based TEE protection, which enabled\nlift-and-shift deployment of legacy applications. This new paradigm has been\nimplemented by Intel only recently, in TDX. While the threat model of the\naforementioned TEE solutions has been widely discussed, a thorough performance\ncomparison is still lacking in the literature. This paper provides a\ncomparative evaluation of TDX, SEV, Gramine-SGX, and Occlum-SGX. We study\ncomputational overhead and resource usage, under different operational\nscenarios and using a diverse suite of legacy applications. By doing so, we\nprovide a reliable performance assessment under realistic conditions. We\nexplicitly emphasize that, at the time of writing, TDX was not yet available to\nthe public. Thus, the evaluation of TDX is a unique feature of this study.", "categories": "cs.CR", "created": "2024-08-01", "doi": null, "arxiv_id": "2408.00443"}
{"title": "Ontological Relations from Word Embeddings", "authors": [], "abstract": "It has been reliably shown that the similarity of word embeddings obtained\nfrom popular neural models such as BERT approximates effectively a form of\nsemantic similarity of the meaning of those words. It is therefore natural to\nwonder if those embeddings contain enough information to be able to connect\nthose meanings through ontological relationships such as the one of\nsubsumption. If so, large knowledge models could be built that are capable of\nsemantically relating terms based on the information encapsulated in word\nembeddings produced by pre-trained models, with implications not only for\nontologies (ontology matching, ontology evolution, etc.) but also on the\nability to integrate ontological knowledge in neural models. In this paper, we\ntest how embeddings produced by several pre-trained models can be used to\npredict relations existing between classes and properties of popular\nupper-level and general ontologies. We show that even a simple feed-forward\narchitecture on top of those embeddings can achieve promising accuracies, with\nvarying generalisation abilities depending on the input data. To achieve that,\nwe produce a dataset that can be used to further enhance those models, opening\nnew possibilities for applications integrating knowledge from web ontologies.", "categories": "cs.AI", "created": "2024-08-01", "doi": null, "arxiv_id": "2408.00444"}
{"title": "DiscipLink: Unfolding Interdisciplinary Information Seeking Process via\n  Human-AI Co-Exploration", "authors": [], "abstract": "Interdisciplinary studies often require researchers to explore literature in\ndiverse branches of knowledge. Yet, navigating through the highly scattered\nknowledge from unfamiliar disciplines poses a significant challenge. In this\npaper, we introduce DiscipLink, a novel interactive system that facilitates\ncollaboration between researchers and large language models (LLMs) in\ninterdisciplinary information seeking (IIS). Based on users' topics of\ninterest, DiscipLink initiates exploratory questions from the perspectives of\npossible relevant fields of study, and users can further tailor these\nquestions. DiscipLink then supports users in searching and screening papers\nunder selected questions by automatically expanding queries with\ndisciplinary-specific terminologies, extracting themes from retrieved papers,\nand highlighting the connections between papers and questions. Our evaluation,\ncomprising a within-subject comparative experiment and an open-ended\nexploratory study, reveals that DiscipLink can effectively support researchers\nin breaking down disciplinary boundaries and integrating scattered knowledge in\ndiverse fields. The findings underscore the potential of LLM-powered tools in\nfostering information-seeking practices and bolstering interdisciplinary\nresearch.", "categories": "cs.HC cs.AI cs.IR", "created": "2024-08-01", "doi": null, "arxiv_id": "2408.00447"}
{"title": "How quantum and evolutionary algorithms can help each other: two\n  examples", "authors": [], "abstract": "We investigate the potential of bio-inspired evolutionary algorithms for\ndesigning quantum circuits with specific goals, focusing on two particular\ntasks. The first one is motivated by the ideas of Artificial Life that are used\nto reproduce stochastic cellular automata with given rules. We test the\nrobustness of quantum implementations of the cellular automata for different\nnumbers of quantum gates The second task deals with the sampling of quantum\ncircuits that generate highly entangled quantum states, which constitute an\nimportant resource for quantum computing. In particular, an evolutionary\nalgorithm is employed to optimize circuits with respect to a fitness function\ndefined with the Mayer-Wallach entanglement measure. We demonstrate that, by\nbalancing the mutation rate between exploration and exploitation, we can find\nentangling quantum circuits for up to five qubits. We also discuss the\ntrade-off between the number of gates in quantum circuits and the computational\ncosts of finding the gate arrangements leading to a strongly entangled state.\nOur findings provide additional insight into the trade-off between the\ncomplexity of a circuit and its performance, which is an important factor in\nthe design of quantum circuits.", "categories": "quant-ph cs.NE", "created": "2024-08-01", "doi": null, "arxiv_id": "2408.00448"}
{"title": "Space-Time Isogeometric Method for a Nonlocal Parabolic Problem", "authors": [], "abstract": "In the present work, we focus on the space-time isogeometric discretization\nof a parabolic problem with a nonlocal diffusion coefficient. The use of a\nspace-time discretization with smooth basis functions yields advantages in the\napproximation of the solution. The existence of the unique solution for\ncontinuous and discrete space-time variational formulations is proven. We also\nestablish the a priori error estimate for the space-time isogeometric scheme.\nThe non-linear system is linearized through Picard's method and a suitable\npreconditioner for the linearized system is provided. Finally, to confirm the\ntheoretical findings, results of some numerical experiments are presented.", "categories": "math.NA cs.NA", "created": "2024-08-01", "doi": null, "arxiv_id": "2408.00450"}
{"title": "Reenact Anything: Semantic Video Motion Transfer Using Motion-Textual\n  Inversion", "authors": [], "abstract": "Recent years have seen a tremendous improvement in the quality of video\ngeneration and editing approaches. While several techniques focus on editing\nappearance, few address motion. Current approaches using text, trajectories, or\nbounding boxes are limited to simple motions, so we specify motions with a\nsingle motion reference video instead. We further propose to use a pre-trained\nimage-to-video model rather than a text-to-video model. This approach allows us\nto preserve the exact appearance and position of a target object or scene and\nhelps disentangle appearance from motion. Our method, called motion-textual\ninversion, leverages our observation that image-to-video models extract\nappearance mainly from the (latent) image input, while the text/image embedding\ninjected via cross-attention predominantly controls motion. We thus represent\nmotion using text/image embedding tokens. By operating on an inflated\nmotion-text embedding containing multiple text/image embedding tokens per\nframe, we achieve a high temporal motion granularity. Once optimized on the\nmotion reference video, this embedding can be applied to various target images\nto generate videos with semantically similar motions. Our approach does not\nrequire spatial alignment between the motion reference video and target image,\ngeneralizes across various domains, and can be applied to various tasks such as\nfull-body and face reenactment, as well as controlling the motion of inanimate\nobjects and the camera. We empirically demonstrate the effectiveness of our\nmethod in the semantic video motion transfer task, significantly outperforming\nexisting methods in this context.", "categories": "cs.CV cs.GR cs.LG", "created": "2024-08-01", "doi": null, "arxiv_id": "2408.00458"}
{"title": "Designing Efficient LLM Accelerators for Edge Devices", "authors": [], "abstract": "The increase in open-source availability of Large Language Models (LLMs) has\nenabled users to deploy them on more and more resource-constrained edge devices\nto reduce reliance on network connections and provide more privacy. However,\nthe high computation and memory demands of LLMs make their execution on\nresource-constrained edge devices challenging and inefficient. To address this\nissue, designing new and efficient edge accelerators for LLM inference is\ncrucial. FPGA-based accelerators are ideal for LLM acceleration due to their\nreconfigurability, as they enable model-specific optimizations and higher\nperformance per watt. However, creating and integrating FPGA-based accelerators\nfor LLMs (particularly on edge devices) has proven challenging, mainly due to\nthe limited hardware design flows for LLMs in existing FPGA platforms.\n  To tackle this issue, in this paper we first propose a new design platform,\nnamed SECDA-LLM, that utilizes the SECDA methodology to streamline the process\nof designing, integrating, and deploying efficient FPGA-based LLM accelerators\nfor the llama.cpp inference framework. We then demonstrate, through a case\nstudy, the potential benefits of SECDA-LLM by creating a new MatMul accelerator\nthat supports block floating point quantized operations for LLMs. Our initial\naccelerator design, deployed on the PYNQ-Z1 board, reduces latency 1.7 seconds\nper token or ~2 seconds per word) by 11x over the dual-core Arm NEON-based CPU\nexecution for the TinyLlama model.", "categories": "cs.AR cs.LG", "created": "2024-08-01", "doi": null, "arxiv_id": "2408.00462"}
{"title": "Image Super-Resolution with Taylor Expansion Approximation and Large\n  Field Reception", "authors": [], "abstract": "Self-similarity techniques are booming in blind super-resolution (SR) due to\naccurate estimation of the degradation types involved in low-resolution images.\nHowever, high-dimensional matrix multiplication within self-similarity\ncomputation prohibitively consumes massive computational costs. We find that\nthe high-dimensional attention map is derived from the matrix multiplication\nbetween Query and Key, followed by a softmax function. This softmax makes the\nmatrix multiplication between Query and Key inseparable, posing a great\nchallenge in simplifying computational complexity. To address this issue, we\nfirst propose a second-order Taylor expansion approximation (STEA) to separate\nthe matrix multiplication of Query and Key, resulting in the complexity\nreduction from $\\mathcal{O}(N^2)$ to $\\mathcal{O}(N)$. Then, we design a\nmulti-scale large field reception (MLFR) to compensate for the performance\ndegradation caused by STEA. Finally, we apply these two core designs to\nlaboratory and real-world scenarios by constructing LabNet and RealNet,\nrespectively. Extensive experimental results tested on five synthetic datasets\ndemonstrate that our LabNet sets a new benchmark in qualitative and\nquantitative evaluations. Tested on the RealWorld38 dataset, our RealNet\nachieves superior visual quality over existing methods. Ablation studies\nfurther verify the contributions of STEA and MLFR towards both LabNet and\nRealNet frameworks.", "categories": "cs.CV cs.AI eess.IV", "created": "2024-08-01", "doi": null, "arxiv_id": "2408.00470"}
{"title": "Towards Explainable and Interpretable Musical Difficulty Estimation: A\n  Parameter-efficient Approach", "authors": [], "abstract": "Estimating music piece difficulty is important for organizing educational\nmusic collections. This process could be partially automatized to facilitate\nthe educator's role. Nevertheless, the decisions performed by prevalent\ndeep-learning models are hardly understandable, which may impair the acceptance\nof such a technology in music education curricula. Our work employs explainable\ndescriptors for difficulty estimation in symbolic music representations.\nFurthermore, through a novel parameter-efficient white-box model, we outperform\nprevious efforts while delivering interpretable results. These comprehensible\noutcomes emulate the functionality of a rubric, a tool widely used in music\neducation. Our approach, evaluated in piano repertoire categorized in 9\nclasses, achieved 41.4% accuracy independently, with a mean squared error (MSE)\nof 1.7, showing precise difficulty estimation. Through our baseline, we\nillustrate how building on top of past research can offer alternatives for\nmusic difficulty assessment which are explainable and interpretable. With this,\nwe aim to promote a more effective communication between the Music Information\nRetrieval (MIR) community and the music education one.", "categories": "cs.SD cs.AI cs.IR eess.AS", "created": "2024-08-01", "doi": null, "arxiv_id": "2408.00473"}
{"title": "Enhance the Detection of DoS and Brute Force Attacks within the MQTT\n  Environment through Feature Engineering and Employing an Ensemble Technique", "authors": [], "abstract": "The rapid development of the Internet of Things (IoT) environment has\nintroduced unprecedented levels of connectivity and automation. The Message\nQueuing Telemetry Transport (MQTT) protocol has become recognized in IoT\napplications due to its lightweight and efficient features; however, this\nsimplicity also renders MQTT vulnerable to multiple attacks that can be\nlaunched against the protocol, including denial of service (DoS) and\nbrute-force attacks. This study aims to improve the detection of intrusion DoS\nand brute-force attacks in an MQTT traffic intrusion detection system (IDS).\nOur approach utilizes the MQTT dataset for model training by employing\neffective feature engineering and ensemble learning techniques. Following our\nanalysis and comparison, we identified the top 10 features demonstrating the\nhighest effectiveness, leading to improved model accuracy. We used supervised\nmachine learning models, including Random Forest, Decision Trees, k-Nearest\nNeighbors, and XGBoost, in combination with ensemble classifiers. Stacking,\nvoting, and bagging ensembles utilize these four supervised machine-learning\nmethods to combine models. This study's results illustrate the proposed\ntechnique's efficacy in enhancing the accuracy of detecting DoS and brute-force\nattacks in MQTT traffic. Stacking and voting classifiers achieved the highest\naccuracy of 0.9538. Our approach outperforms the most recent study that\nutilized the same dataset.", "categories": "cs.NI", "created": "2024-08-01", "doi": null, "arxiv_id": "2408.00480"}
{"title": "HBot: A Chatbot for Healthcare Applications in Traditional Chinese\n  Medicine Based on Human Body 3D Visualization", "authors": [], "abstract": "The unique diagnosis and treatment techniques and remarkable clinical\nefficacy of traditional Chinese medicine (TCM) make it play an important role\nin the field of elderly care and healthcare, especially in the rehabilitation\nof some common chronic diseases of the elderly. Therefore, building a TCM\nchatbot for healthcare application will help users obtain consultation services\nin a direct and natural way. However, concepts such as acupuncture points\n(acupoints) and meridians involved in TCM always appear in the consultation,\nwhich cannot be displayed intuitively. To this end, we develop a\n\\textbf{h}ealthcare chat\\textbf{bot} (HBot) based on a human body model in 3D\nand knowledge graph, which provides conversational services such as knowledge\nQ\\&A, prescription recommendation, moxibustion therapy recommendation, and\nacupoint search. When specific acupoints are involved in the conversations\nbetween user and HBot, the 3D body will jump to the corresponding acupoints and\nhighlight them. Moreover, Hbot can also be used in training scenarios to\naccelerate the teaching process of TCM by intuitively displaying acupuncture\npoints and knowledge cards. The demonstration video is available at\nhttps://www.youtube.com/watch?v=UhQhutSKkTU . Our code and dataset are publicly\navailable at Gitee: https://gitee.com/plabrolin/interactive-3d-acup.git", "categories": "cs.AI", "created": "2024-08-01", "doi": null, "arxiv_id": "2408.00481"}
{"title": "A Systematic Review on Long-Tailed Learning", "authors": [], "abstract": "Long-tailed data is a special type of multi-class imbalanced data with a very\nlarge amount of minority/tail classes that have a very significant combined\ninfluence. Long-tailed learning aims to build high-performance models on\ndatasets with long-tailed distributions, which can identify all the classes\nwith high accuracy, in particular the minority/tail classes. It is a\ncutting-edge research direction that has attracted a remarkable amount of\nresearch effort in the past few years. In this paper, we present a\ncomprehensive survey of latest advances in long-tailed visual learning. We\nfirst propose a new taxonomy for long-tailed learning, which consists of eight\ndifferent dimensions, including data balancing, neural architecture, feature\nenrichment, logits adjustment, loss function, bells and whistles, network\noptimization, and post hoc processing techniques. Based on our proposed\ntaxonomy, we present a systematic review of long-tailed learning methods,\ndiscussing their commonalities and alignable differences. We also analyze the\ndifferences between imbalance learning and long-tailed learning approaches.\nFinally, we discuss prospects and future directions in this field.", "categories": "cs.LG cs.AI cs.CV cs.MM", "created": "2024-08-01", "doi": null, "arxiv_id": "2408.00483"}
{"title": "SF-TIM: A Simple Framework for Enhancing Quadrupedal Robot Jumping\n  Agility by Combining Terrain Imagination and Measurement", "authors": [], "abstract": "Dynamic jumping on high platforms and over gaps differentiates legged robots\nfrom wheeled counterparts. Compared to walking on rough terrains, dynamic\nlocomotion on abrupt surfaces requires fusing proprioceptive and exteroceptive\nperception for explosive movements. In this paper, we propose SF-TIM (Simple\nFramework combining Terrain Imagination and Measurement), a single-policy\nmethod that enhances quadrupedal robot jumping agility, while preserving their\nfundamental blind walking capabilities. In addition, we introduce a\nterrain-guided reward design specifically to assist quadrupedal robots in high\njumping, improving their performance in this task. To narrow the\nsimulation-to-reality gap in quadrupedal robot learning, we introduce a stable\nand high-speed elevation map generation framework, enabling zero-shot\nsimulation-to-reality transfer of locomotion ability. Our algorithm has been\ndeployed and validated on both the small-/large-size quadrupedal robots,\ndemonstrating its effectiveness in real-world applications: the robot has\nsuccessfully traversed various high platforms and gaps, showing the robustness\nof our proposed approach. A demo video has been made available at\nhttps://flysoaryun.github.io/SF-TIM.", "categories": "cs.RO", "created": "2024-08-01", "doi": null, "arxiv_id": "2408.00486"}
{"title": "Absolute-value based preconditioner for complex-shifted Laplacian\n  systems", "authors": [], "abstract": "The complex-shifted Laplacian systems arising in a wide range of\napplications. In this work, we propose an absolute-value based preconditioner\nfor solving the complex-shifted Laplacian system. In our approach, the\ncomplex-shifted Laplacian system is equivalently rewritten as a $2\\times 2$\nblock real linear system. With the Toeplitz structure of uniform-grid\ndiscretization of the constant-coefficient Laplacian operator, the absolute\nvalue of the block real matrix is fast invertible by means of fast sine\ntransforms. For more general coefficient function, we then average the\ncoefficient function and take the absolute value of the averaged matrix as our\npreconditioner. With assumptions on the complex shift, we theoretically prove\nthat the eigenvalues of the preconditioned matrix in absolute value are upper\nand lower bounded by constants independent of matrix size, indicating a\nmatrix-size independent linear convergence rate of MINRES solver.\nInterestingly, numerical results show that the proposed preconditioner is still\nefficient even if the assumptions on the complex shift are not met. The fast\ninvertibility of the proposed preconditioner and the robust convergence rate of\nthe preconditioned MINRES solver lead to a linearithmic (nearly optimal)\ncomplexity of the proposed solver. The proposed preconditioner is compared with\nseveral state-of-the-art preconditioners via several numerical examples to\ndemonstrate the efficiency of the proposed preconditioner.", "categories": "math.NA cs.NA", "created": "2024-08-01", "doi": null, "arxiv_id": "2408.00488"}
{"title": "Multi-label Sewer Pipe Defect Recognition with Mask Attention Feature\n  Enhancement and Label Correlation Learning", "authors": [], "abstract": "The coexistence of multiple defect categories as well as the substantial\nclass imbalance problem significantly impair the detection of sewer pipeline\ndefects. To solve this problem, a multi-label pipe defect recognition method is\nproposed based on mask attention guided feature enhancement and label\ncorrelation learning. The proposed method can achieve current approximate\nstate-of-the-art classification performance using just 1/16 of the Sewer-ML\ntraining dataset and exceeds the current best method by 11.87\\% in terms of F2\nmetric on the full dataset, while also proving the superiority of the model.\nThe major contribution of this study is the development of a more efficient\nmodel for identifying and locating multiple defects in sewer pipe images for a\nmore accurate sewer pipeline condition assessment. Moreover, by employing class\nactivation maps, our method can accurately pinpoint multiple defect categories\nin the image which demonstrates a strong model interpretability. Our code is\navailable at\n\\href{https://github.com/shengyu27/MA-Q2L}{\\textcolor{black}{https://github.com/shengyu27/MA-Q2L.}", "categories": "cs.CV", "created": "2024-08-01", "doi": null, "arxiv_id": "2408.00489"}
{"title": "Graph Representation Learning via Causal Diffusion for\n  Out-of-Distribution Recommendation", "authors": [], "abstract": "Graph Neural Networks (GNNs)-based recommendation algorithms typically assume\nthat training and testing data are drawn from independent and identically\ndistributed (IID) spaces. However, this assumption often fails in the presence\nof out-of-distribution (OOD) data, resulting in significant performance\ndegradation. In this study, we construct a Structural Causal Model (SCM) to\nanalyze interaction data, revealing that environmental confounders (e.g., the\nCOVID-19 pandemic) lead to unstable correlations in GNN-based models, thus\nimpairing their generalization to OOD data. To address this issue, we propose a\nnovel approach, graph representation learning via causal diffusion\n(CausalDiffRec) for OOD recommendation. This method enhances the model's\ngeneralization on OOD data by eliminating environmental confounding factors and\nlearning invariant graph representations. Specifically, we use backdoor\nadjustment and variational inference to infer the real environmental\ndistribution, thereby eliminating the impact of environmental confounders. This\ninferred distribution is then used as prior knowledge to guide the\nrepresentation learning in the reverse phase of the diffusion process to learn\nthe invariant representation. In addition, we provide a theoretical derivation\nthat proves optimizing the objective function of CausalDiffRec can encourage\nthe model to learn environment-invariant graph representations, thereby\nachieving excellent generalization performance in recommendations under\ndistribution shifts. Our extensive experiments validate the effectiveness of\nCausalDiffRec in improving the generalization of OOD data, and the average\nimprovement is up to 10.69% on Food, 18.83% on KuaiRec, 22.41% on Yelp2018, and\n11.65% on Douban datasets.", "categories": "cs.LG cs.AI cs.IR cs.SI", "created": "2024-08-01", "doi": null, "arxiv_id": "2408.00490"}
{"title": "GalleryGPT: Analyzing Paintings with Large Multimodal Models", "authors": [], "abstract": "Artwork analysis is important and fundamental skill for art appreciation,\nwhich could enrich personal aesthetic sensibility and facilitate the critical\nthinking ability. Understanding artworks is challenging due to its subjective\nnature, diverse interpretations, and complex visual elements, requiring\nexpertise in art history, cultural background, and aesthetic theory. However,\nlimited by the data collection and model ability, previous works for\nautomatically analyzing artworks mainly focus on classification, retrieval, and\nother simple tasks, which is far from the goal of AI. To facilitate the\nresearch progress, in this paper, we step further to compose comprehensive\nanalysis inspired by the remarkable perception and generation ability of large\nmultimodal models. Specifically, we first propose a task of composing paragraph\nanalysis for artworks, i.e., painting in this paper, only focusing on visual\ncharacteristics to formulate more comprehensive understanding of artworks. To\nsupport the research on formal analysis, we collect a large dataset\nPaintingForm, with about 19k painting images and 50k analysis paragraphs. We\nfurther introduce a superior large multimodal model for painting analysis\ncomposing, dubbed GalleryGPT, which is slightly modified and fine-tuned based\non LLaVA architecture leveraging our collected data. We conduct formal analysis\ngeneration and zero-shot experiments across several datasets to assess the\ncapacity of our model. The results show remarkable performance improvements\ncomparing with powerful baseline LMMs, demonstrating its superb ability of art\nanalysis and generalization. \\textcolor{blue}{The codes and model are available\nat: https://github.com/steven640pixel/GalleryGPT.", "categories": "cs.CL cs.CV cs.MM", "created": "2024-08-01", "doi": "10.1145/3664647.3681656", "arxiv_id": "2408.00491"}
{"title": "Explainable Emotion Decoding for Human and Computer Vision", "authors": [], "abstract": "Modern Machine Learning (ML) has significantly advanced various research\nfields, but the opaque nature of ML models hinders their adoption in several\ndomains. Explainable AI (XAI) addresses this challenge by providing additional\ninformation to help users understand the internal decision-making process of ML\nmodels. In the field of neuroscience, enriching a ML model for brain decoding\nwith attribution-based XAI techniques means being able to highlight which brain\nareas correlate with the task at hand, thus offering valuable insights to\ndomain experts. In this paper, we analyze human and Computer Vision (CV)\nsystems in parallel, training and explaining two ML models based respectively\non functional Magnetic Resonance Imaging (fMRI) and movie frames. We do so by\nleveraging the \"StudyForrest\" dataset, which includes functional Magnetic\nResonance Imaging (fMRI) scans of subjects watching the \"Forrest Gump\" movie,\nemotion annotations, and eye-tracking data. For human vision the ML task is to\nlink fMRI data with emotional annotations, and the explanations highlight the\nbrain regions strongly correlated with the label. On the other hand, for\ncomputer vision, the input data is movie frames, and the explanations are\npixel-level heatmaps. We cross-analyzed our results, linking human attention\n(obtained through eye-tracking) with XAI saliency on CV models and brain region\nactivations. We show how a parallel analysis of human and computer vision can\nprovide useful information for both the neuroscience community (allocation\ntheory) and the ML community (biological plausibility of convolutional models).", "categories": "cs.CV eess.IV q-bio.NC", "created": "2024-08-01", "doi": null, "arxiv_id": "2408.00493"}
{"title": "Chance-Constrained Information-Theoretic Stochastic Model Predictive\n  Control with Safety Shielding", "authors": [], "abstract": "This paper introduces a novel nonlinear stochastic model predictive control\npath integral (MPPI) method, which considers chance constraints on system\nstates. The proposed belief-space stochastic MPPI (BSS-MPPI) applies\nMonte-Carlo sampling to evaluate state distributions resulting from underlying\nsystematic disturbances, and utilizes a Control Barrier Function (CBF) inspired\nheuristic in belief space to fulfill the specified chance constraints. Compared\nto several previous stochastic predictive control methods, our approach applies\nto general nonlinear dynamics without requiring the computationally expensive\nsystem linearization step. Moreover, the BSS-MPPI controller can solve\noptimization problems without limiting the form of the objective function and\nchance constraints. By multi-threading the sampling process using a GPU, we can\nachieve fast real-time planning for time- and safety-critical tasks such as\nautonomous racing. Our results on a realistic race-car simulation study show\nsignificant reductions in constraint violation compared to some of the prior\nMPPI approaches, while being comparable in computation times.", "categories": "cs.RO", "created": "2024-08-01", "doi": null, "arxiv_id": "2408.00494"}
{"title": "SegStitch: Multidimensional Transformer for Robust and Efficient Medical\n  Imaging Segmentation", "authors": [], "abstract": "Medical imaging segmentation plays a significant role in the automatic\nrecognition and analysis of lesions. State-of-the-art methods, particularly\nthose utilizing transformers, have been prominently adopted in 3D semantic\nsegmentation due to their superior performance in scalability and\ngeneralizability. However, plain vision transformers encounter challenges due\nto their neglect of local features and their high computational complexity. To\naddress these challenges, we introduce three key contributions: Firstly, we\nproposed SegStitch, an innovative architecture that integrates transformers\nwith denoising ODE blocks. Instead of taking whole 3D volumes as inputs, we\nadapt axial patches and customize patch-wise queries to ensure semantic\nconsistency. Additionally, we conducted extensive experiments on the BTCV and\nACDC datasets, achieving improvements up to 11.48% and 6.71% respectively in\nmDSC, compared to state-of-the-art methods. Lastly, our proposed method\ndemonstrates outstanding efficiency, reducing the number of parameters by 36.7%\nand the number of FLOPS by 10.7% compared to UNETR. This advancement holds\npromising potential for adapting our method to real-world clinical practice.\nThe code will be available at https://github.com/goblin327/SegStitch", "categories": "cs.CV", "created": "2024-08-01", "doi": null, "arxiv_id": "2408.00496"}
{"title": "A note about high-order semi-implicit differentiation: application to a\n  numerical integration scheme with Taylor-based compensated error", "authors": [], "abstract": "In this brief, we discuss the implementation of a third order semi-implicit\ndifferentiator as a complement of the recent work by the author that proposes\nan interconnected semi-implicit Euler double differentiators algorithm through\nTaylor expansion refinement. The proposed algorithm is dual to the\ninterconnected approach since it offers alternative flexibility to be tuned and\nto be implemented in real-time processes. In particular, an application to a\nnumerical integration scheme is presented as the Taylor refinement can be of\ninterest to improve the global convergence. Numerical results are presented to\nsupport the rightness of the proposed method.", "categories": "math.NA cs.NA cs.SY eess.SY", "created": "2024-08-01", "doi": null, "arxiv_id": "2408.00497"}
{"title": "How Effective are Self-Supervised Models for Contact Identification in\n  Videos", "authors": [], "abstract": "The exploration of video content via Self-Supervised Learning (SSL) models\nhas unveiled a dynamic field of study, emphasizing both the complex challenges\nand unique opportunities inherent in this area. Despite the growing body of\nresearch, the ability of SSL models to detect physical contacts in videos\nremains largely unexplored, particularly the effectiveness of methods such as\ndownstream supervision with linear probing or full fine-tuning. This work aims\nto bridge this gap by employing eight different convolutional neural networks\n(CNNs) based video SSL models to identify instances of physical contact within\nvideo sequences specifically. The Something-Something v2 (SSv2) and\nEpic-Kitchen (EK-100) datasets were chosen for evaluating these approaches due\nto the promising results on UCF101 and HMDB51, coupled with their limited prior\nassessment on SSv2 and EK-100. Additionally, these datasets feature diverse\nenvironments and scenarios, essential for testing the robustness and accuracy\nof video-based models. This approach not only examines the effectiveness of\neach model in recognizing physical contacts but also explores the performance\nin the action recognition downstream task. By doing so, valuable insights into\nthe adaptability of SSL models in interpreting complex, dynamic visual\ninformation are contributed.", "categories": "cs.CV", "created": "2024-08-01", "doi": null, "arxiv_id": "2408.00498"}
{"title": "To Change Or To Stick: Unveiling The Consistency Of Cyber Criminal\n  Signatures Through Statistical Analysis", "authors": [], "abstract": "This study unveils the elusive presence of criminal signatures in cyberspace,\nvalidating for the first time their existence through statistical evidence. By\napplying the A priori algorithm to the modus operandi of Advanced Persistent\nThreats, extracted from an extensive corpus of over 17,000 articles spanning\n2007 to 2020, we highlight the enduring patterns leveraged by sophisticated\ncyber criminals. Our findings verify the existence of unique signatures\nassociated with advanced cybercriminals, bridging a crucial gap in current\nunderstanding of human behavior in cyber-attacks. This pivotal research sets\nthe foundation for an entirely new academic intersection in cybersecurity and\ncomputational criminology.", "categories": "cs.CR", "created": "2024-08-01", "doi": null, "arxiv_id": "2408.00499"}
{"title": "If It Looks Like a Rootkit and Deceives Like a Rootkit: A Critical\n  Examination of Kernel-Level Anti-Cheat Systems", "authors": [], "abstract": "Addressing a critical aspect of cybersecurity in online gaming, this paper\nsystematically evaluates the extent to which kernel-level anti-cheat systems\nmirror the properties of rootkits, highlighting the importance of\ndistinguishing between protective and potentially invasive software. After\nestablishing a definition for rootkits (making distinctions between rootkits\nand simple kernel-level applications) and defining metrics to evaluate such\nsoftware, we introduce four widespread kernel-level anti-cheat solutions. We\nlay out the inner workings of these types of software, assess them according to\nour previously established definitions, and discuss ethical considerations and\nthe possible privacy infringements introduced by such programs. Our analysis\nshows two of the four anti-cheat solutions exhibiting rootkit-like behaviour,\nthreatening the privacy and the integrity of the system. This paper thus\nprovides crucial insights for researchers and developers in the field of gaming\nsecurity and software engineering, highlighting the need for informed\ndevelopment practices that carefully consider the intersection of effective\nanti-cheat mechanisms and user privacy.", "categories": "cs.CR cs.CY", "created": "2024-08-01", "doi": "10.1145/3664476.3670433", "arxiv_id": "2408.00500"}
{"title": "Quantum Program Testing Through Commuting Pauli Strings on IBM's Quantum\n  Computers", "authors": [], "abstract": "The most promising applications of quantum computing are centered around\nsolving search and optimization tasks, particularly in fields such as physics\nsimulations, quantum chemistry, and finance. However, the current quantum\nsoftware testing methods face practical limitations when applied in industrial\ncontexts: (i) they do not apply to quantum programs most relevant to the\nindustry, (ii) they require a full program specification, which is usually not\navailable for these programs, and (iii) they are incompatible with error\nmitigation methods currently adopted by main industry actors like IBM. To\naddress these challenges, we present QOPS, a novel quantum software testing\napproach. QOPS introduces a new definition of test cases based on Pauli strings\nto improve compatibility with different quantum programs. QOPS also introduces\na new test oracle that can be directly integrated with industrial APIs such as\nIBM's Estimator API and can utilize error mitigation methods for testing on\nreal noisy quantum computers. We also leverage the commuting property of Pauli\nstrings to relax the requirement of having complete program specifications,\nmaking QOPS practical for testing complex quantum programs in industrial\nsettings. We empirically evaluate QOPS on 194,982 real quantum programs,\ndemonstrating effective performance in test assessment compared to the\nstate-of-the-art with a perfect F1-score, precision, and recall. Furthermore,\nwe validate the industrial applicability of QOPS by assessing its performance\non IBM's three real quantum computers, incorporating both industrial and\nopen-source error mitigation methods.", "categories": "cs.SE", "created": "2024-08-01", "doi": null, "arxiv_id": "2408.00501"}
{"title": "Hacked in Translation -- from Subtitles to Complete Takeover", "authors": [], "abstract": "Check Point researchers revealed a new attack vector which threatens millions\nof users worldwide - attack by subtitles. By crafting malicious subtitle files,\nwhich are then downloaded by a victim's media player, attackers can take\ncomplete control over any type of device via vulnerabilities found in many\npopular streaming platforms, including VLC, Kodi (XBMC), Popcorn-Time and\nstrem.io. We estimate there are approximately 200 million video players and\nstreamers that currently run the vulnerable software, making this one of the\nmost widespread, easily accessed and zero-resistance vulnerability reported in\nrecent years.\n  Our research reveals a new possible attack vector, using a completely\noverlooked technique in which the cyberattack is delivered when movie subtitles\nare automatically loaded from online repositories by the user's media player.\nThese subtitles repositories are, in practice, treated as a trusted source by\nthe user or media player; our research also reveals that those repositories can\nbe manipulated and be made to award the attacker's malicious subtitles a high\nscore, which results in those specific subtitles being served to the user. This\nmethod requires little or no deliberate action on the part of the user, making\nit all the more dangerous.\n  Unlike traditional attack vectors, which security firms and users are widely\naware of, movie subtitles are perceived as nothing more than benign text files.\nThis means users, Anti-Virus software, and other security solutions vet them\nwithout trying to assess their real nature, leaving millions of users exposed\nto this risk.", "categories": "cs.CR", "created": "2024-08-01", "doi": null, "arxiv_id": "2408.00502"}
{"title": "Spatial Weather, Socio-Economic and Political Risks in Probabilistic\n  Load Forecasting", "authors": [], "abstract": "Accurate forecasts of the impact of spatial weather and pan-European\nsocio-economic and political risks on hourly electricity demand for the\nmid-term horizon are crucial for strategic decision-making amidst the inherent\nuncertainty. Most importantly, these forecasts are essential for the\noperational management of power plants, ensuring supply security and grid\nstability, and in guiding energy trading and investment decisions. The primary\nchallenge for this forecasting task lies in disentangling the multifaceted\ndrivers of load, which include national deterministic (daily, weekly, annual,\nand holiday patterns) and national stochastic weather and autoregressive\neffects. Additionally, transnational stochastic socio-economic and political\neffects add further complexity, in particular, due to their non-stationarity.\nTo address this challenge, we present an interpretable probabilistic mid-term\nforecasting model for the hourly load that captures, besides all deterministic\neffects, the various uncertainties in load. This model recognizes transnational\ndependencies across 24 European countries, with multivariate modeled\nsocio-economic and political states and cross-country dependent forecasting.\nBuilt from interpretable Generalized Additive Models (GAMs), the model enables\nan analysis of the transmission of each incorporated effect to the\nhour-specific load. Our findings highlight the vulnerability of countries\nreliant on electric heating under extreme weather scenarios. This emphasizes\nthe need for high-resolution forecasting of weather effects on pan-European\nelectricity consumption especially in anticipation of widespread electric\nheating adoption.", "categories": "stat.AP cs.CE econ.GN q-fin.EC q-fin.RM stat.CO", "created": "2024-08-01", "doi": null, "arxiv_id": "2408.00507"}
{"title": "Block-Operations: Using Modular Routing to Improve Compositional\n  Generalization", "authors": [], "abstract": "We explore the hypothesis that poor compositional generalization in neural\nnetworks is caused by difficulties with learning effective routing. To solve\nthis problem, we propose the concept of block-operations, which is based on\nsplitting all activation tensors in the network into uniformly sized blocks and\nusing an inductive bias to encourage modular routing and modification of these\nblocks. Based on this concept we introduce the Multiplexer, a new architectural\ncomponent that enhances the Feed Forward Neural Network (FNN). We\nexperimentally confirm that Multiplexers exhibit strong compositional\ngeneralization. On both a synthetic and a realistic task our model was able to\nlearn the underlying process behind the task, whereas both FNNs and\nTransformers were only able to learn heuristic approximations. We propose as\nfuture work to use the principles of block-operations to improve other existing\narchitectures.", "categories": "cs.LG", "created": "2024-08-01", "doi": null, "arxiv_id": "2408.00508"}
{"title": "Multiscale topology optimization of functionally graded lattice\n  structures based on physics-augmented neural network material models", "authors": [], "abstract": "We present a new framework for the simultaneous optimiziation of both the\ntopology as well as the relative density grading of cellular structures and\nmaterials, also known as lattices. Due to manufacturing constraints, the\noptimization problem falls into the class of NP-complete mixed-integer\nnonlinear programming problems. To tackle this difficulty, we obtain a relaxed\nproblem from a multiplicative split of the relative density and a penalization\napproach. The sensitivities of the objective function are derived such that any\ngradient-based solver might be applied for the iterative update of the design\nvariables. In a next step, we introduce a material model that is parametric in\nthe design variables of interest and suitable to describe the isotropic\ndeformation behavior of quasi-stochastic lattices. For that, we derive and\nimplement further physical constraints and enhance a physics-augmented neural\nnetwork from the literature that was formulated initially for rhombic\nmaterials. Finally, to illustrate the applicability of the method, we\nincorporate the material model into our computational framework and exemplary\noptimize two-and three-dimensional benchmark structures as well as a complex\naircraft component.", "categories": "cs.CE", "created": "2024-08-01", "doi": null, "arxiv_id": "2408.00510"}
{"title": "Comparative Study of Data-driven Area Inertia Estimation Approaches on\n  WECC Power Systems", "authors": [], "abstract": "With the increasing integration of inverter-based resources into the power\ngrid, there has been a notable reduction in system inertia, potentially\ncompromising frequency stability. To assess the suitability of existing area\ninertia estimation techniques for real-world power systems, this paper presents\na rigorous comparative analysis of system identification, measurement\nreconstruction, and electromechanical oscillation-based area inertia estimation\nmethodologies, specifically applied to the large-scale and multi-area WECC\n240-bus power system. Comprehensive results show that the system\nidentification-based approach exhibits superior robustness and accuracy\nrelative to its counterparts.", "categories": "eess.SY cs.SY", "created": "2024-08-01", "doi": null, "arxiv_id": "2408.00511"}
{"title": "FlowGPT: Exploring Domains, Output Modalities, and Goals of\n  Community-Generated AI Chatbots", "authors": [], "abstract": "The advent of Generative AI and Large Language Models has not only enhanced\nthe intelligence of interactive applications but also catalyzed the formation\nof communities passionate about customizing these AI capabilities. FlowGPT, an\nemerging platform for sharing AI prompts and use cases, exemplifies this trend,\nattracting many creators who develop and share chatbots with a broader\ncommunity. Despite its growing popularity, there remains a significant gap in\nunderstanding the types and purposes of the AI tools created and shared by\ncommunity members. In this study, we delve into FlowGPT and present our\npreliminary findings on the domain, output modality, and goals of chatbots. We\naim to highlight common types of AI applications and identify future directions\nfor research in AI-sharing communities.", "categories": "cs.HC", "created": "2024-08-01", "doi": "10.1145/3678884.3681875", "arxiv_id": "2408.00512"}
{"title": "VecAug: Unveiling Camouflaged Frauds with Cohort Augmentation for\n  Enhanced Detection", "authors": [], "abstract": "Fraud detection presents a challenging task characterized by ever-evolving\nfraud patterns and scarce labeled data. Existing methods predominantly rely on\ngraph-based or sequence-based approaches. While graph-based approaches connect\nusers through shared entities to capture structural information, they remain\nvulnerable to fraudsters who can disrupt or manipulate these connections. In\ncontrast, sequence-based approaches analyze users' behavioral patterns,\noffering robustness against tampering but overlooking the interactions between\nsimilar users. Inspired by cohort analysis in retention and healthcare, this\npaper introduces VecAug, a novel cohort-augmented learning framework that\naddresses these challenges by enhancing the representation learning of target\nusers with personalized cohort information. To this end, we first propose a\nvector burn-in technique for automatic cohort identification, which retrieves a\ntask-specific cohort for each target user. Then, to fully exploit the cohort\ninformation, we introduce an attentive cohort aggregation technique for\naugmenting target user representations. To improve the robustness of such\ncohort augmentation, we also propose a novel label-aware cohort neighbor\nseparation mechanism to distance negative cohort neighbors and calibrate the\naggregated cohort information. By integrating this cohort information with\ntarget user representations, VecAug enhances the modeling capacity and\ngeneralization capabilities of the model to be augmented. Our framework is\nflexible and can be seamlessly integrated with existing fraud detection models.\nWe deploy our framework on e-commerce platforms and evaluate it on three fraud\ndetection datasets, and results show that VecAug improves the detection\nperformance of base models by up to 2.48\\% in AUC and 22.5\\% in R@P$_{0.9}$,\noutperforming state-of-the-art methods significantly.", "categories": "cs.LG", "created": "2024-08-01", "doi": null, "arxiv_id": "2408.00513"}
{"title": "Low-Power Vibration-Based Predictive Maintenance for Industry 4.0 using\n  Neural Networks: A Survey", "authors": [], "abstract": "The advancements in smart sensors for Industry 4.0 offer ample opportunities\nfor low-powered predictive maintenance and condition monitoring. However,\ntraditional approaches in this field rely on processing in the cloud, which\nincurs high costs in energy and storage. This paper investigates the potential\nof neural networks for low-power on-device computation of vibration sensor data\nfor predictive maintenance. We review the literature on Spiking Neural Networks\n(SNNs) and Artificial Neuronal Networks (ANNs) for vibration-based predictive\nmaintenance by analyzing datasets, data preprocessing, network architectures,\nand hardware implementations. Our findings suggest that no satisfactory\nstandard benchmark dataset exists for evaluating neural networks in predictive\nmaintenance tasks. Furthermore frequency domain transformations are commonly\nemployed for preprocessing. SNNs mainly use shallow feed forward architectures,\nwhereas ANNs explore a wider range of models and deeper networks. Finally, we\nhighlight the need for future research on hardware implementations of neural\nnetworks for low-power predictive maintenance applications and the development\nof a standardized benchmark dataset.", "categories": "cs.LG", "created": "2024-08-01", "doi": null, "arxiv_id": "2408.00516"}
{"title": "A new approach for encoding code and assisting code understanding", "authors": [], "abstract": "Some companies(e.g., Microsoft Research and Google DeepMind) have discovered\nsome of the limitations of GPTs autoregressive paradigm next-word prediction,\nmanifested in the model lack of planning, working memory, backtracking, and\nreasoning skills. GPTs rely on a local and greedy process of generating the\nnext word, without a global understanding of the task or the output.We have\nconfirmed the above limitations through specialized empirical studies of code\ncomprehension. Although GPT4 is good at producing fluent and coherent text, it\ncannot handle complex logic and generate new code that haven not been seen, and\nit relies too much on the formatting of the prompt to generate the correct\ncode.We propose a new paradigm for code understanding that goes beyond the\nnext-word prediction paradigm, inspired by the successful application of\ndiffusion techniques to image generation(Dalle2, Sora) and protein structure\ngeneration(AlphaFold3), which have no autoregressive constraints.Instead of\nencoding the code in a form that mimics natural language, we encode the code as\na heterogeneous image paradigm with a memory of global information that mimics\nboth images and protein structures.We then refer to Sora's CLIP upstream\ntext-to-image encoder model to design a text-to-code encoder model that can be\napplied to various downstream code understanding tasks.The model learns the\nglobal understanding of code under the new paradigm heterogeneous image,\nconnects the encoding space of text and code, and encodes the input of text\ninto the vector of code most similar to it.Using self-supervised comparative\nlearning on 456,360 text-code pairs, the model achieved a zero-shot prediction\nof new data. This work is the basis for future work on code generation using\ndiffusion techniques under a new paradigm to avoid autoregressive limitations.", "categories": "cs.AI", "created": "2024-08-01", "doi": null, "arxiv_id": "2408.00521"}
{"title": "Jailbreaking Text-to-Image Models with LLM-Based Agents", "authors": [], "abstract": "Recent advancements have significantly improved automated task-solving\ncapabilities using autonomous agents powered by large language models (LLMs).\nHowever, most LLM-based agents focus on dialogue, programming, or specialized\ndomains, leaving gaps in addressing generative AI safety tasks. These gaps are\nprimarily due to the challenges posed by LLM hallucinations and the lack of\nclear guidelines. In this paper, we propose Atlas, an advanced LLM-based\nmulti-agent framework that integrates an efficient fuzzing workflow to target\ngenerative AI models, specifically focusing on jailbreak attacks against\ntext-to-image (T2I) models with safety filters. Atlas utilizes a\nvision-language model (VLM) to assess whether a prompt triggers the T2I model's\nsafety filter. It then iteratively collaborates with both LLM and VLM to\ngenerate an alternative prompt that bypasses the filter. Atlas also enhances\nthe reasoning abilities of LLMs in attack scenarios by leveraging multi-agent\ncommunication, in-context learning (ICL) memory mechanisms, and the\nchain-of-thought (COT) approach. Our evaluation demonstrates that Atlas\nsuccessfully jailbreaks several state-of-the-art T2I models in a black-box\nsetting, which are equipped with multi-modal safety filters. In addition, Atlas\noutperforms existing methods in both query efficiency and the quality of the\ngenerated images.", "categories": "cs.CR cs.AI cs.LG", "created": "2024-08-01", "doi": null, "arxiv_id": "2408.00523"}
{"title": "Identifying the Hierarchical Emotional Areas in the Human Brain Through\n  Information Fusion", "authors": [], "abstract": "The brain basis of emotion has consistently received widespread attention,\nattracting a large number of studies to explore this cutting-edge topic.\nHowever, the methods employed in these studies typically only model the\npairwise relationship between two brain regions, while neglecting the\ninteractions and information fusion among multiple brain\nregions$\\unicode{x2014}$one of the key ideas of the psychological\nconstructionist hypothesis. To overcome the limitations of traditional methods,\nthis study provides an in-depth theoretical analysis of how to maximize\ninteractions and information fusion among brain regions. Building on the\nresults of this analysis, we propose to identify the hierarchical emotional\nareas in the human brain through multi-source information fusion and graph\nmachine learning methods. Comprehensive experiments reveal that the identified\nhierarchical emotional areas, from lower to higher levels, primarily facilitate\nthe fundamental process of emotion perception, the construction of basic\npsychological operations, and the coordination and integration of these\noperations. Overall, our findings provide unique insights into the brain\nmechanisms underlying specific emotions based on the psychological\nconstructionist hypothesis.", "categories": "cs.HC cs.DM cs.LG", "created": "2024-08-01", "doi": null, "arxiv_id": "2408.00525"}
{"title": "Hilbert curves for efficient exploratory landscape analysis\n  neighbourhood sampling", "authors": [], "abstract": "Landscape analysis aims to characterise optimisation problems based on their\nobjective (or fitness) function landscape properties. The problem search space\nis typically sampled, and various landscape features are estimated based on the\nsamples. One particularly salient set of features is information content, which\nrequires the samples to be sequences of neighbouring solutions, such that the\nlocal relationships between consecutive sample points are preserved. Generating\nsuch spatially correlated samples that also provide good search space coverage\nis challenging. It is therefore common to first obtain an unordered sample with\ngood search space coverage, and then apply an ordering algorithm such as the\nnearest neighbour to minimise the distance between consecutive points in the\nsample. However, the nearest neighbour algorithm becomes computationally\nprohibitive in higher dimensions, thus there is a need for more efficient\nalternatives. In this study, Hilbert space-filling curves are proposed as a\nmethod to efficiently obtain high-quality ordered samples. Hilbert curves are a\nspecial case of fractal curves, and guarantee uniform coverage of a bounded\nsearch space while providing a spatially correlated sample. We study the\neffectiveness of Hilbert curves as samplers, and discover that they are capable\nof extracting salient features at a fraction of the computational cost compared\nto Latin hypercube sampling with post-factum ordering. Further, we investigate\nthe use of Hilbert curves as an ordering strategy, and find that they order the\nsample significantly faster than the nearest neighbour ordering, without\nsacrificing the saliency of the extracted features.", "categories": "cs.LG cs.AI cs.NE", "created": "2024-08-01", "doi": "10.1007/978-3-031-56855-8_18", "arxiv_id": "2408.00526"}
{"title": "Contrastive Learning with Dynamic Localized Repulsion for Brain Age\n  Prediction on 3D Stiffness Maps", "authors": [], "abstract": "In the field of neuroimaging, accurate brain age prediction is pivotal for\nuncovering the complexities of brain aging and pinpointing early indicators of\nneurodegenerative conditions. Recent advancements in self-supervised learning,\nparticularly in contrastive learning, have demonstrated greater robustness when\ndealing with complex datasets. However, current approaches often fall short in\ngeneralizing across non-uniformly distributed data, prevalent in medical\nimaging scenarios. To bridge this gap, we introduce a novel contrastive loss\nthat adapts dynamically during the training process, focusing on the localized\nneighborhoods of samples. Moreover, we expand beyond traditional structural\nfeatures by incorporating brain stiffness, a mechanical property previously\nunderexplored yet promising due to its sensitivity to age-related changes. This\nwork presents the first application of self-supervised learning to brain\nmechanical properties, using compiled stiffness maps from various clinical\nstudies to predict brain age. Our approach, featuring dynamic localized loss,\nconsistently outperforms existing state-of-the-art methods, demonstrating\nsuperior performance and laying the way for new directions in brain aging\nresearch.", "categories": "cs.LG", "created": "2024-08-01", "doi": null, "arxiv_id": "2408.00527"}
{"title": "ReSi: A Comprehensive Benchmark for Representational Similarity Measures", "authors": [], "abstract": "Measuring the similarity of different representations of neural architectures\nis a fundamental task and an open research challenge for the machine learning\ncommunity. This paper presents the first comprehensive benchmark for evaluating\nrepresentational similarity measures based on well-defined groundings of\nsimilarity. The representational similarity (ReSi) benchmark consists of (i)\nsix carefully designed tests for similarity measures, (ii) 23 similarity\nmeasures, (iii) eleven neural network architectures, and (iv) six datasets,\nspanning over the graph, language, and vision domains. The benchmark opens up\nseveral important avenues of research on representational similarity that\nenable novel explorations and applications of neural architectures. We\ndemonstrate the utility of the ReSi benchmark by conducting experiments on\nvarious neural network architectures, real world datasets and similarity\nmeasures. All components of the benchmark are publicly available and thereby\nfacilitate systematic reproduction and production of research results. The\nbenchmark is extensible, future research can build on and further expand it. We\nbelieve that the ReSi benchmark can serve as a sound platform catalyzing future\nresearch that aims to systematically evaluate existing and explore novel ways\nof comparing representations of neural architectures.", "categories": "cs.LG", "created": "2024-08-01", "doi": null, "arxiv_id": "2408.00531"}
{"title": "Predicting nonlinear-flow regions in highly heterogeneous porous media\n  using adaptive constitutive laws and neural networks", "authors": [], "abstract": "In a porous medium featuring heterogeneous permeabilities, a wide range of\nfluid velocities may be recorded, so that significant inertial and frictional\neffects may arise in high-speed regions. In such parts, the link between\npressure gradient and velocity is typically made via Darcy's law, which may\nfail to account for these effects; instead, the Darcy Forchheimer law, which\nintroduces a nonlinear term, may be more adequate. Applying the Darcy\nForchheimer law globally in the domain is very costly numerically and, rather,\nshould only be done where strictly necessary. The question of finding a prori\nthe subdomain where to restrict the use of the Darcy Forchheimer law was\nrecently answered in FP23 by using an adaptive model: given a threshold on the\nflow velocity, the model locally selects the more appropriate law as it is\nbeing solved. At the end of the resolution, each mesh cell is flagged as being\nin the Darcy or Darcy Forchheimer subdomain. Still, this model is nonlinear\nitself and thus relatively expensive to run. In this paper, to accelerate the\nsubdivision of the domain into low and high speed regions, we instead exploit\nthe adaptive model from FP23 to generate partitioning data given an array of\ndifferent input parameters, such as boundary conditions and inertial\ncoefficients, and then train neural networks on these data classifying each\nmesh cell as Darcy or not. Two test cases are studied to illustrate the\nresults, where cost functions, parity plots, precision-recall plots and\nreceiver operating characteristic curves are analyzed.", "categories": "math.NA cs.NA physics.flu-dyn", "created": "2024-08-01", "doi": null, "arxiv_id": "2408.00533"}
{"title": "The Monetisation of Toxicity: Analysing YouTube Content Creators and\n  Controversy-Driven Engagement", "authors": [], "abstract": "YouTube is a major social media platform that plays a significant role in\ndigital culture, with content creators at its core. These creators often engage\nin controversial behaviour to drive engagement, which can foster toxicity. This\npaper presents a quantitative analysis of controversial content on YouTube,\nfocusing on the relationship between controversy, toxicity, and monetisation.\nWe introduce a curated dataset comprising 20 controversial YouTube channels\nextracted from Reddit discussions, including 16,349 videos and more than 105\nmillion comments. We identify and categorise monetisation cues from video\ndescriptions into various models, including affiliate marketing and direct\nselling, using lists of URLs and keywords. Additionally, we train a machine\nlearning model to measure the toxicity of comments in these videos. Our\nfindings reveal that while toxic comments correlate with higher engagement,\nthey negatively impact monetisation, indicating that controversy-driven\ninteraction does not necessarily lead to financial gain. We also observed\nsignificant variation in monetisation strategies, with some creators showing\nextensive monetisation despite high toxicity levels. Our study introduces a\ncurated dataset, lists of URLs and keywords to categorise monetisation, a\nmachine learning model to measure toxicity, and is a significant step towards\nunderstanding the complex relationship between controversy, engagement, and\nmonetisation on YouTube. The lists used for detecting and categorising\nmonetisation cues are available on https://github.com/thalesbertaglia/toxmon.", "categories": "cs.CY cs.CL", "created": "2024-08-01", "doi": "10.1145/3677117.3685005", "arxiv_id": "2408.00534"}
{"title": "High-Quality, ROS Compatible Video Encoding and Decoding for\n  High-Definition Datasets", "authors": [], "abstract": "Robotic datasets are important for scientific benchmarking and developing\nalgorithms, for example for Simultaneous Localization and Mapping (SLAM).\nModern robotic datasets feature video data of high resolution and high\nframerates. Storing and sharing those datasets becomes thus very costly,\nespecially if more than one camera is used for the datasets. It is thus\nessential to store this video data in a compressed format. This paper\ninvestigates the use of modern video encoders for robotic datasets. We provide\na software that can replay mp4 videos within ROS 1 and ROS 2 frameworks,\nsupporting the synchronized playback in simulated time. Furthermore, the paper\nevaluates different encoders and their settings to find optimal configurations\nin terms of resulting size, quality and encoding time. Through this work we\nshow that it is possible to store and share even highest quality video datasets\nwithin reasonable storage constraints.", "categories": "cs.RO cs.CV", "created": "2024-08-01", "doi": null, "arxiv_id": "2408.00538"}
{"title": "Intermittent Semi-working Mask: A New Masking Paradigm for LLMs", "authors": [], "abstract": "Multi-turn dialogues are a key interaction method between humans and Large\nLanguage Models (LLMs), as conversations extend over multiple rounds, keeping\nLLMs' high generation quality and low latency is a challenge. Mainstream LLMs\ncan be grouped into two categories based on masking strategy: causal LLM and\nprefix LLM. Several works have demonstrated that prefix LLMs tend to outperform\ncausal ones in scenarios that heavily depend on historical context such as\nmulti-turn dialogues or in-context learning, thanks to their bidirectional\nattention on prefix sequences. However, prefix LLMs have an inherent\ninefficient training problem in multi-turn dialogue datasets. In addition, the\nattention mechanism of prefix LLM makes it unable to reuse Key-Value Cache (KV\nCache) across dialogue rounds to reduce generation latency. In this paper, we\npropose a novel masking scheme called Intermittent Semi-working Mask (ISM) to\naddress these problems. Specifically, we apply alternate bidirectional and\nunidirectional attention on queries and answers in the dialogue history. In\nthis way, ISM is able to maintain the high quality of prefix LLM and low\ngeneration latency of causal LLM, simultaneously. Extensive experiments\nillustrate that our ISM achieves significant performance.", "categories": "cs.CL cs.AI", "created": "2024-08-01", "doi": null, "arxiv_id": "2408.00539"}
{"title": "The Energy Cost of Artificial Intelligence of Things Lifecycle", "authors": [], "abstract": "Artificial intelligence (AI)coupled with existing Internet of Things (IoT)\nenables more streamlined and autonomous operations across various economic\nsectors. Consequently, the paradigm of Artificial Intelligence of Things (AIoT)\nhaving AI techniques at its core implies additional energy and carbon costs\nthat may become significant with more complex neural architectures. To better\nunderstand the energy and Carbon Footprint (CF) of some AIoT components, very\nrecent studies employ conventional metrics. However, these metrics are not\ndesigned to capture energy efficiency aspects of inference. In this paper, we\npropose a new metric, the Energy Cost of AIoT Lifecycle (eCAL) to capture the\noverall energy cost of inference over the lifecycle of an AIoT system. We\ndevise a new methodology for determining eCAL of an AIoT system by analyzing\nthe complexity of data manipulation in individual components involved in the\nAIoT lifecycle and derive the overall and per bit energy consumption. With eCAL\nwe show that the better a model is and the more it is used, the more energy\nefficient an inference is. For an example AIoT configuration, eCAL for making\n$100$ inferences is $1.43$ times higher than for $1000$ inferences. We also\nevaluate the CF of the AIoT system by calculating the equivalent CO$_{2}$\nemissions based on the energy consumption and the Carbon Intensity (CI) across\ndifferent countries. Using 2023 renewable data, our analysis reveals that\ndeploying an AIoT system in Germany results in emitting $4.62$ times higher\nCO$_2$ than in Finland, due to latter using more low-CI energy sources.", "categories": "cs.ET cs.AI cs.LG", "created": "2024-08-01", "doi": null, "arxiv_id": "2408.00540"}
{"title": "Secret Sharing for Secure and Private Information Retrieval: A\n  Construction Using Algebraic Geometry Codes", "authors": [], "abstract": "Private information retrieval (PIR) considers the problem of retrieving a\ndata item from a database or distributed storage system without disclosing any\ninformation about which data item was retrieved. Secure PIR complements this\nproblem by further requiring the contents of the data to be kept secure.\nPrivacy and security can be achieved by adding suitable noise to the queries\nand data using methods from secret sharing. In this paper, a new framework for\nhomomorphic secret sharing in secure and private information retrieval from\ncolluding servers is proposed, generalizing the original cross-subspace\nalignment (CSA) codes proposed by Jia, Sun, and Jafar. We utilize this\nframework to give a secure PIR construction using algebraic geometry codes over\nhyperelliptic curves of arbitrary genus. It is shown that the proposed scheme\noffers interesting tradeoffs between the field size, file size, number of\ncolluding servers, and the total number of servers. When the field size is\nfixed, this translates in some cases to higher retrieval rates than those of\nthe original scheme. In addition, the new schemes exist also for some\nparameters where the original ones do not.", "categories": "cs.IT math.IT", "created": "2024-08-01", "doi": null, "arxiv_id": "2408.00542"}
{"title": "Illustrating Classic Brazilian Books using a Text-To-Image Diffusion\n  Model", "authors": [], "abstract": "In recent years, Generative Artificial Intelligence (GenAI) has undergone a\nprofound transformation in addressing intricate tasks involving diverse\nmodalities such as textual, auditory, visual, and pictorial generation. Within\nthis spectrum, text-to-image (TTI) models have emerged as a formidable approach\nto generating varied and aesthetically appealing compositions, spanning\napplications from artistic creation to realistic facial synthesis, and\ndemonstrating significant advancements in computer vision, image processing,\nand multimodal tasks. The advent of Latent Diffusion Models (LDMs) signifies a\nparadigm shift in the domain of AI capabilities. This article delves into the\nfeasibility of employing the Stable Diffusion LDM to illustrate literary works.\nFor this exploration, seven classic Brazilian books have been selected as case\nstudies. The objective is to ascertain the practicality of this endeavor and to\nevaluate the potential of Stable Diffusion in producing illustrations that\naugment and enrich the reader's experience. We will outline the beneficial\naspects, such as the capacity to generate distinctive and contextually\npertinent images, as well as the drawbacks, including any shortcomings in\nfaithfully capturing the essence of intricate literary depictions. Through this\nstudy, we aim to provide a comprehensive assessment of the viability and\nefficacy of utilizing AI-generated illustrations in literary contexts,\nelucidating both the prospects and challenges encountered in this pioneering\napplication of technology.", "categories": "cs.AI", "created": "2024-08-01", "doi": null, "arxiv_id": "2408.00544"}
{"title": "Collecting Larg-Scale Robotic Datasets on a High-Speed Mobile Platform", "authors": [], "abstract": "Mobile robotics datasets are essential for research on robotics, for example\nfor research on Simultaneous Localization and Mapping (SLAM). Therefore the\nShanghaiTech Mapping Robot was constructed, that features a multitude\nhigh-performance sensors and a 16-node cluster to collect all this data. That\nrobot is based on a Clearpath Husky mobile base with a maximum speed of 1 meter\nper second. This is fine for indoor datasets, but to collect large-scale\noutdoor datasets a faster platform is needed. This system paper introduces our\nhigh-speed mobile platform for data collection. The mapping robot is secured on\nthe rear-steered flatbed car with maximum field of view. Additionally two\nencoders collect odometry data from two of the car wheels and an external\nsensor plate houses a downlooking RGB and event camera. With this setup a\ndataset of more than 10km in the underground parking garage and the outside of\nour campus was collected and is published with this paper.", "categories": "cs.RO", "created": "2024-08-01", "doi": null, "arxiv_id": "2408.00545"}
{"title": "Learning to Embed Distributions via Maximum Kernel Entropy", "authors": [], "abstract": "Empirical data can often be considered as samples from a set of probability\ndistributions. Kernel methods have emerged as a natural approach for learning\nto classify these distributions. Although numerous kernels between\ndistributions have been proposed, applying kernel methods to distribution\nregression tasks remains challenging, primarily because selecting a suitable\nkernel is not straightforward. Surprisingly, the question of learning a\ndata-dependent distribution kernel has received little attention. In this\npaper, we propose a novel objective for the unsupervised learning of\ndata-dependent distribution kernel, based on the principle of entropy\nmaximization in the space of probability measure embeddings. We examine the\ntheoretical properties of the latent embedding space induced by our objective,\ndemonstrating that its geometric structure is well-suited for solving\ndownstream discriminative tasks. Finally, we demonstrate the performance of the\nlearned kernel across different modalities.", "categories": "cs.LG cs.AI eess.SP stat.ML", "created": "2024-08-01", "doi": null, "arxiv_id": "2408.00549"}
{"title": "Mitigating Multilingual Hallucination in Large Vision-Language Models", "authors": [], "abstract": "While Large Vision-Language Models (LVLMs) have exhibited remarkable\ncapabilities across a wide range of tasks, they suffer from hallucination\nproblems, where models generate plausible yet incorrect answers given the input\nimage-query pair. This hallucination phenomenon is even more severe when\nquerying the image in non-English languages, while existing methods for\nmitigating hallucinations in LVLMs only consider the English scenarios. In this\npaper, we make the first attempt to mitigate this important multilingual\nhallucination in LVLMs. With thorough experiment analysis, we found that\nmultilingual hallucination in LVLMs is a systemic problem that could arise from\ndeficiencies in multilingual capabilities or inadequate multimodal abilities.\nTo this end, we propose a two-stage Multilingual Hallucination Removal (MHR)\nframework for LVLMs, aiming to improve resistance to hallucination for both\nhigh-resource and low-resource languages. Instead of relying on the intricate\nmanual annotations of multilingual resources, we fully leverage the inherent\ncapabilities of the LVLM and propose a novel cross-lingual alignment method,\nwhich generates multiple responses for each image-query input and then\nidentifies the hallucination-aware pairs for each language. These data pairs\nare finally used for direct preference optimization to prompt the LVLMs to\nfavor non-hallucinating responses. Experimental results show that our MHR\nachieves a substantial reduction in hallucination generation for LVLMs.\nNotably, on our extended multilingual POPE benchmark, our framework delivers an\naverage increase of 19.0% in accuracy across 13 different languages. Our code\nand model weights are available at https://github.com/ssmisya/MHR", "categories": "cs.CV cs.AI cs.CL", "created": "2024-08-01", "doi": null, "arxiv_id": "2408.00550"}
{"title": "Manifold-Based Optimizations for RIS-Aided Massive MIMO Systems", "authors": [], "abstract": "Manifold optimization (MO) is a powerful mathematical framework that can be\napplied to optimize functions over complex geometric structures, which is\nparticularly useful in advanced wireless communication systems, such as\nreconfigurable intelligent surface (RIS)-aided massive MIMO (mMIMO) and\nextra-large scale massive MIMO (XL-MIMO) systems. MO provides a structured\napproach to tackling complex optimization problems. By leveraging the geometric\nproperties of the manifold, more efficient and effective solutions can be found\ncompared to conventional optimization methods. This paper provides a tutorial\non MO technique and provides some applications of MO in the context of wireless\ncommunications systems. In particular, to corroborate the effectiveness of MO\nmethodology, we explore five application examples in RIS-aided mMIMO system,\nfocusing on fairness, energy efficiency (EE) maximization, intracell pilot\nreuse interference mitigation, and grant-free (GF) random access (RA).", "categories": "cs.NI", "created": "2024-08-01", "doi": null, "arxiv_id": "2408.00553"}
{"title": "Alleviating Hallucination in Large Vision-Language Models with Active\n  Retrieval Augmentation", "authors": [], "abstract": "Despite the remarkable ability of large vision-language models (LVLMs) in\nimage comprehension, these models frequently generate plausible yet factually\nincorrect responses, a phenomenon known as hallucination.Recently, in large\nlanguage models (LLMs), augmenting LLMs by retrieving information from external\nknowledge resources has been proven as a promising solution to mitigate\nhallucinations.However, the retrieval augmentation in LVLM significantly lags\nbehind the widespread applications of LVLM. Moreover, when transferred to\naugmenting LVLMs, sometimes the hallucination degree of the model is even\nexacerbated.Motivated by the research gap and counter-intuitive phenomenon, we\nintroduce a novel framework, the Active Retrieval-Augmented large\nvision-language model (ARA), specifically designed to address hallucinations by\nincorporating three critical dimensions: (i) dissecting the retrieval targets\nbased on the inherent hierarchical structures of images. (ii) pinpointing the\nmost effective retrieval methods and filtering out the reliable retrieval\nresults. (iii) timing the retrieval process to coincide with episodes of low\ncertainty, while circumventing unnecessary retrieval during periods of high\ncertainty. To assess the capability of our proposed ARA model in reducing\nhallucination, we employ three widely used LVLM models (LLaVA-1.5, Qwen-VL, and\nmPLUG-Owl2) across four benchmarks. Our empirical observations suggest that by\nutilizing fitting retrieval mechanisms and timing the retrieval judiciously, we\ncan effectively mitigate the hallucination problem. We hope that this study can\nprovide deeper insights into how to adapt the retrieval augmentation to LVLMs\nfor reducing hallucinations with more effective retrieval and minimal retrieval\noccurrences.", "categories": "cs.CV cs.AI cs.CL", "created": "2024-08-01", "doi": null, "arxiv_id": "2408.00555"}
{"title": "End-to-End Protocol for High-Quality QAOA Parameters with Few Shots", "authors": [], "abstract": "The quantum approximate optimization algorithm (QAOA) is a quantum heuristic\nfor combinatorial optimization that has been demonstrated to scale better than\nstate-of-the-art classical solvers for some problems. For a given problem\ninstance, QAOA performance depends crucially on the choice of the parameters.\nWhile average-case optimal parameters are available in many cases, meaningful\nperformance gains can be obtained by fine-tuning these parameters for a given\ninstance. This task is especially challenging, however, when the number of\ncircuit executions (shots) is limited. In this work, we develop an end-to-end\nprotocol that combines multiple parameter settings and fine-tuning techniques.\nWe use large-scale numerical experiments to optimize the protocol for the\nshot-limited setting and observe that optimizers with the simplest internal\nmodel (linear) perform best. We implement the optimized pipeline on a\ntrapped-ion processor using up to $32$ qubits and $5$ QAOA layers, and we\ndemonstrate that the pipeline is robust to small amounts of hardware noise. To\nthe best of our knowledge, these are the largest demonstrations of QAOA\nparameter tuning on a trapped-ion processor.", "categories": "quant-ph cs.ET", "created": "2024-08-01", "doi": null, "arxiv_id": "2408.00557"}
{"title": "New Compressed Indices for Multijoins on Graph Databases", "authors": [], "abstract": "A recent surprising result in the implementation of worst-case-optimal (wco)\nmultijoins in graph databases (specifically, basic graph patterns) is that they\ncan be supported on graph representations that take even less space than a\nplain representation, and orders of magnitude less space than classical\nindices, while offering comparable performance. In this paper we uncover a wide\nset of new wco space-time tradeoffs: we (1) introduce new compact indices that\nhandle multijoins in wco time, and (2) combine them with new query resolution\nstrategies that offer better times in practice. As a result, we improve the\naverage query times of current compact representations by a factor of up to 13\nto produce the first 1000 results, and using twice their space, reduce their\ntotal average query time by a factor of 2. Our experiments suggest that there\nis more room for improvement in terms of generating better query plans for\nmultijoins.", "categories": "cs.DB cs.DS", "created": "2024-08-01", "doi": null, "arxiv_id": "2408.00558"}
{"title": "AMFR-W numerical methods for solving high dimensional SABR/LIBOR PDE\n  models", "authors": [], "abstract": "In this work we mainly develop a new numerical methodology to solve a PDE\nmodel recently proposed in the literature for pricing interest rate\nderivatives. More precisely, we use high order in time AMFR-W methods, which\nbelong to a class of W-methods based on Approximate Matrix Factorization (AMF)\nand are especially suitable in the presence of mixed spatial derivatives.\nHigh-order convergence in time allows larger time steps which combined with the\nsplitting of the involved operators, highly reduces the computational time for\na given accuracy. Moreover, the consideration of a large number of underlying\nforward rates makes the PDE problem high dimensional in space, so the use of\nAMFR-W methods with a sparse grids combination technique represents another\ninnovative aspect, making AMFR-W more efficient than with full grids and\nopening the possibility of parallelization. Also the consideration of new\nhomogeneous Neumann boundary conditions provides another original feature to\navoid the difficulties associated to the presence of boundary layers when using\nDirichlet ones, especially in advection-dominated regimes. These Neumann\nboundary conditions motivate the introduction of a modified combination\ntechnique to overcome a decrease in the accuracy of the standard combination\ntechnique.", "categories": "math.NA cs.NA", "created": "2024-08-01", "doi": "10.1137/20M1348595", "arxiv_id": "2408.00559"}
{"title": "MUFASA: Multi-View Fusion and Adaptation Network with Spatial Awareness\n  for Radar Object Detection", "authors": [], "abstract": "In recent years, approaches based on radar object detection have made\nsignificant progress in autonomous driving systems due to their robustness\nunder adverse weather compared to LiDAR. However, the sparsity of radar point\nclouds poses challenges in achieving precise object detection, highlighting the\nimportance of effective and comprehensive feature extraction technologies. To\naddress this challenge, this paper introduces a comprehensive feature\nextraction method for radar point clouds. This study first enhances the\ncapability of detection networks by using a plug-and-play module, GeoSPA. It\nleverages the Lalonde features to explore local geometric patterns.\nAdditionally, a distributed multi-view attention mechanism, DEMVA, is designed\nto integrate the shared information across the entire dataset with the global\ninformation of each individual frame. By employing the two modules, we present\nour method, MUFASA, which enhances object detection performance through\nimproved feature extraction. The approach is evaluated on the VoD and\nTJ4DRaDSet datasets to demonstrate its effectiveness. In particular, we achieve\nstate-of-the-art results among radar-based methods on the VoD dataset with the\nmAP of 50.24%.", "categories": "cs.CV", "created": "2024-08-01", "doi": null, "arxiv_id": "2408.00565"}
{"title": "Enhancing Digital Forensics Readiness In Big Data Wireless Medical\n  Networks: A Secure Decentralised Framework", "authors": [], "abstract": "Wireless medical networks are pivotal for chronic disease management, yet the\nsensitive Big Data they generate presents administration challenges and cyber\nvulnerability. This Big Data is valuable within both healthcare and legal\ncontexts, serving as a resource for investigating medical malpractice, civil\ncases, criminal activities, and network-related incidents. However, the rapid\nevolution of network technologies and data creates complexities in digital\nforensics investigations and audits. To address these issues, this paper\nproposes a secure decentralised framework aimed at bolstering digital forensics\nreadiness (DFR) in Big Data wireless medical networks by identifying security\nthreats, complexities, and gaps in current research efforts. By improving the\nnetwork's resilience to cyber threats and aiding in medical malpractice\ninvestigations, this framework significantly advances digital forensics,\nwireless networks, and healthcare. It enhances digital forensics readiness,\nincident response, and the management of medical malpractice incidents in Big\nData wireless medical networks. A real-world scenario-based evaluation\ndemonstrated the framework's effectiveness in improving forensic readiness and\nresponse capabilities, validating its practical applicability and impact. A\ncomparison of the proposed framework with existing frameworks concluded that it\nis an advancement in framework design for DFR, especially in regard to Big Data\nprocessing, decentralised DFR storage and scalability.", "categories": "cs.DC cs.NI", "created": "2024-08-01", "doi": "10.5121/ijnsa.2024.16402", "arxiv_id": "2408.00568"}
{"title": "Analyzing the Effectiveness of Quantum Annealing with Meta-Learning", "authors": [], "abstract": "The field of Quantum Computing has gathered significant popularity in recent\nyears and a large number of papers have studied its effectiveness in tackling\nmany tasks. We focus in particular on Quantum Annealing (QA), a meta-heuristic\nsolver for Quadratic Unconstrained Binary Optimization (QUBO) problems. It is\nknown that the effectiveness of QA is dependent on the task itself, as is the\ncase for classical solvers, but there is not yet a clear understanding of which\nare the characteristics of a problem that makes it difficult to solve with QA.\nIn this work, we propose a new methodology to study the effectiveness of QA\nbased on meta-learning models. To do so, we first build a dataset composed of\nmore than five thousand instances of ten different optimization problems. We\ndefine a set of more than a hundred features to describe their characteristics,\nand solve them with both QA and three classical solvers. We publish this\ndataset online for future research. Then, we train multiple meta-models to\npredict whether QA would solve that instance effectively and use them to probe\nwhich are the features with the strongest impact on the effectiveness of QA.\nOur results indicate that it is possible to accurately predict the\neffectiveness of QA, validating our methodology. Furthermore, we observe that\nthe distribution of the problem coefficients representing the bias and coupling\nterms is very informative to identify the probability of finding good\nsolutions, while the density of these coefficients alone is not enough. The\nmethodology we propose allows to open new research directions to further our\nunderstanding of the effectiveness of QA, by probing specific dimensions or by\ndeveloping new QUBO formulations that are better suited for the particular\nnature of QA. Furthermore, the proposed methodology is flexible and can be\nextended or used to study other quantum or classical solvers.", "categories": "quant-ph cs.LG", "created": "2024-08-01", "doi": "10.1007/s42484-024-00179-8", "arxiv_id": "2408.00570"}
{"title": "Fluctuating Line-of-Sight Fading Distribution: Statistical\n  Characterization and Applications", "authors": [], "abstract": "We introduce the fluctuating Line-of-Sight (fLoS) fading model, characterized\nby parameters $K$, $k$, $\\lambda$, and $\\Omega$. The fLoS fading distribution\nis expressed in terms of the multivariate confluent hypergeometric functions\n$\\Psi_2$, $\\Phi_3^{(n)}$, and $\\Phi_3 = \\Phi_3^{(2)}$ and encompasses\nwell-known distributions, such as the Nakagami-$m$, Hoyt, Rice, and Rician\nshadowed fading distributions as special cases. An efficient method to\nnumerically compute the fLoS fading distribution is also addressed. Notably,\nfor a positive integer $k$, the fLoS fading distribution simplifies to a finite\nmixture of $\\kappa$-$\\mu$ distributions. Additionally, we analyze the outage\nprobability and Ergodic capacity, presenting a tailored Prony's approximation\nmethod for the latter. Numerical results are presented to show the impact of\nthe fading parameters and verify the accuracy of the proposed approximation.\nMoreover, we illustrate an application of the proposed fLoS fading distribution\nfor characterizing wireless systems affected by channel aging.", "categories": "cs.IT eess.SP math.IT", "created": "2024-08-01", "doi": null, "arxiv_id": "2408.00575"}
{"title": "Dimension reduction for large-scale stochastic systems with non-zero\n  initial states and controlled diffusion", "authors": [], "abstract": "In this paper, we establish new strategies to reduce the dimension of\nlarge-scale controlled stochastic differential equations with non-zero initial\nstates. The first approach transforms the original setting into a stochastic\nsystem with zero initial states. This transformation naturally leads to\nequations with controlled diffusion. A detailed analysis of dominant subspaces\nand bounds for the reduction error is provided in this controlled diffusion\nframework. Subsequently, we introduce a reduced system for the original\nframework and prove an a-priori error bound for the first ansatz. This bound\ninvolves so-called Hankel singular values that are linked to a new pair of\nGramians. A second strategy is presented that is based on the idea of reducing\ncontrol and initial state dynamics separately. Here, different Gramians are\nused in order to derive a reduced model and their relation to dominant\nsubspaces are pointed out. We also show an a posteriori error bound for the\nsecond approach involving two types of Hankel singular values.", "categories": "math.NA cs.NA math.OC math.PR", "created": "2024-08-01", "doi": null, "arxiv_id": "2408.00581"}
{"title": "Non Verbis, Sed Rebus: Large Language Models are Weak Solvers of Italian\n  Rebuses", "authors": [], "abstract": "Rebuses are puzzles requiring constrained multi-step reasoning to identify a\nhidden phrase from a set of images and letters. In this work, we introduce a\nlarge collection of verbalized rebuses for the Italian language and use it to\nassess the rebus-solving capabilities of state-of-the-art large language\nmodels. While general-purpose systems such as LLaMA-3 and GPT-4o perform poorly\non this task, ad-hoc fine-tuning seems to improve models' performance. However,\nwe find that performance gains from training are largely motivated by\nmemorization. Our results suggest that rebus solving remains a challenging test\nbed to evaluate large language models' linguistic proficiency and sequential\ninstruction-following skills.", "categories": "cs.CL cs.AI", "created": "2024-08-01", "doi": null, "arxiv_id": "2408.00584"}
{"title": "Regional quality estimation for echocardiography using deep learning", "authors": [], "abstract": "Automatic estimation of cardiac ultrasound image quality can be beneficial\nfor guiding operators and ensuring the accuracy of clinical measurements.\nPrevious work often fails to distinguish the view correctness of the\nechocardiogram from the image quality. Additionally, previous studies only\nprovide a global image quality value, which limits their practical utility. In\nthis work, we developed and compared three methods to estimate image quality:\n1) classic pixel-based metrics like the generalized contrast-to-noise ratio\n(gCNR) on myocardial segments as region of interest and left ventricle lumen as\nbackground, obtained using a U-Net segmentation 2) local image coherence\nderived from a U-Net model that predicts coherence from B-Mode images 3) a deep\nconvolutional network that predicts the quality of each region directly in an\nend-to-end fashion. We evaluate each method against manual regional image\nquality annotations by three experienced cardiologists. The results indicate\npoor performance of the gCNR metric, with Spearman correlation to the\nannotations of \\r{ho} = 0.24. The end-to-end learning model obtains the best\nresult, \\r{ho} = 0.69, comparable to the inter-observer correlation, \\r{ho} =\n0.63. Finally, the coherence-based method, with \\r{ho} = 0.58, outperformed the\nclassical metrics and is more generic than the end-to-end approach.", "categories": "eess.IV cs.CV", "created": "2024-08-01", "doi": null, "arxiv_id": "2408.00591"}
{"title": "Learned Compression of Point Cloud Geometry and Attributes in a Single\n  Model through Multimodal Rate-Control", "authors": [], "abstract": "Point cloud compression is essential to experience volumetric multimedia as\nit drastically reduces the required streaming data rates. Point attributes,\nspecifically colors, extend the challenge of lossy compression beyond geometric\nrepresentation to achieving joint reconstruction of texture and geometry.\nState-of-the-art methods separate geometry and attributes to compress them\nindividually. This comes at a computational cost, requiring an encoder and a\ndecoder for each modality. Additionally, as attribute compression methods\nrequire the same geometry for encoding and decoding, the encoder emulates the\ndecoder-side geometry reconstruction as an input step to project and compress\nthe attributes. In this work, we propose to learn joint compression of geometry\nand attributes using a single, adaptive autoencoder model, embedding both\nmodalities into a unified latent space which is then entropy encoded. Key to\nthe technique is to replace the search for trade-offs between rate, attribute\nquality and geometry quality, through conditioning the model on the desired\nqualities of both modalities, bypassing the need for training model ensembles.\nTo differentiate important point cloud regions during encoding or to allow\nview-dependent compression for user-centered streaming, conditioning is\npointwise, which allows for local quality and rate variation. Our evaluation\nshows comparable performance to state-of-the-art compression methods for\ngeometry and attributes, while reducing complexity compared to related\ncompression methods.", "categories": "cs.CV cs.MM eess.IV", "created": "2024-08-01", "doi": null, "arxiv_id": "2408.00599"}
{"title": "Ground-to-UAV and RIS-assisted UAV-to-Ground Communication Under Channel\n  Aging: Statistical Characterization and Outage Performance", "authors": [], "abstract": "This paper studies the statistical characterization of ground-to-air (G2A)\nand reconfigurable intelligent surface (RIS)-assisted air-to-ground (A2G)\ncommunications in RIS-assisted UAV networks under the impact of channel aging.\nA comprehensive channel model is presented, which incorporates the time-varying\nfading, three-dimensional (3D) mobility, Doppler shifts, and the effects of\nchannel aging on array antenna structures. We provide analytical expressions\nfor the G2A signal-to-noise ratio (SNR) probability density function (PDF) and\ncumulative distribution function (CDF), demonstrating that the G2A SNR follows\na mixture of noncentral $\\chi^2$ distributions. The A2G communication is\ncharacterized under RIS arbitrary phase-shift configurations, showing that the\nA2G SNR can be represented as the product of two correlated noncentral $\\chi^2$\nrandom variables (RVs). Additionally, we present the PDF and the CDF of the\nproduct of two independently distributed noncentral $\\chi^2$ RVs, which\naccurately characterize the A2G SNR's distribution. Our paper confirms the\neffectiveness of RISs in mitigating channel aging effects within the coherence\ntime. Finally, we propose an adaptive spectral efficiency method that ensures\nconsistent system performance and satisfactory outage levels when the UAV and\nthe ground user equipments are in motion.", "categories": "cs.IT eess.SP math.IT", "created": "2024-08-01", "doi": null, "arxiv_id": "2408.00600"}
{"title": "AutoPV: Automatically Design Your Photovoltaic Power Forecasting Model", "authors": [], "abstract": "Photovoltaic power forecasting (PVPF) is a critical area in time series\nforecasting (TSF), enabling the efficient utilization of solar energy. With\nadvancements in machine learning and deep learning, various models have been\napplied to PVPF tasks. However, constructing an optimal predictive architecture\nfor specific PVPF tasks remains challenging, as it requires cross-domain\nknowledge and significant labor costs. To address this challenge, we introduce\nAutoPV, a novel framework for the automated search and construction of PVPF\nmodels based on neural architecture search (NAS) technology. We develop a brand\nnew NAS search space that incorporates various data processing techniques from\nstate-of-the-art (SOTA) TSF models and typical PVPF deep learning models. The\neffectiveness of AutoPV is evaluated on diverse PVPF tasks using a dataset from\nthe Daqing Photovoltaic Station in China. Experimental results demonstrate that\nAutoPV can complete the predictive architecture construction process in a\nrelatively short time, and the newly constructed architecture is superior to\nSOTA predefined models. This work bridges the gap in applying NAS to TSF\nproblems, assisting non-experts and industries in automatically designing\neffective PVPF models.", "categories": "cs.LG", "created": "2024-08-01", "doi": null, "arxiv_id": "2408.00601"}
{"title": "In-Hand Singulation and Scooping Manipulation with a 5 DOF Tactile\n  Gripper", "authors": [], "abstract": "Manipulation tasks often require a high degree of dexterity, typically\nnecessitating grippers with multiple degrees of freedom (DoF). While a robotic\nhand equipped with multiple fingers can execute precise and intricate\nmanipulation tasks, the inherent redundancy stemming from its extensive DoF\noften adds unnecessary complexity. In this paper, we introduce the design of a\ntactile sensor-equipped gripper with two fingers and five DoF. We present a\nnovel design integrating a GelSight tactile sensor, enhancing sensing\ncapabilities and enabling finer control during specific manipulation tasks. To\nevaluate the gripper's performance, we conduct experiments involving two\nchallenging tasks: 1) retrieving, singularizing, and classification of various\nobjects embedded in granular media, and 2) executing scooping manipulations of\ncredit cards in confined environments to achieve precise insertion. Our results\ndemonstrate the efficiency of the proposed approach, with a high success rate\nfor singulation and classification tasks, particularly for spherical objects at\nhigh as 94.3%, and a 100% success rate for scooping and inserting credit cards.", "categories": "cs.RO", "created": "2024-08-01", "doi": null, "arxiv_id": "2408.00610"}
{"title": "Using CSNNs to Perform Event-based Data Processing & Classification on\n  ASL-DVS", "authors": [], "abstract": "Recent advancements in bio-inspired visual sensing and neuromorphic computing\nhave led to the development of various highly efficient bio-inspired solutions\nwith real-world applications. One notable application integrates event-based\ncameras with spiking neural networks (SNNs) to process event-based sequences\nthat are asynchronous and sparse, making them difficult to handle. In this\nproject, we develop a convolutional spiking neural network (CSNN) architecture\nthat leverages convolutional operations and recurrent properties of a spiking\nneuron to learn the spatial and temporal relations in the ASL-DVS gesture\ndataset. The ASL-DVS gesture dataset is a neuromorphic dataset containing hand\ngestures when displaying 24 letters (A to Y, excluding J and Z due to the\nnature of their symbols) from the American Sign Language (ASL). We performed\nclassification on a pre-processed subset of the full ASL-DVS dataset to\nidentify letter signs and achieved 100\\% training accuracy. Specifically, this\nwas achieved by training in the Google Cloud compute platform while using a\nlearning rate of 0.0005, batch size of 25 (total of 20 batches), 200\niterations, and 10 epochs.", "categories": "cs.NE cs.LG", "created": "2024-08-01", "doi": null, "arxiv_id": "2408.00611"}
{"title": "Downstream bias mitigation is all you need", "authors": [], "abstract": "The advent of transformer-based architectures and large language models\n(LLMs) have significantly advanced the performance of natural language\nprocessing (NLP) models. Since these LLMs are trained on huge corpuses of data\nfrom the web and other sources, there has been a major concern about harmful\nprejudices that may potentially be transferred from the data. In many\napplications, these pre-trained LLMs are fine-tuned on task specific datasets,\nwhich can further contribute to biases. This paper studies the extent of biases\nabsorbed by LLMs during pre-training as well as task-specific behaviour after\nfine-tuning. We found that controlled interventions on pre-trained LLMs, prior\nto fine-tuning, have minimal effect on lowering biases in classifiers. However,\nthe biases present in domain-specific datasets play a much bigger role, and\nhence mitigating them at this stage has a bigger impact. While pre-training\ndoes matter, but after the model has been pre-trained, even slight changes to\nco-occurrence rates in the fine-tuning dataset has a significant effect on the\nbias of the model.", "categories": "cs.CL", "created": "2024-08-01", "doi": null, "arxiv_id": "2408.00612"}
{"title": "Unlocking Fair Use in the Generative AI Supply Chain: A Systematized\n  Literature Review", "authors": [], "abstract": "Through a systematization of generative AI (GenAI) stakeholder goals and\nexpectations, this work seeks to uncover what value different stakeholders see\nin their contributions to the GenAI supply line. This valuation enables us to\nunderstand whether fair use advocated by GenAI companies to train model\nprogresses the copyright law objective of promoting science and arts. While\nassessing the validity and efficacy of the fair use argument, we uncover\nresearch gaps and potential avenues for future works for researchers and\npolicymakers to address.", "categories": "cs.AI cs.CY cs.LG", "created": "2024-08-01", "doi": null, "arxiv_id": "2408.00613"}
{"title": "Harnessing Uncertainty-aware Bounding Boxes for Unsupervised 3D Object\n  Detection", "authors": [], "abstract": "Unsupervised 3D object detection aims to identify objects of interest from\nunlabeled raw data, such as LiDAR points. Recent approaches usually adopt\npseudo 3D bounding boxes (3D bboxes) from clustering algorithm to initialize\nthe model training, and then iteratively updating both pseudo labels and the\ntrained model. However, pseudo bboxes inevitably contain noises, and such\ninaccurate annotation accumulates to the final model, compromising the\nperformance. Therefore, in an attempt to mitigate the negative impact of pseudo\nbboxes, we introduce a new uncertainty-aware framework. In particular, Our\nmethod consists of two primary components: uncertainty estimation and\nuncertainty regularization. (1) In the uncertainty estimation phase, we\nincorporate an extra auxiliary detection branch alongside the primary detector.\nThe prediction disparity between the primary and auxiliary detectors is\nleveraged to estimate uncertainty at the box coordinate level, including\nposition, shape, orientation. (2) Based on the assessed uncertainty, we\nregularize the model training via adaptively adjusting every 3D bboxes\ncoordinates. For pseudo bbox coordinates with high uncertainty, we assign a\nrelatively low loss weight. Experiment verifies that the proposed method is\nrobust against the noisy pseudo bboxes, yielding substantial improvements on\nnuScenes and Lyft compared to existing techniques, with increases of 6.9% in\nAP$_{BEV}$ and 2.5% in AP$_{3D}$ on nuScenes, and 2.2% in AP$_{BEV}$ and 1.0%\nin AP$_{3D}$ on Lyft.", "categories": "cs.CV", "created": "2024-08-01", "doi": null, "arxiv_id": "2408.00619"}
{"title": "Are Bigger Encoders Always Better in Vision Large Models?", "authors": [], "abstract": "In recent years, multimodal large language models (MLLMs) have shown strong\npotential in real-world applications. They are developing rapidly due to their\nremarkable ability to comprehend multimodal information and their inherent\npowerful cognitive and reasoning capabilities. Among MLLMs, vision language\nmodels (VLM) stand out for their ability to understand vision information.\nHowever, the scaling trend of VLMs under the current mainstream paradigm has\nnot been extensively studied. Whether we can achieve better performance by\ntraining even larger models is still unclear. To address this issue, we\nconducted experiments on the pretraining stage of MLLMs. We conduct our\nexperiment using different encoder sizes and large language model (LLM) sizes.\nOur findings indicate that merely increasing the size of encoders does not\nnecessarily enhance the performance of VLMs. Moreover, we analyzed the effects\nof LLM backbone parameter size and data quality on the pretraining outcomes.\nAdditionally, we explored the differences in scaling laws between LLMs and\nVLMs.", "categories": "cs.CV cs.CL", "created": "2024-08-01", "doi": null, "arxiv_id": "2408.00620"}
{"title": "CAVE: Crowdsourcing Passing-By Vehicles for Reliable In-Vehicle Edge\n  Computing", "authors": [], "abstract": "In-vehicle edge computing is a much anticipated paradigm to serve\never-increasing computation demands originated from the ego vehicle, such as\npassenger entertainments. In this paper, we explore the unique idea of\ncrowdsourcing passing-by vehicles to augment computing of the ego vehicle. The\nchallenges lie in the high dynamics of passing-by vehicles, time-correlated\ntask computation, and the stringent requirement of computing reliability for\nindividual user tasks. To this end, we formulate an optimization problem to\nminimize the end-to-end latency by optimizing the task assignment and resource\nallocation of user tasks. To address the complex problem, we propose a new\nalgorithm (named CAVE) with multiple key designs. We build an end-to-end\nnetwork and compute simulator and conduct extensive simulation to evaluate the\nperformance of the proposed algorithm.", "categories": "cs.NI", "created": "2024-08-01", "doi": null, "arxiv_id": "2408.00621"}
{"title": "SynesLM: A Unified Approach for Audio-visual Speech Recognition and\n  Translation via Language Model and Synthetic Data", "authors": [], "abstract": "In this work, we present SynesLM, an unified model which can perform three\nmultimodal language understanding tasks: audio-visual automatic speech\nrecognition(AV-ASR) and visual-aided speech/machine translation(VST/VMT).\nUnlike previous research that focused on lip motion as visual cues for speech\nsignals, our work explores more general visual information within entire\nframes, such as objects and actions. Additionally, we use synthetic image data\nto enhance the correlation between image and speech data. We benchmark SynesLM\nagainst the How2 dataset, demonstrating performance on par with\nstate-of-the-art (SOTA) models dedicated to AV-ASR while maintaining our\nmultitasking framework. Remarkably, for zero-shot AV-ASR, SynesLM achieved SOTA\nperformance by lowering the Word Error Rate (WER) from 43.4% to 39.4% on the\nVisSpeech Dataset. Furthermore, our results in VST and VMT outperform the\nprevious results, improving the BLEU score to 43.5 from 37.2 for VST, and to\n54.8 from 54.4 for VMT.", "categories": "eess.AS cs.CL cs.CV", "created": "2024-08-01", "doi": null, "arxiv_id": "2408.00624"}
{"title": "Factorization of a prime matrix in even blocks", "authors": [], "abstract": "In this paper, a matrix is said to be prime if the row and column of this\nmatrix are both prime numbers. We establish various necessary and sufficient\nconditions for developing matrices into the sum of tensor products of prime\nmatrices. For example, if the diagonal of a matrix blocked evenly are pairwise\ncommutative, it yields such a decomposition. The computational complexity of\nmultiplication of these algorithms is shown to be $O(n^{5/2})$. In the section\n5, a decomposition is proved to hold if and only if every even natural number\ngreater than 2 is the sum of two prime numbers.", "categories": "math.NA cs.NA math.OC math.RA", "created": "2024-08-01", "doi": null, "arxiv_id": "2408.00627"}
{"title": "Empowering Snapshot Compressive Imaging: Spatial-Spectral State Space\n  Model with Across-Scanning and Local Enhancement", "authors": [], "abstract": "Snapshot Compressive Imaging (SCI) relies on decoding algorithms such as CNN\nor Transformer to reconstruct the hyperspectral image (HSI) from its compressed\nmeasurement. Although existing CNN and Transformer-based methods have proven\neffective, CNNs are limited by their inadequate modeling of long-range\ndependencies, while Transformer ones face high computational costs due to\nquadratic complexity. Recent Mamba models have demonstrated superior\nperformance over CNN and Transformer-based architectures in some visual tasks,\nbut these models have not fully utilized the local similarities in both spatial\nand spectral dimensions. Moreover, the long-sequence modeling capability of SSM\nmay offer an advantage in processing the numerous spectral bands for HSI\nreconstruction, which has not yet been explored. In this paper, we introduce a\nState Space Model with Across-Scanning and Local Enhancement, named ASLE-SSM,\nthat employs a Spatial-Spectral SSM for global-local balanced context encoding\nand cross-channel interaction promoting. Specifically, we introduce local\nscanning in the spatial dimension to balance the global and local receptive\nfields, and then propose our across-scanning method based on spatial-spectral\nlocal cubes to leverage local similarities between adjacent spectral bands and\npixels to guide the reconstruction process. These two scanning mechanisms\nextract the HSI's local features while balancing the global perspective without\nany additional costs. Experimental results illustrate ASLE-SSM's superiority\nover existing state-of-the-art methods, with an inference speed 2.4 times\nfaster than Transformer-based MST and saving 0.12 (M) of parameters, achieving\nthe lowest computational cost and parameter count.", "categories": "cs.CV eess.IV", "created": "2024-08-01", "doi": null, "arxiv_id": "2408.00629"}
{"title": "DisTrack: a new Tool for Semi-automatic Misinformation Tracking in\n  Online Social Networks", "authors": [], "abstract": "Introduction: This article introduces DisTrack, a methodology and a tool\ndeveloped for tracking and analyzing misinformation within Online Social\nNetworks (OSNs). DisTrack is designed to combat the spread of misinformation\nthrough a combination of Natural Language Processing (NLP) Social Network\nAnalysis (SNA) and graph visualization. The primary goal is to detect\nmisinformation, track its propagation, identify its sources, and assess the\ninfluence of various actors within the network.\n  Methods: DisTrack's architecture incorporates a variety of methodologies\nincluding keyword search, semantic similarity assessments, and graph generation\ntechniques. These methods collectively facilitate the monitoring of\nmisinformation, the categorization of content based on alignment with known\nfalse claims, and the visualization of dissemination cascades through detailed\ngraphs. The tool is tailored to capture and analyze the dynamic nature of\nmisinformation spread in digital environments.\n  Results: The effectiveness of DisTrack is demonstrated through three case\nstudies focused on different themes: discredit/hate speech, anti-vaccine\nmisinformation, and false narratives about the Russia-Ukraine conflict. These\nstudies show DisTrack's capabilities in distinguishing posts that propagate\nfalsehoods from those that counteract them, and tracing the evolution of\nmisinformation from its inception.\n  Conclusions: The research confirms that DisTrack is a valuable tool in the\nfield of misinformation analysis. It effectively distinguishes between\ndifferent types of misinformation and traces their development over time. By\nproviding a comprehensive approach to understanding and combating\nmisinformation in digital spaces, DisTrack proves to be an essential asset for\nresearchers and practitioners working to mitigate the impact of false\ninformation in online social environments.", "categories": "cs.SI cs.AI", "created": "2024-08-01", "doi": null, "arxiv_id": "2408.00633"}
{"title": "Evaluation Metrics and Methods for Generative Models in the Wireless PHY\n  Layer", "authors": [], "abstract": "Generative models are typically evaluated by direct inspection of their\ngenerated samples, e.g., by visual inspection in the case of images. Further\nevaluation metrics like the Fr\\'echet inception distance or maximum mean\ndiscrepancy are intricate to interpret and lack physical motivation. These\nobservations make evaluating generative models in the wireless PHY layer\nnon-trivial. This work establishes a framework consisting of evaluation metrics\nand methods for generative models applied to the wireless PHY layer. The\nproposed metrics and methods are motivated by wireless applications,\nfacilitating interpretation and understandability for the wireless community.\nIn particular, we propose a spectral efficiency analysis for validating the\ngenerated channel norms and a codebook fingerprinting method to validate the\ngenerated channel directions. Moreover, we propose an application cross-check\nto evaluate the generative model's samples for training machine learning-based\nmodels in relevant downstream tasks. Our analysis is based on real-world\nmeasurement data and includes the Gaussian mixture model, variational\nautoencoder, diffusion model, and generative adversarial network as generative\nmodels. Our results under a fair comparison in terms of model architecture\nindicate that solely relying on metrics like the maximum mean discrepancy\nproduces insufficient evaluation outcomes. In contrast, the proposed metrics\nand methods exhibit consistent and explainable behavior.", "categories": "cs.IT eess.SP math.IT", "created": "2024-08-01", "doi": null, "arxiv_id": "2408.00634"}
{"title": "Deep Learning in Medical Image Classification from MRI-based Brain Tumor\n  Images", "authors": [], "abstract": "Brain tumors are among the deadliest diseases in the world. Magnetic\nResonance Imaging (MRI) is one of the most effective ways to detect brain\ntumors. Accurate detection of brain tumors based on MRI scans is critical, as\nit can potentially save many lives and facilitate better decision-making at the\nearly stages of the disease. Within our paper, four different types of\nMRI-based images have been collected from the database: glioma tumor, no tumor,\npituitary tumor, and meningioma tumor. Our study focuses on making predictions\nfor brain tumor classification. Five models, including four pre-trained models\n(MobileNet, EfficientNet-B0, ResNet-18, and VGG16) and one new model,\nMobileNet-BT, have been proposed for this study.", "categories": "cs.CV", "created": "2024-08-01", "doi": null, "arxiv_id": "2408.00636"}
{"title": "CrystalTac: 3D-Printed Vision-Based Tactile Sensor Family through Rapid\n  Monolithic Manufacturing Technique", "authors": [], "abstract": "Recently, vision-based tactile sensors (VBTSs) have gained popularity in\nrobotics systems. The sensing mechanisms of most VBTSs can be categorised based\non the type of tactile features they capture. Each category requires specific\nstructural designs to convert physical contact into optical information. The\ncomplex architectures of VBTSs pose challenges for traditional manufacturing\ntechniques in terms of design flexibility, cost-effectiveness, and quality\nstability. Previous research has shown that monolithic manufacturing using\nmulti-material 3D printing technology can partially address these challenges.\nThis study introduces the CrystalTac family, a series of VBTSs designed with a\nunique sensing mechanism and fabricated through rapid monolithic manufacturing.\nCase studies on CrystalTac-type sensors demonstrate their effective performance\nin tasks involving tactile perception, along with impressive cost-effectiveness\nand design flexibility. The CrystalTac family aims to highlight the potential\nof monolithic manufacturing in VBTS development and inspire further research in\ntactile sensing and manipulation.", "categories": "cs.RO eess.SP", "created": "2024-08-01", "doi": null, "arxiv_id": "2408.00638"}
{"title": "Privacy-preserving datasets by capturing feature distributions with\n  Conditional VAEs", "authors": [], "abstract": "Large and well-annotated datasets are essential for advancing deep learning\napplications, however often costly or impossible to obtain by a single entity.\nIn many areas, including the medical domain, approaches relying on data sharing\nhave become critical to address those challenges. While effective in increasing\ndataset size and diversity, data sharing raises significant privacy concerns.\nCommonly employed anonymization methods based on the k-anonymity paradigm often\nfail to preserve data diversity, affecting model robustness. This work\nintroduces a novel approach using Conditional Variational Autoencoders (CVAEs)\ntrained on feature vectors extracted from large pre-trained vision foundation\nmodels. Foundation models effectively detect and represent complex patterns\nacross diverse domains, allowing the CVAE to faithfully capture the embedding\nspace of a given data distribution to generate (sample) a diverse,\nprivacy-respecting, and potentially unbounded set of synthetic feature vectors.\nOur method notably outperforms traditional approaches in both medical and\nnatural image domains, exhibiting greater dataset diversity and higher\nrobustness against perturbations while preserving sample privacy. These results\nunderscore the potential of generative models to significantly impact deep\nlearning applications in data-scarce and privacy-sensitive environments. The\nsource code is available at\nhttps://github.com/francescodisalvo05/cvae-anonymization .", "categories": "cs.LG cs.CV eess.IV", "created": "2024-08-01", "doi": null, "arxiv_id": "2408.00639"}
{"title": "AMAES: Augmented Masked Autoencoder Pretraining on Public Brain MRI Data\n  for 3D-Native Segmentation", "authors": [], "abstract": "This study investigates the impact of self-supervised pretraining of 3D\nsemantic segmentation models on a large-scale, domain-specific dataset. We\nintroduce BRAINS-45K, a dataset of 44,756 brain MRI volumes from public\nsources, the largest public dataset available, and revisit a number of design\nchoices for pretraining modern segmentation architectures by simplifying and\noptimizing state-of-the-art methods, and combining them with a novel\naugmentation strategy. The resulting AMAES framework is based on\nmasked-image-modeling and intensity-based augmentation reversal and balances\nmemory usage, runtime, and finetuning performance. Using the popular U-Net and\nthe recent MedNeXt architecture as backbones, we evaluate the effect of\npretraining on three challenging downstream tasks, covering single-sequence,\nlow-resource settings, and out-of-domain generalization. The results highlight\nthat pretraining on the proposed dataset with AMAES significantly improves\nsegmentation performance in the majority of evaluated cases, and that it is\nbeneficial to pretrain the model with augmentations, despite pretraing on a\nlarge-scale dataset. Code and model checkpoints for reproducing results, as\nwell as the BRAINS-45K dataset are available at\n\\url{https://github.com/asbjrnmunk/amaes}.", "categories": "eess.IV cs.AI cs.CV", "created": "2024-08-01", "doi": null, "arxiv_id": "2408.00640"}
{"title": "Enhancing Ethereum Fraud Detection via Generative and Contrastive\n  Self-supervision", "authors": [], "abstract": "The rampant fraudulent activities on Ethereum hinder the healthy development\nof the blockchain ecosystem, necessitating the reinforcement of regulations.\nHowever, multiple imbalances involving account interaction frequencies and\ninteraction types in the Ethereum transaction environment pose significant\nchallenges to data mining-based fraud detection research. To address this, we\nfirst propose the concept of meta-interactions to refine interaction behaviors\nin Ethereum, and based on this, we present a dual self-supervision enhanced\nEthereum fraud detection framework, named Meta-IFD. This framework initially\nintroduces a generative self-supervision mechanism to augment the interaction\nfeatures of accounts, followed by a contrastive self-supervision mechanism to\ndifferentiate various behavior patterns, and ultimately characterizes the\nbehavioral representations of accounts and mines potential fraud risks through\nmulti-view interaction feature learning. Extensive experiments on real Ethereum\ndatasets demonstrate the effectiveness and superiority of our framework in\ndetecting common Ethereum fraud behaviors such as Ponzi schemes and phishing\nscams. Additionally, the generative module can effectively alleviate the\ninteraction distribution imbalance in Ethereum data, while the contrastive\nmodule significantly enhances the framework's ability to distinguish different\nbehavior patterns. The source code will be released on GitHub soon.", "categories": "cs.LG", "created": "2024-08-01", "doi": null, "arxiv_id": "2408.00641"}
{"title": "Coverage Path Planning For Minimizing Expected Time to Search For an\n  Object With Continuous Sensing", "authors": [], "abstract": "In this paper, we present several results of both theoretical as well as\npractical interests. First, we propose the quota lawn mowing problem, an\nextension of the classic lawn mowing problem in computational geometry, as\nfollows: given a quota of coverage, compute the shortest lawn mowing route to\nachieve said quota. We give constant-factor approximations for the quota lawn\nmowing problem.\n  Second, we investigate the expected detection time minimization problem in\ngeometric coverage path planning with local, continuous sensory information. We\nprovide the first approximation algorithm with provable error bounds with\npseudopolynomial running time. Our ideas also extend to another search\nmechanism, namely visibility-based search, which is related to the watchman\nroute problem. We complement our theoretical analysis with some simple but\neffective heuristics for finding an object in minimum expected time, on which\nwe provide simulation results.", "categories": "cs.RO", "created": "2024-08-01", "doi": null, "arxiv_id": "2408.00642"}
{"title": "Towards End-to-End Explainable Facial Action Unit Recognition via\n  Vision-Language Joint Learning", "authors": [], "abstract": "Facial action units (AUs), as defined in the Facial Action Coding System\n(FACS), have received significant research interest owing to their diverse\nrange of applications in facial state analysis. Current mainstream FAU\nrecognition models have a notable limitation, i.e., focusing only on the\naccuracy of AU recognition and overlooking explanations of corresponding AU\nstates. In this paper, we propose an end-to-end Vision-Language joint learning\nnetwork for explainable FAU recognition (termed VL-FAU), which aims to\nreinforce AU representation capability and language interpretability through\nthe integration of joint multimodal tasks. Specifically, VL-FAU brings together\nlanguage models to generate fine-grained local muscle descriptions and\ndistinguishable global face description when optimising FAU recognition.\nThrough this, the global facial representation and its local AU representations\nwill achieve higher distinguishability among different AUs and different\nsubjects. In addition, multi-level AU representation learning is utilised to\nimprove AU individual attention-aware representation capabilities based on\nmulti-scale combined facial stem feature. Extensive experiments on DISFA and\nBP4D AU datasets show that the proposed approach achieves superior performance\nover the state-of-the-art methods on most of the metrics. In addition, compared\nwith mainstream FAU recognition methods, VL-FAU can provide local- and\nglobal-level interpretability language descriptions with the AUs' predictions.", "categories": "cs.CV", "created": "2024-08-01", "doi": "10.1145/3664647.3681443", "arxiv_id": "2408.00644"}
{"title": "Token Interdependency Parsing (Tipping) -- Fast and Accurate Log Parsing", "authors": [], "abstract": "In the last decade, an impressive increase in software adaptions has led to a\nsurge in log data production, making manual log analysis impractical and\nestablishing the necessity for automated methods. Conversely, most automated\nanalysis tools include a component designed to separate log templates from\ntheir parameters, commonly referred to as a \"log parser\". This paper aims to\nintroduce a new fast and accurate log parser, named \"Tipping\". Tipping combines\nrule-based tokenizers, interdependency token graphs, strongly connected\ncomponents, and various techniques to ensure rapid, scalable, and precise log\nparsing. Furthermore, Tipping is parallelized and capable of running on\nmultiple processing cores with close to linear efficiency. We evaluated Tipping\nagainst other state-of-the-art log parsers in terms of accuracy, performance,\nand the downstream task of anomaly detection. Accordingly, we found that\nTipping outperformed existing methods in accuracy and performance in our\nevaluations. More in-depth, Tipping can parse 11 million lines of logs in less\nthan 20 seconds on a laptop machine. Furthermore, we re-implemented a\nparallelized version of the past IpLom algorithm to demonstrate the effect of\nparallel processing, and it became the second-fastest parser. As logs keep\ngrowing in volume and complexity, the software engineering community needs to\nensure automated log analysis tools keep up with the demand, being capable of\nefficiently handling massive volumes of logs with high accuracy. Tipping's\nrobustness, versatility, efficiency, and scalability make it a viable tool for\nthe modern automated log analysis task.", "categories": "cs.SE", "created": "2024-08-01", "doi": null, "arxiv_id": "2408.00645"}
{"title": "Counterclockwise Dissipativity, Potential Games and Evolutionary Nash\n  Equilibrium Learning", "authors": [], "abstract": "We use system-theoretic passivity methods to study evolutionary Nash\nequilibria learning in large populations of agents engaged in strategic,\nnon-cooperative interactions. The agents follow learning rules (rules for\nshort) that capture their strategic preferences and a payoff mechanism ascribes\npayoffs to the available strategies. The population's aggregate strategic\nprofile is the state of an associated evolutionary dynamical system.\nEvolutionary Nash equilibrium learning refers to the convergence of this state\nto the Nash equilibria set of the payoff mechanism. Most approaches consider\nmemoryless payoff mechanisms, such as potential games. Recently, methods using\n$\\delta$-passivity and equilibrium independent passivity (EIP) have introduced\ndynamic payoff mechanisms. However, $\\delta$-passivity does not hold when\nagents follow rules exhibiting ``imitation\" behavior, such as in replicator\ndynamics. Conversely, EIP applies to the replicator dynamics but not to\n$\\delta$-passive rules. We address this gap using counterclockwise\ndissipativity (CCW). First, we prove that continuous memoryless payoff\nmechanisms are CCW if and only if they are potential games. Subsequently, under\n(possibly dynamic) CCW payoff mechanisms, we establish evolutionary Nash\nequilibrium learning for any rule within a convex cone spanned by imitation\nrules and continuous $\\delta$-passive rules.", "categories": "cs.GT cs.SY eess.SY math.DS math.OC", "created": "2024-08-01", "doi": null, "arxiv_id": "2408.00647"}
{"title": "Enhancing Multistep Prediction of Multivariate Market Indices Using\n  Weighted Optical Reservoir Computing", "authors": [], "abstract": "We propose and experimentally demonstrate an innovative stock index\nprediction method using a weighted optical reservoir computing system. We\nconstruct fundamental market data combined with macroeconomic data and\ntechnical indicators to capture the broader behavior of the stock market. Our\napproach shows significant higher performance than state-of-the-art methods\nsuch as linear regression, decision trees, and neural network architectures\nincluding long short-term memory. It captures well the market's high volatility\nand nonlinear behaviors despite limited data, demonstrating great potential for\nreal-time, parallel, multi-dimensional data processing and predictions.", "categories": "cs.LG physics.app-ph", "created": "2024-08-01", "doi": null, "arxiv_id": "2408.00652"}
{"title": "SF3D: Stable Fast 3D Mesh Reconstruction with UV-unwrapping and\n  Illumination Disentanglement", "authors": [], "abstract": "We present SF3D, a novel method for rapid and high-quality textured object\nmesh reconstruction from a single image in just 0.5 seconds. Unlike most\nexisting approaches, SF3D is explicitly trained for mesh generation,\nincorporating a fast UV unwrapping technique that enables swift texture\ngeneration rather than relying on vertex colors. The method also learns to\npredict material parameters and normal maps to enhance the visual quality of\nthe reconstructed 3D meshes. Furthermore, SF3D integrates a delighting step to\neffectively remove low-frequency illumination effects, ensuring that the\nreconstructed meshes can be easily used in novel illumination conditions.\nExperiments demonstrate the superior performance of SF3D over the existing\ntechniques. Project page: https://stable-fast-3d.github.io", "categories": "cs.CV cs.GR", "created": "2024-08-01", "doi": null, "arxiv_id": "2408.00653"}
{"title": "Aligning Multiple Knowledge Graphs in a Single Pass", "authors": [], "abstract": "Entity alignment (EA) is to identify equivalent entities across different\nknowledge graphs (KGs), which can help fuse these KGs into a more comprehensive\none. Previous EA methods mainly focus on aligning a pair of KGs, and to the\nbest of our knowledge, no existing EA method considers aligning multiple (more\nthan two) KGs. To fill this research gap, in this work, we study a novel\nproblem of aligning multiple KGs and propose an effective framework named\nMultiEA to solve the problem. First, we embed the entities of all the candidate\nKGs into a common feature space by a shared KG encoder. Then, we explore three\nalignment strategies to minimize the distances among pre-aligned entities. In\nparticular, we propose an innovative inference enhancement technique to improve\nthe alignment performance by incorporating high-order similarities. Finally, to\nverify the effectiveness of MultiEA, we construct two new real-world benchmark\ndatasets and conduct extensive experiments on them. The results show that our\nMultiEA can effectively and efficiently align multiple KGs in a single pass.", "categories": "cs.CL cs.LG", "created": "2024-08-01", "doi": null, "arxiv_id": "2408.00662"}
{"title": "AutoM3L: An Automated Multimodal Machine Learning Framework with Large\n  Language Models", "authors": [], "abstract": "Automated Machine Learning (AutoML) offers a promising approach to streamline\nthe training of machine learning models. However, existing AutoML frameworks\nare often limited to unimodal scenarios and require extensive manual\nconfiguration. Recent advancements in Large Language Models (LLMs) have\nshowcased their exceptional abilities in reasoning, interaction, and code\ngeneration, presenting an opportunity to develop a more automated and\nuser-friendly framework. To this end, we introduce AutoM3L, an innovative\nAutomated Multimodal Machine Learning framework that leverages LLMs as\ncontrollers to automatically construct multimodal training pipelines. AutoM3L\ncomprehends data modalities and selects appropriate models based on user\nrequirements, providing automation and interactivity. By eliminating the need\nfor manual feature engineering and hyperparameter optimization, our framework\nsimplifies user engagement and enables customization through directives,\naddressing the limitations of previous rule-based AutoML approaches. We\nevaluate the performance of AutoM3L on six diverse multimodal datasets spanning\nclassification, regression, and retrieval tasks, as well as a comprehensive set\nof unimodal datasets. The results demonstrate that AutoM3L achieves competitive\nor superior performance compared to traditional rule-based AutoML methods.\nFurthermore, a user study highlights the user-friendliness and usability of our\nframework, compared to the rule-based AutoML methods.", "categories": "cs.LG", "created": "2024-08-01", "doi": null, "arxiv_id": "2408.00665"}
{"title": "Absorbing Boundary Conditions for Variable Potential Schr\\\"odinger\n  Equations via Titchmarsh-Weyl Theory", "authors": [], "abstract": "We propose a novel approach to simulate the solution of the time-dependent\nSchr\\\"odinger equation with a general variable potential. The key idea is to\napproximate the Titchmarsh-Weyl m-function (exact Dirichlet-to-Neumann\noperator) by a rational function with respect to an appropriate spectral\nparameter. By using this method, we overcome the usual high-frequency\nrestriction associated with absorbing boundary conditions in general variable\npotential problems. The resulting fast computational algorithm for absorbing\nboundary conditions ensures accuracy over the entire frequency range.", "categories": "math.NA cs.NA physics.comp-ph", "created": "2024-08-01", "doi": null, "arxiv_id": "2408.00671"}
{"title": "ExpertAF: Expert Actionable Feedback from Video", "authors": [], "abstract": "Feedback is essential for learning a new skill or improving one's current\nskill-level. However, current methods for skill-assessment from video only\nprovide scores or compare demonstrations, leaving the burden of knowing what to\ndo differently on the user. We introduce a novel method to generate actionable\nfeedback from video of a person doing a physical activity, such as basketball\nor soccer. Our method takes a video demonstration and its accompanying 3D body\npose and generates (1) free-form expert commentary describing what the person\nis doing well and what they could improve, and (2) a visual expert\ndemonstration that incorporates the required corrections. We show how to\nleverage Ego-Exo4D's videos of skilled activity and expert commentary together\nwith a strong language model to create a weakly-supervised training dataset for\nthis task, and we devise a multimodal video-language model to infer coaching\nfeedback. Our method is able to reason across multi-modal input combinations to\noutput full-spectrum, actionable coaching -- expert commentary, expert video\nretrieval, and the first-of-its-kind expert pose generation -- outperforming\nstrong vision-language models on both established metrics and human preference\nstudies.", "categories": "cs.CV", "created": "2024-08-01", "doi": null, "arxiv_id": "2408.00672"}
{"title": "Modeling stochastic eye tracking data: A comparison of quantum\n  generative adversarial networks and Markov models", "authors": [], "abstract": "We explore the use of quantum generative adversarial networks QGANs for\nmodeling eye movement velocity data. We assess whether the advanced\ncomputational capabilities of QGANs can enhance the modeling of complex\nstochastic distribution beyond the traditional mathematical models,\nparticularly the Markov model. The findings indicate that while QGANs\ndemonstrate potential in approximating complex distributions, the Markov model\nconsistently outperforms in accurately replicating the real data distribution.\nThis comparison underlines the challenges and avenues for refinement in time\nseries data generation using quantum computing techniques. It emphasizes the\nneed for further optimization of quantum models to better align with real-world\ndata characteristics.", "categories": "cs.NE quant-ph", "created": "2024-08-01", "doi": "10.1145/3638530.3664134", "arxiv_id": "2408.00673"}
{"title": "ChordSync: Conformer-Based Alignment of Chord Annotations to Music Audio", "authors": [], "abstract": "In the Western music tradition, chords are the main constituent components of\nharmony, a fundamental dimension of music. Despite its relevance for several\nMusic Information Retrieval (MIR) tasks, chord-annotated audio datasets are\nlimited and need more diversity. One way to improve those resources is to\nleverage the large number of chord annotations available online, but this\nrequires aligning them with music audio. However, existing audio-to-score\nalignment techniques, which typically rely on Dynamic Time Warping (DTW), fail\nto address this challenge, as they require weakly aligned data for precise\nsynchronisation. In this paper, we introduce ChordSync, a novel conformer-based\nmodel designed to seamlessly align chord annotations with audio, eliminating\nthe need for weak alignment. We also provide a pre-trained model and a\nuser-friendly library, enabling users to synchronise chord annotations with\naudio tracks effortlessly. In this way, ChordSync creates opportunities for\nharnessing crowd-sourced chord data for MIR, especially in audio chord\nestimation, thereby facilitating the generation of novel datasets.\nAdditionally, our system extends its utility to music education, enhancing\nmusic learning experiences by providing accurately aligned annotations, thus\nenabling learners to engage in synchronised musical practices.", "categories": "cs.SD cs.LG cs.MM eess.AS", "created": "2024-08-01", "doi": null, "arxiv_id": "2408.00674"}
{"title": "Leveraging Entailment Judgements in Cross-Lingual Summarisation", "authors": [], "abstract": "Synthetically created Cross-Lingual Summarisation (CLS) datasets are prone to\ninclude document-summary pairs where the reference summary is unfaithful to the\ncorresponding document as it contains content not supported by the document\n(i.e., hallucinated content). This low data quality misleads model learning and\nobscures evaluation results. Automatic ways to assess hallucinations and\nimprove training have been proposed for monolingual summarisation,\npredominantly in English. For CLS, we propose to use off-the-shelf\ncross-lingual Natural Language Inference (X-NLI) to evaluate faithfulness of\nreference and model generated summaries. Then, we study training approaches\nthat are aware of faithfulness issues in the training data and propose an\napproach that uses unlikelihood loss to teach a model about unfaithful summary\nsequences. Our results show that it is possible to train CLS models that yield\nmore faithful summaries while maintaining comparable or better informativess.", "categories": "cs.CL", "created": "2024-08-01", "doi": null, "arxiv_id": "2408.00675"}
{"title": "An effect analysis of the balancing techniques on the counterfactual\n  explanations of student success prediction models", "authors": [], "abstract": "In the past decade, we have experienced a massive boom in the usage of\ndigital solutions in higher education. Due to this boom, large amounts of data\nhave enabled advanced data analysis methods to support learners and examine\nlearning processes. One of the dominant research directions in learning\nanalytics is predictive modeling of learners' success using various machine\nlearning methods. To build learners' and teachers' trust in such methods and\nsystems, exploring the methods and methodologies that enable relevant\nstakeholders to deeply understand the underlying machine-learning models is\nnecessary. In this context, counterfactual explanations from explainable\nmachine learning tools are promising. Several counterfactual generation methods\nhold much promise, but the features must be actionable and causal to be\neffective. Thus, obtaining which counterfactual generation method suits the\nstudent success prediction models in terms of desiderata, stability, and\nrobustness is essential. Although a few studies have been published in recent\nyears on the use of counterfactual explanations in educational sciences, they\nhave yet to discuss which counterfactual generation method is more suitable for\nthis problem. This paper analyzed the effectiveness of commonly used\ncounterfactual generation methods, such as WhatIf Counterfactual Explanations,\nMulti-Objective Counterfactual Explanations, and Nearest Instance\nCounterfactual Explanations after balancing. This contribution presents a case\nstudy using the Open University Learning Analytics dataset to demonstrate the\npractical usefulness of counterfactual explanations. The results illustrate the\nmethod's effectiveness and describe concrete steps that could be taken to alter\nthe model's prediction.", "categories": "cs.LG stat.ML", "created": "2024-08-01", "doi": null, "arxiv_id": "2408.00676"}
{"title": "Alpha-VI DeepONet: A prior-robust variational Bayesian approach for\n  enhancing DeepONets with uncertainty quantification", "authors": [], "abstract": "We introduce a novel deep operator network (DeepONet) framework that\nincorporates generalised variational inference (GVI) using R\\'enyi's\n$\\alpha$-divergence to learn complex operators while quantifying uncertainty.\nBy incorporating Bayesian neural networks as the building blocks for the branch\nand trunk networks, our framework endows DeepONet with uncertainty\nquantification. The use of R\\'enyi's $\\alpha$-divergence, instead of the\nKullback-Leibler divergence (KLD), commonly used in standard variational\ninference, mitigates issues related to prior misspecification that are\nprevalent in Variational Bayesian DeepONets. This approach offers enhanced\nflexibility and robustness. We demonstrate that modifying the variational\nobjective function yields superior results in terms of minimising the mean\nsquared error and improving the negative log-likelihood on the test set. Our\nframework's efficacy is validated across various mechanical systems, where it\noutperforms both deterministic and standard KLD-based VI DeepONets in\npredictive accuracy and uncertainty quantification. The hyperparameter\n$\\alpha$, which controls the degree of robustness, can be tuned to optimise\nperformance for specific problems. We apply this approach to a range of\nmechanics problems, including gravity pendulum, advection-diffusion, and\ndiffusion-reaction systems. Our findings underscore the potential of\n$\\alpha$-VI DeepONet to advance the field of data-driven operator learning and\nits applications in engineering and scientific domains.", "categories": "stat.ML cs.LG", "created": "2024-08-01", "doi": null, "arxiv_id": "2408.00681"}
{"title": "Learning in Multi-Objective Public Goods Games with Non-Linear Utilities", "authors": [], "abstract": "Addressing the question of how to achieve optimal decision-making under risk\nand uncertainty is crucial for enhancing the capabilities of artificial agents\nthat collaborate with or support humans. In this work, we address this question\nin the context of Public Goods Games. We study learning in a novel\nmulti-objective version of the Public Goods Game where agents have different\nrisk preferences, by means of multi-objective reinforcement learning. We\nintroduce a parametric non-linear utility function to model risk preferences at\nthe level of individual agents, over the collective and individual reward\ncomponents of the game. We study the interplay between such preference\nmodelling and environmental uncertainty on the incentive alignment level in the\ngame. We demonstrate how different combinations of individual preferences and\nenvironmental uncertainties sustain the emergence of cooperative patterns in\nnon-cooperative environments (i.e., where competitive strategies are dominant),\nwhile others sustain competitive patterns in cooperative environments (i.e.,\nwhere cooperative strategies are dominant).", "categories": "cs.MA cs.AI cs.GT", "created": "2024-08-01", "doi": null, "arxiv_id": "2408.00682"}
{"title": "Assessing the Variety of a Concept Space Using an Unbiased Estimate of\n  Rao's Quadratic Index", "authors": [], "abstract": "Past research relates design creativity to 'divergent thinking,' i.e., how\nwell the concept space is explored during the early phase of design.\nResearchers have argued that generating several concepts would increase the\nchances of producing better design solutions. 'Variety' is one of the\nparameters by which one can quantify the breadth of a concept space explored by\nthe designers. It is useful to assess variety at the conceptual design stage\nbecause, at this stage, designers have the freedom to explore different\nsolution principles so as to satisfy a design problem with substantially novel\nconcepts. This article elaborates on and critically examines the existing\nvariety metrics from the engineering design literature, discussing their\nlimitations. A new distance-based variety metric is proposed, along with a\nprescriptive framework to support the assessment process. This framework uses\nthe SAPPhIRE model of causality as a knowledge representation scheme to measure\nthe real-valued distance between two design concepts. The proposed framework is\nimplemented in a software tool called 'VariAnT.' Furthermore, the tool's\napplication is demonstrated through an illustrative example.", "categories": "cs.CL", "created": "2024-08-01", "doi": null, "arxiv_id": "2408.00684"}
{"title": "Can Developers Prompt? A Controlled Experiment for Code Documentation\n  Generation", "authors": [], "abstract": "Large language models (LLMs) bear great potential for automating tedious\ndevelopment tasks such as creating and maintaining code documentation. However,\nit is unclear to what extent developers can effectively prompt LLMs to create\nconcise and useful documentation. We report on a controlled experiment with 20\nprofessionals and 30 computer science students tasked with code documentation\ngeneration for two Python functions. The experimental group freely entered\nad-hoc prompts in a ChatGPT-like extension of Visual Studio Code, while the\ncontrol group executed a predefined few-shot prompt. Our results reveal that\nprofessionals and students were unaware of or unable to apply prompt\nengineering techniques. Especially students perceived the documentation\nproduced from ad-hoc prompts as significantly less readable, less concise, and\nless helpful than documentation from prepared prompts. Some professionals\nproduced higher quality documentation by just including the keyword Docstring\nin their ad-hoc prompts. While students desired more support in formulating\nprompts, professionals appreciated the flexibility of ad-hoc prompting.\nParticipants in both groups rarely assessed the output as perfect. Instead,\nthey understood the tools as support to iteratively refine the documentation.\nFurther research is needed to understand which prompting skills and preferences\ndevelopers have and which support they need for certain tasks.", "categories": "cs.AI cs.HC cs.SE", "created": "2024-08-01", "doi": null, "arxiv_id": "2408.00686"}
{"title": "Speed Limit Reduction Enhances Urban Worker Safety: Evidence from a\n  Decade of Traffic Incidents in Santiago, Chile", "authors": [], "abstract": "Work-related traffic incidents significantly impact urban mobility and\nproductivity. This study analyzes a decade of work-related traffic incident\ndata (2012--2021) in Santiago, Chile, using records from a major social\ninsurance company. We explore temporal, spatial, and demographic patterns in\nthese incidents in urban and rural areas. We also evaluate the impact of a 2018\nurban speed limit reduction law on incident injury severity. Using negative\nbinomial regression, we assess how various factors, including the speed limit\nchange, affect injury severity measured by prescribed medical leave days.\n  Our analysis reveals distinct incident occurrence and severity patterns\nacross different times, locations, and demographic groups. We find that\nmotorcycles and cycles are associated with more severe injuries, with marginal\neffects of 26.94 and 13.06 additional days of medical leave, respectively,\ncompared to motorized vehicles. Female workers tend to have less severe\ninjuries, with an average of 7.57 fewer days of medical leave. Age is also a\nsignificant factor, with each year associated with 0.57 additional days of\nleave.\n  Notably, the urban speed limit reduction is associated with a decrease of\n4.26 days in prescribed medical leave for incidents in urban areas, suggesting\nthat lower speed limits contribute to reduced injury severity in work-related\ntraffic incidents. Our results provide insights for urban planning,\ntransportation policy, and workplace safety initiatives, highlighting the\npotential benefits of speed management in urban areas for improving road safety\nand minimizing the economic impact of work-related incidents.", "categories": "cs.CY", "created": "2024-08-01", "doi": null, "arxiv_id": "2408.00687"}
{"title": "Kernel-based multi-step predictors for data-driven analysis and control\n  of nonlinear systems through the velocity form", "authors": [], "abstract": "We propose kernel-based approaches for the construction of a single-step and\nmulti-step predictor of the velocity form of nonlinear (NL) systems, which\ndescribes the time-difference dynamics of the corresponding NL system and\nadmits a highly structured representation. The predictors in turn allow to\nformulate completely data-driven representations of the velocity form. The\nkernel-based formulation that we derive, inherently respects the structured\nquasi-linear and specific time-dependent relationship of the velocity form.\nThis results in an efficient multi-step predictor for the velocity form and\nhence for nonlinear systems. Moreover, by using the velocity form, our methods\nopen the door for data-driven behavioral analysis and control of nonlinear\nsystems with global stability and performance guarantees.", "categories": "eess.SY cs.SY", "created": "2024-08-01", "doi": null, "arxiv_id": "2408.00688"}
{"title": "Convergence analysis of inner-iteration preconditioned GMRES", "authors": [], "abstract": "The objective of this paper is to understand the superlinear convergence\nbehavior of the inner-iteration preconditioned GMRES method. In order to\nunderstand the phenomenon, we analyze the convergence using the Vandermonde\nmatrix which is defined using the eigenvalues of the coefficient matrix.\nAlthough eigenvalues alone cannot explain the convergence, they may provide an\nupper bound of the residual, together with the right hand side vector and the\neigenvectors. For the diagonalizable case, if the eigenvalues of the\ncoefficient matrix are clustered, the upper bound of the convergence curve\nshows superlinear convergence, when the norm of the matrix obtained by\ndecomposing the right hand side vector into the eigenvector components is not\nso large. We especially analyze the effect of inner-iteration preconditioning\nfor least squares problems, where the eigenvalues cluster towards 1.", "categories": "math.NA cs.NA", "created": "2024-08-01", "doi": null, "arxiv_id": "2408.00693"}
{"title": "Accelerating Full Waveform Inversion By Transfer Learning", "authors": [], "abstract": "Full waveform inversion (FWI) is a powerful tool for reconstructing material\nfields based on sparsely measured data obtained by wave propagation. For\nspecific problems, discretizing the material field with a neural network (NN)\nimproves the robustness and reconstruction quality of the corresponding\noptimization problem. We call this method NN-based FWI. Starting from an\ninitial guess, the weights of the NN are iteratively updated to fit the\nsimulated wave signals to the sparsely measured data set. For gradient-based\noptimization, a suitable choice of the initial guess, i.e., a suitable NN\nweight initialization, is crucial for fast and robust convergence.\n  In this paper, we introduce a novel transfer learning approach to further\nimprove NN-based FWI. This approach leverages supervised pretraining to provide\na better NN weight initialization, leading to faster convergence of the\nsubsequent optimization problem. Moreover, the inversions yield physically more\nmeaningful local minima. The network is pretrained to predict the unknown\nmaterial field using the gradient information from the first iteration of\nconventional FWI. In our computational experiments on two-dimensional domains,\nthe training data set consists of reference simulations with arbitrarily\npositioned elliptical voids of different shapes and orientations. We compare\nthe performance of the proposed transfer learning NN-based FWI with three other\nmethods: conventional FWI, NN-based FWI without pretraining and conventional\nFWI with an initial guess predicted from the pretrained NN. Our results show\nthat transfer learning NN-based FWI outperforms the other methods in terms of\nconvergence speed and reconstruction quality.", "categories": "cs.LG cs.AI", "created": "2024-08-01", "doi": null, "arxiv_id": "2408.00695"}
{"title": "Granular-Balls based Fuzzy Twin Support Vector Machine for\n  Classification", "authors": [], "abstract": "The twin support vector machine (TWSVM) classifier has attracted increasing\nattention because of its low computational complexity. However, its performance\ntends to degrade when samples are affected by noise. The granular-ball fuzzy\nsupport vector machine (GBFSVM) classifier partly alleviates the adverse\neffects of noise, but it relies solely on the distance between the\ngranular-ball's center and the class center to design the granular-ball\nmembership function. In this paper, we first introduce the granular-ball twin\nsupport vector machine (GBTWSVM) classifier, which integrates granular-ball\ncomputing (GBC) with the twin support vector machine (TWSVM) classifier. By\nreplacing traditional point inputs with granular-balls, we demonstrate how to\nderive a pair of non-parallel hyperplanes for the GBTWSVM classifier by solving\na quadratic programming problem. Subsequently, we design the membership and\nnon-membership functions of granular-balls using Pythagorean fuzzy sets to\ndifferentiate the contributions of granular-balls in various regions.\nAdditionally, we develop the granular-ball fuzzy twin support vector machine\n(GBFTSVM) classifier by incorporating GBC with the fuzzy twin support vector\nmachine (FTSVM) classifier. We demonstrate how to derive a pair of non-parallel\nhyperplanes for the GBFTSVM classifier by solving a quadratic programming\nproblem. We also design algorithms for the GBTSVM classifier and the GBFTSVM\nclassifier. Finally, the superior classification performance of the GBTWSVM\nclassifier and the GBFTSVM classifier on 20 benchmark datasets underscores\ntheir scalability, efficiency, and robustness in tackling classification tasks.", "categories": "cs.LG", "created": "2024-08-01", "doi": null, "arxiv_id": "2408.00699"}
{"title": "You Can't Ignore Either: Unifying Structure and Feature Denoising for\n  Robust Graph Learning", "authors": [], "abstract": "Recent research on the robustness of Graph Neural Networks (GNNs) under\nnoises or attacks has attracted great attention due to its importance in\nreal-world applications. Most previous methods explore a single noise source,\nrecovering corrupt node embedding by reliable structures bias or developing\nstructure learning with reliable node features. However, the noises and attacks\nmay come from both structures and features in graphs, making the graph\ndenoising a dilemma and challenging problem. In this paper, we develop a\nunified graph denoising (UGD) framework to unravel the deadlock between\nstructure and feature denoising. Specifically, a high-order neighborhood\nproximity evaluation method is proposed to recognize noisy edges, considering\nfeatures may be perturbed simultaneously. Moreover, we propose to refine noisy\nfeatures with reconstruction based on a graph auto-encoder. An iterative\nupdating algorithm is further designed to optimize the framework and acquire a\nclean graph, thus enabling robust graph learning for downstream tasks. Our UGD\nframework is self-supervised and can be easily implemented as a plug-and-play\nmodule. We carry out extensive experiments, which proves the effectiveness and\nadvantages of our method. Code is avalaible at\nhttps://github.com/YoungTimmy/UGD.", "categories": "cs.LG", "created": "2024-08-01", "doi": null, "arxiv_id": "2408.00700"}
{"title": "Joint Neural Networks for One-shot Object Recognition and Detection", "authors": [], "abstract": "This paper presents a novel joint neural networks approach to address the\nchallenging one-shot object recognition and detection tasks. Inspired by\nSiamese neural networks and state-of-art multi-box detection approaches, the\njoint neural networks are able to perform object recognition and detection for\ncategories that remain unseen during the training process. Following the\none-shot object recognition/detection constraints, the training and testing\ndatasets do not contain overlapped classes, in other words, all the test\nclasses remain unseen during training. The joint networks architecture is able\nto effectively compare pairs of images via stacked convolutional layers of the\nquery and target inputs, recognising patterns of the same input query category\nwithout relying on previous training around this category. The proposed\napproach achieves 61.41% accuracy for one-shot object recognition on the\nMiniImageNet dataset and 47.1% mAP for one-shot object detection when trained\non the COCO dataset and tested using the Pascal VOC dataset. Code available at\nhttps://github.com/cjvargasc/JNN recog and https://github.com/cjvargasc/JNN\ndetection/", "categories": "cs.CV", "created": "2024-08-01", "doi": null, "arxiv_id": "2408.00701"}
{"title": "Future Directions in Human Mobility Science", "authors": [], "abstract": "We provide a brief review of human mobility science and present three key\nareas where we expect to see substantial advancements. We start from the mind\nand discuss the need to better understand how spatial cognition shapes mobility\npatterns. We then move to societies and argue the importance of better\nunderstanding new forms of transportation. We conclude by discussing how\nalgorithms shape mobility behaviour and provide useful tools for modellers.\nFinally, we discuss how progress in these research directions may help us\naddress some of the challenges our society faces today.", "categories": "physics.soc-ph cs.CY", "created": "2024-08-01", "doi": "10.1038/s43588-023-00469-4", "arxiv_id": "2408.00702"}
{"title": "Future of Artificial Intelligence in Agile Software Development", "authors": [], "abstract": "The advent of Artificial intelligence has promising advantages that can be\nutilized to transform the landscape of software project development. The\nSoftware process framework consists of activities that constantly require\nroutine human interaction, leading to the possibility of errors and\nuncertainties. AI can assist software development managers, software testers,\nand other team members by leveraging LLMs, GenAI models, and AI agents to\nperform routine tasks, risk analysis and prediction, strategy recommendations,\nand support decision making. AI has the potential to increase efficiency and\nreduce the risks encountered by the project management team while increasing\nthe project success rates. Additionally, it can also break down complex notions\nand development processes for stakeholders to make informed decisions. In this\npaper, we propose an approach in which AI tools and technologies can be\nutilized to bestow maximum assistance for agile software projects, which have\nbecome increasingly favored in the industry in recent years.", "categories": "cs.SE cs.AI", "created": "2024-08-01", "doi": null, "arxiv_id": "2408.00703"}
{"title": "Segment-Based Test Case Prioritization: A Multi-objective Approach", "authors": [], "abstract": "Regression testing of software is a crucial but time-consuming task,\nespecially in the context of user interface (UI) testing where multiple\nmicroservices must be validated simultaneously. Test case prioritization (TCP)\nis a cost-efficient solution to address this by scheduling test cases in an\nexecution order that maximizes an objective function, generally aimed at\nincreasing the fault detection rate. While several techniques have been\nproposed for TCP, most rely on source code information which is usually not\navailable for UI testing. In this paper, we introduce a multi-objective\noptimization approach to prioritize UI test cases, using evolutionary search\nalgorithms and four coverage criteria focusing on web page elements as\nobjectives for the optimization problem. Our method, which does not require\nsource code information, is evaluated using two evolutionary algorithms\n(AGE-MOEA and NSGA-II) and compared with other TCP methods on a self-collected\ndataset of 11 test suites. The results show that our approach significantly\noutperforms other methods in terms of Average Percentage of Faults Detected\n(APFD) and APFD with Cost (APFDc), achieving the highest scores of 87.8\\% and\n79.2\\%, respectively. We also introduce a new dataset and demonstrate the\nsignificant improvement of our approach over existing ones via empirical\nexperiments. The paper's contributions include the application of web page\nsegmentation in TCP, the construction of a new dataset for UI TCP, and\nempirical comparisons that demonstrate the improvement of our approach.", "categories": "cs.SE", "created": "2024-08-01", "doi": "10.1145/3650212.3680349", "arxiv_id": "2408.00705"}
{"title": "Point-supervised Brain Tumor Segmentation with Box-prompted MedSAM", "authors": [], "abstract": "Delineating lesions and anatomical structure is important for image-guided\ninterventions. Point-supervised medical image segmentation (PSS) has great\npotential to alleviate costly expert delineation labeling. However, due to the\nlack of precise size and boundary guidance, the effectiveness of PSS often\nfalls short of expectations. Although recent vision foundational models, such\nas the medical segment anything model (MedSAM), have made significant\nadvancements in bounding-box-prompted segmentation, it is not straightforward\nto utilize point annotation, and is prone to semantic ambiguity. In this\npreliminary study, we introduce an iterative framework to facilitate\nsemantic-aware point-supervised MedSAM. Specifically, the semantic box-prompt\ngenerator (SBPG) module has the capacity to convert the point input into\npotential pseudo bounding box suggestions, which are explicitly refined by the\nprototype-based semantic similarity. This is then succeeded by a prompt-guided\nspatial refinement (PGSR) module that harnesses the exceptional\ngeneralizability of MedSAM to infer the segmentation mask, which also updates\nthe box proposal seed in SBPG. Performance can be progressively improved with\nadequate iterations. We conducted an evaluation on BraTS2018 for the\nsegmentation of whole brain tumors and demonstrated its superior performance\ncompared to traditional PSS methods and on par with box-supervised methods.", "categories": "cs.CV cs.AI cs.LG eess.IV physics.med-ph", "created": "2024-08-01", "doi": null, "arxiv_id": "2408.00706"}
{"title": "Synthetic dual image generation for reduction of labeling efforts in\n  semantic segmentation of micrographs with a customized metric function", "authors": [], "abstract": "Training of semantic segmentation models for material analysis requires\nmicrographs and their corresponding masks. It is quite unlikely that perfect\nmasks will be drawn, especially at the edges of objects, and sometimes the\namount of data that can be obtained is small, since only a few samples are\navailable. These aspects make it very problematic to train a robust model. We\ndemonstrate a workflow for the improvement of semantic segmentation models of\nmicrographs through the generation of synthetic microstructural images in\nconjunction with masks. The workflow only requires joining a few micrographs\nwith their respective masks to create the input for a Vector\nQuantised-Variational AutoEncoder model that includes an embedding space, which\nis trained such that a generative model (PixelCNN) learns the distribution of\neach input, transformed into discrete codes, and can be used to sample new\ncodes. The latter will eventually be decoded by VQ-VAE to generate images\nalongside corresponding masks for semantic segmentation. To evaluate the\nsynthetic data, we have trained U-Net models with different amounts of these\nsynthetic data in conjunction with real data. These models were then evaluated\nusing non-synthetic images only. Additionally, we introduce a customized metric\nderived from the mean Intersection over Union (mIoU). The proposed metric\nprevents a few falsely predicted pixels from greatly reducing the value of the\nmIoU. We have achieved a reduction in sample preparation and acquisition times,\nas well as the efforts, needed for image processing and labeling tasks, are\nless when it comes to training semantic segmentation model. The approach could\nbe generalized to various types of image data such that it serves as a\nuser-friendly solution for training models with a small number of real images.", "categories": "cs.CV cs.CE cs.LG", "created": "2024-08-01", "doi": null, "arxiv_id": "2408.00707"}
{"title": "Investigating Brain Connectivity and Regional Statistics from EEG for\n  early stage Parkinson's Classification", "authors": [], "abstract": "We evaluate the effectiveness of combining brain connectivity metrics with\nsignal statistics for early stage Parkinson's Disease (PD) classification using\nelectroencephalogram data (EEG). The data is from 5 arousal states - wakeful\nand four sleep stages (N1, N2, N3 and REM). Our pipeline uses an Ada Boost\nmodel for classification on a challenging early stage PD classification task\nwith with only 30 participants (11 PD , 19 Healthy Control). Evaluating 9 brain\nconnectivity metrics we find the best connectivity metric to be different for\neach arousal state with Phase Lag Index achieving the highest individual\nclassification accuracy of 86\\% on N1 data. Further to this our pipeline using\nregional signal statistics achieves an accuracy of 78\\%, using brain\nconnectivity only achieves an accuracy of 86\\% whereas combining the two\nachieves a best accuracy of 91\\%. This best performance is achieved on N1 data\nusing Phase Lag Index (PLI) combined with statistics derived from the frequency\ncharacteristics of the EEG signal. This model also achieves a recall of 80 \\%\nand precision of 96\\%. Furthermore we find that on data from each arousal\nstate, combining PLI with regional signal statistics improves classification\naccuracy versus using signal statistics or brain connectivity alone. Thus we\nconclude that combining brain connectivity statistics with regional EEG\nstatistics is optimal for classifier performance on early stage Parkinson's.\nAdditionally, we find outperformance of N1 EEG for classification of\nParkinson's and expect this could be due to disrupted N1 sleep in PD. This\nshould be explored in future work.", "categories": "q-bio.NC cs.AI eess.SP", "created": "2024-08-01", "doi": null, "arxiv_id": "2408.00711"}
{"title": "MotionFix: Text-Driven 3D Human Motion Editing", "authors": [], "abstract": "The focus of this paper is 3D motion editing. Given a 3D human motion and a\ntextual description of the desired modification, our goal is to generate an\nedited motion as described by the text. The challenges include the lack of\ntraining data and the design of a model that faithfully edits the source\nmotion. In this paper, we address both these challenges. We build a methodology\nto semi-automatically collect a dataset of triplets in the form of (i) a source\nmotion, (ii) a target motion, and (iii) an edit text, and create the new\nMotionFix dataset. Having access to such data allows us to train a conditional\ndiffusion model, TMED, that takes both the source motion and the edit text as\ninput. We further build various baselines trained only on text-motion pairs\ndatasets, and show superior performance of our model trained on triplets. We\nintroduce new retrieval-based metrics for motion editing and establish a new\nbenchmark on the evaluation set of MotionFix. Our results are encouraging,\npaving the way for further research on finegrained motion generation. Code and\nmodels will be made publicly available.", "categories": "cs.CV cs.GR", "created": "2024-08-01", "doi": null, "arxiv_id": "2408.00712"}
{"title": "SAM 2: Segment Anything in Images and Videos", "authors": [], "abstract": "We present Segment Anything Model 2 (SAM 2), a foundation model towards\nsolving promptable visual segmentation in images and videos. We build a data\nengine, which improves model and data via user interaction, to collect the\nlargest video segmentation dataset to date. Our model is a simple transformer\narchitecture with streaming memory for real-time video processing. SAM 2\ntrained on our data provides strong performance across a wide range of tasks.\nIn video segmentation, we observe better accuracy, using 3x fewer interactions\nthan prior approaches. In image segmentation, our model is more accurate and 6x\nfaster than the Segment Anything Model (SAM). We believe that our data, model,\nand insights will serve as a significant milestone for video segmentation and\nrelated perception tasks. We are releasing a version of our model, the dataset\nand an interactive demo.", "categories": "cs.CV cs.AI cs.LG", "created": "2024-08-01", "doi": null, "arxiv_id": "2408.00714"}
{"title": "A Natural Language Processing Framework for Hotel Recommendation Based\n  on Users' Text Reviews", "authors": [], "abstract": "Recently, the application of Artificial Intelligence algorithms in hotel\nrecommendation systems has become an increasingly popular topic. One such\nmethod that has proven to be effective in this field is Deep Learning,\nespecially Natural Language processing models, which are able to extract\nsemantic knowledge from user's text reviews to create more efficient\nrecommendation systems. This can lead to the development of intelligent models\nthat can classify a user's preferences and emotions based on their feedback in\nthe form of text reviews about their hotel stay experience. In this study, we\npropose a Natural Language Processing framework that utilizes customer text\nreviews to provide personalized recommendations for the most appropriate hotel\nbased on their preferences. The framework is based on Bidirectional Encoder\nRepresentations from Transformers (BERT) and a fine-tuning/validation pipeline\nthat categorizes customer hotel review texts into \"Bad,\" \"Good,\" or \"Excellent\"\nrecommended hotels. Our findings indicate that the hotel recommendation system\nwe propose can significantly enhance the user experience of booking\naccommodations by providing personalized recommendations based on user\npreferences and previous booking history.", "categories": "cs.LG", "created": "2024-08-01", "doi": null, "arxiv_id": "2408.00716"}
{"title": "A Multi-Reference Relaxation Enforced Neighborhood Search Heuristic in\n  SCIP", "authors": [], "abstract": "This paper proposes and evaluates a Multi-Reference Relaxation Enforced\nNeighborhood Search (MRENS) heuristic within the SCIP solver. This study marks\nthe first integration and evaluation of MRENS in a full-fledged MILP solver,\nspecifically coupled with the recently-introduced Lagromory separator for\ngenerating multiple reference solutions. Computational experiments on the\nMIPLIB 2017 benchmark set show that MRENS, with multiple reference solutions,\nimproves the solver's ability to find higher-quality feasible solutions\ncompared to single-reference approaches. This study highlights the potential of\nmulti-reference heuristics in enhancing primal heuristics in MILP solvers.", "categories": "math.OC cs.MS", "created": "2024-08-01", "doi": null, "arxiv_id": "2408.00718"}
{"title": "Pathway to Secure and Trustworthy 6G for LLMs: Attacks, Defense, and\n  Opportunities", "authors": [], "abstract": "Recently, large language models (LLMs) have been gaining a lot of interest\ndue to their adaptability and extensibility in emerging applications, including\ncommunication networks. It is anticipated that 6G mobile edge computing\nnetworks will be able to support LLMs as a service, as they provide ultra\nreliable low-latency communications and closed loop massive connectivity.\nHowever, LLMs are vulnerable to data and model privacy issues that affect the\ntrustworthiness of LLMs to be deployed for user-based services. In this paper,\nwe explore the security vulnerabilities associated with fine-tuning LLMs in 6G\nnetworks, in particular the membership inference attack. We define the\ncharacteristics of an attack network that can perform a membership inference\nattack if the attacker has access to the fine-tuned model for the downstream\ntask. We show that the membership inference attacks are effective for any\ndownstream task, which can lead to a personal data breach when using LLM as a\nservice. The experimental results show that the attack success rate of maximum\n92% can be achieved on named entity recognition task. Based on the experimental\nanalysis, we discuss possible defense mechanisms and present possible research\ndirections to make the LLMs more trustworthy in the context of 6G networks.", "categories": "cs.CR cs.AI cs.DC", "created": "2024-08-01", "doi": null, "arxiv_id": "2408.00722"}
{"title": "An Empirical Analysis of Compute-Optimal Inference for Problem-Solving\n  with Language Models", "authors": [], "abstract": "The optimal training configurations of large language models (LLMs) with\nrespect to model sizes and compute budgets have been extensively studied. But\nhow to optimally configure LLMs during inference has not been explored in\nsufficient depth. We study compute-optimal inference: designing models and\ninference strategies that optimally trade off additional inference-time compute\nfor improved performance. As a first step towards understanding and designing\ncompute-optimal inference methods, we assessed the effectiveness and\ncomputational efficiency of multiple inference strategies such as Greedy\nSearch, Majority Voting, Best-of-N, Weighted Voting, and their variants on two\ndifferent Tree Search algorithms, involving different model sizes and\ncomputational budgets. We found that a smaller language model with a novel tree\nsearch algorithm typically achieves a Pareto-optimal trade-off. These results\nhighlight the potential benefits of deploying smaller models equipped with more\nsophisticated decoding algorithms in budget-constrained scenarios, e.g., on\nend-devices, to enhance problem-solving accuracy. For instance, we show that\nthe Llemma-7B model can achieve competitive accuracy to a Llemma-34B model on\nMATH500 while using $2\\times$ less FLOPs. Our findings could potentially apply\nto any generation task with a well-defined measure of success.", "categories": "cs.AI", "created": "2024-08-01", "doi": null, "arxiv_id": "2408.00724"}
{"title": "Improving Retrieval-Augmented Generation in Medicine with Iterative\n  Follow-up Questions", "authors": [], "abstract": "The emergent abilities of large language models (LLMs) have demonstrated\ngreat potential in solving medical questions. They can possess considerable\nmedical knowledge, but may still hallucinate and are inflexible in the\nknowledge updates. While Retrieval-Augmented Generation (RAG) has been proposed\nto enhance the medical question-answering capabilities of LLMs with external\nknowledge bases, it may still fail in complex cases where multiple rounds of\ninformation-seeking are required. To address such an issue, we propose\niterative RAG for medicine (i-MedRAG), where LLMs can iteratively ask follow-up\nqueries based on previous information-seeking attempts. In each iteration of\ni-MedRAG, the follow-up queries will be answered by a vanilla RAG system and\nthey will be further used to guide the query generation in the next iteration.\nOur experiments show the improved performance of various LLMs brought by\ni-MedRAG compared with vanilla RAG on complex questions from clinical vignettes\nin the United States Medical Licensing Examination (USMLE), as well as various\nknowledge tests in the Massive Multitask Language Understanding (MMLU) dataset.\nNotably, our zero-shot i-MedRAG outperforms all existing prompt engineering and\nfine-tuning methods on GPT-3.5, achieving an accuracy of 69.68\\% on the MedQA\ndataset. In addition, we characterize the scaling properties of i-MedRAG with\ndifferent iterations of follow-up queries and different numbers of queries per\niteration. Our case studies show that i-MedRAG can flexibly ask follow-up\nqueries to form reasoning chains, providing an in-depth analysis of medical\nquestions. To the best of our knowledge, this is the first-of-its-kind study on\nincorporating follow-up queries into medical RAG.", "categories": "cs.CL cs.AI", "created": "2024-08-01", "doi": null, "arxiv_id": "2408.00727"}
{"title": "CERT-ED: Certifiably Robust Text Classification for Edit Distance", "authors": [], "abstract": "With the growing integration of AI in daily life, ensuring the robustness of\nsystems to inference-time attacks is crucial. Among the approaches for\ncertifying robustness to such adversarial examples, randomized smoothing has\nemerged as highly promising due to its nature as a wrapper around arbitrary\nblack-box models. Previous work on randomized smoothing in natural language\nprocessing has primarily focused on specific subsets of edit distance\noperations, such as synonym substitution or word insertion, without exploring\nthe certification of all edit operations. In this paper, we adapt Randomized\nDeletion (Huang et al., 2023) and propose, CERTified Edit Distance defense\n(CERT-ED) for natural language classification. Through comprehensive\nexperiments, we demonstrate that CERT-ED outperforms the existing Hamming\ndistance method RanMASK (Zeng et al., 2023) in 4 out of 5 datasets in terms of\nboth accuracy and the cardinality of the certificate. By covering various\nthreat models, including 5 direct and 5 transfer attacks, our method improves\nempirical robustness in 38 out of 50 settings.", "categories": "cs.CL cs.CR cs.LG", "created": "2024-08-01", "doi": null, "arxiv_id": "2408.00728"}
{"title": "Litmus: Fair Pricing for Serverless Computing", "authors": [], "abstract": "Serverless computing has emerged as a market-dominant paradigm in modern\ncloud computing, benefiting both cloud providers and tenants. While service\nproviders can optimize their machine utilization, tenants only need to pay for\nthe resources they use. To maximize resource utilization, these serverless\nsystems co-run numerous short-lived functions, bearing frequent system\ncondition shifts. When the system gets overcrowded, a tenant's function may\nsuffer from disturbing slowdowns. Ironically, tenants also incur higher costs\nduring these slowdowns, as commercial serverless platforms determine costs\nproportional to their execution times.\n  This paper argues that cloud providers should compensate tenants for losses\nincurred when the server is over-provisioned. However, estimating tenants'\nlosses is challenging without pre-profiled information about their functions.\nPrior studies have indicated that assessing tenant losses leads to heavy\noverheads. As a solution, this paper introduces a new pricing model that offers\ndiscounts based on the machine's state while presuming the tenant's loss under\nthat state. To monitor the machine state accurately, Litmus pricing frequently\nconducts Litmus tests, an effective and lightweight solution for measuring\nsystem congestion. Our experiments show that Litmus pricing can accurately\ngauge the impact of system congestion and offer nearly ideal prices, with only\na 0.2% price difference on average, in a heavily congested system.", "categories": "cs.DC", "created": "2024-08-01", "doi": "10.1145/3622781.3674181", "arxiv_id": "2408.00731"}
{"title": "TurboEdit: Text-Based Image Editing Using Few-Step Diffusion Models", "authors": [], "abstract": "Diffusion models have opened the path to a wide range of text-based image\nediting frameworks. However, these typically build on the multi-step nature of\nthe diffusion backwards process, and adapting them to distilled, fast-sampling\nmethods has proven surprisingly challenging. Here, we focus on a popular line\nof text-based editing frameworks - the ``edit-friendly'' DDPM-noise inversion\napproach. We analyze its application to fast sampling methods and categorize\nits failures into two classes: the appearance of visual artifacts, and\ninsufficient editing strength. We trace the artifacts to mismatched noise\nstatistics between inverted noises and the expected noise schedule, and suggest\na shifted noise schedule which corrects for this offset. To increase editing\nstrength, we propose a pseudo-guidance approach that efficiently increases the\nmagnitude of edits without introducing new artifacts. All in all, our method\nenables text-based image editing with as few as three diffusion steps, while\nproviding novel insights into the mechanisms behind popular text-based editing\napproaches.", "categories": "cs.CV cs.GR", "created": "2024-08-01", "doi": null, "arxiv_id": "2408.00735"}
{"title": "Virchow 2: Scaling Self-Supervised Mixed Magnification Models in\n  Pathology", "authors": [], "abstract": "Foundation models are rapidly being developed for computational pathology\napplications. However, it remains an open question which factors are most\nimportant for downstream performance with data scale and diversity, model size,\nand training algorithm all playing a role. In this work, we present the result\nof scaling both data and model size, surpassing previous studies in both\ndimensions, and introduce two new models: Virchow 2, a 632M parameter vision\ntransformer, and Virchow 2G, a 1.85B parameter vision transformer, each trained\nwith 3.1M histopathology whole slide images. To support this scale, we propose\ndomain-inspired adaptations to the DINOv2 training algorithm, which is quickly\nbecoming the default method in self-supervised learning for computational\npathology. We achieve state of the art performance on twelve tile-level tasks,\nas compared to the top performing competing models. Our results suggest that\ndata diversity and domain-specific training can outperform models that only\nscale in the number of parameters, but, on average, performance benefits from\ndomain-tailoring, data scale, and model scale.", "categories": "cs.CV", "created": "2024-08-01", "doi": null, "arxiv_id": "2408.00738"}
{"title": "DynamoLLM: Designing LLM Inference Clusters for Performance and Energy\n  Efficiency", "authors": [], "abstract": "The rapid evolution and widespread adoption of generative large language\nmodels (LLMs) have made them a pivotal workload in various applications. Today,\nLLM inference clusters receive a large number of queries with strict Service\nLevel Objectives (SLOs). To achieve the desired performance, these models\nexecute on power-hungry GPUs causing the inference clusters to consume large\namount of energy and, consequently, result in excessive carbon emissions.\nFortunately, we find that there is a great opportunity to exploit the\nheterogeneity in inference compute properties and fluctuations in inference\nworkloads, to significantly improve energy-efficiency. However, such a diverse\nand dynamic environment creates a large search-space where different system\nconfigurations (e.g., number of instances, model parallelism, and GPU\nfrequency) translate into different energy-performance trade-offs. To address\nthese challenges, we propose DynamoLLM, the first energy-management framework\nfor LLM inference environments. DynamoLLM automatically and dynamically\nreconfigures the inference cluster to optimize for energy and cost of LLM\nserving under the service's performance SLOs. We show that at a service-level,\nDynamoLLM conserves 53% energy and 38% operational carbon emissions, and\nreduces 61% cost to the customer, while meeting the latency SLOs.", "categories": "cs.AI cs.AR cs.DC", "created": "2024-08-01", "doi": null, "arxiv_id": "2408.00741"}
{"title": "Collaborative Vision-Text Representation Optimizing for Open-Vocabulary\n  Segmentation", "authors": [], "abstract": "Pre-trained vision-language models, e.g. CLIP, have been increasingly used to\naddress the challenging Open-Vocabulary Segmentation (OVS) task, benefiting\nfrom their well-aligned vision-text embedding space. Typical solutions involve\neither freezing CLIP during training to unilaterally maintain its zero-shot\ncapability, or fine-tuning CLIP vision encoder to achieve perceptual\nsensitivity to local regions. However, few of them incorporate vision-text\ncollaborative optimization. Based on this, we propose the Content-Dependent\nTransfer to adaptively enhance each text embedding by interacting with the\ninput image, which presents a parameter-efficient way to optimize the text\nrepresentation. Besides, we additionally introduce a Representation\nCompensation strategy, reviewing the original CLIP-V representation as\ncompensation to maintain the zero-shot capability of CLIP. In this way, the\nvision and text representation of CLIP are optimized collaboratively, enhancing\nthe alignment of the vision-text feature space. To the best of our knowledge,\nwe are the first to establish the collaborative vision-text optimizing\nmechanism within the OVS field. Extensive experiments demonstrate our method\nachieves superior performance on popular OVS benchmarks. In open-vocabulary\nsemantic segmentation, our method outperforms the previous state-of-the-art\napproaches by +0.5, +2.3, +3.4, +0.4 and +1.1 mIoU, respectively on A-847,\nA-150, PC-459, PC-59 and PAS-20. Furthermore, in a panoptic setting on ADE20K,\nwe achieve the performance of 27.1 PQ, 73.5 SQ, and 32.9 RQ. Code will be\navailable at https://github.com/jiaosiyu1999/MAFT-Plus.git .", "categories": "cs.CV", "created": "2024-08-01", "doi": null, "arxiv_id": "2408.00744"}
{"title": "Leaf Angle Estimation using Mask R-CNN and LETR Vision Transformer", "authors": [], "abstract": "Modern day studies show a high degree of correlation between high yielding\ncrop varieties and plants with upright leaf angles. It is observed that plants\nwith upright leaf angles intercept more light than those without upright leaf\nangles, leading to a higher rate of photosynthesis. Plant scientists and\nbreeders benefit from tools that can directly measure plant parameters in the\nfield i.e. on-site phenotyping. The estimation of leaf angles by manual means\nin a field setting is tedious and cumbersome. We mitigate the tedium using a\ncombination of the Mask R-CNN instance segmentation neural network, and Line\nSegment Transformer (LETR), a vision transformer. The proposed Computer Vision\n(CV) pipeline is applied on two image datasets, Summer 2015-Ames ULA and Summer\n2015- Ames MLA, with a combined total of 1,827 plant images collected in the\nfield using FieldBook, an Android application aimed at on-site phenotyping. The\nleaf angles estimated by the proposed pipeline on the image datasets are\ncompared to two independent manual measurements using ImageJ, a Java-based\nimage processing program developed at the National Institutes of Health and the\nLaboratory for Optical and Computational Instrumentation. The results, when\ncompared for similarity using the Cosine Similarity measure, exhibit 0.98\nsimilarity scores on both independent measurements of Summer 2015-Ames ULA and\nSummer 2015-Ames MLA image datasets, demonstrating the feasibility of the\nproposed pipeline for on-site measurement of leaf angles.", "categories": "cs.CV cs.AI cs.LG", "created": "2024-08-01", "doi": null, "arxiv_id": "2408.00749"}
{"title": "Algebraic power series and their automatic complexity II: modulo prime\n  powers", "authors": [], "abstract": "Christol and, independently, Denef and Lipshitz showed that an algebraic\nsequence of $p$-adic integers (or integers) is $p$-automatic when reduced\nmodulo $p^\\alpha$. Previously, the best known bound on the minimal automaton\nsize for such a sequence was doubly exponential in $\\alpha$. We improve this\nbound to the order of $p^{\\alpha^3 h d}$, where $h$ and $d$ are the height and\ndegree of the minimal annihilating polynomial. We achieve this bound by showing\nthat all states in the automaton are naturally represented in a new numeration\nsystem. This significantly restricts the set of possible states. Since our\napproach embeds algebraic sequences as diagonals of rational functions, we also\nobtain bounds more generally for diagonals of multivariate rational functions.", "categories": "math.NT cs.FL cs.SC", "created": "2024-08-01", "doi": null, "arxiv_id": "2408.00750"}
{"title": "A Policy-Gradient Approach to Solving Imperfect-Information Games with\n  Iterate Convergence", "authors": [], "abstract": "Policy gradient methods have become a staple of any single-agent\nreinforcement learning toolbox, due to their combination of desirable\nproperties: iterate convergence, efficient use of stochastic trajectory\nfeedback, and theoretically-sound avoidance of importance sampling corrections.\nIn multi-agent imperfect-information settings (extensive-form games), however,\nit is still unknown whether the same desiderata can be guaranteed while\nretaining theoretical guarantees. Instead, sound methods for extensive-form\ngames rely on approximating counterfactual values (as opposed to Q values),\nwhich are incompatible with policy gradient methodologies. In this paper, we\ninvestigate whether policy gradient can be safely used in two-player zero-sum\nimperfect-information extensive-form games (EFGs). We establish positive\nresults, showing for the first time that a policy gradient method leads to\nprovable best-iterate convergence to a regularized Nash equilibrium in\nself-play.", "categories": "cs.GT cs.AI cs.LG stat.ML", "created": "2024-08-01", "doi": null, "arxiv_id": "2408.00751"}
{"title": "A deep learning-enabled smart garment for versatile sleep behaviour\n  monitoring", "authors": [], "abstract": "Continuous monitoring and accurate detection of complex sleep patterns\nassociated to different sleep-related conditions is essential, not only for\nenhancing sleep quality but also for preventing the risk of developing chronic\nillnesses associated to unhealthy sleep. Despite significant advances in\nresearch, achieving versatile recognition of various unhealthy and sub-healthy\nsleep patterns with simple wearable devices at home remains a significant\nchallenge. Here, we report a robust and durable ultrasensitive strain sensor\narray printed on a smart garment, in its collar region. This solution allows\ndetecting subtle vibrations associated with multiple sleep patterns at the\nextrinsic laryngeal muscles. Equipped with a deep learning neural network, it\ncan precisely identify six sleep states-nasal breathing, mouth breathing,\nsnoring, bruxism, central sleep apnea (CSA), and obstructive sleep apnea\n(OSA)-with an impressive accuracy of 98.6%, all without requiring specific\npositioning. We further demonstrate its explainability and generalization\ncapabilities in practical applications. Explainable artificial intelligence\n(XAI) visualizations reflect comprehensive signal pattern analysis with low\nbias. Transfer learning tests show that the system can achieve high accuracy\n(overall accuracy of 95%) on new users with very few-shot learning (less than\n15 samples per class). The scalable manufacturing process, robustness, high\naccuracy, and excellent generalization of the smart garment make it a promising\ntool for next-generation continuous sleep monitoring.", "categories": "eess.SP cs.AI", "created": "2024-08-01", "doi": null, "arxiv_id": "2408.00753"}
{"title": "Coarse Correspondence Elicit 3D Spacetime Understanding in Multimodal\n  Language Model", "authors": [], "abstract": "Multimodal language models (MLLMs) are increasingly being implemented in\nreal-world environments, necessitating their ability to interpret 3D spaces and\ncomprehend temporal dynamics. Despite their potential, current top models\nwithin our community still fall short in adequately understanding spatial and\ntemporal dimensions. We introduce Coarse Correspondence, a simple,\ntraining-free, effective, and general-purpose visual prompting method to elicit\n3D and temporal understanding in multimodal LLMs. Our method uses a lightweight\ntracking model to find object correspondences between frames in a video or\nbetween sets of image viewpoints. It selects the most frequent object instances\nand visualizes them with markers with unique IDs in the image. With this simple\napproach, we achieve state-of-the-art results on 3D understanding benchmarks\nincluding ScanQA (+20.5\\%) and a subset of OpenEQA (+9.7\\%), and on long-form\nvideo benchmarks such as EgoSchema (+6.0\\%). We also curate a small diagnostic\ndataset to evaluate whether MLLMs can reason about space from a described\nviewpoint other than the camera viewpoint. Again, Coarse Correspondence\nimproves spatial perspective-taking abilities but we highlight that MLLMs\nstruggle with this task. Together, we demonstrate that our simple prompting\nmethod can significantly aid downstream tasks that require 3D or temporal\nreasoning.", "categories": "cs.CV cs.LG", "created": "2024-08-01", "doi": null, "arxiv_id": "2408.00754"}
{"title": "Text-Guided Video Masked Autoencoder", "authors": [], "abstract": "Recent video masked autoencoder (MAE) works have designed improved masking\nalgorithms focused on saliency. These works leverage visual cues such as motion\nto mask the most salient regions. However, the robustness of such visual cues\ndepends on how often input videos match underlying assumptions. On the other\nhand, natural language description is an information dense representation of\nvideo that implicitly captures saliency without requiring modality-specific\nassumptions, and has not been explored yet for video MAE. To this end, we\nintroduce a novel text-guided masking algorithm (TGM) that masks the video\nregions with highest correspondence to paired captions. Without leveraging any\nexplicit visual cues for saliency, our TGM is competitive with state-of-the-art\nmasking algorithms such as motion-guided masking. To further benefit from the\nsemantics of natural language for masked reconstruction, we next introduce a\nunified framework for joint MAE and masked video-text contrastive learning. We\nshow that across existing masking algorithms, unifying MAE and masked\nvideo-text contrastive learning improves downstream performance compared to\npure MAE on a variety of video recognition tasks, especially for linear probe.\nWithin this unified framework, our TGM achieves the best relative performance\non five action recognition and one egocentric datasets, highlighting the\ncomplementary nature of natural language for masked video modeling.", "categories": "cs.CV", "created": "2024-08-01", "doi": null, "arxiv_id": "2408.00759"}
{"title": "Smoothed Energy Guidance: Guiding Diffusion Models with Reduced Energy\n  Curvature of Attention", "authors": [], "abstract": "Conditional diffusion models have shown remarkable success in visual content\ngeneration, producing high-quality samples across various domains, largely due\nto classifier-free guidance (CFG). Recent attempts to extend guidance to\nunconditional models have relied on heuristic techniques, resulting in\nsuboptimal generation quality and unintended effects. In this work, we propose\nSmoothed Energy Guidance (SEG), a novel training- and condition-free approach\nthat leverages the energy-based perspective of the self-attention mechanism to\nenhance image generation. By defining the energy of self-attention, we\nintroduce a method to reduce the curvature of the energy landscape of attention\nand use the output as the unconditional prediction. Practically, we control the\ncurvature of the energy landscape by adjusting the Gaussian kernel parameter\nwhile keeping the guidance scale parameter fixed. Additionally, we present a\nquery blurring method that is equivalent to blurring the entire attention\nweights without incurring quadratic complexity in the number of tokens. In our\nexperiments, SEG achieves a Pareto improvement in both quality and the\nreduction of side effects. The code is available at\n\\url{https://github.com/SusungHong/SEG-SDXL}.", "categories": "cs.CV cs.AI cs.LG", "created": "2024-08-01", "doi": null, "arxiv_id": "2408.00760"}
{"title": "UniTalker: Scaling up Audio-Driven 3D Facial Animation through A Unified\n  Model", "authors": [], "abstract": "Audio-driven 3D facial animation aims to map input audio to realistic facial\nmotion. Despite significant progress, limitations arise from inconsistent 3D\nannotations, restricting previous models to training on specific annotations\nand thereby constraining the training scale. In this work, we present\nUniTalker, a unified model featuring a multi-head architecture designed to\neffectively leverage datasets with varied annotations. To enhance training\nstability and ensure consistency among multi-head outputs, we employ three\ntraining strategies, namely, PCA, model warm-up, and pivot identity embedding.\nTo expand the training scale and diversity, we assemble A2F-Bench, comprising\nfive publicly available datasets and three newly curated datasets. These\ndatasets contain a wide range of audio domains, covering multilingual speech\nvoices and songs, thereby scaling the training data from commonly employed\ndatasets, typically less than 1 hour, to 18.5 hours. With a single trained\nUniTalker model, we achieve substantial lip vertex error reductions of 9.2% for\nBIWI dataset and 13.7% for Vocaset. Additionally, the pre-trained UniTalker\nexhibits promise as the foundation model for audio-driven facial animation\ntasks. Fine-tuning the pre-trained UniTalker on seen datasets further enhances\nperformance on each dataset, with an average error reduction of 6.3% on\nA2F-Bench. Moreover, fine-tuning UniTalker on an unseen dataset with only half\nthe data surpasses prior state-of-the-art models trained on the full dataset.\nThe code and dataset are available at the project page\nhttps://github.com/X-niper/UniTalker.", "categories": "cs.CV", "created": "2024-08-01", "doi": null, "arxiv_id": "2408.00762"}
{"title": "AgentGen: Enhancing Planning Abilities for Large Language Model based\n  Agent via Environment and Task Generation", "authors": [], "abstract": "Large Language Model (LLM) based agents have garnered significant attention\nand are becoming increasingly popular. Furthermore, planning ability is a\ncrucial component of an LLM-based agent, involving interaction with the\nenvironment and executing actions to complete a planning task, which generally\nentails achieving a desired goal from an initial state. This paper investigates\nenhancing the planning abilities of LLMs through instruction tuning, referred\nto as agent training. Recent studies have demonstrated that utilizing\nexpert-level trajectory for instruction-tuning LLMs effectively enhances their\nplanning capabilities. However, existing work primarily focuses on synthesizing\ntrajectories from manually designed planning tasks and environments. The\nlabor-intensive nature of creating these environments and tasks impedes the\ngeneration of sufficiently varied and extensive trajectories. To address this\nlimitation, this paper explores the automated synthesis of diverse environments\nand a gradual range of planning tasks, from easy to difficult. We introduce a\nframework, AgentGen, that leverages LLMs first to generate environments and\nsubsequently generate planning tasks conditioned on these environments.\nSpecifically, to improve environmental diversity, we propose using an\ninspiration corpus composed of various domain-specific text segments as the\ncontext for synthesizing environments. Moreover, to increase the difficulty\ndiversity of generated planning tasks, we propose a bidirectional evolution\nmethod, Bi-Evol, that evolves planning tasks from easier and harder directions\nto synthesize a task set with a smoother difficulty curve. The evaluation\nresults derived from AgentBoard show that AgentGen greatly improves LLMs'\nplanning ability, e.g., the AgentGen instruction-tuned Llama-3 8B surpasses\nGPT-3.5 in overall performance. Moreover, in certain tasks, it even outperforms\nGPT-4.", "categories": "cs.CL cs.AI cs.LG", "created": "2024-08-01", "doi": null, "arxiv_id": "2408.00764"}
{"title": "MM-Vet v2: A Challenging Benchmark to Evaluate Large Multimodal Models\n  for Integrated Capabilities", "authors": [], "abstract": "MM-Vet, with open-ended vision-language questions targeting at evaluating\nintegrated capabilities, has become one of the most popular benchmarks for\nlarge multimodal model evaluation. MM-Vet assesses six core vision-language\n(VL) capabilities: recognition, knowledge, spatial awareness, language\ngeneration, OCR, and math. However, its question format is restricted to single\nimage-text pairs, lacking the interleaved image and text sequences prevalent in\nreal-world scenarios. To address this limitation, we introduce MM-Vet v2, which\nincludes a new VL capability called \"image-text sequence understanding\",\nevaluating models' ability to process VL sequences. Furthermore, we maintain\nthe high quality of evaluation samples while further expanding the evaluation\nset size. Using MM-Vet v2 to benchmark large multimodal models, we found that\nClaude 3.5 Sonnet is the best model with a score of 71.8, slightly\noutperforming GPT-4o which scored 71.0. Among open-weight models,\nInternVL2-Llama3-76B leads with a score of 68.4.", "categories": "cs.CV cs.AI cs.CL", "created": "2024-08-01", "doi": null, "arxiv_id": "2408.00765"}
{"title": "Optimizing Diffusion Models for Joint Trajectory Prediction and\n  Controllable Generation", "authors": [], "abstract": "Diffusion models are promising for joint trajectory prediction and\ncontrollable generation in autonomous driving, but they face challenges of\ninefficient inference steps and high computational demands. To tackle these\nchallenges, we introduce Optimal Gaussian Diffusion (OGD) and Estimated Clean\nManifold (ECM) Guidance. OGD optimizes the prior distribution for a small\ndiffusion time $T$ and starts the reverse diffusion process from it. ECM\ndirectly injects guidance gradients to the estimated clean manifold,\neliminating extensive gradient backpropagation throughout the network. Our\nmethodology streamlines the generative process, enabling practical applications\nwith reduced computational overhead. Experimental validation on the large-scale\nArgoverse 2 dataset demonstrates our approach's superior performance, offering\na viable solution for computationally efficient, high-quality joint trajectory\nprediction and controllable generation for autonomous driving. Our project\nwebpage is at https://yixiaowang7.github.io/OptTrajDiff_Page/.", "categories": "cs.CV", "created": "2024-08-01", "doi": null, "arxiv_id": "2408.00766"}
