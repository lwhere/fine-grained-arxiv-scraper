{"id":"2401.00670","title":"hybrid physics-informed metabolic cybergenetics: process rates augmented   with machine-learning surrogates informed by flux balance analysis","categories":"eess.sy cs.sy math.oc","abstract":"metabolic cybergenetics is a promising concept that interfaces gene expression and cellular metabolism with computers for real-time dynamic metabolic control. the focus is on control at the transcriptional level, serving as a means to modulate intracellular metabolic fluxes. recent strategies in this field have employed constraint-based dynamic models for process optimization, control, and estimation. however, this results in bilevel dynamic optimization problems, which pose considerable numerical and conceptual challenges. in this study, we present an alternative hybrid physics-informed dynamic modeling framework for metabolic cybergenetics, aimed at simplifying optimization, control, and estimation tasks. by utilizing machine-learning surrogates, our approach effectively embeds the physics of metabolic networks into the process rates of structurally simpler macro-kinetic models coupled with gene expression. these surrogates, informed by flux balance analysis, link the domains of manipulatable intracellular enzymes to metabolic exchange fluxes. this ensures that critical knowledge captured by the system's metabolic network is preserved. the resulting models can be integrated into metabolic cybergenetic schemes involving single-level optimizations. additionally, the hybrid modeling approach maintains the number of system states at a necessary minimum, easing the burden of process monitoring and estimation. our hybrid physics-informed metabolic cybergenetic framework is demonstrated using a computational case study on the optogenetically-assisted production of itaconate by $\\textit{escherichia coli}$.","doi":"10.1021\/acs.iecr.4c00001","created":1704067200000,"updated":"2024-03-25","authors":["sebastián espinel-ríos","josé l. avalos"]}
{"id":"2401.00676","title":"digger: detecting copyright content mis-usage in large language model   training","categories":"cs.cr cs.cl cs.lg","abstract":"pre-training, which utilizes extensive and varied datasets, is a critical factor in the success of large language models (llms) across numerous applications. however, the detailed makeup of these datasets is often not disclosed, leading to concerns about data security and potential misuse. this is particularly relevant when copyrighted material, still under legal protection, is used inappropriately, either intentionally or unintentionally, infringing on the rights of the authors.   in this paper, we introduce a detailed framework designed to detect and assess the presence of content from potentially copyrighted books within the training datasets of llms. this framework also provides a confidence estimation for the likelihood of each content sample's inclusion. to validate our approach, we conduct a series of simulated experiments, the results of which affirm the framework's effectiveness in identifying and addressing instances of content misuse in llm training processes. furthermore, we investigate the presence of recognizable quotes from famous literary works within these datasets. the outcomes of our study have significant implications for ensuring the ethical use of copyrighted materials in the development of llms, highlighting the need for more transparent and responsible data management practices in this field.","doi":"","created":1704067200000,"updated":"","authors":["haodong li","gelei deng","yi liu","kailong wang","yuekang li","tianwei zhang","yang liu","guoai xu","guosheng xu","haoyu wang"]}
{"id":"2401.00678","title":"general-purpose foundation models for increased autonomy in   robot-assisted surgery","categories":"cs.ro cs.lg q-bio.to","abstract":"the dominant paradigm for end-to-end robot learning focuses on optimizing task-specific objectives that solve a single robotic problem such as picking up an object or reaching a target position. however, recent work on high-capacity models in robotics has shown promise toward being trained on large collections of diverse and task-agnostic datasets of video demonstrations. these models have shown impressive levels of generalization to unseen circumstances, especially as the amount of data and the model complexity scale. surgical robot systems that learn from data have struggled to advance as quickly as other fields of robot learning for a few reasons: (1) there is a lack of existing large-scale open-source data to train models, (2) it is challenging to model the soft-body deformations that these robots work with during surgery because simulation cannot match the physical and visual complexity of biological tissue, and (3) surgical robots risk harming patients when tested in clinical trials and require more extensive safety measures. this perspective article aims to provide a path toward increasing robot autonomy in robot-assisted surgery through the development of a multi-modal, multi-task, vision-language-action model for surgical robots. ultimately, we argue that surgical robots are uniquely positioned to benefit from general-purpose models and provide three guiding actions toward increased autonomy in robot-assisted surgery.","doi":"","created":1704067200000,"updated":"","authors":["samuel schmidgall","ji woong kim","alan kuntz","ahmed ezzat ghazi","axel krieger"]}
{"id":"2401.00681","title":"mitigating procrastination in spatial crowdsourcing via efficient   scheduling algorithm","categories":"cs.ce","abstract":"several works related to spatial crowdsourcing have been proposed in the direction where the task executers are to perform the tasks within the stipulated deadlines. though the deadlines are set, it may be a practical scenario that majority of the task executers submit the tasks as late as possible. this situation where the task executers may delay their task submission is termed as procrastination in behavioural economics. in many applications, these late submission of tasks may be problematic for task providers. so here, the participating agents (both task providers and task executers) are articulated with the procrastination issue. in literature, how to prevent this procrastination within the deadline is not addressed in spatial crowdsourcing scenario. however, in a bipartite graph setting one procrastination aware scheduling is proposed but balanced job (task and job will synonymously be used) distribution in different slots (also termed as schedules) is not considered there. in this paper, a procrastination aware scheduling of jobs is proliferated by proposing an (randomized) algorithm in spatial crowdsourcing scenario. our algorithm ensures that balancing of jobs in different schedules are maintained. our scheme is compared with the existing algorithm through extensive simulation and in terms of balancing effect, our proposed algorithm outperforms the existing one. analytically it is shown that our proposed algorithm maintains the balanced distribution.","doi":"","created":1704067200000,"updated":"2024-02-07","authors":["naren debnath","sajal mukhopadhyay","fatos xhafa"]}
{"id":"2401.00682","title":"the smooth trajectory estimator for lmb filters","categories":"eess.sp cs.sy eess.sy","abstract":"this paper proposes a smooth-trajectory estimator for the labelled multi-bernoulli (lmb) filter by exploiting the special structure of the generalised labelled multi-bernoulli (glmb) filter. we devise a simple and intuitive approach to store the best association map when approximating the glmb random finite set (rfs) to the lmb rfs. in particular, we construct a smooth-trajectory estimator (i.e., an estimator over the entire trajectories of labelled estimates) for the lmb filter based on the history of the best association map and all of the measurements up to the current time. experimental results under two challenging scenarios demonstrate significant tracking accuracy improvements with negligible additional computational time compared to the conventional lmb filter. the source code is publicly available at https:\/\/tinyurl.com\/ste-lmb, aimed at promoting advancements in mot algorithms.","doi":"10.1109\/iccais59597.2023.10382267","created":1704067200000,"updated":"","authors":["hoa van nguyen","tran thien dat nguyen","changbeom shim","marzhar anuar"]}
{"id":"2401.00683","title":"asymptotically optimal sequence sets with low\/zero ambiguity zone   properties","categories":"cs.it math.it","abstract":"sequences with low\/zero ambiguity zone (laz\/zaz) properties are useful for modern wireless communication and radar systems operating in mobile environments. this paper first presents a new family of zaz sequence sets by generalizing an earlier construction of zero correlation zone (zcz) sequences arising from perfect nonlinear functions. we then introduce a second family of zaz sequence sets with comb-like spectrum, whereby the local doppler resilience is ensured by their inherent spectral nulls in the frequency-domain. finally, laz sequence sets are obtained thanks to its connection with a novel class of mapping functions. these proposed unimodular zaz and laz sets are cyclically distinct and asymptotically optimal with respect to the existing theoretical bounds.","doi":"","created":1704067200000,"updated":"2024-01-01","authors":["liying tian","xiaoshi song","zilong liu","yubo li"]}
{"id":"2401.00684","title":"a temporal filter to extract doped conducting polymer information   features from an electronic nose","categories":"cond-mat.mtrl-sci cs.lg","abstract":"identifying relevant machine-learning features for multi-sensing platforms is both an applicative limitation to recognize environments and a necessity to interpret the physical relevance of transducers' complementarity in their information processing. particularly for long acquisitions, feature extraction must be fully automatized without human intervention and resilient to perturbations without increasing significantly the computational cost of a classifier. in this study, we investigate on the relative resistance and current modulation of a 24-dimensional conductimetric electronic nose, which uses the exponential moving average as a floating reference in a low-cost information descriptor for environment recognition. in particular, we identified that depending on the structure of a linear classifier, the 'modema' descriptor is optimized for different material sensing elements' contributions to classify information patterns. the low-pass filtering optimization leads to opposite behaviors between unsupervised and supervised learning: the latter one favors longer integration of the reference, allowing to recognize five different classes over 90%, while the first one prefers using the latest events as its reference to clusterize patterns by environment nature. its electronic implementation shall greatly diminish the computational requirements of conductimetric electronic noses for on-board environment recognition without human supervision.","doi":"","created":1704067200000,"updated":"","authors":["wiem haj ammar","aicha boujnah","antoine baron","aimen boubaker","adel kalboussi","kamal lmimouni","sebastien pecqueur"]}
{"id":"2401.00685","title":"communication-efficient federated learning for leo satellite networks   integrated with haps using hybrid noma-ofdm","categories":"cs.lg cs.ai cs.dc","abstract":"space ai has become increasingly important and sometimes even necessary for government, businesses, and society. an active research topic under this mission is integrating federated learning (fl) with satellite communications (satcom) so that numerous low earth orbit (leo) satellites can collaboratively train a machine learning model. however, the special communication environment of satcom leads to a very slow fl training process up to days and weeks. this paper proposes nomafedhap, a novel fl-satcom approach tailored to leo satellites, that (1) utilizes high-altitude platforms (haps) as distributed parameter servers (ps) to enhance satellite visibility, and (2) introduces non-orthogonal multiple access (noma) into leo to enable fast and bandwidth-efficient model transmissions. in addition, nomafedhap includes (3) a new communication topology that exploits haps to bridge satellites among different orbits to mitigate the doppler shift, and (4) a new fl model aggregation scheme that optimally balances models between different orbits and shells. moreover, we (5) derive a closed-form expression of the outage probability for satellites in near and far shells, as well as for the entire system. our extensive simulations have validated the mathematical analysis and demonstrated the superior performance of nomafedhap in achieving fast and efficient fl model convergence with high accuracy as compared to the state-of-the-art.","doi":"","created":1704067200000,"updated":"2024-02-16","authors":["mohamed elmahallawy","tie luo","khaled ramadan"]}
{"id":"2401.00688","title":"inferring community structure in attributed hypergraphs using stochastic   block models","categories":"cs.si cs.lg","abstract":"hypergraphs are a representation of complex systems involving interactions among more than two entities and allow to investigation of higher-order structure and dynamics in real-world complex systems. community structure is a common property observed in empirical networks in various domains. stochastic block models have been employed to investigate community structure in networks. node attribute data, often accompanying network data, has been found to potentially enhance the learning of community structure in dyadic networks. in this study, we develop a statistical framework that incorporates node attribute data into the learning of community structure in a hypergraph, employing a stochastic block model. we demonstrate that our model, which we refer to as hyperneo, enhances the learning of community structure in synthetic and empirical hypergraphs when node attributes are sufficiently associated with the communities. furthermore, we found that applying a dimensionality reduction method, umap, to the learned representations obtained using stochastic block models, including our model, maps nodes into a two-dimensional vector space while largely preserving community structure in empirical hypergraphs. we expect that our framework will broaden the investigation and understanding of higher-order community structure in real-world complex systems.","doi":"","created":1704067200000,"updated":"","authors":["kazuki nakajima","takeaki uno"]}
{"id":"2401.00689","title":"large language model for bible sentiment analysis: sermon on the mount","categories":"cs.cl cs.ai","abstract":"the revolution of natural language processing via large language models has motivated its use in multidisciplinary areas that include social sciences and humanities and more specifically, comparative religion. sentiment analysis provides a mechanism to study the emotions expressed in text. recently, sentiment analysis has been used to study and compare translations of the bhagavad gita, which is a fundamental and sacred hindu text. in this study, we use sentiment analysis for studying selected chapters of the bible. these chapters are known as the sermon on the mount. we utilize a pre-trained language model for sentiment analysis by reviewing five translations of the sermon on the mount, which include the king james version, the new international version, the new revised standard version, the lamsa version, and the basic english version. we provide a chapter-by-chapter and verse-by-verse comparison using sentiment and semantic analysis and review the major sentiments expressed. our results highlight the varying sentiments across the chapters and verses. we found that the vocabulary of the respective translations is significantly different. we detected different levels of humour, optimism, and empathy in the respective chapters that were used by jesus to deliver his message.","doi":"","created":1704067200000,"updated":"","authors":["mahek vora","tom blau","vansh kachhwal","ashu m. g. solo","rohitash chandra"]}
{"id":"2401.00690","title":"benchmarking large language models on controllable generation under   diversified instructions","categories":"cs.cl","abstract":"while large language models (llms) have exhibited impressive instruction-following capabilities, it is still unclear whether and to what extent they can respond to explicit constraints that might be entailed in various instructions. as a significant aspect of llm alignment, it is thus important to formulate such a specialized set of instructions as well as investigate the resulting behavior of llms. to address this vacancy, we propose a new benchmark codi-eval to systematically and comprehensively evaluate llms' responses to instructions with various constraints. we construct a large collection of constraints-attributed instructions as a test suite focused on both generalization and coverage. specifically, we advocate an instruction diversification process to synthesize diverse forms of constraint expression and also deliberate the candidate task taxonomy with even finer-grained sub-categories. finally, we automate the entire evaluation process to facilitate further developments. different from existing studies on controllable text generation, codi-eval extends the scope to the prevalent instruction-following paradigm for the first time. we provide extensive evaluations of representative llms (e.g., chatgpt, vicuna) on codi-eval, revealing their limitations in following instructions with specific constraints and there is still a significant gap between open-source and commercial closed-source llms. we believe this benchmark will facilitate research into improving the controllability of llms' responses to instructions. our data and code are available at https:\/\/github.com\/xt-cyh\/codi-eval.","doi":"","created":1704067200000,"updated":"","authors":["yihan chen","benfeng xu","quan wang","yi liu","zhendong mao"]}
{"id":"2401.00691","title":"stochastic gradient descent for additive nonparametric regression","categories":"stat.ml cs.lg","abstract":"this paper introduces an iterative algorithm for training additive models that enjoys favorable memory storage and computational requirements. the algorithm can be viewed as the functional counterpart of stochastic gradient descent, applied to the coefficients of a truncated basis expansion of the component functions. we show that the resulting estimator satisfies an oracle inequality that allows for model mis-specification. in the well-specified setting, by choosing the learning rate carefully across three distinct stages of training, we demonstrate that its risk is minimax optimal in terms of the dependence on the dimensionality of the data and the size of the training sample. we further illustrate the computational benefits by comparing the approach with traditional backfitting on two real-world datasets.","doi":"","created":1704067200000,"updated":"2024-02-13","authors":["xin chen","jason m. klusowski"]}
{"id":"2401.00692","title":"self-supervised learning for skin cancer diagnosis with limited training   data","categories":"eess.iv cs.cv cs.lg","abstract":"cancer diagnosis is a well-studied problem in machine learning since early detection of cancer is often the determining factor in prognosis. supervised deep learning achieves excellent results in cancer image classification, usually through transfer learning. however, these models require large amounts of labelled data and for several types of cancer, large labelled datasets do not exist. in this paper, we demonstrate that a model pre-trained using a self-supervised learning algorithm known as barlow twins can outperform the conventional supervised transfer learning pipeline. we juxtapose two base models: i) pretrained in a supervised fashion on imagenet; ii) pretrained in a self-supervised fashion on imagenet. both are subsequently fine tuned on a small labelled skin lesion dataset and evaluated on a large test set. we achieve a mean test accuracy of 70\\% for self-supervised transfer in comparison to 66\\% for supervised transfer. interestingly, boosting performance further is possible by self-supervised pretraining a second time (on unlabelled skin lesion images) before subsequent fine tuning. this hints at an alternative path to collecting more labelled data in settings where this is challenging - namely just collecting more unlabelled images. our framework is applicable to cancer image classification models in the low-labelled data regime.","doi":"","created":1704067200000,"updated":"","authors":["hamish haggerty","rohitash chandra"]}
{"id":"2401.00695","title":"credible teacher for semi-supervised object detection in open scene","categories":"cs.cv","abstract":"semi-supervised object detection (ssod) has achieved resounding success by leveraging unlabeled data to improve detection performance. however, in open scene semi-supervised object detection (o-ssod), unlabeled data may contains unknown objects not observed in the labeled data, which will increase uncertainty in the model's predictions for known objects. it is detrimental to the current methods that mainly rely on self-training, as more uncertainty leads to the lower localization and classification precision of pseudo labels. to this end, we propose credible teacher, an end-to-end framework. credible teacher adopts an interactive teaching mechanism using flexible labels to prevent uncertain pseudo labels from misleading the model and gradually reduces its uncertainty through the guidance of other credible pseudo labels. empirical results have demonstrated our method effectively restrains the adverse effect caused by o-ssod and significantly outperforms existing counterparts.","doi":"","created":1704067200000,"updated":"2024-01-02","authors":["jingyu zhuang","kuo wang","liang lin","guanbin li"]}
{"id":"2401.00698","title":"large language models aren't all that you need","categories":"cs.cl cs.ai cs.lg","abstract":"this paper describes the architecture and systems built towards solving the semeval 2023 task 2: multiconer ii (multilingual complex named entity recognition) [1]. we evaluate two approaches (a) a traditional conditional random fields model and (b) a large language model (llm) fine-tuned with a customized head and compare the two approaches. the novel ideas explored are: 1) decaying auxiliary loss (with residual) - where we train the model on an auxiliary task of coarse-grained ner and include this task as a part of the loss function 2) triplet token blending - where we explore ways of blending the embeddings of neighboring tokens in the final ner layer prior to prediction 3) task-optimal heads - where we explore a variety of custom heads and learning rates for the final layer of the llm. we also explore multiple llms including gpt-3 and experiment with a variety of dropout and other hyperparameter settings before arriving at our final model which achieves micro & macro f1 of 0.85\/0.84 (on dev) and 0.67\/0.61 on the test data . we show that while pre-trained llms, by themselves, bring about a large improvement in scores as compared to traditional models, we also demonstrate that tangible improvements to the macro-f1 score can be made by augmenting the llm with additional feature\/loss\/model engineering techniques described above.","doi":"","created":1704067200000,"updated":"","authors":["kiran voderhobli holla","chaithanya kumar","aryan singh"]}
{"id":"2401.00700","title":"an attempt to generate new bridge types from latent space of generative   adversarial network","categories":"cs.lg cs.ai cs.cv","abstract":"try to generate new bridge types using generative artificial intelligence technology. symmetric structured image dataset of three-span beam bridge, arch bridge, cable-stayed bridge and suspension bridge are used . based on python programming language, tensorflow and keras deep learning platform framework , as well as wasserstein loss function and lipschitz constraints, generative adversarial network is constructed and trained. from the obtained low dimensional bridge-type latent space sampling, new bridge types with asymmetric structures can be generated. generative adversarial network can create new bridge types by organically combining different structural components on the basis of human original bridge types. it has a certain degree of human original ability. generative artificial intelligence technology can open up imagination space and inspire humanity.","doi":"","created":1704067200000,"updated":"","authors":["hongjun zhang"]}
{"id":"2401.00701","title":"towards efficient and effective text-to-video retrieval with   coarse-to-fine visual representation learning","categories":"cs.cv","abstract":"in recent years, text-to-video retrieval methods based on clip have experienced rapid development. the primary direction of evolution is to exploit the much wider gamut of visual and textual cues to achieve alignment. concretely, those methods with impressive performance often design a heavy fusion block for sentence (words)-video (frames) interaction, regardless of the prohibitive computation complexity. nevertheless, these approaches are not optimal in terms of feature utilization and retrieval efficiency. to address this issue, we adopt multi-granularity visual feature learning, ensuring the model's comprehensiveness in capturing visual content features spanning from abstract to detailed levels during the training phase. to better leverage the multi-granularity features, we devise a two-stage retrieval architecture in the retrieval phase. this solution ingeniously balances the coarse and fine granularity of retrieval content. moreover, it also strikes a harmonious equilibrium between retrieval effectiveness and efficiency. specifically, in training phase, we design a parameter-free text-gated interaction block (tib) for fine-grained video representation learning and embed an extra pearson constraint to optimize cross-modal representation learning. in retrieval phase, we use coarse-grained video representations for fast recall of top-k candidates, which are then reranked by fine-grained video representations. extensive experiments on four benchmarks demonstrate the efficiency and effectiveness. notably, our method achieves comparable performance with the current state-of-the-art methods while being nearly 50 times faster.","doi":"","created":1704067200000,"updated":"","authors":["kaibin tian","yanhua cheng","yi liu","xinglin hou","quan chen","han li"]}
{"id":"2401.00708","title":"revisiting nonlocal self-similarity from continuous representation","categories":"cs.cv eess.iv","abstract":"nonlocal self-similarity (nss) is an important prior that has been successfully applied in multi-dimensional data processing tasks, e.g., image and video recovery. however, existing nss-based methods are solely suitable for meshgrid data such as images and videos, but are not suitable for emerging off-meshgrid data, e.g., point cloud and climate data. in this work, we revisit the nss from the continuous representation perspective and propose a novel continuous representation-based nonlocal method (termed as crnl), which has two innovative features as compared with classical nonlocal methods. first, based on the continuous representation, our crnl unifies the measure of self-similarity for on-meshgrid and off-meshgrid data and thus is naturally suitable for both of them. second, the nonlocal continuous groups can be more compactly and efficiently represented by the coupled low-rank function factorization, which simultaneously exploits the similarity within each group and across different groups, while classical nonlocal methods neglect the similarity across groups. this elaborately designed coupled mechanism allows our method to enjoy favorable performance over conventional nss methods in terms of both effectiveness and efficiency. extensive multi-dimensional data processing experiments on-meshgrid (e.g., image inpainting and image denoising) and off-meshgrid (e.g., climate data prediction and point cloud recovery) validate the versatility, effectiveness, and efficiency of our crnl as compared with state-of-the-art methods.","doi":"","created":1704067200000,"updated":"","authors":["yisi luo","xile zhao","deyu meng"]}
{"id":"2401.00710","title":"parallel integer sort: theory and practice","categories":"cs.ds cs.dc","abstract":"integer sorting is a fundamental problem in computer science. this paper studies parallel integer sort both in theory and in practice. in theory, we show tighter bounds for a class of existing practical integer sort algorithms, which provides a solid theoretical foundation for their widespread usage in practice and strong performance. in practice, we design a new integer sorting algorithm, \\textsf{dovetailsort}, that is theoretically-efficient and has good practical performance.   in particular, \\textsf{dovetailsort} overcomes a common challenge in existing parallel integer sorting algorithms, which is the difficulty of detecting and taking advantage of duplicate keys. the key insight in \\textsf{dovetailsort} is to combine algorithmic ideas from both integer- and comparison-sorting algorithms. in our experiments, \\textsf{dovetailsort} achieves competitive or better performance than existing state-of-the-art parallel integer and comparison sorting algorithms on various synthetic and real-world datasets.","doi":"","created":1704067200000,"updated":"","authors":["xiaojun dong","laxman dhulipala","yan gu","yihan sun"]}
{"id":"2401.00711","title":"text2avatar: text to 3d human avatar generation with codebook-driven   body controllable attribute","categories":"cs.cv cs.ai","abstract":"generating 3d human models directly from text helps reduce the cost and time of character modeling. however, achieving multi-attribute controllable and realistic 3d human avatar generation is still challenging due to feature coupling and the scarcity of realistic 3d human avatar datasets. to address these issues, we propose text2avatar, which can generate realistic-style 3d avatars based on the coupled text prompts. text2avatar leverages a discrete codebook as an intermediate feature to establish a connection between text and avatars, enabling the disentanglement of features. furthermore, to alleviate the scarcity of realistic style 3d human avatar data, we utilize a pre-trained unconditional 3d human avatar generation model to obtain a large amount of 3d avatar pseudo data, which allows text2avatar to achieve realistic style generation. experimental results demonstrate that our method can generate realistic 3d avatars from coupled textual data, which is challenging for other existing methods in this field.","doi":"10.1109\/icassp48485.2024.10446237","created":1704067200000,"updated":"","authors":["chaoqun gong","yuqin dai","ronghui li","achun bao","jun li","jian yang","yachao zhang","xiu li"]}
{"id":"2401.00713","title":"a survey on graph neural networks in intelligent transportation systems","categories":"cs.lg","abstract":"intelligent transportation system (its) is vital in improving traffic congestion, reducing traffic accidents, optimizing urban planning, etc. however, due to the complexity of the traffic network, traditional machine learning and statistical methods are relegated to the background. with the advent of the artificial intelligence era, many deep learning frameworks have made remarkable progress in various fields and are now considered effective methods in many areas. as a deep learning method, graph neural networks (gnns) have emerged as a highly competitive method in the its field since 2019 due to their strong ability to model graph-related problems. as a result, more and more scholars pay attention to the applications of gnns in transportation domains, which have shown excellent performance. however, most of the research in this area is still concentrated on traffic forecasting, while other its domains, such as autonomous vehicles and urban planning, still require more attention. this paper aims to review the applications of gnns in six representative and emerging its domains: traffic forecasting, autonomous vehicles, traffic signal control, transportation safety, demand prediction, and parking management. we have reviewed extensive graph-related studies from 2018 to 2023, summarized their methods, features, and contributions, and presented them in informative tables or lists. finally, we have identified the challenges of applying gnns to its and suggested potential future directions.","doi":"","created":1704067200000,"updated":"2024-01-02","authors":["hourun li","yusheng zhao","zhengyang mao","yifang qin","zhiping xiao","jiaqi feng","yiyang gu","wei ju","xiao luo","ming zhang"]}
{"id":"2401.00717","title":"heno-mac: hybrid energy harvesting-based energy neutral operation mac   protocol for delay-sensitive iot applications","categories":"cs.ni","abstract":"the internet of things (iot) technology uses small and cost-effective sensors for various applications, such as industrial iot. however, these sensor nodes are powered by fixed-size batteries, which creates a trade-off between network performance and long-term sustainability. moreover, some applications require the network to provide a certain level of service, such as a lower delay for critical data, while ensuring the operational reliability of sensor nodes. to address this energy challenge, external energy harvesting sources, such as solar and wind, offer promising and eco-friendly solutions. however, the available energy from a single energy source is insufficient to meet these requirements. this drives the utilization of a hybrid energy harvesting approach, such as the integration of solar and wind energy harvesters, to increase the amount of harvested energy. nevertheless, to fully utilize the available energy, which is dynamic in nature, the sensor node must adapt its operation to ensure sustainable operation and enhanced network performance. therefore, this paper proposes a hybrid energy harvesting-based energy neutral operation (eno) medium access control (mac) protocol, called heno-mac, that allows the receiver node to harvest energy from the solar-wind harvesters and adapt its duty cycle accordingly. the performance of the proposed heno-mac was evaluated using the latest realistic solar and wind data for two consecutive days in greencastalia. the simulation results demonstrate that the duty cycle mechanism of heno-mac effectively utilizes the harvested energy to achieve eno and uses the available energy resources efficiently to reduce the packet delay for all packets and the highest priority packet by up to 28.5% and 27.3%, respectively, when compared with other existing mac protocols.","doi":"10.1109\/wcnc57260.2024.10571258","created":1704067200000,"updated":"","authors":["sohail sarang","goran m stojanović","micheal drieberg","varun jeoti","mikko valkama"]}
{"id":"2401.00719","title":"depth map denoising network and lightweight fusion network for enhanced   3d face recognition","categories":"cs.cv cs.ai","abstract":"with the increasing availability of consumer depth sensors, 3d face recognition (fr) has attracted more and more attention. however, the data acquired by these sensors are often coarse and noisy, making them impractical to use directly. in this paper, we introduce an innovative depth map denoising network (dmdnet) based on the denoising implicit image function (diif) to reduce noise and enhance the quality of facial depth images for low-quality 3d fr. after generating clean depth faces using dmdnet, we further design a powerful recognition network called lightweight depth and normal fusion network (ldnfnet), which incorporates a multi-branch fusion block to learn unique and complementary features between different modalities such as depth and normal images. comprehensive experiments conducted on four distinct low-quality databases demonstrate the effectiveness and robustness of our proposed methods. furthermore, when combining dmdnet and ldnfnet, we achieve state-of-the-art results on the lock3dface database.","doi":"","created":1704067200000,"updated":"","authors":["ruizhuo xu","ke wang","chao deng","mei wang","xi chen","wenhui huang","junlan feng","weihong deng"]}
{"id":"2401.00722","title":"brau-net++: u-shaped hybrid cnn-transformer network for medical image   segmentation","categories":"cs.cv","abstract":"accurate medical image segmentation is essential for clinical quantification, disease diagnosis, treatment planning and many other applications. both convolution-based and transformer-based u-shaped architectures have made significant success in various medical image segmentation tasks. the former can efficiently learn local information of images while requiring much more image-specific inductive biases inherent to convolution operation. the latter can effectively capture long-range dependency at different feature scales using self-attention, whereas it typically encounters the challenges of quadratic compute and memory requirements with sequence length increasing. to address this problem, through integrating the merits of these two paradigms in a well-designed u-shaped architecture, we propose a hybrid yet effective cnn-transformer network, named brau-net++, for an accurate medical image segmentation task. specifically, brau-net++ uses bi-level routing attention as the core building block to design our u-shaped encoder-decoder structure, in which both encoder and decoder are hierarchically constructed, so as to learn global semantic information while reducing computational complexity. furthermore, this network restructures skip connection by incorporating channel-spatial attention which adopts convolution operations, aiming to minimize local spatial information loss and amplify global dimension-interaction of multi-scale features. extensive experiments on three public benchmark datasets demonstrate that our proposed approach surpasses other state-of-the-art methods including its baseline: brau-net under almost all evaluation metrics. we achieve the average dice-similarity coefficient (dsc) of 82.47, 90.10, and 92.94 on synapse multi-organ segmentation, isic-2018 challenge, and cvc-clinicdb, as well as the miou of 84.01 and 88.17 on isic-2018 challenge and cvc-clinicdb, respectively.","doi":"","created":1704067200000,"updated":"","authors":["libin lan","pengzhou cai","lu jiang","xiaojuan liu","yongmei li","yudong zhang"]}
{"id":"2401.00728","title":"multifusionnet: multilayer multimodal fusion of deep neural networks for   chest x-ray image classification","categories":"eess.iv cs.cv cs.lg","abstract":"chest x-ray imaging is a critical diagnostic tool for identifying pulmonary diseases. however, manual interpretation of these images is time-consuming and error-prone. automated systems utilizing convolutional neural networks (cnns) have shown promise in improving the accuracy and efficiency of chest x-ray image classification. while previous work has mainly focused on using feature maps from the final convolution layer, there is a need to explore the benefits of leveraging additional layers for improved disease classification. extracting robust features from limited medical image datasets remains a critical challenge. in this paper, we propose a novel deep learning-based multilayer multimodal fusion model that emphasizes extracting features from different layers and fusing them. our disease detection model considers the discriminatory information captured by each layer. furthermore, we propose the fusion of different-sized feature maps (fdsfm) module to effectively merge feature maps from diverse layers. the proposed model achieves a significantly higher accuracy of 97.21% and 99.60% for both three-class and two-class classifications, respectively. the proposed multilayer multimodal fusion model, along with the fdsfm module, holds promise for accurate disease classification and can also be extended to other disease classifications in chest x-ray images.","doi":"","created":1704067200000,"updated":"","authors":["saurabh agarwal","k. v. arya","yogesh kumar meena"]}
{"id":"2401.00729","title":"nightrain: nighttime video deraining via adaptive-rain-removal and   adaptive-correction","categories":"cs.cv","abstract":"existing deep-learning-based methods for nighttime video deraining rely on synthetic data due to the absence of real-world paired data. however, the intricacies of the real world, particularly with the presence of light effects and low-light regions affected by noise, create significant domain gaps, hampering synthetic-trained models in removing rain streaks properly and leading to over-saturation and color shifts. motivated by this, we introduce nightrain, a novel nighttime video deraining method with adaptive-rain-removal and adaptive-correction. our adaptive-rain-removal uses unlabeled rain videos to enable our model to derain real-world rain videos, particularly in regions affected by complex light effects. the idea is to allow our model to obtain rain-free regions based on the confidence scores. once rain-free regions and the corresponding regions from our input are obtained, we can have region-based paired real data. these paired data are used to train our model using a teacher-student framework, allowing the model to iteratively learn from less challenging regions to more challenging regions. our adaptive-correction aims to rectify errors in our model's predictions, such as over-saturation and color shifts. the idea is to learn from clear night input training videos based on the differences or distance between those input videos and their corresponding predictions. our model learns from these differences, compelling our model to correct the errors. from extensive experiments, our method demonstrates state-of-the-art performance. it achieves a psnr of 26.73db, surpassing existing nighttime video deraining methods by a substantial margin of 13.7%.","doi":"","created":1704067200000,"updated":"2024-01-10","authors":["beibei lin","yeying jin","wending yan","wei ye","yuan yuan","shunli zhang","robby tan"]}
{"id":"2401.00730","title":"the pml-method for a scattering problem for a local perturbation of an   open periodic waveguide","categories":"math.na cs.na math.ap","abstract":"the perfectly matched layers method is a well known truncation technique for its efficiency and convenience in numerical implementations of wave scattering problems in unbounded domains. in this paper, we study the convergence of the perfectly matched layers (pml) for wave scattering from a local perturbation of an open waveguide in the half space above the real line, where the refractive index is a function which is periodic along the axis of the waveguide and equals to one above a finite height. the problem is challenging due to the existence of guided waves, and a typical way to deal with the difficulty is to apply the limiting absorption principle. based on the floquet-bloch transform and a curve deformation theory, the solution from the limiting absorption principle is rewritten as the integral of a coupled family of quasi-periodic problems with respect to the quasi-periodicity parameter on a particularly designed curve. by comparing the dirichlet-to-neumann maps on a straight line above the locally perturbed periodic layer, we finally show that the pml method converges exponentially with respect to the pml parameter. finally, the numerical examples are shown to illustrate the theoretical results.","doi":"","created":1704067200000,"updated":"","authors":["andreas kirsch","ruming zhang"]}
{"id":"2401.00733","title":"approximate generalized steiner systems and near-optimal constant weight   codes","categories":"math.co cs.it math.it","abstract":"constant weight codes (cwcs) and constant composition codes (cccs) are two important classes of codes that have been studied extensively in both combinatorics and coding theory for nearly sixty years. in this paper we show that for {\\it all} fixed odd distances, there exist near-optimal cwcs and cccs asymptotically achieving the classic johnson-type upper bounds.   let $a_q(n,w,d)$ denote the maximum size of $q$-ary cwcs of length $n$ with constant weight $w$ and minimum distance $d$. one of our main results shows that for {\\it all} fixed $q,w$ and odd $d$, one has $\\lim_{n\\rightarrow\\infty}\\frac{a_q(n,d,w)}{\\binom{n}{t}}=\\frac{(q-1)^t}{\\binom{w}{t}}$, where $t=\\frac{2w-d+1}{2}$. this implies the existence of near-optimal generalized steiner systems originally introduced by etzion, and can be viewed as a counterpart of a celebrated result of r\\\"odl on the existence of near-optimal steiner systems. note that prior to our work, very little is known about $a_q(n,w,d)$ for $q\\ge 3$. a similar result is proved for the maximum size of cccs.   we provide different proofs for our two main results, based on two strengthenings of the well-known frankl-r\\\"odl-pippenger theorem on the existence of near-optimal matchings in hypergraphs: the first proof follows by kahn's linear programming variation of the above theorem, and the second follows by the recent independent work of delcour-postle, and glock-joos-kim-k\\\"uhn-lichev on the existence of near-optimal matchings avoiding certain forbidden configurations.   we also present several intriguing open questions for future research.","doi":"","created":1704067200000,"updated":"2024-01-20","authors":["miao liu","chong shangguan"]}
{"id":"2401.00735","title":"dynamical processes on metric networks","categories":"math.ds cs.na math-ph math.ap math.mp math.na physics.comp-ph","abstract":"the structure of a network has a major effect on dynamical processes on that network. many studies of the interplay between network structure and dynamics have focused on models of phenomena such as disease spread, opinion formation and changes, coupled oscillators, and random walks. in parallel to these developments, there have been many studies of wave propagation and other spatially extended processes on networks. these latter studies consider metric networks, in which the edges are associated with real intervals. metric networks give a mathematical framework to describe dynamical processes that include both temporal and spatial evolution of some quantity of interest -- such as the concentration of a diffusing substance or the amplitude of a wave -- by using edge-specific intervals that quantify distance information between nodes. dynamical processes on metric networks often take the form of partial differential equations (pdes). in this paper, we present a collection of techniques and paradigmatic linear pdes that are useful to investigate the interplay between structure and dynamics in metric networks. we start by considering a time-independent schr\\\"odinger equation. we then use both finite-difference and spectral approaches to study the poisson, heat, and wave equations as paradigmatic examples of elliptic, parabolic, and hyperbolic pde problems on metric networks. our spectral approach is able to account for degenerate eigenmodes. in our numerical experiments, we consider metric networks with up to about $10^4$ nodes and about $10^4$ edges. a key contribution of our paper is to increase the accessibility of studying pdes on metric networks. software that implements our numerical approaches is available at https:\/\/gitlab.com\/computationalscience\/metric-networks.","doi":"","created":1704067200000,"updated":"","authors":["lucas böttcher","mason a. porter"]}
{"id":"2401.00736","title":"diffusion models, image super-resolution and everything: a survey","categories":"cs.cv cs.ai cs.lg cs.mm","abstract":"diffusion models (dms) have disrupted the image super-resolution (sr) field and further closed the gap between image quality and human perceptual preferences. they are easy to train and can produce very high-quality samples that exceed the realism of those produced by previous generative methods. despite their promising results, they also come with new challenges that need further research: high computational demands, comparability, lack of explainability, color shifts, and more. unfortunately, entry into this field is overwhelming because of the abundance of publications. to address this, we provide a unified recount of the theoretical foundations underlying dms applied to image sr and offer a detailed analysis that underscores the unique characteristics and methodologies within this domain, distinct from broader existing reviews in the field. this survey articulates a cohesive understanding of dm principles and explores current research avenues, including alternative input domains, conditioning techniques, guidance mechanisms, corruption spaces, and zero-shot learning approaches. by offering a detailed examination of the evolution and current trends in image sr through the lens of dms, this survey sheds light on the existing challenges and charts potential future directions, aiming to inspire further innovation in this rapidly advancing area.","doi":"","created":1704067200000,"updated":"2024-06-23","authors":["brian b. moser","arundhati s. shanbhag","federico raue","stanislav frolov","sebastian palacio","andreas dengel"]}
{"id":"2401.00737","title":"searching, fast and slow, through product catalogs","categories":"cs.ir cs.ai cs.lg cs.se","abstract":"string matching algorithms in the presence of abbreviations, such as in stock keeping unit (sku) product catalogs, remains a relatively unexplored topic. in this paper, we present a unified architecture for sku search that provides both a real-time suggestion system (based on a trie data structure) as well as a lower latency search system (making use of character level tf-idf in combination with language model vector embeddings) where users initiate the search process explicitly. we carry out ablation studies that justify designing a complex search system composed of multiple components to address the delicate trade-off between speed and accuracy. using sku search in the dynamics crm as an example, we show how our system vastly outperforms, in all aspects, the results provided by the default search engine. finally, we show how sku descriptions may be enhanced via generative text models (using gpt-3.5-turbo) so that the consumers of the search results may get more context and a generally better experience when presented with the results of their sku search.","doi":"","created":1704067200000,"updated":"","authors":["dayananda ubrangala","juhi sharma","sharath kumar rangappa","kiran r","ravi prasad kondapalli","laurent boué"]}
{"id":"2401.00739","title":"diffmorph: text-less image morphing with diffusion models","categories":"cs.cv cs.ai","abstract":"text-conditioned image generation models are a prevalent use of ai image synthesis, yet intuitively controlling output guided by an artist remains challenging. current methods require multiple images and textual prompts for each object to specify them as concepts to generate a single customized image.   on the other hand, our work, \\verb|diffmorph|, introduces a novel approach that synthesizes images that mix concepts without the use of textual prompts. our work integrates a sketch-to-image module to incorporate user sketches as input. \\verb|diffmorph| takes an initial image with conditioning artist-drawn sketches to generate a morphed image.   we employ a pre-trained text-to-image diffusion model and fine-tune it to reconstruct each image faithfully. we seamlessly merge images and concepts from sketches into a cohesive composition. the image generation capability of our work is demonstrated through our results and a comparison of these with prompt-based image generation.","doi":"","created":1704067200000,"updated":"","authors":["shounak chatterjee"]}
{"id":"2401.00740","title":"beyond subspace isolation: many-to-many transformer for light field   image super-resolution","categories":"eess.iv cs.cv","abstract":"the effective extraction of spatial-angular features plays a crucial role in light field image super-resolution (lfsr) tasks, and the introduction of convolution and transformers leads to significant improvement in this area. nevertheless, due to the large 4d data volume of light field images, many existing methods opted to decompose the data into a number of lower-dimensional subspaces and perform transformers in each sub-space individually. as a side effect, these methods inadvertently restrict the self-attention mechanisms to a one-to-one scheme accessing only a limited subset of lf data, explicitly preventing comprehensive optimization on all spatial and angular cues. in this paper, we identify this limitation as subspace isolation and introduce a novel many-to-many transformer (m2mt) to address it. m2mt aggregates angular information in the spatial subspace before performing the self-attention mechanism. it enables complete access to all information across all sub-aperture images (sais) in a light field image. consequently, m2mt is enabled to comprehensively capture long-range correlation dependencies. with m2mt as the pivotal component, we develop a simple yet effective m2mt network for lfsr. our experimental results demonstrate that m2mt achieves state-of-the-art performance across various public datasets. we further conduct in-depth analysis using local attribution maps (lam) to obtain visual interpretability, and the results validate that m2mt is empowered with a truly non-local context in both spatial and angular subspaces to mitigate subspace isolation and acquire effective spatial-angular representation.","doi":"","created":1704067200000,"updated":"","authors":["zeke zexi hu","xiaoming chen","vera yuk ying chung","yiran shen"]}
{"id":"2401.00741","title":"tooleyes: fine-grained evaluation for tool learning capabilities of   large language models in real-world scenarios","categories":"cs.cl cs.ai","abstract":"existing evaluations of tool learning primarily focus on validating the alignment of selected tools for large language models (llms) with expected outcomes. however, these approaches rely on a limited set of scenarios where answers can be pre-determined, diverging from genuine needs. furthermore, a sole emphasis on outcomes disregards the intricate capabilities essential for llms to effectively utilize tools. to tackle this issue, we propose tooleyes, a fine-grained system tailored for the evaluation of the llms' tool learning capabilities in authentic scenarios. the system meticulously examines seven real-world scenarios, analyzing five dimensions crucial to llms in tool learning: format alignment, intent comprehension, behavior planning, tool selection, and answer organization. additionally, tooleyes incorporates a tool library boasting approximately 600 tools, serving as an intermediary between llms and the physical world. evaluations involving ten llms across three categories reveal a preference for specific scenarios and limited cognitive abilities in tool learning. intriguingly, expanding the model size even exacerbates the hindrance to tool learning. these findings offer instructive insights aimed at advancing the field of tool learning. the data is available att https:\/\/github.com\/junjie-ye\/tooleyes.","doi":"","created":1704067200000,"updated":"2024-01-14","authors":["junjie ye","guanyu li","songyang gao","caishuang huang","yilong wu","sixian li","xiaoran fan","shihan dou","qi zhang","tao gui","xuanjing huang"]}
{"id":"2401.00744","title":"towards harmonization of so(3)-equivariance and expressiveness: a hybrid   deep learning framework for electronic-structure hamiltonian prediction","categories":"physics.comp-ph cond-mat.mtrl-sci cs.lg","abstract":"deep learning for predicting the electronic-structure hamiltonian of quantum systems necessitates satisfying the covariance laws, among which achieving so(3)-equivariance without sacrificing the non-linear expressive capability of networks remains unsolved. to navigate the harmonization between equivariance and expressiveness, we propose a deep learning method synergizing two distinct categories of neural mechanisms as a two-stage encoding and regression framework. the first stage corresponds to group theory-based neural mechanisms with inherent so(3)-equivariant properties prior to the parameter learning process, while the second stage is characterized by a non-linear 3d graph transformer network we propose, featuring high capability on non-linear expressiveness. the novel combination lies in the point that, the first stage predicts baseline hamiltonians with abundant so(3)-equivariant features extracted, assisting the second stage in empirical learning of equivariance; and in turn, the second stage refines the first stage's output as a fine-grained prediction of hamiltonians using powerful non-linear neural mappings, compensating for the intrinsic weakness on non-linear expressiveness capability of mechanisms in the first stage. our method enables precise, generalizable predictions while capturing so(3)-equivariance under rotational transformations, and achieves state-of-the-art performance in hamiltonian prediction on six benchmark databases.","doi":"","created":1704067200000,"updated":"2024-06-21","authors":["shi yin","xinyang pan","xudong zhu","tianyu gao","haochong zhang","feng wu","lixin he"]}
{"id":"2401.00746","title":"learn to integrate parts for whole through correlated neural variability","categories":"q-bio.nc cs.ne physics.bio-ph","abstract":"sensory perception originates from the responses of sensory neurons, which react to a collection of sensory signals linked to various physical attributes of a singular perceptual object. unraveling how the brain extracts perceptual information from these neuronal responses is a pivotal challenge in both computational neuroscience and machine learning. here we introduce a statistical mechanical theory, where perceptual information is first encoded in the correlated variability of sensory neurons and then reformatted into the firing rates of downstream neurons. applying this theory, we illustrate the encoding of motion direction using neural covariance and demonstrate high-fidelity direction recovery by spiking neural networks. networks trained under this theory also show enhanced performance in classifying natural images, achieving higher accuracy and faster inference speed. our results challenge the traditional view of neural covariance as a secondary factor in neural coding, highlighting its potential influence on brain function.","doi":"","created":1704067200000,"updated":"","authors":["zhichao zhu","yang qi","wenlian lu","jianfeng feng"]}
{"id":"2401.00747","title":"polynomial-time approximation scheme for equilibriums of games","categories":"cs.gt cs.ma","abstract":"whether a ptas (polynomial-time approximation scheme) exists for equilibriums of games has been an open question, which relates to questions in three fields, the practicality of methods in algorithmic game theory, the equation ppad=fp about the two complexity classes in computational complexity theory, and non-stationarity and curse of multiagency in marl (multi-agent reinforcement learning). this paper introduces our discovery of the sufficient and necessary conditions for iterations based on dynamic programming and line search to approximate perfect equilibriums of dynamic games, out of which we construct a method proved to be a fptas (fully ptas) for non-singular perfect equilibriums of dynamic games, where for almost any given dynamic game, all its perfect equilibriums are non-singular, indicating that fp$\\subseteq$ppad$\\subseteq$almost-fp. our discovery consists of cone interior dynamic programming and primal-dual unbiased regret minimization, which fit into existing theories by degeneration in a structure-preserving manner. the former enables a dynamic programming operator to iteratively converge to a perfect equilibrium based on a concept called policy cone. the latter enables an interior-point line search to approximate a nash equilibrium based on two concepts called primal-dual bias and unbiased central variety, solving a subproblem of the former. validity of our discovery is cross-corroborated by a combination of theorem proofs, graphs of the three main concepts, and experimental results.","doi":"","created":1704067200000,"updated":"2024-06-03","authors":["hongbo sun","chongkun xia","junbo tan","bo yuan","xueqian wang","bin liang"]}
{"id":"2401.00751","title":"machine translation testing via syntactic tree pruning","categories":"cs.cl cs.se","abstract":"machine translation systems have been widely adopted in our daily life, making life easier and more convenient. unfortunately, erroneous translations may result in severe consequences, such as financial losses. this requires to improve the accuracy and the reliability of machine translation systems. however, it is challenging to test machine translation systems because of the complexity and intractability of the underlying neural models. to tackle these challenges, we propose a novel metamorphic testing approach by syntactic tree pruning (stp) to validate machine translation systems. our key insight is that a pruned sentence should have similar crucial semantics compared with the original sentence. specifically, stp (1) proposes a core semantics-preserving pruning strategy by basic sentence structure and dependency relations on the level of syntactic tree representation; (2) generates source sentence pairs based on the metamorphic relation; (3) reports suspicious issues whose translations break the consistency property by a bag-of-words model. we further evaluate stp on two state-of-the-art machine translation systems (i.e., google translate and bing microsoft translator) with 1,200 source sentences as inputs. the results show that stp can accurately find 5,073 unique erroneous translations in google translate and 5,100 unique erroneous translations in bing microsoft translator (400% more than state-of-the-art techniques), with 64.5% and 65.4% precision, respectively. the reported erroneous translations vary in types and more than 90% of them cannot be found by state-of-the-art techniques. there are 9,393 erroneous translations unique to stp, which is 711.9% more than state-of-the-art techniques. moreover, stp is quite effective to detect translation errors for the original sentences with a recall reaching 74.0%, improving state-of-the-art techniques by 55.1% on average.","doi":"","created":1704067200000,"updated":"","authors":["quanjun zhang","juan zhai","chunrong fang","jiawei liu","weisong sun","haichuan hu","qingyu wang"]}
{"id":"2401.00752","title":"a note on laguerre truncated polynomials and quadrature formula","categories":"math.na cs.na","abstract":"in this contribution we deal with gaussian quadrature rules based on orthogonal polynomials associated with a weight function $w(x)= x^{\\alpha} e^{-x}$ supported on an interval $(0,z)$, $z>0.$ the modified chebyshev algorithm is used in order to test the accuracy in the computation of the coefficients of the three-term recurrence relation, the zeros and weights, as well as the dependence on the parameter $z.$","doi":"","created":1704067200000,"updated":"2024-01-03","authors":["juan c. garcía-ardila","francisco marcellán"]}
{"id":"2401.00755","title":"saliency-aware regularized graph neural network","categories":"cs.lg","abstract":"the crux of graph classification lies in the effective representation learning for the entire graph. typical graph neural networks focus on modeling the local dependencies when aggregating features of neighboring nodes, and obtain the representation for the entire graph by aggregating node features. such methods have two potential limitations: 1) the global node saliency w.r.t. graph classification is not explicitly modeled, which is crucial since different nodes may have different semantic relevance to graph classification; 2) the graph representation directly aggregated from node features may have limited effectiveness to reflect graph-level information. in this work, we propose the saliency-aware regularized graph neural network (sar-gnn) for graph classification, which consists of two core modules: 1) a traditional graph neural network serving as the backbone for learning node features and 2) the graph neural memory designed to distill a compact graph representation from node features of the backbone. we first estimate the global node saliency by measuring the semantic similarity between the compact graph representation and node features. then the learned saliency distribution is leveraged to regularize the neighborhood aggregation of the backbone, which facilitates the message passing of features for salient nodes and suppresses the less relevant nodes. thus, our model can learn more effective graph representation. we demonstrate the merits of sar-gnn by extensive experiments on seven datasets across various types of graph data. code will be released.","doi":"","created":1704067200000,"updated":"","authors":["wenjie pei","weina xu","zongze wu","weichao li","jinfan wang","guangming lu","xiangrong wang"]}
{"id":"2401.00756","title":"mpre: multi-perspective patient representation extractor for disease   prediction","categories":"cs.lg cs.ai","abstract":"patient representation learning based on electronic health records (ehr) is a critical task for disease prediction. this task aims to effectively extract useful information on dynamic features. although various existing works have achieved remarkable progress, the model performance can be further improved by fully extracting the trends, variations, and the correlation between the trends and variations in dynamic features. in addition, sparse visit records limit the performance of deep learning models. to address these issues, we propose the multi-perspective patient representation extractor (mpre) for disease prediction. specifically, we propose frequency transformation module (ftm) to extract the trend and variation information of dynamic features in the time-frequency domain, which can enhance the feature representation. in the 2d multi-extraction network (2d men), we form the 2d temporal tensor based on trend and variation. then, the correlations between trend and variation are captured by the proposed dilated operation. moreover, we propose the first-order difference attention mechanism (fodam) to calculate the contributions of differences in adjacent variations to the disease diagnosis adaptively. to evaluate the performance of mpre and baseline methods, we conduct extensive experiments on two real-world public datasets. the experiment results show that mpre outperforms state-of-the-art baseline methods in terms of auroc and auprc.","doi":"","created":1704067200000,"updated":"","authors":["ziyue yu","jiayi wang","wuman luo","rita tse","giovanni pau"]}
{"id":"2401.00757","title":"a & b == b & a: triggering logical reasoning failures in large language   models","categories":"cs.se cs.ai cs.cl cs.lo","abstract":"recent advancements in large language models (llms) have propelled artificial intelligence (ai) to new heights, enabling breakthroughs in various tasks such as writing assistance, code generation, and machine translation. a significant distinction of advanced llms, such as chatgpt, is their demonstrated ability to \"reason.\" however, evaluating the reasoning ability of llms remains a challenge as most existing evaluations focus on their accuracy on the downstream tasks rather than directly assessing their reasoning processes. efforts have been made to develop benchmarks and metrics to assess reasoning in llms, but they suffer from data leakage or limited scope. in this paper, we introduce logicasker, an automatic approach that comprehensively evaluates and improves the logical reasoning abilities of llms under a set of atomic reasoning skills based on propositional and predicate logic. the results provide insights into llms' reasoning abilities and reveal the logical rules the llms did not learn well. we evaluate logicasker on six widely deployed llms, including gpt-3, chatgpt, gpt-4, bard, vicuna, and guanaco. the results show that test cases from logicasker can find logical reasoning failures in different llms with a rate of 25\\% - 94\\%. in addition, the test cases of logicasker can be further used to design demonstration examples for in-context learning, which effectively improves the logical reasoning ability of llms, e.g., 10\\% for gpt-4. as far as we know, our work is the first to create prompts based on testing results to improve llms' formal reasoning ability effectively. all the code, data, and results will be released for reproduction and future research.","doi":"","created":1704067200000,"updated":"","authors":["yuxuan wan","wenxuan wang","yiliu yang","youliang yuan","jen-tse huang","pinjia he","wenxiang jiao","michael r. lyu"]}
{"id":"2401.00761","title":"the earth is flat? unveiling factual errors in large language models","categories":"cs.se cs.ai cs.cl","abstract":"large language models (llms) like chatgpt are foundational in various applications due to their extensive knowledge from pre-training and fine-tuning. despite this, they are prone to generating factual and commonsense errors, raising concerns in critical areas like healthcare, journalism, and education to mislead users. current methods for evaluating llms' veracity are limited by test data leakage or the need for extensive human labor, hindering efficient and accurate error detection. to tackle this problem, we introduce a novel, automatic testing framework, factchecker, aimed at uncovering factual inaccuracies in llms. this framework involves three main steps: first, it constructs a factual knowledge graph by retrieving fact triplets from a large-scale knowledge database. then, leveraging the knowledge graph, factchecker employs a rule-based approach to generates three types of questions (yes-no, multiple-choice, and wh questions) that involve single-hop and multi-hop relations, along with correct answers. lastly, it assesses the llms' responses for accuracy using tailored matching strategies for each question type. our extensive tests on six prominent llms, including text-davinci-002, text-davinci-003, chatgpt~(gpt-3.5-turbo, gpt-4), vicuna, and llama-2, reveal that factchecker can trigger factual errors in up to 45\\% of questions in these models. moreover, we demonstrate that factchecker's test cases can improve llms' factual accuracy through in-context learning and fine-tuning (e.g., llama-2-13b-chat's accuracy increase from 35.3\\% to 68.5\\%). we are making all code, data, and results available for future research endeavors.","doi":"","created":1704067200000,"updated":"","authors":["wenxuan wang","juluan shi","zhaopeng tu","youliang yuan","jen-tse huang","wenxiang jiao","michael r. lyu"]}
{"id":"2401.00762","title":"algorithm for globally identifiable reparametrizations of odes","categories":"eess.sy cs.sc cs.sy math.ap","abstract":"structural global parameter identifiability indicates whether one can determine a parameter's value in an ode model from given inputs and outputs. if a given model has parameters for which there is exactly one value, such parameters are called globally identifiable. given an ode model involving not globally identifiable parameters, first we transform the system into one with locally identifiable parameters. as a main contribution of this paper, then we present a procedure for replacing, if possible, the ode model with an equivalent one that has globally identifiable parameters. we first derive this as an algorithm for one-dimensional ode models and then reuse this approach for higher-dimensional models.","doi":"","created":1704067200000,"updated":"2024-07-16","authors":["sebastian falkensteiner","alexey ovchinnikov","j. rafael sendra"]}
{"id":"2401.00765","title":"hexe -- securing audio contents in voice chat using puzzle and timestamp","categories":"cs.cr","abstract":"cryptography is the study of securing information. it is the physical process that scrambles the information by rearrangement and substitution of content, so that it becomes difficult for anyone to understand. in today's world, security has become an inevitable part of our day-to-day life, right from normal browsing to performing critical payment transactions. hackers work endlessly to break the security present in the apps\/websites on which we perform day-to-day operations and salvage valuable information. because of this, many illegal activities have taken place which affect the user. one such illegal activity is tapping the voice communication between two users. if left unencrypted, the communication between the users is compromised, thereby causing issues. one way to prevent this act is to encrypt the audio in that the contents cannot have tampered with unless the receiver has the valid key to decrypt it. the proposed solution termed \"hexe\" aims to create a puzzle-based algorithm which would encrypt and decrypt the audio files without manipulating the file header, thus securing the contents. the algorithm works on an nxn sudoku-based puzzle which is accepted both by the sender and receiver. using the timestamp of the event (unix based), a grid from the puzzle is chosen which in turn will act as the key for both encryption and decryption. if the timestamp is slightly adjusted, the process will end up in failure during decryption, thus ensuring confidentiality. another approach to secure the audio files is to implement ipfs (inter planetary file system) alongside the puzzle algorithm in which the encrypted audio is stored on it and the receiver can fetch the audio provided if the valid ipfs hash of the file is present. in this way, the audio file is secured.","doi":"","created":1704067200000,"updated":"","authors":["aadhitya a"]}
{"id":"2401.00766","title":"exposure bracketing is all you need for unifying image restoration and   enhancement tasks","categories":"cs.cv eess.iv","abstract":"it is highly desired but challenging to acquire high-quality photos with clear content in low-light environments. although multi-image processing methods (using burst, dual-exposure, or multi-exposure images) have made significant progress in addressing this issue, they typically focus on specific restoration or enhancement problems, and do not fully explore the potential of utilizing multiple images. motivated by the fact that multi-exposure images are complementary in denoising, deblurring, high dynamic range imaging, and super-resolution, we propose to utilize exposure bracketing photography to unify image restoration and enhancement tasks in this work. due to the difficulty in collecting real-world pairs, we suggest a solution that first pre-trains the model with synthetic paired data and then adapts it to real-world unlabeled images. in particular, a temporally modulated recurrent network (tmrnet) and self-supervised adaptation method are proposed. moreover, we construct a data simulation pipeline to synthesize pairs and collect real-world images from 200 nighttime scenarios. experiments on both datasets show that our method performs favorably against the state-of-the-art multi-image processing ones. the dataset, code, and pre-trained models are available at https:\/\/github.com\/cszhilu1998\/bracketire.","doi":"","created":1704067200000,"updated":"2024-05-31","authors":["zhilu zhang","shuohao zhang","renlong wu","zifei yan","wangmeng zuo"]}
{"id":"2401.00772","title":"algorithms for improving the automatically synthesized instruction set   of an extensible processor","categories":"cs.ar cs.cr","abstract":"processors with extensible instruction sets are often used today as programmable hardware accelerators for various domains. when extending risc-v and other similar extensible processor architectures, the task of designing specialized instructions arises. this task can be solved automatically by using instruction synthesis algorithms. in this paper, we consider algorithms that can be used in addition to the known approaches and improve the synthesized instruction sets by recomputing common operations (the result of which is consumed by multiple operations) of a program inside clustered synthesized instructions (common operations clustering algorithm), and by identifying redundant (which have equivalents among the other instructions) synthesized instructions (subsuming functions algorithm).   experimental evaluations of the developed algorithms are presented for the tests from the domains of cryptography and three-dimensional graphics. for magma cipher test, the common operations clustering algorithm allows reducing the size of the compiled code by 9%, and the subsuming functions algorithm allows reducing the synthesized instruction set extension size by 2 times. for aes cipher test, the common operations clustering algorithm allows reducing the size of the compiled code by 10%, and the subsuming functions algorithm allows reducing the synthesized instruction set extension size by 2.5 times. finally, for the instruction set extension from volume ray-casting test, the additional use of subsuming functions algorithm allows reducing problem-specific instruction extension set size from 5 to only 2 instructions without losing its functionality.","doi":"10.17587\/prin.14.225-231","created":1704067200000,"updated":"","authors":["peter sovietov"]}
{"id":"2401.00773","title":"unsupervised outlier detection using random subspace and subsampling   ensembles of dirichlet process mixtures","categories":"cs.lg cs.ai stat.ml","abstract":"probabilistic mixture models are recognized as effective tools for unsupervised outlier detection owing to their interpretability and global characteristics. among these, dirichlet process mixture models stand out as a strong alternative to conventional finite mixture models for both clustering and outlier detection tasks. unlike finite mixture models, dirichlet process mixtures are infinite mixture models that automatically determine the number of mixture components based on the data. despite their advantages, the adoption of dirichlet process mixture models for unsupervised outlier detection has been limited by challenges related to computational inefficiency and sensitivity to outliers in the construction of outlier detectors. additionally, dirichlet process gaussian mixtures struggle to effectively model non-gaussian data with discrete or binary features. to address these challenges, we propose a novel outlier detection method that utilizes ensembles of dirichlet process gaussian mixtures. this unsupervised algorithm employs random subspace and subsampling ensembles to ensure efficient computation and improve the robustness of the outlier detector. the ensemble approach further improves the suitability of the proposed method for detecting outliers in non-gaussian data. furthermore, our method uses variational inference for dirichlet process mixtures, which ensures both efficient and rapid computation. empirical analyses using benchmark datasets demonstrate that our method outperforms existing approaches in unsupervised outlier detection.","doi":"","created":1704067200000,"updated":"2024-07-25","authors":["dongwook kim","juyeon park","hee cheol chung","seonghyun jeong"]}
{"id":"2401.00775","title":"recent advances in text analysis","categories":"stat.ap cs.ir","abstract":"text analysis is an interesting research area in data science and has various applications, such as in artificial intelligence, biomedical research, and engineering. we review popular methods for text analysis, ranging from topic modeling to the recent neural language models. in particular, we review topic-score, a statistical approach to topic modeling, and discuss how to use it to analyze madstat - a dataset on statistical publications that we collected and cleaned.   the application of topic-score and other methods on madstat leads to interesting findings. for example, $11$ representative topics in statistics are identified. for each journal, the evolution of topic weights over time can be visualized, and these results are used to analyze the trends in statistical research. in particular, we propose a new statistical model for ranking the citation impacts of $11$ topics, and we also build a cross-topic citation graph to illustrate how research results on different topics spread to one another.   the results on madstat provide a data-driven picture of the statistical research in $1975$--$2015$, from a text analysis perspective.","doi":"10.1146\/annurev-statistics-040522-022138","created":1704067200000,"updated":"2024-02-07","authors":["zheng tracy ke","pengsheng ji","jiashun jin","wanshan li"]}
{"id":"2401.00776","title":"edge computing based human-robot cognitive fusion: a medical case study   in the autism spectrum disorder therapy","categories":"cs.ro cs.ai cs.dc cs.lg cs.ma","abstract":"in recent years, edge computing has served as a paradigm that enables many future technologies like ai, robotics, iot, and high-speed wireless sensor networks (like 5g) by connecting cloud computing facilities and services to the end users. especially in medical and healthcare applications, it provides remote patient monitoring and increases voluminous multimedia. from the robotics angle, robot-assisted therapy (rat) is an active-assistive robotic technology in rehabilitation robotics, attracting many researchers to study and benefit people with disability like autism spectrum disorder (asd) children. however, the main challenge of rat is that the model capable of detecting the affective states of asd people exists and can recall individual preferences. moreover, involving expert diagnosis and recommendations to guide robots in updating the therapy approach to adapt to different statuses and scenarios is a crucial part of the asd therapy process. this paper proposes the architecture of edge cognitive computing by combining human experts and assisted robots collaborating in the same framework to help asd patients with long-term support. by integrating the real-time computing and analysis of a new cognitive robotic model for asd therapy, the proposed architecture can achieve a seamless remote diagnosis, round-the-clock symptom monitoring, emergency warning, therapy alteration, and advanced assistance.","doi":"","created":1704067200000,"updated":"","authors":["qin yang"]}
{"id":"2401.00778","title":"convergence analysis of lawson's iteration for the polynomial and   rational minimax approximations","categories":"math.na cs.na","abstract":"lawson's iteration is a classical and effective method for solving the linear (polynomial) minimax approximation in the complex plane. extension of lawson's iteration for the rational minimax approximation with both computationally high efficiency and theoretical guarantee is challenging. a recent work [l.-h. zhang, l. yang, w. h. yang and y.-n. zhang, a convex dual programming for the rational minimax approximation and lawson's iteration, 2023, arxiv:2308.06991v1] reveals that lawson's iteration can be viewed as a method for solving the dual problem of the original rational minimax approximation, and a new type of lawson's iteration was proposed. such a dual problem is guaranteed to obtain the original minimax solution under ruttan's sufficient condition, and numerically, the proposed lawson's iteration was observed to converge monotonically with respect to the dual objective function. in this paper, we perform theoretical convergence analysis for lawson's iteration for both the linear and rational minimax approximations. in particular, we show that (i) for the linear minimax approximation, the near-optimal lawson exponent $\\beta$ in lawson's iteration is $\\beta=1$, and (ii) for the rational minimax approximation, the proposed lawson's iteration converges monotonically with respect to the dual objective function for any sufficiently small $\\beta>0$, and the limit approximant fulfills the complementary slackness: any node associated with positive weight either is an interpolation point or has a constant error.","doi":"","created":1704067200000,"updated":"2024-04-14","authors":["lei-hong zhang","shanheng han"]}
{"id":"2401.00779","title":"temporal validity change prediction","categories":"cs.cl cs.ai","abstract":"temporal validity is an important property of text that is useful for many downstream applications, such as recommender systems, conversational ai, or story understanding. existing benchmarking tasks often require models to identify the temporal validity duration of a single statement. however, in many cases, additional contextual information, such as sentences in a story or posts on a social media profile, can be collected from the available text stream. this contextual information may greatly alter the duration for which a statement is expected to be valid. we propose temporal validity change prediction, a natural language processing task benchmarking the capability of machine learning models to detect contextual statements that induce such change. we create a dataset consisting of temporal target statements sourced from twitter and crowdsource sample context statements. we then benchmark a set of transformer-based language models on our dataset. finally, we experiment with temporal validity duration prediction as an auxiliary task to improve the performance of the state-of-the-art model.","doi":"","created":1704067200000,"updated":"","authors":["georg wenzel","adam jatowt"]}
{"id":"2401.00781","title":"inferring heterogeneous treatment effects of crashes on highway traffic:   a doubly robust causal machine learning approach","categories":"cs.lg stat.ml","abstract":"highway traffic crashes exert a considerable impact on both transportation systems and the economy. in this context, accurate and dependable emergency responses are crucial for effective traffic management. however, the influence of crashes on traffic status varies across diverse factors and may be biased due to selection bias. therefore, there arises a necessity to accurately estimate the heterogeneous causal effects of crashes, thereby providing essential insights to facilitate individual-level emergency decision-making. this paper proposes a novel causal machine learning framework to estimate the causal effect of different types of crashes on highway speed. the neyman-rubin causal model (rcm) is employed to formulate this problem from a causal perspective. the conditional shapley value index (csvi) is proposed based on causal graph theory to filter adverse variables, and the structural causal model (scm) is then adopted to define the statistical estimand for causal effects. the treatment effects are estimated by doubly robust learning (drl) methods, which combine doubly robust causal inference with classification and regression machine learning models. experimental results from 4815 crashes on highway interstate 5 in washington state reveal the heterogeneous treatment effects of crashes at varying distances and durations. the rear-end crashes cause more severe congestion and longer durations than other types of crashes, and the sideswipe crashes have the longest delayed impact. additionally, the findings show that rear-end crashes affect traffic greater at night, while crash to objects has the most significant influence during peak hours. statistical hypothesis tests, error metrics based on matched \"counterfactual outcomes\", and sensitive analyses are employed for assessment, and the results validate the accuracy and effectiveness of our method.","doi":"","created":1704067200000,"updated":"","authors":["shuang li","ziyuan pu","zhiyong cui","seunghyeon lee","xiucheng guo","dong ngoduy"]}
{"id":"2401.00787","title":"quantum multiple gray scale images encryption scheme in the bit plane   representation model","categories":"quant-ph cs.cr math.qa","abstract":"after introducing a bit-plane quantum representation for a multi-image, we present a novel way to encrypt\/decrypt multiple images using a quantum computer. our encryption scheme is based on a two-stage scrambling of the images and of the bit planes on one hand and of the pixel positions on the other hand, each time using quantum baker maps. the resulting quantum multi-image is then diffused with controlled cnot gates using a sine chaotification of a two-dimensional h\\'enon map as well as chebyshev polynomials. the decryption is processed by operating all the inverse quantum gates in the reverse order.","doi":"","created":1704067200000,"updated":"","authors":["claire i. levaillant"]}
{"id":"2401.00788","title":"astraios: parameter-efficient instruction tuning code large language   models","categories":"cs.cl cs.ai cs.se","abstract":"the high cost of full-parameter fine-tuning (fft) of large language models (llms) has led to a series of parameter-efficient fine-tuning (peft) methods. however, it remains unclear which methods provide the best cost-performance trade-off at different model scales. we introduce astraios, a suite of 28 instruction-tuned octocoder models using 7 tuning methods and 4 model sizes up to 16 billion parameters. through investigations across 5 tasks and 8 different datasets encompassing both code comprehension and code generation tasks, we find that fft generally leads to the best downstream performance across all scales, and peft methods differ significantly in their efficacy based on the model scale. lora usually offers the most favorable trade-off between cost and performance. further investigation into the effects of these methods on both model robustness and code security reveals that larger models tend to demonstrate reduced robustness and less security. at last, we explore the relationships among updated parameters, cross-entropy loss, and task performance. we find that the tuning effectiveness observed in small models generalizes well to larger models, and the validation loss in instruction tuning can be a reliable indicator of overall downstream performance.","doi":"","created":1704067200000,"updated":"","authors":["terry yue zhuo","armel zebaze","nitchakarn suppattarachai","leandro von werra","harm de vries","qian liu","niklas muennighoff"]}
{"id":"2401.00789","title":"retrieval-augmented egocentric video captioning","categories":"cs.cv","abstract":"understanding human actions from videos of first-person view poses significant challenges. most prior approaches explore representation learning on egocentric videos only, while overlooking the potential benefit of exploiting existing large-scale third-person videos. in this paper, (1) we develop egoinstructor, a retrieval-augmented multimodal captioning model that automatically retrieves semantically relevant third-person instructional videos to enhance the video captioning of egocentric videos. (2) for training the cross-view retrieval module, we devise an automatic pipeline to discover ego-exo video pairs from distinct large-scale egocentric and exocentric datasets. (3) we train the cross-view retrieval module with a novel egoexonce loss that pulls egocentric and exocentric video features closer by aligning them to shared text features that describe similar actions. (4) through extensive experiments, our cross-view retrieval module demonstrates superior performance across seven benchmarks. regarding egocentric video captioning, egoinstructor exhibits significant improvements by leveraging third-person videos as references. project page is available at: https:\/\/jazzcharles.github.io\/egoinstructor\/","doi":"","created":1704067200000,"updated":"2024-06-19","authors":["jilan xu","yifei huang","junlin hou","guo chen","yuejie zhang","rui feng","weidi xie"]}
{"id":"2401.00793","title":"secformer: towards fast and accurate privacy-preserving inference for   large language models","categories":"cs.lg cs.cl cs.cr","abstract":"with the growing use of large language models hosted on cloud platforms to offer inference services, privacy concerns are escalating, especially concerning sensitive data like investment plans and bank account details. secure multi-party computing (smpc) emerges as a promising solution to protect the privacy of inference data and model parameters. however, the application of smpc in privacy-preserving inference (ppi) for large language models, particularly those based on the transformer architecture, often leads to considerable slowdowns or declines in performance. this is largely due to the multitude of nonlinear operations in the transformer architecture, which are not well-suited to smpc and difficult to circumvent or optimize effectively. to address this concern, we introduce an advanced optimization framework called secformer, to achieve fast and accurate ppi for transformer models. by implementing model design optimization, we successfully eliminate the high-cost exponential and maximum operations in ppi without sacrificing model performance. additionally, we have developed a suite of efficient smpc protocols that utilize segmented polynomials, fourier series and goldschmidt's method to handle other complex nonlinear functions within ppi, such as gelu, layernorm, and softmax. our extensive experiments reveal that secformer outperforms mpcformer in performance, showing improvements of $5.6\\%$ and $24.2\\%$ for bert$_{\\text{base}}$ and bert$_{\\text{large}}$, respectively. in terms of efficiency, secformer is 3.56 and 3.58 times faster than puma for bert$_{\\text{base}}$ and bert$_{\\text{large}}$, demonstrating its effectiveness and speed.","doi":"","created":1704067200000,"updated":"2024-06-06","authors":["jinglong luo","yehong zhang","zhuo zhang","jiaqi zhang","xin mu","hui wang","yue yu","zenglin xu"]}
{"id":"2401.00794","title":"privacy-preserving data in iot-based cloud systems: a comprehensive   survey with ai integration","categories":"cs.cr","abstract":"as the integration of internet of things devices with cloud computing proliferates, the paramount importance of privacy preservation comes to the forefront. this survey paper meticulously explores the landscape of privacy issues in the dynamic intersection of iot and cloud systems. the comprehensive literature review synthesizes existing research, illuminating key challenges and discerning emerging trends in privacy preserving techniques. the categorization of diverse approaches unveils a nuanced understanding of encryption techniques, anonymization strategies, access control mechanisms, and the burgeoning integration of artificial intelligence. notable trends include the infusion of machine learning for dynamic anonymization, homomorphic encryption for secure computation, and ai-driven access control systems. the culmination of this survey contributes a holistic view, laying the groundwork for understanding the multifaceted strategies employed in securing sensitive data within iot-based cloud environments. the insights garnered from this survey provide a valuable resource for researchers, practitioners, and policymakers navigating the complex terrain of privacy preservation in the evolving landscape of iot and cloud computing","doi":"","created":1704067200000,"updated":"","authors":["d. dhinakaran","s. m. udhaya sankar","d. selvaraj","s. edwin raja"]}
{"id":"2401.00797","title":"distillation is all you need for practically using different pre-trained   recommendation models","categories":"cs.ir","abstract":"pre-trained recommendation models (prms) have attracted widespread attention recently. however, their totally different model structure, huge model size and computation cost hinder their application in practical recommender systems. hence, it is highly essential to explore how to practically utilize prms in real-world recommendations. in this paper, we propose a novel joint knowledge distillation from different pre-trained recommendation models named prm-kd for recommendation, which takes full advantages of diverse prms as teacher models for enhancing student models efficiently. specifically, prm-kd jointly distills diverse informative knowledge from multiple representative prms such as unisrec, recformer, and unim^2rec. the knowledge from the above prms are then smartly integrated into the student recommendation model considering their confidence and consistency. we further verify the universality of prm-kd with various types of student models, including sequential recommendation, feature interaction, and graph-based models. extensive experiments on five real-world datasets demonstrate the effectiveness and efficacy of prm-kd, which could be viewed as an economical shortcut in practically and conveniently making full use of different prms in online systems.","doi":"","created":1704067200000,"updated":"","authors":["wenqi sun","ruobing xie","junjie zhang","wayne xin zhao","leyu lin","ji-rong wen"]}
{"id":"2401.00801","title":"improved bounds for the bracketing number of orthants or revisiting an   algorithm of thi\\'{e}mard to compute bounds for the star discrepancy","categories":"math.co cs.cg cs.dm","abstract":"we improve the best known upper bound for the bracketing number of $d$-dimensional axis-parallel boxes anchored in $0$ (or, put differently, of lower left orthants intersected with the $d$-dimensional unit cube $[0,1]^d$). more precisely, we provide a better upper bound for the cardinality of an algorithmic bracketing cover construction due to eric thi\\'emard, which forms the core of his algorithm to approximate the star discrepancy of arbitrary point sets from [e. thi\\'emard, an algorithm to compute bounds for the star discrepancy, j.~complexity 17 (2001), 850 -- 880].   moreover, the new upper bound for the bracketing number of anchored axis-parallel boxes yields an improved upper bound for the bracketing number of arbitrary axis-parallel boxes in $[0,1]^d$.   in our upper bounds all constants are fully explicit.","doi":"","created":1704067200000,"updated":"2024-04-12","authors":["michael gnewuch"]}
{"id":"2401.00806","title":"noise-aware and equitable urban air traffic management: an optimization   approach","categories":"eess.sy cs.sy","abstract":"urban air mobility (uam), a transformative concept for the transport of passengers and cargo, faces several integration challenges in complex urban environments. community acceptance of aircraft noise is among the most noticeable of these challenges when launching or scaling up a uam system. properly managing community noise is fundamental to establishing a uam system that is environmentally and socially sustainable. in this work, we develop a holistic and equitable approach to manage uam air traffic and its community noise impact in urban environments. the proposed approach is a hybrid approach that considers a mix of different noise mitigation strategies, including limiting the number of operations, cruising at higher altitudes, and ambient noise masking. we tackle the problem through the lens of network system control and formulate a multi-objective optimization model for managing traffic flow in a multi-layer uam network while concurrently pursuing demand fulfillment, noise control, and energy saving. further, we use a social welfare function in the optimization model as the basis for the efficiency-fairness trade-off in both demand fulfillment and noise control. we apply the proposed approach to a comprehensive case study in the city of austin and perform design trade-offs through both visual and quantitative analyses.","doi":"","created":1704067200000,"updated":"","authors":["zhenyu gao","yue yu","qinshuang wei","ufuk topcu","john-paul clarke"]}
{"id":"2401.00809","title":"a review on different techniques used to combat the non-iid and   heterogeneous nature of data in fl","categories":"cs.lg","abstract":"federated learning (fl) is a machine-learning approach enabling collaborative model training across multiple decentralized edge devices that hold local data samples, all without exchanging these samples. this collaborative process occurs under the supervision of a central server orchestrating the training or via a peer-to-peer network. the significance of fl is particularly pronounced in industries such as healthcare and finance, where data privacy holds paramount importance. however, training a model under the federated learning setting brings forth several challenges, with one of the most prominent being the heterogeneity of data distribution among the edge devices. the data is typically non-independently and non-identically distributed (non-iid), thereby presenting challenges to model convergence. this report delves into the issues arising from non-iid and heterogeneous data and explores current algorithms designed to address these challenges.","doi":"","created":1704067200000,"updated":"","authors":["venkataraman natarajan iyer"]}
{"id":"2401.00811","title":"pershop -- a persian dataset for shopping dialogue systems modeling","categories":"cs.cl cs.hc","abstract":"nowadays, dialogue systems are used in many fields of industry and research. there are successful instances of these systems, such as apple siri, google assistant, and ibm watson. task-oriented dialogue system is a category of these, that are used in specific tasks. they can perform tasks such as booking plane tickets or making restaurant reservations. shopping is one of the most popular areas on these systems. the bot replaces the human salesperson and interacts with the customers by speaking. to train the models behind the scenes of these systems, annotated data is needed. in this paper, we developed a dataset of dialogues in the persian language through crowd-sourcing. we annotated these dialogues to train a model. this dataset contains nearly 22k utterances in 15 different domains and 1061 dialogues. this is the largest persian dataset in this field, which is provided freely so that future researchers can use it. also, we proposed some baseline models for natural language understanding (nlu) tasks. these models perform two tasks for nlu: intent classification and entity extraction. the f-1 score metric obtained for intent classification is around 91% and for entity extraction is around 93%, which can be a baseline for future research.","doi":"","created":1704067200000,"updated":"","authors":["keyvan mahmoudi","heshaam faili"]}
{"id":"2401.00812","title":"if llm is the wizard, then code is the wand: a survey on how code   empowers large language models to serve as intelligent agents","categories":"cs.cl","abstract":"the prominent large language models (llms) of today differ from past language models not only in size, but also in the fact that they are trained on a combination of natural language and formal language (code). as a medium between humans and computers, code translates high-level goals into executable steps, featuring standard syntax, logical consistency, abstraction, and modularity. in this survey, we present an overview of the various benefits of integrating code into llms' training data. specifically, beyond enhancing llms in code generation, we observe that these unique properties of code help (i) unlock the reasoning ability of llms, enabling their applications to a range of more complex natural language tasks; (ii) steer llms to produce structured and precise intermediate steps, which can then be connected to external execution ends through function calls; and (iii) take advantage of code compilation and execution environment, which also provides diverse feedback for model improvement. in addition, we trace how these profound capabilities of llms, brought by code, have led to their emergence as intelligent agents (ias) in situations where the ability to understand instructions, decompose goals, plan and execute actions, and refine from feedback are crucial to their success on downstream tasks. finally, we present several key challenges and future directions of empowering llms with code.","doi":"","created":1704067200000,"updated":"2024-01-08","authors":["ke yang","jiateng liu","john wu","chaoqi yang","yi r. fung","sha li","zixuan huang","xu cao","xingyao wang","yiquan wang","heng ji","chengxiang zhai"]}
{"id":"2401.00813","title":"ultraspherical\/gegenbauer polynomials to unify 2d\/3d ambisonic   directivity designs","categories":"eess.as cs.sd","abstract":"this report on axisymmetric ultraspherical\/gegenbauer polynomials and their use in ambisonic directivity design in 2d and 3d presents an alternative mathematical formalism to what can be read in, e.g., my and matthias frank's book on ambisonics or j\\'er\\^ome daniel's thesis, gary elko's differential array book chapters, or boaz rafaely's spherical microphone array book.   ultraspherical\/gegenbauer polynomials are highly valuable when designing axisymmetric beams and understanding spherical t designs, and this report will shed some light on what circular, spherical, and ultraspherical axisymmetric polynomials are. while mathematically interesting by themselves already, they can be useful in spherical beamforming as described in the literature on spherical and differential microphone arrays.   in this report, these ultraspherical\/gegenbauer polynomials will be used to uniformly derive for arbitrary dimensions d the various directivity designs or ambisonic order weightings known from literature: max-di\/basic, max-re , supercardioid, cardioid\/inphase. is there a way to relate higher-order cardioids and supercardioids? how could one define directivity patterns with an on-axis flatness constraint?","doi":"","created":1704067200000,"updated":"2024-05-04","authors":["franz zotter"]}
{"id":"2401.00814","title":"agricultural 4.0 leveraging on technological solutions: study for smart   farming sector","categories":"cs.hc cs.cy","abstract":"by 2050, it is predicted that there will be 9 billion people on the planet, which will call for more production, lower costs, and the preservation of natural resources. it is anticipated that atypical occurrences and climate change will pose severe risks to agricultural output. it follows that a 70% or more significant rise in food output is anticipated. smart farming, often known as agriculture 4.0, is a tech-driven revolution in agriculture with the goal of raising industry production and efficiency. four primary trends are responsible for it: food waste, climate change, population shifts, and resource scarcity. the agriculture industry is changing as a result of the adoption of emerging technologies. using cutting-edge technology like iot, ai, and other sensors, smart farming transforms traditional production methods and international agricultural policies. the objective is to establish a value chain that is optimized to facilitate enhanced monitoring and decreased labor expenses. the agricultural sector has seen tremendous transformation as a result of the fourth industrial revolution, which has combined traditional farming methods with cutting-edge technology to increase productivity, sustainability, and efficiency. to effectively utilize the potential of technology gadgets in the agriculture sector, collaboration between governments, private sector entities, and other stakeholders is necessary. this paper covers agriculture 4.0, looks at its possible benefits and drawbacks of the implementation methodologies, compatibility, reliability, and investigates the several digital tools that are being utilized to change the agriculture industry and how to mitigate the challenges.","doi":"","created":1704067200000,"updated":"","authors":["emmanuel kojo gyamfi","zag elsayed","jess kropczynski","mustapha awinsongya yakubu","nelly elsayed"]}
{"id":"2401.00815","title":"unsafe probabilities and risk contours for stochastic processes using   convex optimization","categories":"math.oc cs.sy eess.sy","abstract":"this paper proposes an algorithm to calculate the maximal probability of unsafety with respect to trajectories of a stochastic process and a hazard set. the unsafe probability estimation problem is cast as a primal-dual pair of infinite-dimensional linear programs in occupation measures and continuous functions. this convex relaxation is nonconservative (to the true probability of unsafety) under compactness and regularity conditions in dynamics. the continuous-function linear program is linked to existing probability-certifying barrier certificates of safety. risk contours for initial conditions of the stochastic process may be generated by suitably modifying the objective of the continuous-function program, forming an interpretable and visual representation of stochastic safety for test initial conditions. all infinite-dimensional linear programs are truncated to finite dimension by the moment-sum-of-squares hierarchy of semidefinite programs. unsafe-probability estimation and risk contours are generated for example stochastic processes.","doi":"","created":1704067200000,"updated":"","authors":["jared miller","matteo tacchi","didier henrion","mario sznaier"]}
{"id":"2401.00816","title":"glimpse: generalized local imaging with mlps","categories":"cs.cv cs.lg eess.iv","abstract":"deep learning is the current de facto state of the art in tomographic imaging. a common approach is to feed the result of a simple inversion, for example the backprojection, to a convolutional neural network (cnn) which then computes the reconstruction. despite strong results on 'in-distribution' test data similar to the training data, backprojection from sparse-view data delocalizes singularities, so these approaches require a large receptive field to perform well. as a consequence, they overfit to certain global structures which leads to poor generalization on out-of-distribution (ood) samples. moreover, their memory complexity and training time scale unfavorably with image resolution, making them impractical for application at realistic clinical resolutions, especially in 3d: a standard u-net requires a substantial 140gb of memory and 2600 seconds per epoch on a research-grade gpu when training on 1024x1024 images. in this paper, we introduce glimpse, a local processing neural network for computed tomography which reconstructs a pixel value by feeding only the measurements associated with the neighborhood of the pixel to a simple mlp. while achieving comparable or better performance with successful cnns like the u-net on in-distribution test data, glimpse significantly outperforms them on ood samples while maintaining a memory footprint almost independent of image resolution; 5gb memory suffices to train on 1024x1024 images. further, we built glimpse to be fully differentiable, which enables feats such as recovery of accurate projection angles if they are out of calibration.","doi":"","created":1704067200000,"updated":"2024-06-20","authors":["amirehsan khorashadizadeh","valentin debarnot","tianlin liu","ivan dokmanić"]}
{"id":"2401.00819","title":"3d beamforming through joint phase-time arrays","categories":"cs.it eess.sp math.it","abstract":"high-frequency wideband cellular communications over mmwave and sub-thz offer the opportunity for high data rates. however, it also presents high path loss, resulting in limited coverage. high-gain beamforming brought by the antenna array is essential to mitigate the coverage limitations. the conventional phased antenna arrays (paa) cause high scheduling latency owing to analog beam constraints, i.e., only one frequency-flat beam is generated. recently introduced joint phase-time array (jpta) architecture, which utilizes both true-time-delay (ttd) units and phase shifters (pss), alleviates analog beam constraints by creating multiple frequency-dependent beams for scheduling multiple users at different directions in a frequency-division manner. one class of previous studies offered solutions with \"rainbow\" beams, which tend to allocate a small bandwidth per beam direction. another class focused on uniform linear array (ula) antenna architecture, whose frequency-dependent beams were designed along a single axis of either azimuth or elevation direction. this paper presents a novel 3d beamforming design that maximizes beamforming gain toward desired azimuth and elevation directions and across sub-bands partitioned according to scheduled users' bandwidth requirements. we provide analytical solutions and iterative algorithms to design the pss and ttd units for a desired subband beam pattern. through simulations of the beamforming gain, we observe that our proposed solutions outperform the state-of-the-art solutions reported elsewhere.","doi":"","created":1704067200000,"updated":"2024-01-31","authors":["ozlem yildiz","ahmad alammouri","jianhua mo","younghan nam","elza erkip","n\/a jianzhong","n\/a zhang"]}
{"id":"2401.00820","title":"a computational framework for behavioral assessment of llm therapists","categories":"cs.cl cs.hc","abstract":"the emergence of chatgpt and other large language models (llms) has greatly increased interest in utilizing llms as therapists to support individuals struggling with mental health challenges. however, due to the lack of systematic studies, our understanding of how llm therapists behave, i.e., ways in which they respond to clients, is significantly limited. understanding their behavior across a wide range of clients and situations is crucial to accurately assess their capabilities and limitations in the high-risk setting of mental health, where undesirable behaviors can lead to severe consequences. in this paper, we propose bolt, a novel computational framework to study the conversational behavior of llms when employed as therapists. we develop an in-context learning method to quantitatively measure the behavior of llms based on 13 different psychotherapy techniques including reflections, questions, solutions, normalizing, and psychoeducation. subsequently, we compare the behavior of llm therapists against that of high- and low-quality human therapy, and study how their behavior can be modulated to better reflect behaviors observed in high-quality therapy. our analysis of gpt and llama-variants reveals that these llms often resemble behaviors more commonly exhibited in low-quality therapy rather than high-quality therapy, such as offering a higher degree of problem-solving advice when clients share emotions, which is against typical recommendations. at the same time, unlike low-quality therapy, llms reflect significantly more upon clients' needs and strengths. our analysis framework suggests that despite the ability of llms to generate anecdotal examples that appear similar to human therapists, llm therapists are currently not fully consistent with high-quality care, and thus require additional research to ensure quality care.","doi":"","created":1704067200000,"updated":"","authors":["yu ying chiu","ashish sharma","inna wanyin lin","tim althoff"]}
{"id":"2401.00824","title":"graph-convolutional autoencoder ensembles for the humanities,   illustrated with a study of the american slave trade","categories":"cs.lg cs.cl","abstract":"we introduce a graph-aware autoencoder ensemble framework, with associated formalisms and tooling, designed to facilitate deep learning for scholarship in the humanities. by composing sub-architectures to produce a model isomorphic to a humanistic domain we maintain interpretability while providing function signatures for each sub-architectural choice, allowing both traditional and computational researchers to collaborate without disrupting established practices. we illustrate a practical application of our approach to a historical study of the american post-atlantic slave trade, and make several specific technical contributions: a novel hybrid graph-convolutional autoencoder mechanism, batching policies for common graph topologies, and masking techniques for particular use-cases. the effectiveness of the framework for broadening participation of diverse domains is demonstrated by a growing suite of two dozen studies, both collaborations with humanists and established tasks from machine learning literature, spanning a variety of fields and data modalities. we make performance comparisons of several different architectural choices and conclude with an ambitious list of imminent next steps for this research.","doi":"","created":1704067200000,"updated":"","authors":["tom lippincott"]}
{"id":"2401.00825","title":"sharp-nerf: grid-based fast deblurring neural radiance fields using   sharpness prior","categories":"cs.cv cs.gr eess.iv","abstract":"neural radiance fields (nerf) have shown remarkable performance in neural rendering-based novel view synthesis. however, nerf suffers from severe visual quality degradation when the input images have been captured under imperfect conditions, such as poor illumination, defocus blurring, and lens aberrations. especially, defocus blur is quite common in the images when they are normally captured using cameras. although few recent studies have proposed to render sharp images of considerably high-quality, yet they still face many key challenges. in particular, those methods have employed a multi-layer perceptron (mlp) based nerf, which requires tremendous computational time. to overcome these shortcomings, this paper proposes a novel technique sharp-nerf -- a grid-based nerf that renders clean and sharp images from the input blurry images within half an hour of training. to do so, we used several grid-based kernels to accurately model the sharpness\/blurriness of the scene. the sharpness level of the pixels is computed to learn the spatially varying blur kernels. we have conducted experiments on the benchmarks consisting of blurry images and have evaluated full-reference and non-reference metrics. the qualitative and quantitative results have revealed that our approach renders the sharp novel views with vivid colors and fine details, and it has considerably faster training time than the previous works. our project page is available at https:\/\/benhenryl.github.io\/sharpnerf\/","doi":"","created":1704067200000,"updated":"","authors":["byeonghyeon lee","howoong lee","usman ali","eunbyung park"]}
{"id":"2401.00827","title":"a multipartite analogue of dilworth's theorem","categories":"math.co cs.dm","abstract":"we prove that every partially ordered set on $n$ elements contains $k$ subsets $a_{1},a_{2},\\dots,a_{k}$ such that either each of these subsets has size $\\omega(n\/k^{5})$ and, for every $i<j$, every element in $a_{i}$ is less than or equal to every element in $a_{j}$, or each of these subsets has size $\\omega(n\/(k^{2}\\log n))$ and, for every $i \\not = j$, every element in $a_{i}$ is incomparable with every element in $a_{j}$ for $i\\ne j$. this answers a question of the first author from 2006. as a corollary, we prove for each positive integer $h$ there is $c_h$ such that for any $h$ partial orders $<_{1},<_{2},\\dots,<_{h}$ on a set of $n$ elements, there exists $k$ subsets $a_{1},a_{2},\\dots,a_{k}$ each of size at least $n\/(k\\log n)^{c_{h}}$ such that for each partial order $<_{\\ell}$, either $a_{1}<_{\\ell}a_{2}<_{\\ell}\\dots<_{\\ell}a_{k}$ for any tuple of elements $(a_1,a_2,\\dots,a_k) \\in a_1\\times a_2\\times \\dots \\times a_k$, or $a_{1}>_{\\ell}a_{2}>_{\\ell}\\dots>_{\\ell}a_{k}$ for any $(a_1,a_2,\\dots,a_k) \\in a_1\\times a_2\\times \\dots \\times a_k$, or $a_i$ is incomparable with $a_j$ for any $i\\ne j$, $a_i\\in a_i$ and $a_j\\in a_j$. this improves on a 2009 result of pach and the first author motivated by problems in discrete geometry.","doi":"","created":1704067200000,"updated":"","authors":["jacob fox","huy tuan pham"]}
{"id":"2401.00828","title":"multi-lattice sampling of quantum field theories via neural   operator-based flows","categories":"cs.lg hep-lat stat.ml","abstract":"we consider the problem of sampling discrete field configurations $\\phi$ from the boltzmann distribution $[d\\phi] z^{-1} e^{-s[\\phi]}$, where $s$ is the lattice-discretization of the continuous euclidean action $\\mathcal s$ of some quantum field theory. since such densities arise as the approximation of the underlying functional density $[\\mathcal d\\phi(x)] \\mathcal z^{-1} e^{-\\mathcal s[\\phi(x)]}$, we frame the task as an instance of operator learning. in particular, we propose to approximate a time-dependent operator $\\mathcal v_t$ whose time integral provides a mapping between the functional distributions of the free theory $[\\mathcal d\\phi(x)] \\mathcal z_0^{-1} e^{-\\mathcal s_{0}[\\phi(x)]}$ and of the target theory $[\\mathcal d\\phi(x)]\\mathcal z^{-1}e^{-\\mathcal s[\\phi(x)]}$. whenever a particular lattice is chosen, the operator $\\mathcal v_t$ can be discretized to a finite dimensional, time-dependent vector field $v_t$ which in turn induces a continuous normalizing flow between finite dimensional distributions over the chosen lattice. this flow can then be trained to be a diffeormorphism between the discretized free and target theories $[d\\phi] z_0^{-1} e^{-s_{0}[\\phi]}$, $[d\\phi] z^{-1}e^{-s[\\phi]}$. we run experiments on the $\\phi^4$-theory to explore to what extent such operator-based flow architectures generalize to lattice sizes they were not trained on and show that pretraining on smaller lattices can lead to speedup over training only a target lattice size.","doi":"","created":1704067200000,"updated":"2024-01-17","authors":["bálint máté","françois fleuret"]}
{"id":"2401.00830","title":"socially compliant control of autonomous vehicles with application to   eco-driving","categories":"eess.sy cs.sy","abstract":"control design of autonomous vehicles (avs) has mostly focused on achieving a prespecified goal for an individually controlled av or for a swarm of cooperatively controlled avs. however, the impact of autonomous driving on human-driven vehicles (hvs) has been largely ignored in av controller synthesis, which could result in egoistic av behavior detrimental to the safety of passengers and surrounding traffic. in this study we develop a general framework for socially compliant control design of avs with a useful metric of social psychology, called social value orientation (svo), allowing avs to leverage their impact on the behavior of the following hvs. this is critical since avs that behave in a socially compliant manner enable human drivers to comprehend their actions and respond appropriately. within the proposed framework, we define the utilities of the controlled av and its following vehicle, to be maximized in a weighted fashion determined by the av's svo. the utility maximization covers an array of design objectives given the goal of the av and the benefits for the following hv stemming from the courtesy of socially compliant av controls. an optimal control problem is then formulated to maximize the utility function defined, which is numerically solved using pontryagin's minimum principle with optimality guarantees. the methodology developed is applied to synthesize socially compliant control for eco-driving of avs. a set of numerical results are presented to show the mechanism and effectiveness of the proposed approach using real-world experimental data collected on highway 55 in minnesota.","doi":"","created":1704067200000,"updated":"","authors":["shian wang"]}
{"id":"2401.00832","title":"taking the next step with generative artificial intelligence: the   transformative role of multimodal large language models in science education","categories":"cs.ai cs.cy","abstract":"the integration of artificial intelligence (ai), particularly large language model (llm)-based systems, in education has shown promise in enhancing teaching and learning experiences. however, the advent of multimodal large language models (mllms) like gpt-4 with vision (gpt-4v), capable of processing multimodal data including text, sound, and visual inputs, opens a new era of enriched, personalized, and interactive learning landscapes in education. grounded in theory of multimedia learning, this paper explores the transformative role of mllms in central aspects of science education by presenting exemplary innovative learning scenarios. possible applications for mllms could range from content creation to tailored support for learning, fostering competencies in scientific practices, and providing assessment and feedback. these scenarios are not limited to text-based and uni-modal formats but can be multimodal, increasing thus personalization, accessibility, and potential learning effectiveness. besides many opportunities, challenges such as data protection and ethical considerations become more salient, calling for robust frameworks to ensure responsible integration. this paper underscores the necessity for a balanced approach in implementing mllms, where the technology complements rather than supplants the educator's role, ensuring thus an effective and ethical use of ai in science education. it calls for further research to explore the nuanced implications of mllms on the evolving role of educators and to extend the discourse beyond science education to other disciplines. through the exploration of potentials, challenges, and future implications, we aim to contribute to a preliminary understanding of the transformative trajectory of mllms in science education and beyond.","doi":"","created":1704067200000,"updated":"","authors":["arne bewersdorff","christian hartmann","marie hornberger","kathrin seßler","maria bannert","enkelejda kasneci","gjergji kasneci","xiaoming zhai","claudia nerdel"]}
{"id":"2401.00833","title":"rethinking raft for efficient optical flow","categories":"cs.cv","abstract":"despite significant progress in deep learning-based optical flow methods, accurately estimating large displacements and repetitive patterns remains a challenge. the limitations of local features and similarity search patterns used in these algorithms contribute to this issue. additionally, some existing methods suffer from slow runtime and excessive graphic memory consumption. to address these problems, this paper proposes a novel approach based on the raft framework. the proposed attention-based feature localization (afl) approach incorporates the attention mechanism to handle global feature extraction and address repetitive patterns. it introduces an operator for matching pixels with corresponding counterparts in the second frame and assigning accurate flow values. furthermore, an amorphous lookup operator (alo) is proposed to enhance convergence speed and improve rafts ability to handle large displacements by reducing data redundancy in its search operator and expanding the search space for similarity extraction. the proposed method, efficient raft (ef-raft),achieves significant improvements of 10% on the sintel dataset and 5% on the kitti dataset over raft. remarkably, these enhancements are attained with a modest 33% reduction in speed and a mere 13% increase in memory usage. the code is available at: https:\/\/github.com\/n3slami\/ef-raft","doi":"","created":1704067200000,"updated":"","authors":["navid eslami","farnoosh arefi","amir m. mansourian","shohreh kasaei"]}
{"id":"2401.00834","title":"deblurring 3d gaussian splatting","categories":"cs.cv","abstract":"recent studies in radiance fields have paved the robust way for novel view synthesis with their photorealistic rendering quality. nevertheless, they usually employ neural networks and volumetric rendering, which are costly to train and impede their broad use in various real-time applications due to the lengthy rendering time. lately 3d gaussians splatting-based approach has been proposed to model the 3d scene, and it achieves remarkable visual quality while rendering the images in real-time. however, it suffers from severe degradation in the rendering quality if the training images are blurry. blurriness commonly occurs due to the lens defocusing, object motion, and camera shake, and it inevitably intervenes in clean image acquisition. several previous studies have attempted to render clean and sharp images from blurry input images using neural fields. the majority of those works, however, are designed only for volumetric rendering-based neural radiance fields and are not straightforwardly applicable to rasterization-based 3d gaussian splatting methods. thus, we propose a novel real-time deblurring framework, deblurring 3d gaussian splatting, using a small multi-layer perceptron (mlp) that manipulates the covariance of each 3d gaussian to model the scene blurriness. while deblurring 3d gaussian splatting can still enjoy real-time rendering, it can reconstruct fine and sharp details from blurry images. a variety of experiments have been conducted on the benchmark, and the results have revealed the effectiveness of our approach for deblurring. qualitative results are available at https:\/\/benhenryl.github.io\/deblurring-3d-gaussian-splatting\/","doi":"","created":1704067200000,"updated":"2024-05-26","authors":["byeonghyeon lee","howoong lee","xiangyu sun","usman ali","eunbyung park"]}
{"id":"2401.00844","title":"the semi-analytic theory and computation of finite-depth standing water   waves","categories":"physics.flu-dyn cs.na math.na","abstract":"we propose a semi-analytic stokes expansion ansatz for finite-depth standing water waves and devise a recursive algorithm to solve the system of differential equations governing the expansion coefficients. we implement the algorithm on a supercomputer using arbitrary-precision arithmetic. the stokes expansion introduces hyperbolic trigonometric terms that require exponentiation of power series. we handle this efficiently using bell polynomials. under mild assumptions on the fluid depth, we prove that there are no exact resonances, though small divisors may occur. sudden changes in growth rate in the expansion coefficients are found to correspond to imperfect bifurcations observed when families of standing waves are computed using a shooting method. a direct connection between small divisors in the recursive algorithm and imperfect bifurcations in the solution curves is observed, where the small divisor excites higher-frequency parasitic standing waves that oscillate on top of the main wave. a 109th order pad\\'e approximation maintains 25--30 digits of accuracy on both sides of the first imperfect bifurcation encountered for the unit-depth problem. this suggests that even if the stokes expansion is divergent, there may be a closely related convergent sequence of rational approximations.","doi":"","created":1704067200000,"updated":"","authors":["ahmad abassi","jon wilkening"]}
{"id":"2401.00847","title":"mocap everyone everywhere: lightweight motion capture with smartwatches   and a head-mounted camera","categories":"cs.cv cs.gr","abstract":"we present a lightweight and affordable motion capture method based on two smartwatches and a head-mounted camera. in contrast to the existing approaches that use six or more expert-level imu devices, our approach is much more cost-effective and convenient. our method can make wearable motion capture accessible to everyone everywhere, enabling 3d full-body motion capture in diverse environments. as a key idea to overcome the extreme sparsity and ambiguities of sensor inputs with different modalities, we integrate 6d head poses obtained from the head-mounted cameras for motion estimation. to enable capture in expansive indoor and outdoor scenes, we propose an algorithm to track and update floor level changes to define head poses, coupled with a multi-stage transformer-based regression module. we also introduce novel strategies leveraging visual cues of egocentric images to further enhance the motion capture quality while reducing ambiguities. we demonstrate the performance of our method on various challenging scenarios, including complex outdoor environments and everyday motions including object interactions and social interactions among multiple individuals.","doi":"","created":1704067200000,"updated":"2024-05-06","authors":["jiye lee","hanbyul joo"]}
{"id":"2401.00849","title":"cosmo: contrastive streamlined multimodal model with interleaved   pre-training","categories":"cs.cv","abstract":"in the evolution of vision-language pre-training, shifting from short-text comprehension to encompassing extended textual contexts is pivotal. recent autoregressive vision-language models like \\cite{flamingo, palme}, leveraging the long-context capability of large language models, have excelled in few-shot text generation tasks but face challenges in alignment tasks. addressing this gap, we introduce the contrastive loss into text generation models, presenting the contrastive-streamlined multimodal framework (\\modelname), strategically partitioning the language model into dedicated unimodal text processing and adept multimodal data handling components. \\modelname, our unified framework, merges unimodal and multimodal elements, enhancing model performance for tasks involving textual and visual data while notably reducing learnable parameters. however, these models demand extensive long-text datasets, yet the availability of high-quality long-text video datasets remains limited. to bridge this gap, this work introduces \\videodatasetname, an inaugural interleaved video-text dataset featuring comprehensive captions, marking a significant step forward. demonstrating its impact, we illustrate how \\videodatasetname{} enhances model performance in image-text tasks. with 34% learnable parameters and utilizing 72\\% of the available data, our model demonstrates significant superiority over openflamingo~\\cite{openflamingo}. for instance, in the 4-shot flickr captioning task, performance notably improves from 57.2% to 65.\\%. the contributions of \\modelname{} and \\videodatasetname{} are underscored by notable performance gains across 14 diverse downstream datasets encompassing both image-text and video-text tasks.","doi":"","created":1704067200000,"updated":"","authors":["alex jinpeng wang","linjie li","kevin qinghong lin","jianfeng wang","kevin lin","zhengyuan yang","lijuan wang","mike zheng shou"]}
{"id":"2401.00850","title":"refining pre-trained motion models","categories":"cs.cv cs.ai","abstract":"given the difficulty of manually annotating motion in video, the current best motion estimation methods are trained with synthetic data, and therefore struggle somewhat due to a train\/test gap. self-supervised methods hold the promise of training directly on real video, but typically perform worse. these include methods trained with warp error (i.e., color constancy) combined with smoothness terms, and methods that encourage cycle-consistency in the estimates (i.e., tracking backwards should yield the opposite trajectory as tracking forwards). in this work, we take on the challenge of improving state-of-the-art supervised models with self-supervised training. we find that when the initialization is supervised weights, most existing self-supervision techniques actually make performance worse instead of better, which suggests that the benefit of seeing the new data is overshadowed by the noise in the training signal. focusing on obtaining a \"clean\" training signal from real-world unlabelled video, we propose to separate label-making and training into two distinct stages. in the first stage, we use the pre-trained model to estimate motion in a video, and then select the subset of motion estimates which we can verify with cycle-consistency. this produces a sparse but accurate pseudo-labelling of the video. in the second stage, we fine-tune the model to reproduce these outputs, while also applying augmentations on the input. we complement this boot-strapping method with simple techniques that densify and re-balance the pseudo-labels, ensuring that we do not merely train on \"easy\" tracks. we show that our method yields reliable gains over fully-supervised methods in real videos, for both short-term (flow-based) and long-range (multi-frame) pixel tracking.","doi":"","created":1704067200000,"updated":"2024-02-16","authors":["xinglong sun","adam w. harley","leonidas j. guibas"]}
{"id":"2401.00916","title":"data assimilation in chaotic systems using deep reinforcement learning","categories":"math.ds cs.ai cs.lg physics.ao-ph","abstract":"data assimilation (da) plays a pivotal role in diverse applications, ranging from climate predictions and weather forecasts to trajectory planning for autonomous vehicles. a prime example is the widely used ensemble kalman filter (enkf), which relies on linear updates to minimize variance among the ensemble of forecast states. recent advancements have seen the emergence of deep learning approaches in this domain, primarily within a supervised learning framework. however, the adaptability of such models to untrained scenarios remains a challenge. in this study, we introduce a novel da strategy that utilizes reinforcement learning (rl) to apply state corrections using full or partial observations of the state variables. our investigation focuses on demonstrating this approach to the chaotic lorenz '63 system, where the agent's objective is to minimize the root-mean-squared error between the observations and corresponding forecast states. consequently, the agent develops a correction strategy, enhancing model forecasts based on available system state observations. our strategy employs a stochastic action policy, enabling a monte carlo-based da framework that relies on randomly sampling the policy to generate an ensemble of assimilated realizations. results demonstrate that the developed rl algorithm performs favorably when compared to the enkf. additionally, we illustrate the agent's capability to assimilate non-gaussian data, addressing a significant limitation of the enkf.","doi":"","created":1704067200000,"updated":"","authors":["mohamad abed el rahman hammoud","naila raboudi","edriss s. titi","omar knio","ibrahim hoteit"]}
{"id":"2401.00917","title":"fast and continual learning for hybrid control policies using   generalized benders decomposition","categories":"cs.ro","abstract":"hybrid model predictive control with both continuous and discrete variables is widely applicable to robotic control tasks, especially those involving contact with the environment. due to the combinatorial complexity, the solving speed of hybrid mpc can be insufficient for real-time applications. in this paper, we proposed a hybrid mpc solver based on generalized benders decomposition (gbd). the algorithm enumerates and stores cutting planes online inside a finite buffer. after a short cold-start phase, the stored cuts provide warm-starts for the new problem instances to enhance the solving speed. despite the disturbance and randomly changing environment, the solving speed maintains. leveraging on the sparsity of feasibility cuts, we also propose a fast algorithm for benders master problems. our solver is validated through controlling a cart-pole system with randomly moving soft contact walls, and a free-flying robot navigating around obstacles. the results show that with significantly less data than previous works, the solver reaches competitive speeds to the off-the-shelf solver gurobi despite the python overhead.","doi":"","created":1704067200000,"updated":"2024-01-04","authors":["xuan lin"]}
{"id":"2401.00921","title":"skeleton2vec: a self-supervised learning framework with contextualized   target representations for skeleton sequence","categories":"cs.cv","abstract":"self-supervised pre-training paradigms have been extensively explored in the field of skeleton-based action recognition. in particular, methods based on masked prediction have pushed the performance of pre-training to a new height. however, these methods take low-level features, such as raw joint coordinates or temporal motion, as prediction targets for the masked regions, which is suboptimal. in this paper, we show that using high-level contextualized features as prediction targets can achieve superior performance. specifically, we propose skeleton2vec, a simple and efficient self-supervised 3d action representation learning framework, which utilizes a transformer-based teacher encoder taking unmasked training samples as input to create latent contextualized representations as prediction targets. benefiting from the self-attention mechanism, the latent representations generated by the teacher encoder can incorporate the global context of the entire training samples, leading to a richer training task. additionally, considering the high temporal correlations in skeleton sequences, we propose a motion-aware tube masking strategy which divides the skeleton sequence into several tubes and performs persistent masking within each tube based on motion priors, thus forcing the model to build long-range spatio-temporal connections and focus on action-semantic richer regions. extensive experiments on ntu-60, ntu-120, and pku-mmd datasets demonstrate that our proposed skeleton2vec outperforms previous methods and achieves state-of-the-art results.","doi":"","created":1704067200000,"updated":"","authors":["ruizhuo xu","linzhi huang","mei wang","jiani hu","weihong deng"]}
{"id":"2401.00924","title":"free-form shape modeling in xr: a systematic review","categories":"cs.gr","abstract":"shape modeling research in computer graphics has been an active area for decades. the ability to create and edit complex 3d shapes has been of key importance in computer-aided design, animation, architecture, and entertainment. with the growing popularity of virtual and augmented reality, new applications and tools have been developed for artistic content creation; real-time interactive shape modeling has become increasingly important for a continuum of virtual and augmented reality environments (extended reality (xr)). shape modeling in xr opens new possibilities for intuitive design and shape modeling in an accessible way. artificial intelligence (ai) approaches generating shape information from text prompts are set to change how artists create and edit 3d models. there has been a substantial body of research on interactive 3d shape modeling. however, there is no recent extensive review of the existing techniques and what ai shape generation means for shape modeling in interactive xr environments. in this state-of-the-art paper, we fill this research gap in the literature by surveying free-form shape modeling work in xr, with a focus on sculpting and 3d sketching, the most intuitive forms of free-form shape modeling. we classify and discuss these works across five dimensions: contribution of the articles, domain setting, interaction tool, auto-completion, and collaborative designing. the paper concludes by discussing the disconnect between interactive 3d sculpting and sketching and how this will likely evolve with the prevalence of ai shape-generation tools in the future.","doi":"","created":1704067200000,"updated":"","authors":["shounak chatterjee"]}
{"id":"2401.00926","title":"accurate leukocyte detection based on deformable-detr and multi-level   feature fusion for aiding diagnosis of blood diseases","categories":"cs.cv cs.ai","abstract":"in standard hospital blood tests, the traditional process requires doctors to manually isolate leukocytes from microscopic images of patients' blood using microscopes. these isolated leukocytes are then categorized via automatic leukocyte classifiers to determine the proportion and volume of different types of leukocytes present in the blood samples, aiding disease diagnosis. this methodology is not only time-consuming and labor-intensive, but it also has a high propensity for errors due to factors such as image quality and environmental conditions, which could potentially lead to incorrect subsequent classifications and misdiagnosis. to address these issues, this paper proposes an innovative method of leukocyte detection: the multi-level feature fusion and deformable self-attention detr (mfds-detr). to tackle the issue of leukocyte scale disparity, we designed the high-level screening-feature fusion pyramid (hs-fpn), enabling multi-level fusion. this model uses high-level features as weights to filter low-level feature information via a channel attention module and then merges the screened information with the high-level features, thus enhancing the model's feature expression capability. further, we address the issue of leukocyte feature scarcity by incorporating a multi-scale deformable self-attention module in the encoder and using the self-attention and cross-deformable attention mechanisms in the decoder, which aids in the extraction of the global features of the leukocyte feature maps. the effectiveness, superiority, and generalizability of the proposed mfds-detr method are confirmed through comparisons with other cutting-edge leukocyte detection models using the private wbcdd, public lisc and bccd datasets. our source code and private wbccd dataset are available at https:\/\/github.com\/justlfc03\/mfds-detr.","doi":"","created":1704067200000,"updated":"2024-01-10","authors":["yifei chen","chenyan zhang","ben chen","yiyu huang","yifei sun","changmiao wang","xianjun fu","yuxing dai","feiwei qin","yong peng","yu gao"]}
{"id":"2401.00928","title":"osint research studios: a flexible crowdsourcing framework to scale up   open source intelligence investigations","categories":"cs.hc","abstract":"open source intelligence (osint) investigations, which rely entirely on publicly available data such as social media, play an increasingly important role in solving crimes and holding governments accountable. the growing volume of data and complex nature of tasks, however, means there is a pressing need to scale and speed up osint investigations. expert-led crowdsourcing approaches show promise but tend to either focus on narrow tasks or domains or require resource-intense, long-term relationships between expert investigators and crowds. we address this gap by providing a flexible framework that enables investigators across domains to enlist crowdsourced support for the discovery and verification of osint. we use a design-based research (dbr) approach to develop osint research studios (ors), a sociotechnical system in which novice crowds are trained to support professional investigators with complex osint investigations. through our qualitative evaluation, we found that ors facilitates ethical and effective osint investigations across multiple domains. we also discuss broader implications of expert-crowd collaboration and opportunities for future work.","doi":"","created":1704067200000,"updated":"","authors":["anirban mukhopadhyay","sukrit venkatagiri","kurt luther"]}
{"id":"2401.00929","title":"genh2r: learning generalizable human-to-robot handover via scalable   simulation, demonstration, and imitation","categories":"cs.ro cs.cv","abstract":"this paper presents genh2r, a framework for learning generalizable vision-based human-to-robot (h2r) handover skills. the goal is to equip robots with the ability to reliably receive objects with unseen geometry handed over by humans in various complex trajectories. we acquire such generalizability by learning h2r handover at scale with a comprehensive solution including procedural simulation assets creation, automated demonstration generation, and effective imitation learning. we leverage large-scale 3d model repositories, dexterous grasp generation methods, and curve-based 3d animation to create an h2r handover simulation environment named \\simabbns, surpassing the number of scenes in existing simulators by three orders of magnitude. we further introduce a distillation-friendly demonstration generation method that automatically generates a million high-quality demonstrations suitable for learning. finally, we present a 4d imitation learning method augmented by a future forecasting objective to distill demonstrations into a visuo-motor handover policy. experimental evaluations in both simulators and the real world demonstrate significant improvements (at least +10\\% success rate) over baselines in all cases. the project page is https:\/\/genh2r.github.io\/.","doi":"","created":1704067200000,"updated":"2024-06-14","authors":["zifan wang","junyu chen","ziqing chen","pengwei xie","rui chen","li yi"]}
{"id":"2401.00935","title":"boundary attention: learning to localize boundaries under high noise","categories":"cs.cv","abstract":"we present a differentiable model that infers explicit boundaries, including curves, corners and junctions, using a mechanism that we call boundary attention. boundary attention is a boundary-aware local attention operation that, when applied densely and repeatedly, progressively refines a field of variables that specify an unrasterized description of the local boundary structure in every overlapping patch within an image. it operates in a bottom-up fashion, similar to classical methods for sub-pixel edge localization and edge-linking, but with a higher-dimensional description of local boundary structure, a notion of spatial consistency that is learned instead of designed, and a sequence of operations that is end-to-end differentiable. we train our model using simple synthetic data and then evaluate it using photographs that were captured under low-light conditions with variable amounts of noise. we find that our method generalizes to natural images corrupted by real sensor noise, and predicts consistent boundaries under increasingly noisy conditions where other state-of-the-art methods fail.","doi":"","created":1704067200000,"updated":"2024-03-18","authors":["mia gaia polansky","charles herrmann","junhwa hur","deqing sun","dor verbin","todd zickler"]}
{"id":"2401.00936","title":"the role of direct sound spherical harmonics representation in   externalization using binaural reproduction","categories":"eess.as cs.sd","abstract":"the importance of the information in the direct sound to human perception of spatial sound sources is an ongoing research topic. the classification between direct sound and diffuse or reverberant sound forms the basis of numerous studies in the field of spatial audio. in particular, parametric spatial audio representation methods use this classification and employ signal processing in order to enhance the audio quality at reproduction. however, current literature does not provide information concerning the impact of ideal direct sound representation on externalization, in the context of ambisonics. this paper aims to assess the importance of the spatial information in the direct sound in the externalization of a sound field when using binaural reproduction. this is done in the spherical harmonics (sh) domain, where an ideal direct sound representation within an otherwise ambisonics signal is simulated, and its perceived externalization is evaluated in a formal listening test. this investigation leads to the conclusion that externalization of a first order ambisonics signal may be significantly improved by enhancing the direct sound component, up to a level similar to a third order ambisonics signal.","doi":"10.1016\/j.apacoust.2018.12.011","created":1704067200000,"updated":"","authors":["eran miller","boaz rafaely"]}
{"id":"2401.00942","title":"the influence of biomedical research on future business funding:   analyzing scientific impact and content in industrial investments","categories":"cs.ce","abstract":"this paper investigates the relationship between scientific innovation in biomedical sciences and its impact on industrial activities, focusing on how the historical impact and content of scientific papers influenced future funding and innovation grant application content for small businesses. the research incorporates bibliometric analyses along with sbir (small business innovation research) data to yield a holistic view of the science-industry interface. by evaluating the influence of scientific innovation on industry across 10,873 biomedical topics and taking into account their taxonomic relationships, we present an in-depth exploration of science-industry interactions where we quantify the temporal effects and impact latency of scientific advancements on industrial activities, spanning from 2010 to 2021. our findings indicate that scientific progress substantially influenced industrial innovation funding and the direction of industrial innovation activities. approximately 76% and 73% of topics showed a correlation and granger-causality between scientific interest in papers and future funding allocations to relevant small businesses. moreover, around 74% of topics demonstrated an association between the semantic content of scientific abstracts and future grant applications. overall, the work contributes to a more nuanced and comprehensive understanding of the science-industry interface, opening avenues for more strategic resource allocation and policy developments aimed at fostering innovation.","doi":"","created":1704067200000,"updated":"","authors":["reza khanmohammadi","simerjot kaur","charese h. smiley","tuka alhanai","ivan brugere","armineh nourbakhsh","mohammad m. ghassemi"]}
{"id":"2401.00947","title":"on sat information content, its polynomial-time solvability and fixed   code algorithms","categories":"cs.cc cs.it math.it","abstract":"the amount of information in satisfiability problem (sat) is considered. sat can be polynomial-time solvable when the solving algorithm holds an exponential amount of information. it is also established that sat kolmogorov complexity is constant. it is argued that the amount of information in sat grows at least exponentially with the size of the input instance. the amount of information in sat is compared with the amount of information in the fixed code algorithms and generated over runtime.","doi":"","created":1704067200000,"updated":"2024-07-25","authors":["maciej drozdowski"]}
{"id":"2401.00953","title":"families of costs with zero and nonnegative mtw tensor in optimal   transport","categories":"math.ap cs.it cs.lg math.it stat.ml","abstract":"we compute explicitly the mtw tensor (or cross curvature) for the optimal transport problem on $\\mathbb{r}^n$ with a cost function of form $\\mathsf{c}(x, y) = \\mathsf{u}(x^{\\mathfrak{t}}y)$, where $\\mathsf{u}$ is a scalar function with inverse $\\mathsf{s}$, $x^{\\ft}y$ is a nondegenerate bilinear pairing of vectors $x, y$ belonging to an open subset of $\\mathbb{r}^n$. the condition that the mtw-tensor vanishes on null vectors under the kim-mccann metric is a fourth-order nonlinear ode, which could be reduced to a linear ode of the form $\\mathsf{s}^{(2)} - s\\mathsf{s}^{(1)} + p\\mathsf{s} = 0$ with constant coefficients $p$ and $s$. the resulting inverse functions include {\\it lambert} and {\\it generalized inverse hyperbolic\\slash trigonometric} functions. the square euclidean metric and $\\log$-type costs are equivalent to instances of these solutions. the optimal map for the family is also explicit. for cost functions of a similar form on a hyperboloid model of the hyperbolic space and unit sphere, we also express this tensor in terms of algebraic expressions in derivatives of $\\mathsf{s}$ using the gauss-codazzi equation, obtaining new families of strictly regular costs for these manifolds, including new families of {\\it power function costs}. we analyze the $\\sinh$-type hyperbolic cost, providing examples of $\\mathsf{c}$-convex functions and divergence.","doi":"","created":1704067200000,"updated":"","authors":["du nguyen"]}
{"id":"2401.00959","title":"creating an intelligent dementia-friendly living space: a feasibility   study integrating assistive robotics, wearable sensors, and spatial   technology","categories":"cs.hc","abstract":"this study investigates the integration of assistive therapeutic robotics, wearable sensors, and spatial sensors within an intelligent environment tailored for dementia care. the feasibility study aims to assess the collective impact of these technologies in enhancing care giving by seamlessly integrating supportive technology in the background. the wearable sensors track physiological data, while spatial sensors monitor geo-spatial information, integrated into a system supporting residents without necessitating technical expertise. the designed space fosters various activities, including robot interactions, medication delivery, physical exercises like walking on a treadmill (bruce protocol), entertainment, and household tasks, promoting cognitive stimulation through puzzles. physiological data revealed significant participant engagement during robot interactions, indicating the potential effectiveness of robot-assisted activities in enhancing the quality of life for residents.","doi":"","created":1704067200000,"updated":"","authors":["arshia a khan","rupak kumar das","anna martin","dale dowling","rana imtiaz"]}
{"id":"2401.00961","title":"automated model selection for tabular data","categories":"cs.lg cs.ai","abstract":"structured data in the form of tabular datasets contain features that are distinct and discrete, with varying individual and relative importances to the target. combinations of one or more features may be more predictive and meaningful than simple individual feature contributions. r's mixed effect linear models library allows users to provide such interactive feature combinations in the model design. however, given many features and possible interactions to select from, model selection becomes an exponentially difficult task. we aim to automate the model selection process for predictions on tabular datasets incorporating feature interactions while keeping computational costs small. the framework includes two distinct approaches for feature selection: a priority-based random grid search and a greedy search method. the priority-based approach efficiently explores feature combinations using prior probabilities to guide the search. the greedy method builds the solution iteratively by adding or removing features based on their impact. experiments on synthetic demonstrate the ability to effectively capture predictive feature combinations.","doi":"","created":1704067200000,"updated":"2024-05-28","authors":["avinash amballa","gayathri akkinapalli","manas madine","naga pavana priya yarrabolu","przemyslaw a. grabowicz"]}
{"id":"2401.00963","title":"leveraging large language models to boost dafny's developers   productivity","categories":"cs.se cs.lo cs.pl","abstract":"this research idea paper proposes leveraging large language models (llms) to enhance the productivity of dafny developers. although the use of verification-aware languages, such as dafny, has increased considerably in the last decade, these are still not widely adopted. often the cost of using such languages is too high, due to the level of expertise required from the developers and challenges that they often face when trying to prove a program correct. even though dafny automates a lot of the verification process, sometimes there are steps that are too complex for dafny to perform on its own. one such case is that of missing lemmas, i.e. dafny is unable to prove a result without being given further help in the form of a theorem that can assist it in the proof of the step.   in this paper, we describe preliminary work on a new dafny plugin that leverages llms to assist developers by generating suggestions for relevant lemmas that dafny is unable to discover and use. moreover, for the lemmas that cannot be proved automatically, the plugin also attempts to provide accompanying calculational proofs. we also discuss ideas for future work by describing a research agenda on using llms to increase the adoption of verification-aware languages in general, by increasing developers productivity and by reducing the level of expertise required for crafting formal specifications and proving program properties.","doi":"","created":1704067200000,"updated":"","authors":["álvaro silva","alexandra mendes","joão f. ferreira"]}
{"id":"2401.00964","title":"data augmentation techniques for cross-domain wifi csi-based human   activity recognition","categories":"cs.cv cs.ai cs.lg","abstract":"the recognition of human activities based on wifi channel state information (csi) enables contactless and visual privacy-preserving sensing in indoor environments. however, poor model generalization, due to varying environmental conditions and sensing hardware, is a well-known problem in this space. to address this issue, in this work, data augmentation techniques commonly used in image-based learning are applied to wifi csi to investigate their effects on model generalization performance in cross-scenario and cross-system settings. in particular, we focus on the generalization between line-of-sight (los) and non-line-of-sight (nlos) through-wall scenarios, as well as on the generalization between different antenna systems, which remains under-explored. we collect and make publicly available a dataset of csi amplitude spectrograms of human activities. utilizing this data, an ablation study is conducted in which activity recognition models based on the efficientnetv2 architecture are trained, allowing us to assess the effects of each augmentation on model generalization performance. the gathered results show that specific combinations of simple data augmentation techniques applied to csi amplitude data can significantly improve cross-scenario and cross-system generalization.","doi":"","created":1704067200000,"updated":"","authors":["julian strohmayer","martin kampel"]}
{"id":"2401.00965","title":"improve fidelity and utility of synthetic credit card transaction time   series from data-centric perspective","categories":"cs.lg","abstract":"exploring generative model training for synthetic tabular data, specifically in sequential contexts such as credit card transaction data, presents significant challenges. this paper addresses these challenges, focusing on attaining both high fidelity to actual data and optimal utility for machine learning tasks. we introduce five pre-processing schemas to enhance the training of the conditional probabilistic auto-regressive model (cpar), demonstrating incremental improvements in the synthetic data's fidelity and utility. upon achieving satisfactory fidelity levels, our attention shifts to training fraud detection models tailored for time-series data, evaluating the utility of the synthetic data. our findings offer valuable insights and practical guidelines for synthetic data practitioners in the finance sector, transitioning from real to synthetic datasets for training purposes, and illuminating broader methodologies for synthesizing credit card transaction time series.","doi":"","created":1704067200000,"updated":"","authors":["din-yin hsieh","chi-hua wang","guang cheng"]}
{"id":"2401.00971","title":"efficient multi-domain text recognition deep neural network   parameterization with residual adapters","categories":"cs.cv","abstract":"recent advancements in deep neural networks have markedly enhanced the performance of computer vision tasks, yet the specialized nature of these networks often necessitates extensive data and high computational power. addressing these requirements, this study presents a novel neural network model adept at optical character recognition (ocr) across diverse domains, leveraging the strengths of multi-task learning to improve efficiency and generalization. the model is designed to achieve rapid adaptation to new domains, maintain a compact size conducive to reduced computational resource demand, ensure high accuracy, retain knowledge from previous learning experiences, and allow for domain-specific performance improvements without the need to retrain entirely. rigorous evaluation on open datasets has validated the model's ability to significantly lower the number of trainable parameters without sacrificing performance, indicating its potential as a scalable and adaptable solution in the field of computer vision, particularly for applications in optical text recognition.","doi":"","created":1704067200000,"updated":"","authors":["jiayou chao","wei zhu"]}
{"id":"2401.00972","title":"robust meta-model for predicting the need for blood transfusion in   non-traumatic icu patients","categories":"cs.lg cs.cy stat.ap","abstract":"objective: blood transfusions, crucial in managing anemia and coagulopathy in icu settings, require accurate prediction for effective resource allocation and patient risk assessment. however, existing clinical decision support systems have primarily targeted a particular patient demographic with unique medical conditions and focused on a single type of blood transfusion. this study aims to develop an advanced machine learning-based model to predict the probability of transfusion necessity over the next 24 hours for a diverse range of non-traumatic icu patients.   methods: we conducted a retrospective cohort study on 72,072 adult non-traumatic icu patients admitted to a high-volume us metropolitan academic hospital between 2016 and 2020. we developed a meta-learner and various machine learning models to serve as predictors, training them annually with four-year data and evaluating on the fifth, unseen year, iteratively over five years.   results: the experimental results revealed that the meta-model surpasses the other models in different development scenarios. it achieved notable performance metrics, including an area under the receiver operating characteristic (auroc) curve of 0.97, an accuracy rate of 0.93, and an f1-score of 0.89 in the best scenario.   conclusion: this study pioneers the use of machine learning models for predicting blood transfusion needs in a diverse cohort of critically ill patients. the findings of this evaluation confirm that our model not only predicts transfusion requirements effectively but also identifies key biomarkers for making transfusion decisions.","doi":"","created":1704067200000,"updated":"","authors":["alireza rafiei","ronald moore","tilendra choudhary","curtis marshall","geoffrey smith","john d. roback","ravi m. patel","cassandra d. josephson","rishikesan kamaleswaran"]}
{"id":"2401.00973","title":"facebook report on privacy of fnirs data","categories":"cs.lg cs.cr","abstract":"the primary goal of this project is to develop privacy-preserving machine learning model training techniques for fnirs data. this project will build a local model in a centralized setting with both differential privacy (dp) and certified robustness. it will also explore collaborative federated learning to train a shared model between multiple clients without sharing local fnirs datasets. to prevent unintentional private information leakage of such clients' private datasets, we will also implement dp in the federated learning setting.","doi":"","created":1704067200000,"updated":"","authors":["md imran hossen","sai venkatesh chilukoti","liqun shan","vijay srinivas tida","xiali hei"]}
{"id":"2401.00974","title":"downstream task-oriented generative model selections on synthetic data   training for fraud detection models","categories":"cs.lg cs.ai","abstract":"devising procedures for downstream task-oriented generative model selections is an unresolved problem of practical importance. existing studies focused on the utility of a single family of generative models. they provided limited insights on how synthetic data practitioners select the best family generative models for synthetic training tasks given a specific combination of machine learning model class and performance metric. in this paper, we approach the downstream task-oriented generative model selections problem in the case of training fraud detection models and investigate the best practice given different combinations of model interpretability and model performance constraints. our investigation supports that, while both neural network(nn)-based and bayesian network(bn)-based generative models are both good to complete synthetic training task under loose model interpretability constrain, the bn-based generative models is better than nn-based when synthetic training fraud detection model under strict model interpretability constrain. our results provides practical guidance for machine learning practitioner who is interested in replacing their training dataset from real to synthetic, and shed lights on more general downstream task-oriented generative model selection problems.","doi":"","created":1704067200000,"updated":"","authors":["yinan cheng","chi-hua wang","vamsi k. potluru","tucker balch","guang cheng"]}
{"id":"2401.00978","title":"evolutionary alternating direction method of multipliers for constrained   multi-objective optimization with unknown constraints","categories":"cs.ne","abstract":"constrained multi-objective optimization problems (cmops) pervade real-world applications in science, engineering, and design. constraint violation has been a building block in designing evolutionary multi-objective optimization algorithms for solving constrained multi-objective optimization problems. however, in certain scenarios, constraint functions might be unknown or inadequately defined, making constraint violation unattainable and potentially misleading for conventional constrained evolutionary multi-objective optimization algorithms. to address this issue, we present the first of its kind evolutionary optimization framework, inspired by the principles of the alternating direction method of multipliers that decouples objective and constraint functions. this framework tackles cmops with unknown constraints by reformulating the original problem into an additive form of two subproblems, each of which is allotted a dedicated evolutionary population. notably, these two populations operate towards complementary evolutionary directions during their optimization processes. in order to minimize discrepancy, their evolutionary directions alternate, aiding the discovery of feasible solutions. comparative experiments conducted against five state-of-the-art constrained evolutionary multi-objective optimization algorithms, on 120 benchmark test problem instances with varying properties, as well as two real-world engineering optimization problems, demonstrate the effectiveness and superiority of our proposed framework. its salient features include faster convergence and enhanced resilience to various pareto front shapes.","doi":"","created":1704067200000,"updated":"","authors":["shuang li","ke li","wei li","ming yang"]}
{"id":"2401.00979","title":"3d visibility-aware generalizable neural radiance fields for interacting   hands","categories":"cs.cv","abstract":"neural radiance fields (nerfs) are promising 3d representations for scenes, objects, and humans. however, most existing methods require multi-view inputs and per-scene training, which limits their real-life applications. moreover, current methods focus on single-subject cases, leaving scenes of interacting hands that involve severe inter-hand occlusions and challenging view variations remain unsolved. to tackle these issues, this paper proposes a generalizable visibility-aware nerf (va-nerf) framework for interacting hands. specifically, given an image of interacting hands as input, our va-nerf first obtains a mesh-based representation of hands and extracts their corresponding geometric and textural features. subsequently, a feature fusion module that exploits the visibility of query points and mesh vertices is introduced to adaptively merge features of both hands, enabling the recovery of features in unseen areas. additionally, our va-nerf is optimized together with a novel discriminator within an adversarial learning paradigm. in contrast to conventional discriminators that predict a single real\/fake label for the synthesized image, the proposed discriminator generates a pixel-wise visibility map, providing fine-grained supervision for unseen areas and encouraging the va-nerf to improve the visual quality of synthesized images. experiments on the interhand2.6m dataset demonstrate that our proposed va-nerf outperforms conventional nerfs significantly. project page: \\url{https:\/\/github.com\/xuanhuang0\/vanerf}.","doi":"","created":1704067200000,"updated":"","authors":["xuan huang","hanhui li","zejun yang","zhisheng wang","xiaodan liang"]}
{"id":"2401.00980","title":"trends in practical student peer-review","categories":"cs.dl","abstract":"while much of the literature on student peer-review focusses on the success (or otherwise) of individual activities in specific classes (often implemented as part of scholarly research projects) there is little by way of published data giving an overview of the range and variety of such activities as used in practice. as the creators, administrators and maintainers of the aropa peer review tool, we have unique access to meta-information about peer-review assessments conducted in classes in institutions across the world, together with the variety of class sizes, subjects, rubric design etc. we reported on some of the key assessment configuration data in a 2018 publication covering a period of eight years; here we provide an update on this data, five years later, with particular comment on trends, academic discipline coverage and the possible effect of online delivery during the covid-19 pandemic.","doi":"","created":1704067200000,"updated":"","authors":["helen c. purchase","john hamer"]}
{"id":"2401.00981","title":"machine learning classification of alzheimer's disease stages using   cerebrospinal fluid biomarkers alone","categories":"cs.lg q-bio.qm stat.ap","abstract":"early diagnosis of alzheimer's disease is a challenge because the existing methodologies do not identify the patients in their preclinical stage, which can last up to a decade prior to the onset of clinical symptoms. several research studies demonstrate the potential of cerebrospinal fluid biomarkers, amyloid beta 1-42, t-tau, and p-tau, in early diagnosis of alzheimer's disease stages. in this work, we used machine learning models to classify different stages of alzheimer's disease based on the cerebrospinal fluid biomarker levels alone. an electronic health record of patients from the national alzheimer's coordinating centre database was analyzed and the patients were subdivided based on mini-mental state scores and clinical dementia ratings. statistical and correlation analyses were performed to identify significant differences between the alzheimer's stages. afterward, machine learning classifiers including k-nearest neighbors, ensemble boosted tree, ensemble bagged tree, support vector machine, logistic regression, and naive bayes classifiers were employed to classify the alzheimer's disease stages. the results demonstrate that ensemble boosted tree (84.4%) and logistic regression (73.4%) provide the highest accuracy for binary classification, while ensemble bagged tree (75.4%) demonstrates better accuracy for multiclassification. the findings from this research are expected to help clinicians in making an informed decision regarding the early diagnosis of alzheimer's from the cerebrospinal fluid biomarkers alone, monitoring of the disease progression, and implementation of appropriate intervention measures.","doi":"","created":1704067200000,"updated":"","authors":["vivek kumar tiwari","premananda indic","shawana tabassum"]}
{"id":"2401.00983","title":"cca-secure hybrid encryption in correlated randomness model and kem   combiners","categories":"cs.cr","abstract":"a hybrid encryption (he) system is an efficient public key encryption system for arbitrarily long messages. an he system consists of a public key component called key encapsulation mechanism (kem), and a symmetric key component called data encapsulation mechanism (dem). the he encryption algorithm uses a kem generated key k to encapsulate the message using dem, and send the ciphertext together with the encapsulaton of k, to the decryptor who decapsulates k and uses it to decapsulate the message using the corresponding kem and dem components. the kem\/dem composition theorem proves that if kem and dem satisfy well-defined security notions, then he will be secure with well defined security. we introduce he in correlated randomness model where the encryption and decryption algorithms have samples of correlated random variables that are partially leaked to the adversary. security of the new kem\/dem paradigm is defined against computationally unbounded or polynomially bounded adversaries. we define ikem and ckem with respective information theoretic computational security, and prove a composition theorem for them and a computationally secure dem, resulting in secure hes with proved computational security (cpa and cca) and without any computational assumption. we construct two ikems that provably satisfy the required security notions of the composition theorem. the ikems are used to construct two efficient quantum-resistant hes when used with an aes based dem. we also define and construct combiners with proved security that combine the new kem\/dem paradigm of he with the traditional public key based paradigm of he.","doi":"","created":1704067200000,"updated":"2024-03-24","authors":["somnath panja","setareh sharifian","shaoquan jiang","reihaneh safavi-naini"]}
{"id":"2401.00986","title":"real-time object detection in occluded environment with background   cluttering effects using deep learning","categories":"cs.cv cs.ai","abstract":"detection of small, undetermined moving objects or objects in an occluded environment with a cluttered background is the main problem of computer vision. this greatly affects the detection accuracy of deep learning models. to overcome these problems, we concentrate on deep learning models for real-time detection of cars and tanks in an occluded environment with a cluttered background employing ssd and yolo algorithms and improved precision of detection and reduce problems faced by these models. the developed method makes the custom dataset and employs a preprocessing technique to clean the noisy dataset. for training the developed model we apply the data augmentation technique to balance and diversify the data. we fine-tuned, trained, and evaluated these models on the established dataset by applying these techniques and highlighting the results we got more accurately than without applying these techniques. the accuracy and frame per second of the ssd-mobilenet v2 model are higher than yolo v3 and yolo v4. furthermore, by employing various techniques like data enhancement, noise reduction, parameter optimization, and model fusion we improve the effectiveness of detection and recognition. we further added a counting algorithm, and target attributes experimental comparison, and made a graphical user interface system for the developed model with features of object counting, alerts, status, resolution, and frame per second. subsequently, to justify the importance of the developed method analysis of yolo v3, v4, and ssd were incorporated. which resulted in the overall completion of the proposed method.","doi":"","created":1704067200000,"updated":"","authors":["syed muhammad aamir","hongbin ma","malak abid ali khan","muhammad aaqib"]}
{"id":"2401.00988","title":"holistic autonomous driving understanding by bird's-eye-view injected   multi-modal large models","categories":"cs.cv","abstract":"the rise of multimodal large language models (mllms) has spurred interest in language-based driving tasks. however, existing research typically focuses on limited tasks and often omits key multi-view and temporal information which is crucial for robust autonomous driving. to bridge these gaps, we introduce nuinstruct, a novel dataset with 91k multi-view video-qa pairs across 17 subtasks, where each task demands holistic information (e.g., temporal, multi-view, and spatial), significantly elevating the challenge level. to obtain nuinstruct, we propose a novel sql-based method to generate instruction-response pairs automatically, which is inspired by the driving logical progression of humans. we further present bev-inmllm, an end-to-end method for efficiently deriving instruction-aware bird's-eye-view (bev) features, language-aligned for large language models. bev-inmllm integrates multi-view, spatial awareness, and temporal semantics to enhance mllms' capabilities on nuinstruct tasks. moreover, our proposed bev injection module is a plug-and-play method for existing mllms. our experiments on nuinstruct demonstrate that bev-inmllm significantly outperforms existing mllms, e.g. around 9% improvement on various tasks. we plan to release our nuinstruct for future research development.","doi":"","created":1704067200000,"updated":"","authors":["xinpeng ding","jinahua han","hang xu","xiaodan liang","wei zhang","xiaomeng li"]}
{"id":"2401.00989","title":"diversity-aware buffer for coping with temporally correlated data   streams in online test-time adaptation","categories":"cs.cv","abstract":"since distribution shifts are likely to occur after a model's deployment and can drastically decrease the model's performance, online test-time adaptation (tta) continues to update the model during test-time, leveraging the current test data. in real-world scenarios, test data streams are not always independent and identically distributed (i.i.d.). instead, they are frequently temporally correlated, making them non-i.i.d. many existing methods struggle to cope with this scenario. in response, we propose a diversity-aware and category-balanced buffer that can simulate an i.i.d. data stream, even in non-i.i.d. scenarios. combined with a diversity and entropy-weighted entropy loss, we show that a stable adaptation is possible on a wide range of corruptions and natural domain shifts, based on imagenet. we achieve state-of-the-art results on most considered benchmarks.","doi":"","created":1704067200000,"updated":"","authors":["mario döbler","florian marencke","robert a. marsden","bin yang"]}
{"id":"2401.00991","title":"a novel evaluation framework for assessing resilience against prompt   injection attacks in large language models","categories":"cs.cr","abstract":"prompt injection attacks exploit vulnerabilities in large language models (llms) to manipulate the model into unintended actions or generate malicious content. as llm integrated applications gain wider adoption, they face growing susceptibility to such attacks. this study introduces a novel evaluation framework for quantifying the resilience of applications. the framework incorporates innovative techniques designed to ensure representativeness, interpretability, and robustness. to ensure the representativeness of simulated attacks on the application, a meticulous selection process was employed, resulting in 115 carefully chosen attacks based on coverage and relevance. for enhanced interpretability, a second llm was utilized to evaluate the responses generated from these simulated attacks. unlike conventional malicious content classifiers that provide only a confidence score, the llm-based evaluation produces a score accompanied by an explanation, thereby enhancing interpretability. subsequently, a resilience score is computed by assigning higher weights to attacks with greater impact, thus providing a robust measurement of the application resilience. to assess the framework's efficacy, it was applied on two llms, namely llama2 and chatglm. results revealed that llama2, the newer model exhibited higher resilience compared to chatglm. this finding substantiates the effectiveness of the framework, aligning with the prevailing notion that newer models tend to possess greater resilience. moreover, the framework exhibited exceptional versatility, requiring only minimal adjustments to accommodate emerging attack techniques and classifications, thereby establishing itself as an effective and practical solution. overall, the framework offers valuable insights that empower organizations to make well-informed decisions to fortify their applications against potential threats from prompt injection.","doi":"","created":1704067200000,"updated":"","authors":["daniel wankit yip","aysan esmradi","chun fai chan"]}
{"id":"2401.00994","title":"detection and defense against prominent attacks on preconditioned   llm-integrated virtual assistants","categories":"cs.cr","abstract":"the emergence of llm (large language model) integrated virtual assistants has brought about a rapid transformation in communication dynamics. during virtual assistant development, some developers prefer to leverage the system message, also known as an initial prompt or custom prompt, for preconditioning purposes. however, it is important to recognize that an excessive reliance on this functionality raises the risk of manipulation by malicious actors who can exploit it with carefully crafted prompts. such malicious manipulation poses a significant threat, potentially compromising the accuracy and reliability of the virtual assistant's responses. consequently, safeguarding the virtual assistants with detection and defense mechanisms becomes of paramount importance to ensure their safety and integrity. in this study, we explored three detection and defense mechanisms aimed at countering attacks that target the system message. these mechanisms include inserting a reference key, utilizing an llm evaluator, and implementing a self-reminder. to showcase the efficacy of these mechanisms, they were tested against prominent attack techniques. our findings demonstrate that the investigated mechanisms are capable of accurately identifying and counteracting the attacks. the effectiveness of these mechanisms underscores their potential in safeguarding the integrity and reliability of virtual assistants, reinforcing the importance of their implementation in real-world scenarios. by prioritizing the security of virtual assistants, organizations can maintain user trust, preserve the integrity of the application, and uphold the high standards expected in this era of transformative technologies.","doi":"","created":1704067200000,"updated":"","authors":["chun fai chan","daniel wankit yip","aysan esmradi"]}
{"id":"2401.00996","title":"safety and performance, why not both? bi-objective optimized model   compression against heterogeneous attacks toward ai software deployment","categories":"cs.ai cs.cr cs.se","abstract":"the size of deep learning models in artificial intelligence (ai) software is increasing rapidly, hindering the large-scale deployment on resource-restricted devices (e.g., smartphones). to mitigate this issue, ai software compression plays a crucial role, which aims to compress model size while keeping high performance. however, the intrinsic defects in a big model may be inherited by the compressed one. such defects may be easily leveraged by adversaries, since a compressed model is usually deployed in a large number of devices without adequate protection. in this article, we aim to address the safe model compression problem from the perspective of safety-performance co-optimization. specifically, inspired by the test-driven development (tdd) paradigm in software engineering, we propose a test-driven sparse training framework called safecompress. by simulating the attack mechanism as safety testing, safecompress can automatically compress a big model to a small one following the dynamic sparse training paradigm. then, considering two kinds of representative and heterogeneous attack mechanisms, i.e., black-box membership inference attack and white-box membership inference attack, we develop two concrete instances called bmia-safecompress and wmia-safecompress. further, we implement another instance called mmia-safecompress by extending safecompress to defend against the occasion when adversaries conduct black-box and white-box membership inference attacks simultaneously. we conduct extensive experiments on five datasets for both computer vision and natural language processing tasks. the results show the effectiveness and generalizability of our framework. we also discuss how to adapt safecompress to other attacks besides membership inference attack, demonstrating the flexibility of safecompress.","doi":"","created":1704067200000,"updated":"","authors":["jie zhu","leye wang","xiao han","anmin liu","tao xie"]}
{"id":"2401.00997","title":"$\\phi$ index: a standardized scale-independent citation indicator","categories":"cs.dl","abstract":"the sensitivity of impact factors (ifs) to journal size causes systematic bias in if rankings, in a process akin to {\\it stacking the cards}: a random ``journal'' of $n$ papers can attain a range of if values that decreases rapidly with size, as $\\sim 1\/\\sqrt{n}$ . the central limit theorem, which underlies this effect, also allows us to correct it by standardizing citation averages for scale {\\it and} subject in a geometrically intuitive manner analogous to calculating the $z$-score. we thus propose the $\\phi$ index, a standardized scale- and subject-independent citation average. the $\\phi$ index passes the ``random sample test'', a simple check for scale and subject independence that we argue ought to be used for every citation indicator. we present $\\phi$ index rankings for 12,173 journals using 2020 journal citation reports data. we show how scale standardization alone affects rankings, demonstrate the additional effect of subject standardization for monodisciplinary journals, and discuss how to treat multidisciplinary journals. $\\phi$ index rankings offer a clear improvement over if rankings. and because the $\\phi$ index methodology is general, it can also be applied to compare individual researchers, universities, or countries.","doi":"","created":1704067200000,"updated":"2024-04-21","authors":["manolis antonoyiannakis"]}
{"id":"2401.01009","title":"quantum state preparation using an exact cnot synthesis formulation","categories":"cs.it math.it quant-ph","abstract":"minimizing the use of cnot gates in quantum state preparation is a crucial step in quantum compilation, as they introduce coupling constraints and more noise than single-qubit gates. reducing the number of cnot gates can lead to more efficient and accurate quantum computations. however, the lack of compatibility to model superposition and entanglement challenges the scalability and optimality of cnot optimization algorithms on classical computers. in this paper, we propose an effective state preparation algorithm using an exact cnot synthesis formulation. our method represents a milestone as the first design automation algorithm to surpass manual design, reducing the best cnot numbers to prepare a dicke state by 2x. for general states with up to 20 qubits, our method reduces the cnot number by 9% and 32% for dense and sparse states, on average, compared to the latest algorithms.","doi":"","created":1704067200000,"updated":"","authors":["hanyu wang","bochen tan","jason cong","giovanni de micheli"]}
{"id":"2401.01010","title":"unsupervised continual anomaly detection with contrastively-learned   prompt","categories":"cs.cv cs.lg","abstract":"unsupervised anomaly detection (uad) with incremental training is crucial in industrial manufacturing, as unpredictable defects make obtaining sufficient labeled data infeasible. however, continual learning methods primarily rely on supervised annotations, while the application in uad is limited due to the absence of supervision. current uad methods train separate models for different classes sequentially, leading to catastrophic forgetting and a heavy computational burden. to address this issue, we introduce a novel unsupervised continual anomaly detection framework called ucad, which equips the uad with continual learning capability through contrastively-learned prompts. in the proposed ucad, we design a continual prompting module (cpm) by utilizing a concise key-prompt-knowledge memory bank to guide task-invariant `anomaly' model predictions using task-specific `normal' knowledge. moreover, structure-based contrastive learning (scl) is designed with the segment anything model (sam) to improve prompt learning and anomaly segmentation results. specifically, by treating sam's masks as structure, we draw features within the same mask closer and push others apart for general feature representations. we conduct comprehensive experiments and set the benchmark on unsupervised continual anomaly detection and segmentation, demonstrating that our method is significantly better than anomaly detection methods, even with rehearsal training. the code will be available at https:\/\/github.com\/shirowalker\/ucad.","doi":"","created":1704067200000,"updated":"","authors":["jiaqi liu","kai wu","qiang nie","ying chen","bin-bin gao","yong liu","jinbao wang","chengjie wang","feng zheng"]}
{"id":"2401.01011","title":"fixing your own smells: adding a mistake-based familiarisation step when   teaching code refactoring","categories":"cs.se","abstract":"programming problems can be solved in a multitude of functionally correct ways, but the quality of these solutions (e.g. readability, maintainability) can vary immensely. when code quality is poor, symptoms emerge in the form of 'code smells', which are specific negative characteristics (e.g. duplicate code) that can be resolved by applying refactoring patterns. many undergraduate computing curricula train students on this software engineering practice, often doing so via exercises on unfamiliar instructor-provided code. our observation, however, is that this makes it harder for novices to internalise refactoring as part of their own development practices. in this paper, we propose a new approach to teaching refactoring, in which students must first complete a programming exercise constrained to ensure they will produce a code smell. this simple intervention is based on the idea that learning refactoring is easier if students are familiar with the code (having built it), that it brings refactoring closer to their regular development practice, and that it presents a powerful opportunity to learn from a 'mistake'. we designed and conducted a study with 35 novice undergraduates in which they completed various refactoring exercises alternately taught using a traditional and our 'mistake-based' approach, finding that students were significantly more effective and confident at completing exercises using the latter.","doi":"10.1145\/3626252.3630856","created":1704067200000,"updated":"","authors":["ivan tan","christopher m. poskitt"]}
{"id":"2401.01013","title":"boosting transformer's robustness and efficacy in ppg signal artifact   detection with self-supervised learning","categories":"cs.lg eess.sp","abstract":"recent research at chu sainte justine's pediatric critical care unit (picu) has revealed that traditional machine learning methods, such as semi-supervised label propagation and k-nearest neighbors, outperform transformer-based models in artifact detection from ppg signals, mainly when data is limited. this study addresses the underutilization of abundant unlabeled data by employing self-supervised learning (ssl) to extract latent features from these data, followed by fine-tuning on labeled data. our experiments demonstrate that ssl significantly enhances the transformer model's ability to learn representations, improving its robustness in artifact classification tasks. among various ssl techniques, including masking, contrastive learning, and dino (self-distillation with no labels)-contrastive learning exhibited the most stable and superior performance in small ppg datasets. further, we delve into optimizing contrastive loss functions, which are crucial for contrastive ssl. inspired by infonce, we introduce a novel contrastive loss function that facilitates smoother training and better convergence, thereby enhancing performance in artifact classification. in summary, this study establishes the efficacy of ssl in leveraging unlabeled data, particularly in enhancing the capabilities of the transformer model. this approach holds promise for broader applications in picu environments, where annotated data is often limited.","doi":"","created":1704067200000,"updated":"","authors":["thanh-dung le"]}
{"id":"2401.01019","title":"approximating single-source personalized pagerank with absolute error   guarantees","categories":"cs.ds","abstract":"personalized pagerank (ppr) is an extensively studied and applied node proximity measure in graphs. for a pair of nodes $s$ and $t$ on a graph $g=(v,e)$, the ppr value $\\pi(s,t)$ is defined as the probability that an $\\alpha$-discounted random walk from $s$ terminates at $t$, where the walk terminates with probability $\\alpha$ at each step. we study the classic single-source ppr query, which asks for ppr approximations from a given source node $s$ to all nodes in the graph. specifically, we aim to provide approximations with absolute error guarantees, ensuring that the resultant ppr estimates $\\hat{\\pi}(s,t)$ satisfy $\\max_{t\\in v}\\big|\\hat{\\pi}(s,t)-\\pi(s,t)\\big|\\le\\varepsilon$ for a given error bound $\\varepsilon$. we propose an algorithm that achieves this with high probability, with an expected running time of   - $\\widetilde{o}\\big(\\sqrt{m}\/\\varepsilon\\big)$ for directed graphs, where $m=|e|$;   - $\\widetilde{o}\\big(\\sqrt{d_{\\mathrm{max}}}\/\\varepsilon\\big)$ for undirected graphs, where $d_{\\mathrm{max}}$ is the maximum node degree in the graph;   - $\\widetilde{o}\\left(n^{\\gamma-1\/2}\/\\varepsilon\\right)$ for power-law graphs, where $n=|v|$ and $\\gamma\\in\\left(\\frac{1}{2},1\\right)$ is the extent of the power law.   these sublinear bounds improve upon existing results. we also study the case when degree-normalized absolute error guarantees are desired, requiring $\\max_{t\\in v}\\big|\\hat{\\pi}(s,t)\/d(t)-\\pi(s,t)\/d(t)\\big|\\le\\varepsilon_d$ for a given error bound $\\varepsilon_d$, where the graph is undirected and $d(t)$ is the degree of node $t$. we give an algorithm that provides this error guarantee with high probability, achieving an expected complexity of $\\widetilde{o}\\left(\\sqrt{\\sum_{t\\in v}\\pi(s,t)\/d(t)}\\big\/\\varepsilon_d\\right)$. this improves over the previously known $o(1\/\\varepsilon_d)$ complexity.","doi":"10.4230\/lipics.icdt.2024.9","created":1704067200000,"updated":"","authors":["zhewei wei","ji-rong wen","mingji yang"]}
{"id":"2401.01023","title":"cautionsuicide: a deep learning based approach for detecting suicidal   ideation in real time chatbot conversation","categories":"cs.hc cs.lg","abstract":"suicide is recognized as one of the most serious concerns in the modern society. suicide causes tragedy that affects countries, communities, and families. there are many factors that lead to suicidal ideations. early detection of suicidal ideations can help to prevent suicide occurrence by providing the victim with the required professional support, especially when the victim does not recognize the danger of having suicidal ideations. as technology usage has increased, people share and express their ideations digitally via social media, chatbots, and other digital platforms. in this paper, we proposed a novel, simple deep learning-based model to detect suicidal ideations in digital content, mainly focusing on chatbots as the primary data source. in addition, we provide a framework that employs the proposed suicide detection integration with a chatbot-based support system.","doi":"","created":1704067200000,"updated":"","authors":["nelly elsayed","zag elsayed","murat ozer"]}
{"id":"2401.01035","title":"online continual domain adaptation for semantic image segmentation using   internal representations","categories":"cs.cv","abstract":"semantic segmentation models trained on annotated data fail to generalize well when the input data distribution changes over extended time period, leading to requiring re-training to maintain performance. classic unsupervised domain adaptation (uda) attempts to address a similar problem when there is target domain with no annotated data points through transferring knowledge from a source domain with annotated data. we develop an online uda algorithm for semantic segmentation of images that improves model generalization on unannotated domains in scenarios where source data access is restricted during adaptation. we perform model adaptation is by minimizing the distributional distance between the source latent features and the target features in a shared embedding space. our solution promotes a shared domain-agnostic latent feature space between the two domains, which allows for classifier generalization on the target dataset. to alleviate the need of access to source samples during adaptation, we approximate the source latent feature distribution via an appropriate surrogate distribution, in this case a gassian mixture model (gmm). we evaluate our approach on well established semantic segmentation datasets and demonstrate it compares favorably against state-of-the-art (sota) uda semantic segmentation methods.","doi":"","created":1704067200000,"updated":"","authors":["serban stan","mohammad rostami"]}
{"id":"2401.01036","title":"pte: axiomatic semantics based compiler testing","categories":"cs.se","abstract":"the correctness of a compiler affects the correctness of every program written in the language, and thus must be thoroughly evaluated. existing automatic compiler testing methods however either rely on weak oracles (e.g., a program behaves the same if only dead code is modified), or require substantial initial effort (e.g., having a complete operational language semantics). while the former prevents a comprehensive correctness evaluation, the latter makes those methods irrelevant in practice. in this work, we propose an axiomatic semantics based approach for testing compilers, called pte. the idea is to incrementally develop a set of ``axioms'' capturing anecdotes of the language semantics in the form of \\emph{(\\textbf{p}recondition, \\textbf{t}ransformation, \\textbf{e}xpectation) triples, which allows us to test the compiler automatically.} such axioms are written in the same language whose compiler is under test, and can be developed either based on the language specification, or by generalizing the bug reports. pte has been applied to a newly developed compiler (i.e., cangjie) and a mature compiler (i.e., java), and successfully identified 42 implementation bugs and 9 potential language design issues.","doi":"","created":1704067200000,"updated":"","authors":["guoliang dong","jun sun","richard schumi","bo wang","xinyu wang"]}
{"id":"2401.01040","title":"towards cognitive ai systems: a survey and prospective on neuro-symbolic   ai","categories":"cs.ai cs.ar","abstract":"the remarkable advancements in artificial intelligence (ai), primarily driven by deep neural networks, have significantly impacted various aspects of our lives. however, the current challenges surrounding unsustainable computational trajectories, limited robustness, and a lack of explainability call for the development of next-generation ai systems. neuro-symbolic ai (nsai) emerges as a promising paradigm, fusing neural, symbolic, and probabilistic approaches to enhance interpretability, robustness, and trustworthiness while facilitating learning from much less data. recent nsai systems have demonstrated great potential in collaborative human-ai scenarios with reasoning and cognitive capabilities. in this paper, we provide a systematic review of recent progress in nsai and analyze the performance characteristics and computational operators of nsai models. furthermore, we discuss the challenges and potential future directions of nsai from both system and architectural perspectives.","doi":"","created":1704153600000,"updated":"","authors":["zishen wan","che-kai liu","hanchen yang","chaojian li","haoran you","yonggan fu","cheng wan","tushar krishna","yingyan lin","arijit raychowdhury"]}
{"id":"2401.01042","title":"relating events and frames based on self-supervised learning and   uncorrelated conditioning for unsupervised domain adaptation","categories":"cs.cv","abstract":"event-based cameras provide accurate and high temporal resolution measurements for performing computer vision tasks in challenging scenarios, such as high-dynamic range environments and fast-motion maneuvers. despite their advantages, utilizing deep learning for event-based vision encounters a significant obstacle due to the scarcity of annotated data caused by the relatively recent emergence of event-based cameras. to overcome this limitation, leveraging the knowledge available from annotated data obtained with conventional frame-based cameras presents an effective solution based on unsupervised domain adaptation. we propose a new algorithm tailored for adapting a deep neural network trained on annotated frame-based data to generalize well on event-based unannotated data. our approach incorporates uncorrelated conditioning and self-supervised learning in an adversarial learning scheme to close the gap between the two source and target domains. by applying self-supervised learning, the algorithm learns to align the representations of event-based data with those from frame-based camera data, thereby facilitating knowledge transfer.furthermore, the inclusion of uncorrelated conditioning ensures that the adapted model effectively distinguishes between event-based and conventional data, enhancing its ability to classify event-based images accurately.through empirical experimentation and evaluation, we demonstrate that our algorithm surpasses existing approaches designed for the same purpose using two benchmarks. the superior performance of our solution is attributed to its ability to effectively utilize annotated data from frame-based cameras and transfer the acquired knowledge to the event-based vision domain.","doi":"","created":1704153600000,"updated":"","authors":["mohammad rostami","dayuan jian"]}
{"id":"2401.01044","title":"auffusion: leveraging the power of diffusion and large language models   for text-to-audio generation","categories":"cs.sd cs.ai cs.cl eess.as","abstract":"recent advancements in diffusion models and large language models (llms) have significantly propelled the field of aigc. text-to-audio (tta), a burgeoning aigc application designed to generate audio from natural language prompts, is attracting increasing attention. however, existing tta studies often struggle with generation quality and text-audio alignment, especially for complex textual inputs. drawing inspiration from state-of-the-art text-to-image (t2i) diffusion models, we introduce auffusion, a tta system adapting t2i model frameworks to tta task, by effectively leveraging their inherent generative strengths and precise cross-modal alignment. our objective and subjective evaluations demonstrate that auffusion surpasses previous tta approaches using limited data and computational resource. furthermore, previous studies in t2i recognizes the significant impact of encoder choice on cross-modal alignment, like fine-grained details and object bindings, while similar evaluation is lacking in prior tta works. through comprehensive ablation studies and innovative cross-attention map visualizations, we provide insightful assessments of text-audio alignment in tta. our findings reveal auffusion's superior capability in generating audios that accurately match textual descriptions, which further demonstrated in several related tasks, such as audio style transfer, inpainting and other manipulations. our implementation and demos are available at https:\/\/auffusion.github.io.","doi":"","created":1704153600000,"updated":"","authors":["jinlong xue","yayue deng","yingming gao","ya li"]}
{"id":"2401.01047","title":"sharp analysis of power iteration for tensor pca","categories":"cs.lg cs.na math.na stat.ml","abstract":"we investigate the power iteration algorithm for the tensor pca model introduced in richard and montanari (2014). previous work studying the properties of tensor power iteration is either limited to a constant number of iterations, or requires a non-trivial data-independent initialization. in this paper, we move beyond these limitations and analyze the dynamics of randomly initialized tensor power iteration up to polynomially many steps. our contributions are threefold: first, we establish sharp bounds on the number of iterations required for power method to converge to the planted signal, for a broad range of the signal-to-noise ratios. second, our analysis reveals that the actual algorithmic threshold for power iteration is smaller than the one conjectured in literature by a polylog(n) factor, where n is the ambient dimension. finally, we propose a simple and effective stopping criterion for power iteration, which provably outputs a solution that is highly correlated with the true signal. extensive numerical experiments verify our theoretical results.","doi":"","created":1704153600000,"updated":"","authors":["yuchen wu","kangjie zhou"]}
{"id":"2401.01048","title":"pac-bayesian domain adaptation bounds for multi-view learning","categories":"cs.lg stat.ml","abstract":"this paper presents a series of new results for domain adaptation in the multi-view learning setting. the incorporation of multiple views in the domain adaptation was paid little attention in the previous studies. in this way, we propose an analysis of generalization bounds with pac-bayesian theory to consolidate the two paradigms, which are currently treated separately. firstly, building on previous work by germain et al., we adapt the distance between distribution proposed by germain et al. for domain adaptation with the concept of multi-view learning. thus, we introduce a novel distance that is tailored for the multi-view domain adaptation setting. then, we give pac-bayesian bounds for estimating the introduced divergence. finally, we compare the different new bounds with the previous studies.","doi":"","created":1704153600000,"updated":"","authors":["mehdi hennequin","khalid benabdeslem","haytham elghazel"]}
{"id":"2401.01053","title":"cheetah: natural language generation for 517 african languages","categories":"cs.cl","abstract":"low-resource african languages pose unique challenges for natural language processing (nlp) tasks, including natural language generation (nlg). in this paper, we develop cheetah, a massively multilingual nlg language model for african languages. cheetah supports 517 african languages and language varieties, allowing us to address the scarcity of nlg resources and provide a solution to foster linguistic diversity. we demonstrate the effectiveness of cheetah through comprehensive evaluations across six generation downstream tasks. in five of the six tasks, cheetah significantly outperforms other models, showcasing its remarkable performance for generating coherent and contextually appropriate text in a wide range of african languages. we additionally conduct a detailed human evaluation to delve deeper into the linguistic capabilities of cheetah. the introduction of cheetah has far-reaching benefits for linguistic diversity. by leveraging pretrained models and adapting them to specific languages, our approach facilitates the development of practical nlg applications for african communities. the findings of this study contribute to advancing nlp research in low-resource settings, enabling greater accessibility and inclusion for african languages in a rapidly expanding digital landscape. we publicly release our models for research.","doi":"","created":1704153600000,"updated":"2024-01-10","authors":["ife adebara","abdelrahim elmadany","muhammad abdul-mageed"]}
{"id":"2401.01054","title":"elastic multi-gradient descent for parallel continual learning","categories":"cs.lg cs.ai","abstract":"the goal of continual learning (cl) is to continuously learn from new data streams and accomplish the corresponding tasks. previously studied cl assumes that data are given in sequence nose-to-tail for different tasks, thus indeed belonging to serial continual learning (scl). this paper studies the novel paradigm of parallel continual learning (pcl) in dynamic multi-task scenarios, where a diverse set of tasks is encountered at different time points. pcl presents challenges due to the training of an unspecified number of tasks with varying learning progress, leading to the difficulty of guaranteeing effective model updates for all encountered tasks. in our previous conference work, we focused on measuring and reducing the discrepancy among gradients in a multi-objective optimization problem, which, however, may still contain negative transfers in every model update. to address this issue, in the dynamic multi-objective optimization problem, we introduce task-specific elastic factors to adjust the descent direction towards the pareto front. the proposed method, called elastic multi-gradient descent (emgd), ensures that each update follows an appropriate pareto descent direction, minimizing any negative impact on previously learned tasks. to balance the training between old and new tasks, we also propose a memory editing mechanism guided by the gradient computed using emgd. this editing process updates the stored data points, reducing interference in the pareto descent direction from previous tasks. experiments on public datasets validate the effectiveness of our emgd in the pcl setting.","doi":"","created":1704153600000,"updated":"","authors":["fan lyu","wei feng","yuepan li","qing sun","fanhua shang","liang wan","liang wang"]}
{"id":"2401.01055","title":"llama beyond english: an empirical study on language capability transfer","categories":"cs.cl cs.ai","abstract":"in recent times, substantial advancements have been witnessed in large language models (llms), exemplified by chatgpt, showcasing remarkable proficiency across a range of complex tasks. however, many mainstream llms (e.g. llama) are pretrained on english-dominant corpus, which limits their performance in other non-english languages. in this paper, we focus on how to effectively transfer the capabilities of language generation and following instructions to a non-english language. to answer this question, we conduct an extensive empirical investigation based on llama, accumulating over 1440 gpu hours. we analyze the impact of key factors such as vocabulary extension, further pretraining, and instruction tuning on transfer. to accurately assess the model's level of knowledge, we employ four widely used standardized testing benchmarks: c-eval, mmlu, agi-eval, and gaokao-bench. furthermore, a comprehensive evaluation of the model's response quality is conducted, considering aspects such as accuracy, fluency, informativeness, logical coherence, and harmlessness, based on llm-eval, a benchmarks consisting instruction tasks from 17 diverse categories. our evaluation results demonstrate that comparable performance to state-of-the-art transfer models can be achieved with less than 1% of the pretraining data, both in terms of knowledge alignment and response quality. furthermore, the experimental outcomes across the thirteen low-resource languages also exhibit similar trends. we anticipate that the conclusions revealed by the experiments will aid the community in developing non-english llms.","doi":"","created":1704153600000,"updated":"2024-01-12","authors":["jun zhao","zhihao zhang","luhui gao","qi zhang","tao gui","xuanjing huang"]}
{"id":"2401.01056","title":"enhancing automatic modulation recognition through robust global feature   extraction","categories":"eess.sp cs.ai cs.lg","abstract":"automatic modulation recognition (amr) plays a crucial role in wireless communication systems. deep learning amr strategies have achieved tremendous success in recent years. modulated signals exhibit long temporal dependencies, and extracting global features is crucial in identifying modulation schemes. traditionally, human experts analyze patterns in constellation diagrams to classify modulation schemes. classical convolutional-based networks, due to their limited receptive fields, excel at extracting local features but struggle to capture global relationships. to address this limitation, we introduce a novel hybrid deep framework named tldnn, which incorporates the architectures of the transformer and long short-term memory (lstm). we utilize the self-attention mechanism of the transformer to model the global correlations in signal sequences while employing lstm to enhance the capture of temporal dependencies. to mitigate the impact like rf fingerprint features and channel characteristics on model generalization, we propose data augmentation strategies known as segment substitution (ss) to enhance the model's robustness to modulation-related features. experimental results on widely-used datasets demonstrate that our method achieves state-of-the-art performance and exhibits significant advantages in terms of complexity. our proposed framework serves as a foundational backbone that can be extended to different datasets. we have verified the effectiveness of our augmentation approach in enhancing the generalization of the models, particularly in few-shot scenarios. code is available at \\url{https:\/\/github.com\/amr-master\/tldnn}.","doi":"","created":1704153600000,"updated":"","authors":["yunpeng qu","zhilin lu","rui zeng","jintao wang","jian wang"]}
{"id":"2401.01060","title":"learning in the wild: towards leveraging unlabeled data for effectively   tuning pre-trained code models","categories":"cs.se","abstract":"pre-trained code models have recently achieved substantial improvements in many code intelligence tasks. these models are first pre-trained on large-scale unlabeled datasets in a task-agnostic manner using self-supervised learning, and then fine-tuned on labeled datasets in downstream tasks. however, the labeled datasets are usually limited in size (i.e., human intensive efforts), which may hinder the performance of pre-trained code models in specific tasks. to mitigate this, one possible solution is to leverage the large-scale unlabeled data in the tuning stage by pseudo-labeling. however, directly employing the pseudo-labeled data can bring a large amount of noise, i.e., incorrect labels, leading to suboptimal performance. how to effectively leverage the noisy pseudo-labeled data is a challenging yet under-explored problem.in this paper, we propose a novel approach named hint to improve pre-trained code models with large-scale unlabeled datasets by better utilizing the pseudo-labeled data. hint includes two main modules: hybrid pseudo-labeled data selection and noise-tolerant training. in the hybrid pseudo-data selection module, considering the robustness issue, apart from directly measuring the quality of pseudo labels through training loss, we further propose to employ a retrieval-based method to filter low-quality pseudo-labeled data. the noise-tolerant training module aims to further mitigate the influence of errors in pseudo labels by training the model with a noise-tolerant loss function and by regularizing the consistency of model predictions.the experimental results show that hint can better leverage those unlabeled data in a task-specific way and provide complementary benefits for pre-trained models, e.g., improving the best baseline model by 15.33%, 16.50%, and 8.98% on code summarization, defect detection, and assertion generation, respectively.","doi":"10.1145\/3597503.3639216","created":1704153600000,"updated":"","authors":["shuzheng gao","wenxin mao","cuiyun gao","li li","xing hu","xin xia","michael r. lyu"]}
{"id":"2401.01062","title":"experimenting a new programming practice with llms","categories":"cs.se","abstract":"the recent development on large language models makes automatically constructing small programs possible. it thus has the potential to free software engineers from low-level coding and allow us to focus on the perhaps more interesting parts of software development, such as requirement engineering and system testing. in this project, we develop a prototype named aisd (ai-aided software development), which is capable of taking high-level (potentially vague) user requirements as inputs, generates detailed use cases, prototype system designs, and subsequently system implementation. different from existing attempts, aisd is designed to keep the user in the loop, i.e., by repeatedly taking user feedback on use cases, high-level system designs, and prototype implementations through system testing. aisd has been evaluated with a novel benchmark of non-trivial software projects. the experimental results suggest that it might be possible to imagine a future where software engineering is reduced to requirement engineering and system testing only.","doi":"","created":1704153600000,"updated":"","authors":["simiao zhang","jiaping wang","guoliang dong","jun sun","yueling zhang","geguang pu"]}
{"id":"2401.01065","title":"bev-tsr: text-scene retrieval in bev space for autonomous driving","categories":"cs.cv cs.ai","abstract":"the rapid development of the autonomous driving industry has led to a significant accumulation of autonomous driving data. consequently, there comes a growing demand for retrieving data to provide specialized optimization. however, directly applying previous image retrieval methods faces several challenges, such as the lack of global feature representation and inadequate text retrieval ability for complex driving scenes. to address these issues, firstly, we propose the bev-tsr framework which leverages descriptive text as an input to retrieve corresponding scenes in the bird's eye view (bev) space. then to facilitate complex scene retrieval with extensive text descriptions, we employ a large language model (llm) to extract the semantic features of the text inputs and incorporate knowledge graph embeddings to enhance the semantic richness of the language embedding. to achieve feature alignment between the bev feature and language embedding, we propose shared cross-modal embedding with a set of shared learnable embeddings to bridge the gap between these two modalities, and employ a caption generation task to further enhance the alignment. furthermore, there lack of well-formed retrieval datasets for effective evaluation. to this end, we establish a multi-level retrieval dataset, nuscenes-retrieval, based on the widely adopted nuscenes dataset. experimental results on the multi-level nuscenes-retrieval show that bev-tsr achieves state-of-the-art performance, e.g., 85.78% and 87.66% top-1 accuracy on scene-to-text and text-to-scene retrieval respectively. codes and datasets will be available.","doi":"","created":1704153600000,"updated":"2024-06-18","authors":["tao tang","dafeng wei","zhengyu jia","tian gao","changwei cai","chengkai hou","peng jia","kun zhan","haiyang sun","jingchen fan","yixing zhao","fu liu","xiaodan liang","xianpeng lang","yang wang"]}
{"id":"2401.01066","title":"dtbs: dual-teacher bi-directional self-training for domain adaptation in   nighttime semantic segmentation","categories":"cs.cv","abstract":"due to the poor illumination and the difficulty in annotating, nighttime conditions pose a significant challenge for autonomous vehicle perception systems. unsupervised domain adaptation (uda) has been widely applied to semantic segmentation on such images to adapt models from normal conditions to target nighttime-condition domains. self-training (st) is a paradigm in uda, where a momentum teacher is utilized for pseudo-label prediction, but a confirmation bias issue exists. because the one-directional knowledge transfer from a single teacher is insufficient to adapt to a large domain shift. to mitigate this issue, we propose to alleviate domain gap by incrementally considering style influence and illumination change. therefore, we introduce a one-stage dual-teacher bi-directional self-training (dtbs) framework for smooth knowledge transfer and feedback. based on two teacher models, we present a novel pipeline to respectively decouple style and illumination shift. in addition, we propose a new re-weight exponential moving average (ema) to merge the knowledge of style and illumination factors, and provide feedback to the student model. in this way, our method can be embedded in other uda methods to enhance their performance. for example, the cityscapes to acdc night task yielded 53.8 miou (\\%), which corresponds to an improvement of +5\\% over the previous state-of-the-art. the code is available at \\url{https:\/\/github.com\/hf618\/dtbs}.","doi":"","created":1704153600000,"updated":"","authors":["fanding huang","zihao yao","wenhui zhou"]}
{"id":"2401.01068","title":"discovering significant topics from legal decisions with selective   inference","categories":"cs.cl cs.ai","abstract":"we propose and evaluate an automated pipeline for discovering significant topics from legal decision texts by passing features synthesized with topic models through penalised regressions and post-selection significance tests. the method identifies case topics significantly correlated with outcomes, topic-word distributions which can be manually-interpreted to gain insights about significant topics, and case-topic weights which can be used to identify representative cases for each topic. we demonstrate the method on a new dataset of domain name disputes and a canonical dataset of european court of human rights violation cases. topic models based on latent semantic analysis as well as language model embeddings are evaluated. we show that topics derived by the pipeline are consistent with legal doctrines in both areas and can be useful in other related legal analysis tasks.","doi":"10.1098\/rsta.2023.0147","created":1704153600000,"updated":"","authors":["jerrold soh"]}
{"id":"2401.01069","title":"a prediction-correction based iterative convolution-thresholding method   for topology optimization of heat transfer problems","categories":"math.na cs.ce cs.na","abstract":"in this paper, we propose an iterative convolution-thresholding method (ictm) based on prediction-correction for solving the topology optimization problem in steady-state heat transfer equations. the problem is formulated as a constrained minimization problem of the complementary energy, incorporating a perimeter\/surface-area regularization term, while satisfying a steady-state heat transfer equation. the decision variables of the optimization problem represent the domains of different materials and are represented by indicator functions. the perimeter\/surface-area term of the domain is approximated using gaussian kernel convolution with indicator functions. in each iteration, the indicator function is updated using a prediction-correction approach. the prediction step is based on the variation of the objective functional by imposing the constraints, while the correction step ensures the monotonically decreasing behavior of the objective functional. numerical results demonstrate the efficiency and robustness of our proposed method, particularly when compared to classical approaches based on the ictm.","doi":"","created":1704153600000,"updated":"","authors":["huangxin chen","piaopiao dong","dong wang","xiao-ping wang"]}
{"id":"2401.01070","title":"a novel dual-stage evolutionary algorithm for finding robust solutions","categories":"cs.ne","abstract":"in robust optimization problems, the magnitude of perturbations is relatively small. consequently, solutions within certain regions are less likely to represent the robust optima when perturbations are introduced. hence, a more efficient search process would benefit from increased opportunities to explore promising regions where global optima or good local optima are situated. in this paper, we introduce a novel robust evolutionary algorithm named the dual-stage robust evolutionary algorithm (drea) aimed at discovering robust solutions. drea operates in two stages: the peak-detection stage and the robust solution-searching stage. the primary objective of the peak-detection stage is to identify peaks in the fitness landscape of the original optimization problem. conversely, the robust solution-searching stage focuses on swiftly identifying the robust optimal solution using information obtained from the peaks discovered in the initial stage. these two stages collectively enable the proposed drea to efficiently obtain the robust optimal solution for the optimization problem. this approach achieves a balance between solution optimality and robustness by separating the search processes for optimal and robust optimal solutions. experimental results demonstrate that drea significantly outperforms five state-of-the-art algorithms across 18 test problems characterized by diverse complexities. moreover, when evaluated on higher-dimensional robust optimization problems (100-$d$ and 200-$d$), drea also demonstrates superior performance compared to all five counterpart algorithms.","doi":"","created":1704153600000,"updated":"","authors":["wei du","wenxuan fang","chen liang","yang tang","yaochu jin"]}
{"id":"2401.01073","title":"taming the beast: fully automated unit testing with coyote c++","categories":"cs.pl cs.se","abstract":"in this paper, we present coyote c++, a fully automated white-box unit testing tool for c and c++. whereas existing tools have struggled to realize unit test generation for c++, coyote c++ is able to produce high coverage results from unit test generation at a testing speed of over 10,000 statements per hour. this impressive feat is made possible by the combination of a powerful concolic execution engine with sophisticated automated test harness generation. additionally, the gui of coyote c++ displays detailed code coverage visualizations and provides various configuration features for users seeking to manually optimize their coverage results. combining potent one-click automated testing with rich support for manual tweaking, coyote c++ is the first automated testing tool that is practical enough to make automated testing of c++ code truly viable in industrial applications.","doi":"","created":1704153600000,"updated":"2024-01-04","authors":["sanghoon rho","philipp martens","seungcheol shin","yeoneo kim"]}
{"id":"2401.01074","title":"alifuse: aligning and fusing multi-modal medical data for computer-aided   diagnosis","categories":"cs.cv","abstract":"medical data collected for making a diagnostic decision are typically multi-modal and provide complementary perspectives of a subject. a computer-aided diagnosis system welcomes multi-modal inputs; however, how to effectively fuse such multi-modal data is a challenging task and attracts a lot of attention in the medical research field. in this paper, we propose a transformer-based framework, called alifuse, for aligning and fusing multi-modal medical data. specifically, we convert images and unstructured and structured texts into vision and language tokens, and use intramodal and intermodal attention mechanisms to learn holistic representations of all imaging and non-imaging data for classification. we apply alifuse to classify alzheimer's disease and obtain state-of-the-art performance on five public datasets, by outperforming eight baselines. the source code will be available online later.","doi":"","created":1704153600000,"updated":"2024-01-06","authors":["qiuhui chen","yi hong"]}
{"id":"2401.01075","title":"depth-discriminative metric learning for monocular 3d object detection","categories":"cs.cv","abstract":"monocular 3d object detection poses a significant challenge due to the lack of depth information in rgb images. many existing methods strive to enhance the object depth estimation performance by allocating additional parameters for object depth estimation, utilizing extra modules or data. in contrast, we introduce a novel metric learning scheme that encourages the model to extract depth-discriminative features regardless of the visual attributes without increasing inference time and model size. our method employs the distance-preserving function to organize the feature space manifold in relation to ground-truth object depth. the proposed (k, b, eps)-quasi-isometric loss leverages predetermined pairwise distance restriction as guidance for adjusting the distance among object descriptors without disrupting the non-linearity of the natural feature manifold. moreover, we introduce an auxiliary head for object-wise depth estimation, which enhances depth quality while maintaining the inference time. the broad applicability of our method is demonstrated through experiments that show improvements in overall performance when integrated into various baselines. the results show that our method consistently improves the performance of various baselines by 23.51% and 5.78% on average across kitti and waymo, respectively.","doi":"","created":1704153600000,"updated":"","authors":["wonhyeok choi","mingyu shin","sunghoon im"]}
{"id":"2401.01076","title":"dialclip: empowering clip as multi-modal dialog retriever","categories":"cs.cl","abstract":"recently, substantial advancements in pre-trained vision-language models have greatly enhanced the capabilities of multi-modal dialog systems. these models have demonstrated significant improvements by fine-tuning on downstream tasks. however, the existing pre-trained models primarily focus on effectively capturing the alignment between vision and language modalities, often ignoring the intricate nature of dialog context. in this paper, we propose a parameter-efficient prompt-tuning method named dialclip for multi-modal dialog retrieval. specifically, our approach introduces a multi-modal context prompt generator to learn context features which are subsequently distilled into prompts within the pre-trained vision-language model clip. besides, we introduce domain prompt to mitigate the disc repancy from the downstream dialog data. to facilitate various types of retrieval, we also design multiple experts to learn mappings from clip outputs to multi-modal representation space, with each expert being responsible to one specific retrieval type. extensive experiments show that dialclip achieves state-of-the-art performance on two widely recognized benchmark datasets (i.e., photochat and mmdialog) by tuning a mere 0.04% of the total parameters. these results highlight the efficacy and efficiency of our proposed approach, underscoring its potential to advance the field of multi-modal dialog retrieval.","doi":"","created":1704153600000,"updated":"2024-01-02","authors":["zhichao yin","binyuan hui","min yang","fei huang","yongbin li"]}
{"id":"2401.01077","title":"constrained online two-stage stochastic optimization: algorithm with   (and without) predictions","categories":"cs.lg","abstract":"we consider an online two-stage stochastic optimization with long-term constraints over a finite horizon of $t$ periods. at each period, we take the first-stage action, observe a model parameter realization and then take the second-stage action from a feasible set that depends both on the first-stage decision and the model parameter. we aim to minimize the cumulative objective value while guaranteeing that the long-term average second-stage decision belongs to a set. we develop online algorithms for the online two-stage problem from adversarial learning algorithms. also, the regret bound of our algorithm can be reduced to the regret bound of embedded adversarial learning algorithms. based on this framework, we obtain new results under various settings. when the model parameters are drawn from unknown non-stationary distributions and we are given machine-learned predictions of the distributions, we develop a new algorithm from our framework with a regret $o(w_t+\\sqrt{t})$, where $w_t$ measures the total inaccuracy of the machine-learned predictions. we then develop another algorithm that works when no machine-learned predictions are given and show the performances.","doi":"","created":1704153600000,"updated":"","authors":["piao hu","jiashuo jiang","guodong lyu","hao su"]}
{"id":"2401.01078","title":"vietnamese poem generation & the prospect of cross-language poem-to-poem   translation","categories":"cs.cl cs.ai","abstract":"poetry generation has been a challenging task in the field of natural language processing, as it requires the model to understand the nuances of language, sentiment, and style. in this paper, we propose using large language models to generate vietnamese poems of various genres from natural language prompts, thereby facilitating an intuitive process with enhanced content control. our most efficacious model, the gpt-3 babbage variant, achieves a custom evaluation score of 0.8, specifically tailored to the \"luc bat\" genre of vietnamese poetry. furthermore, we also explore the idea of paraphrasing poems into normal text prompts and yield a relatively high score of 0.781 in the \"luc bat\" genre. this experiment presents the potential for cross-language poem-to-poem translation with translated poems as the inputs while concurrently maintaining complete control over the generated content.","doi":"","created":1704153600000,"updated":"2024-01-04","authors":["triet minh huynh","quan le bao"]}
{"id":"2401.01081","title":"ple-slam: a visual-inertial slam based on point-line features and   efficient imu initialization","categories":"cs.ro","abstract":"visual-inertial slam is crucial in various fields, such as aerial vehicles, industrial robots, and autonomous driving. the fusion of camera and inertial measurement unit (imu) makes up for the shortcomings of a signal sensor, which significantly improves the accuracy and robustness of localization in challenging environments. this article presents ple-slam, an accurate and real-time visual-inertial slam algorithm based on point-line features and efficient imu initialization. first, we use parallel computing methods to extract features and compute descriptors to ensure real-time performance. adjacent short line segments are merged into long line segments, and isolated short line segments are directly deleted. second, a rotation-translation-decoupled initialization method is extended to use both points and lines. gyroscope bias is optimized by tightly coupling imu measurements and image observations. accelerometer bias and gravity direction are solved by an analytical method for efficiency. to improve the system's intelligence in handling complex environments, a scheme of leveraging semantic information and geometric constraints to eliminate dynamic features and a solution for loop detection and closed-loop frame pose estimation using cnn and gnn are integrated into the system. all networks are accelerated to ensure real-time performance. the experiment results on public datasets illustrate that ple-slam is one of the state-of-the-art visual-inertial slam systems.","doi":"","created":1704153600000,"updated":"2024-01-05","authors":["jiaming he","mingrui li","yangyang wang","hongyu wang"]}
{"id":"2401.01083","title":"aircraft landing time prediction with deep learning on trajectory images","categories":"cs.lg","abstract":"aircraft landing time (alt) prediction is crucial for air traffic management, especially for arrival aircraft sequencing on the runway. in this study, a trajectory image-based deep learning method is proposed to predict alts for the aircraft entering the research airspace that covers the terminal maneuvering area (tma). specifically, the trajectories of all airborne arrival aircraft within the temporal capture window are used to generate an image with the target aircraft trajectory labeled as red and all background aircraft trajectory labeled as blue. the trajectory images contain various information, including the aircraft position, speed, heading, relative distances, and arrival traffic flows. it enables us to use state-of-the-art deep convolution neural networks for alt modeling. we also use real-time runway usage obtained from the trajectory data and the external information such as aircraft types and weather conditions as additional inputs. moreover, a convolution neural network (cnn) based module is designed for automatic holding-related featurizing, which takes the trajectory images, the leading aircraft holding status, and their time and speed gap at the research airspace boundary as its inputs. its output is further fed into the final end-to-end alt prediction. the proposed alt prediction approach is applied to singapore changi airport (icao code: wsss) using one-month automatic dependent surveillance-broadcast (ads-b) data from november 1 to november 30, 2022. experimental results show that by integrating the holding featurization, we can reduce the mean absolute error (mae) from 82.23 seconds to 43.96 seconds, and achieve an average accuracy of 96.1\\%, with 79.4\\% of the predictions errors being less than 60 seconds.","doi":"","created":1704153600000,"updated":"","authors":["liping huang","sheng zhang","yicheng zhang","yi zhang","yifang yin"]}
{"id":"2401.01084","title":"global convergence of natural policy gradient with hessian-aided   momentum variance reduction","categories":"cs.lg math.oc","abstract":"natural policy gradient (npg) and its variants are widely-used policy search methods in reinforcement learning. inspired by prior work, a new npg variant coined npg-hm is developed in this paper, which utilizes the hessian-aided momentum technique for variance reduction, while the sub-problem is solved via the stochastic gradient descent method. it is shown that npg-hm can achieve the global last iterate $\\epsilon$-optimality with a sample complexity of $\\mathcal{o}(\\epsilon^{-2})$, which is the best known result for natural policy gradient type methods under the generic fisher non-degenerate policy parameterizations. the convergence analysis is built upon a relaxed weak gradient dominance property tailored for npg under the compatible function approximation framework, as well as a neat way to decompose the error when handling the sub-problem. moreover, numerical experiments on mujoco-based environments demonstrate the superior performance of npg-hm over other state-of-the-art policy gradient methods.","doi":"","created":1704153600000,"updated":"2024-01-21","authors":["jie feng","ke wei","jinchi chen"]}
{"id":"2401.01085","title":"imperio: language-guided backdoor attacks for arbitrary model control","categories":"cs.cr cs.lg","abstract":"natural language processing (nlp) has received unprecedented attention. while advancements in nlp models have led to extensive research into their backdoor vulnerabilities, the potential for these advancements to introduce new backdoor threats remains unexplored. this paper proposes imperio, which harnesses the language understanding capabilities of nlp models to enrich backdoor attacks. imperio provides a new model control experience. demonstrated through controlling image classifiers, it empowers the adversary to manipulate the victim model with arbitrary output through language-guided instructions. this is achieved using a language model to fuel a conditional trigger generator, with optimizations designed to extend its language understanding capabilities to backdoor instruction interpretation and execution. our experiments across three datasets, five attacks, and nine defenses confirm imperio's effectiveness. it can produce contextually adaptive triggers from text descriptions and control the victim model with desired outputs, even in scenarios not encountered during training. the attack reaches a high success rate across complex datasets without compromising the accuracy of clean inputs and exhibits resilience against representative defenses.","doi":"","created":1704153600000,"updated":"2024-03-15","authors":["ka-ho chow","wenqi wei","lei yu"]}
{"id":"2401.01089","title":"quokka: an open-source large language model chatbot for material science","categories":"cs.cl cs.ai cs.ce","abstract":"this paper presents the development of a specialized chatbot for materials science, leveraging the llama-2 language model, and continuing pre-training on the expansive research articles in the materials science domain from the s2orc dataset. the methodology involves an initial pretraining phase on over one million domain-specific papers, followed by an instruction-tuning process to refine the chatbot's capabilities. the chatbot is designed to assist researchers, educators, and students by providing instant, context-aware responses to queries in the field of materials science. we make the four trained checkpoints (7b, 13b, with or without chat ability) freely available to the research community at https:\/\/github.com\/xianjun-yang\/quokka.","doi":"","created":1704153600000,"updated":"","authors":["xianjun yang","stephen d. wilson","linda petzold"]}
{"id":"2401.01092","title":"irs-aided multi-antenna wireless powered communications in interference   channels","categories":"cs.it eess.sp math.it","abstract":"this paper investigates intelligent reflecting surface (irs)-aided multi-antenna wireless powered communications in a multi-link interference channel, where multiple irss are deployed to enhance the downlink\/uplink communications between each pair of hybrid access point (hap) and wireless device. our objective is to maximize the system sum throughput by optimizing the allocation of communication resources. to attain this objective and meanwhile balance the performance-cost tradeoff, we propose three transmission schemes: the irs-aided asynchronous (asy) scheme, the irs-aided time-division multiple access (tdma) scheme, and the irs-aided synchronous (syn) scheme. for the resulting three non-convex design problems, we propose a general algorithmic framework capable of suboptimally addressing all of them. numerical results show that our proposed irs-aided schemes noticeably surpass their counterparts without irss in both system sum throughput and total transmission energy consumption at the haps. moreover, although the irs-aided asy scheme consistently achieves the highest sum throughput, the irs-aided tdma scheme is more appealing in scenarios with substantial cross-link interference and limited irs elements, while the irs-aided syn scheme is preferable in low cross-link interference scenarios.","doi":"10.1109\/tvt.2024.3431676","created":1704153600000,"updated":"2024-07-30","authors":["ying gao","qingqing wu","wen chen"]}
{"id":"2401.01093","title":"exploring hyperspectral anomaly detection with human vision: a small   target aware detector","categories":"cs.cv","abstract":"hyperspectral anomaly detection (had) aims to localize pixel points whose spectral features differ from the background. had is essential in scenarios of unknown or camouflaged target features, such as water quality monitoring, crop growth monitoring and camouflaged target detection, where prior information of targets is difficult to obtain. existing had methods aim to objectively detect and distinguish background and anomalous spectra, which can be achieved almost effortlessly by human perception. however, the underlying processes of human visual perception are thought to be quite complex. in this paper, we analyze hyperspectral image (hsi) features under human visual perception, and transfer the solution process of had to the more robust feature space for the first time. specifically, we propose a small target aware detector (stad), which introduces saliency maps to capture hsi features closer to human visual perception. stad not only extracts more anomalous representations, but also reduces the impact of low-confidence regions through a proposed small target filter (stf). furthermore, considering the possibility of had algorithms being applied to edge devices, we propose a full connected network to convolutional network knowledge distillation strategy. it can learn the spectral and spatial features of the hsi while lightening the network. we train the network on the had100 training set and validate the proposed method on the had100 test set. our method provides a new solution space for had that is closer to human visual perception with high confidence. sufficient experiments on real hsi with multiple method comparisons demonstrate the excellent performance and unique potential of the proposed method. the code is available at https:\/\/github.com\/majitao-xd\/stad-had.","doi":"","created":1704153600000,"updated":"","authors":["jitao ma","weiying xie","yunsong li"]}
{"id":"2401.01096","title":"demystifying $\\mu$","categories":"math.lo cs.lo","abstract":"we develop the theory of illfounded and cyclic proof systems in the context of the modal $\\mu$-calculus. a fine analysis of provability and admissibility bridges the finitary, cyclic and illfounded notions of proof for this logic and re-enforces the subtlety of two important normal form theorems: guardedness and disjunctiveness.","doi":"","created":1704153600000,"updated":"","authors":["bahareh afshari","graham e. leigh","guillermo menéndez turata"]}
{"id":"2401.01097","title":"robust single-particle cryo-em image denoising and restoration","categories":"cs.cv","abstract":"cryo-electron microscopy (cryo-em) has achieved near-atomic level resolution of biomolecules by reconstructing 2d micrographs. however, the resolution and accuracy of the reconstructed particles are significantly reduced due to the extremely low signal-to-noise ratio (snr) and complex noise structure of cryo-em images. in this paper, we introduce a diffusion model with post-processing framework to effectively denoise and restore single particle cryo-em images. our method outperforms the state-of-the-art (sota) denoising methods by effectively removing structural noise that has not been addressed before. additionally, more accurate and high-resolution three-dimensional reconstruction structures can be obtained from denoised cryo-em images.","doi":"","created":1704153600000,"updated":"","authors":["jing zhang","tengfei zhao","shiyu hu","xin zhao"]}
{"id":"2401.01099","title":"efficient parallel audio generation using group masked language modeling","categories":"eess.as cs.ai cs.lg","abstract":"we present a fast and high-quality codec language model for parallel audio generation. while soundstorm, a state-of-the-art parallel audio generation model, accelerates inference speed compared to autoregressive models, it still suffers from slow inference due to iterative sampling. to resolve this problem, we propose group-masked language modeling~(g-mlm) and group iterative parallel decoding~(g-ipd) for efficient parallel audio generation. both the training and sampling schemes enable the model to synthesize high-quality audio with a small number of iterations by effectively modeling the group-wise conditional dependencies. in addition, our model employs a cross-attention-based architecture to capture the speaker style of the prompt voice and improves computational efficiency. experimental results demonstrate that our proposed model outperforms the baselines in prompt-based audio generation.","doi":"","created":1704153600000,"updated":"","authors":["myeonghun jeong","minchan kim","joun yeop lee","nam soo kim"]}
{"id":"2401.01100","title":"scalable manifold learning by uniform landmark sampling and constrained   locally linear embedding","categories":"cs.lg","abstract":"as a pivotal approach in machine learning and data science, manifold learning aims to uncover the intrinsic low-dimensional structure within complex nonlinear manifolds in high-dimensional space. by exploiting the manifold hypothesis, various techniques for nonlinear dimension reduction have been developed to facilitate visualization, classification, clustering, and gaining key insights. although existing manifold learning methods have achieved remarkable successes, they still suffer from extensive distortions incurred in the global structure, which hinders the understanding of underlying patterns. scalability issues also limit their applicability for handling large-scale data. here, we propose a scalable manifold learning (scml) method that can manipulate large-scale and high-dimensional data in an efficient manner. it starts by seeking a set of landmarks to construct the low-dimensional skeleton of the entire data, and then incorporates the non-landmarks into the learned space based on the constrained locally linear embedding (clle). we empirically validated the effectiveness of scml on synthetic datasets and real-world benchmarks of different types, and applied it to analyze the single-cell transcriptomics and detect anomalies in electrocardiogram (ecg) signals. scml scales well with increasing data sizes and embedding dimensions, and exhibits promising performance in preserving the global structure. the experiments demonstrate notable robustness in embedding quality as the sample rate decreases.","doi":"","created":1704153600000,"updated":"2024-01-05","authors":["dehua peng","zhipeng gui","wenzhang wei","huayi wu"]}
{"id":"2401.01102","title":"dual teacher knowledge distillation with domain alignment for face   anti-spoofing","categories":"cs.cv","abstract":"face recognition systems have raised concerns due to their vulnerability to different presentation attacks, and system security has become an increasingly critical concern. although many face anti-spoofing (fas) methods perform well in intra-dataset scenarios, their generalization remains a challenge. to address this issue, some methods adopt domain adversarial training (dat) to extract domain-invariant features. however, the competition between the encoder and the domain discriminator can cause the network to be difficult to train and converge. in this paper, we propose a domain adversarial attack (daa) method to mitigate the training instability problem by adding perturbations to the input images, which makes them indistinguishable across domains and enables domain alignment. moreover, since models trained on limited data and types of attacks cannot generalize well to unknown attacks, we propose a dual perceptual and generative knowledge distillation framework for face anti-spoofing that utilizes pre-trained face-related models containing rich face priors. specifically, we adopt two different face-related models as teachers to transfer knowledge to the target student model. the pre-trained teacher models are not from the task of face anti-spoofing but from perceptual and generative tasks, respectively, which implicitly augment the data. by combining both daa and dual-teacher knowledge distillation, we develop a dual teacher knowledge distillation with domain alignment framework (dtda) for face anti-spoofing. the advantage of our proposed method has been verified through extensive ablation studies and comparison with state-of-the-art methods on public datasets across multiple protocols.","doi":"","created":1704153600000,"updated":"","authors":["zhe kong","wentian zhang","tao wang","kaihao zhang","yuexiang li","xiaoying tang","wenhan luo"]}
{"id":"2401.01103","title":"a nearly linear time construction of approximate single-source distance   sensitivity oracles","categories":"cs.ds","abstract":"an \\emph{$\\alpha$-approximate vertex fault-tolerant distance sensitivity oracle} (\\emph{$\\alpha$-vsdo}) for a weighted input graph $g=(v, e, w)$ and a source vertex $s \\in v$ is the data structure answering an $\\alpha$-approximate distance from $s$ to $t$ in $g-x$ for any given query $(x, t) \\in v \\times v$. it is a data structure version of the so-called single-source replacement path problem (ssrp). in this paper, we present a new \\emph{nearly linear-time} algorithm of constructing a $(1 + \\epsilon)$-vsdo for any directed input graph with polynomially bounded integer edge weights. more precisely, the presented oracle attains $\\tilde{o}(m \\log (nw)\/ \\epsilon + n \\log^2 (nw)\/\\epsilon^2)$ construction time, $\\tilde{o}(n \\log (nw) \/ \\epsilon)$ size, and $\\tilde{o}(1\/\\epsilon)$ query time, where $n$ is the number of vertices, $m$ is the number of edges, and $w$ is the maximum edge weight. these bounds are all optimal up to polylogarithmic factors. to the best of our knowledge, this is the first non-trivial algorithm for ssrp\/vsdo beating $\\tilde{o}(mn)$ computation time for directed graphs with general edge weight functions, and also the first nearly linear-time construction breaking approximation factor 3. such a construction has been unknown even for undirected and unweighted graphs. in addition, our result implies that the known conditional lower bounds for the exact ssrp computation does not apply to the case of approximation.","doi":"","created":1704153600000,"updated":"2024-07-01","authors":["kaito harada","naoki kitamura","taisuke izumi","toshimitsu masuzawa"]}
{"id":"2401.01104","title":"ai-flares: artificial intelligence for the analysis of solar flares data","categories":"astro-ph.sr cs.ai","abstract":"ai-flares (artificial intelligence for the analysis of solar flares data) is a research project funded by the agenzia spaziale italiana and by the istituto nazionale di astrofisica within the framework of the ``attivit\\`a di studio per la comunit\\`a scientifica nazionale sole, sistema solare ed esopianeti'' program. the topic addressed by this project was the development and use of computational methods for the analysis of remote sensing space data associated to solar flare emission. this paper overviews the main results obtained by the project, with specific focus on solar flare forecasting, reconstruction of morphologies of the flaring sources, and interpretation of acceleration mechanisms triggered by solar flares.","doi":"","created":1704153600000,"updated":"","authors":["michele piana","federico benvenuto","anna maria massone","cristina campi","sabrina guastavino","francesco marchetti","paolo massa","emma perracchione","anna volpara"]}
{"id":"2401.01107","title":"citypulse: fine-grained assessment of urban change with street view time   series","categories":"cs.cv","abstract":"urban transformations have profound societal impact on both individuals and communities at large. accurately assessing these shifts is essential for understanding their underlying causes and ensuring sustainable urban planning. traditional measurements often encounter constraints in spatial and temporal granularity, failing to capture real-time physical changes. while street view imagery, capturing the heartbeat of urban spaces from a pedestrian point of view, can add as a high-definition, up-to-date, and on-the-ground visual proxy of urban change. we curate the largest street view time series dataset to date, and propose an end-to-end change detection model to effectively capture physical alterations in the built environment at scale. we demonstrate the effectiveness of our proposed method by benchmark comparisons with previous literature and implementing it at the city-wide level. our approach has the potential to supplement existing dataset and serve as a fine-grained and accurate assessment of urban change.","doi":"","created":1704153600000,"updated":"2024-01-02","authors":["tianyuan huang","zejia wu","jiajun wu","jackelyn hwang","ram rajagopal"]}
{"id":"2401.01108","title":"unveiling comparative sentiments in vietnamese product reviews: a   sequential classification framework","categories":"cs.cl","abstract":"comparative opinion mining is a specialized field of sentiment analysis that aims to identify and extract sentiments expressed comparatively. to address this task, we propose an approach that consists of solving three sequential sub-tasks: (i) identifying comparative sentence, i.e., if a sentence has a comparative meaning, (ii) extracting comparative elements, i.e., what are comparison subjects, objects, aspects, predicates, and (iii) classifying comparison types which contribute to a deeper comprehension of user sentiments in vietnamese product reviews. our method is ranked fifth at the vietnamese language and speech processing (vlsp) 2023 challenge on comparative opinion mining (comom) from vietnamese product reviews.","doi":"","created":1704153600000,"updated":"","authors":["ha le","bao tran","phuong le","tan nguyen","dac nguyen","ngoan pham","dang huynh"]}
{"id":"2401.01112","title":"unique ergodicity of implicit methods for monotone sdes and spdes driven   by nondegenerate multiplicative noise","categories":"math.na cs.na","abstract":"we first establish the unique ergodicity of the markov chain generated by the stochastic theta method (stm) with $\\theta \\in [1\/2, 1]$ for monotone sodes, without growth restriction on the coefficients, driven by nondegenerate multiplicative noise. the main ingredient of the arguments lies in constructing new lyapunov functions involving the coefficients, the stepsize, and $\\theta$, and the irreducibility and the strong feller property for the stm. we then generalize the arguments to the temporal drift-implicit euler (die) method and its galerkin-based full discretizations for a class of monotone spdes driven by infinite-dimensional nondegenerate multiplicative trace-class noise. applying these results to the stochastic allen--cahn equation indicates that its die scheme is uniquely ergodic for any interface thickness, which gives an affirmative answer to a question proposed in (j. cui, j. hong, and l. sun, stochastic process. appl. (2021): 55--93). numerical experiments verify our theoretical results.","doi":"","created":1704153600000,"updated":"2024-07-15","authors":["zhihui liu","zhizhou liu"]}
{"id":"2401.01114","title":"static deadlock detection for rust programs","categories":"cs.pl cs.cr cs.se","abstract":"rust relies on its unique ownership mechanism to ensure thread and memory safety. however, numerous potential security vulnerabilities persist in practical applications. new language features in rust pose new challenges for vulnerability detection. this paper proposes a static deadlock detection method tailored for rust programs, aiming to identify various deadlock types, including double lock, conflict lock, and deadlock associated with conditional variables. with due consideration for rust's ownership and lifetimes, we first complete the pointer analysis. then, based on the obtained points-to information, we analyze dependencies among variables to identify potential deadlocks. we develop a tool and conduct experiments based on the proposed method. the experimental results demonstrate that our method outperforms existing deadlock detection methods in precision.","doi":"","created":1704153600000,"updated":"","authors":["yu zhang","kaiwen zhang","guanjun liu"]}
{"id":"2401.01117","title":"q-refine: a perceptual quality refiner for ai-generated image","categories":"cs.cv eess.iv","abstract":"with the rapid evolution of the text-to-image (t2i) model in recent years, their unsatisfactory generation result has become a challenge. however, uniformly refining ai-generated images (aigis) of different qualities not only limited optimization capabilities for low-quality aigis but also brought negative optimization to high-quality aigis. to address this issue, a quality-award refiner named q-refine is proposed. based on the preference of the human visual system (hvs), q-refine uses the image quality assessment (iqa) metric to guide the refining process for the first time, and modify images of different qualities through three adaptive pipelines. experimental shows that for mainstream t2i models, q-refine can perform effective optimization to aigis of different qualities. it can be a general refiner to optimize aigis from both fidelity and aesthetic quality levels, thus expanding the application of the t2i generation models.","doi":"","created":1704153600000,"updated":"","authors":["chunyi li","haoning wu","zicheng zhang","hongkun hao","kaiwei zhang","lei bai","xiaohong liu","xiongkuo min","weisi lin","guangtao zhai"]}
{"id":"2401.01119","title":"utilizing autoregressive networks for full lifecycle data generation of   rolling bearings for rul prediction","categories":"cs.lg cs.ai","abstract":"the prediction of rolling bearing lifespan is of significant importance in industrial production. however, the scarcity of high-quality, full lifecycle data has been a major constraint in achieving precise predictions. to address this challenge, this paper introduces the cvgan model, a novel framework capable of generating one-dimensional vibration signals in both horizontal and vertical directions, conditioned on historical vibration data and remaining useful life. in addition, we propose an autoregressive generation method that can iteratively utilize previously generated vibration information to guide the generation of current signals. the effectiveness of the cvgan model is validated through experiments conducted on the phm 2012 dataset. our findings demonstrate that the cvgan model, in terms of both mmd and fid metrics, outperforms many advanced methods in both autoregressive and non-autoregressive generation modes. notably, training using the full lifecycle data generated by the cvgan model significantly improves the performance of the predictive model. this result highlights the effectiveness of the data generated by cvgans in enhancing the predictive power of these models.","doi":"","created":1704153600000,"updated":"","authors":["junliang wang","qinghua zhang","guanhua zhu","guoxi sun"]}
{"id":"2401.01123","title":"symbolic manipulation planning with discovered object and relational   predicates","categories":"cs.ro","abstract":"discovering the symbols and rules that can be used in long-horizon planning from a robot's unsupervised exploration of its environment and continuous sensorimotor experience is a challenging task. the previous studies proposed learning symbols from single or paired object interactions and planning with these symbols. in this work, we propose a system that learns rules with discovered object and relational symbols that encode an arbitrary number of objects and the relations between them, converts those rules to planning domain description language (pddl), and generates plans that involve affordances of the arbitrary number of objects to achieve tasks. we validated our system with box-shaped objects in different sizes and showed that the system can develop a symbolic knowledge of pick-up, carry, and place operations, taking into account object compounds in different configurations, such as boxes would be carried together with a larger box that they are placed on. we also compared our method with the state-of-the-art methods and showed that planning with the operators defined over relational symbols gives better planning performance compared to the baselines.","doi":"","created":1704153600000,"updated":"","authors":["alper ahmetoglu","erhan oztop","emre ugur"]}
{"id":"2401.01124","title":"explainable adaptive tree-based model selection for time series   forecasting","categories":"cs.lg cs.ai","abstract":"tree-based models have been successfully applied to a wide variety of tasks, including time series forecasting. they are increasingly in demand and widely accepted because of their comparatively high level of interpretability. however, many of them suffer from the overfitting problem, which limits their application in real-world decision-making. this problem becomes even more severe in online-forecasting settings where time series observations are incrementally acquired, and the distributions from which they are drawn may keep changing over time. in this context, we propose a novel method for the online selection of tree-based models using the treeshap explainability method in the task of time series forecasting. we start with an arbitrary set of different tree-based models. then, we outline a performance-based ranking with a coherent design to make treeshap able to specialize the tree-based forecasters across different regions in the input time series. in this framework, adequate model selection is performed online, adaptively following drift detection in the time series. in addition, explainability is supported on three levels, namely online input importance, model selection, and model output explanation. an extensive empirical study on various real-world datasets demonstrates that our method achieves excellent or on-par results in comparison to the state-of-the-art approaches as well as several baselines.","doi":"","created":1704153600000,"updated":"","authors":["matthias jakobs","amal saadallah"]}
{"id":"2401.01127","title":"wireless 6g connectivity for massive number of devices and critical   services","categories":"cs.it math.it","abstract":"compared to the generations up to 4g, whose main focus was on broadband and coverage aspects, 5g has expanded the scope of wireless cellular systems towards embracing two new types of connectivity: massive machine-type communication (mmtc) and ultra-reliable low-latency communications (urllc). this paper will discuss the possible evolution of these two types of connectivity within the umbrella of 6g wireless systems. the paper consists of three parts. the first part deals with the connectivity for a massive number of devices. while mmtc research in 5g was predominantly focused on the problem of uncoordinated access in the uplink for a large number of devices, the traffic patterns in 6g may become more symmetric, leading to closed-loop massive connectivity. one of the drivers for this is distributed learning\/inference. the second part of the paper will discuss the evolution of wireless connectivity for critical services. while latency and reliability are tightly coupled in 5g, 6g will support a variety of safety critical control applications with different types of timing requirements, as evidenced by the emergence of metrics related to information freshness and information value. additionally, ensuring ultra-high reliability for safety critical control applications requires modeling and estimation of the tail statistics of the wireless channel, queue length, and delay. the fulfillment of these stringent requirements calls for the development of novel ai-based techniques, incorporating optimization theory, explainable ai, generative ai and digital twins. the third part will analyze the coexistence of massive connectivity and critical services. we will consider scenarios in which a massive number of devices need to support traffic patterns of mixed criticality. this will be followed by a discussion about the management of wireless resources shared by services with different criticality.","doi":"","created":1704153600000,"updated":"2024-06-01","authors":["anders e. kalør","giuseppe durisi","sinem coleri","stefan parkvall","wei yu","andreas mueller","petar popovski"]}
{"id":"2401.01128","title":"ssp: a simple and safe automatic prompt engineering method towards   realistic image synthesis on lvm","categories":"cs.cv","abstract":"recently, text-to-image (t2i) synthesis has undergone significant advancements, particularly with the emergence of large language models (llm) and their enhancement in large vision models (lvm), greatly enhancing the instruction-following capabilities of traditional t2i models. nevertheless, previous methods focus on improving generation quality but introduce unsafe factors into prompts. we explore that appending specific camera descriptions to prompts can enhance safety performance. consequently, we propose a simple and safe prompt engineering method (ssp) to improve image generation quality by providing optimal camera descriptions. specifically, we create a dataset from multi-datasets as original prompts. to select the optimal camera, we design an optimal camera matching approach and implement a classifier for original prompts capable of automatically matching. appending camera descriptions to original prompts generates optimized prompts for further lvm image generation. experiments demonstrate that ssp improves semantic consistency by an average of 16% compared to others and safety metrics by 48.9%.","doi":"","created":1704153600000,"updated":"","authors":["weijin cheng","jianzhi liu","jiawen deng","fuji ren"]}
{"id":"2401.01129","title":"reduction by symmetry and optimal control with broken symmetries on   riemannian manifolds","categories":"math.oc cs.sy eess.sy math.dg math.ds","abstract":"this paper studies the reduction by symmetry of variational problems on lie groups and riemannian homogeneous spaces. we derive the reduced equations of motion in the case of lie groups endowed with a left-invariant metric, and on lie groups that admits a bi-invariant metric. we repeated this analysis for riemannian homogeneous spaces, where we derive the reduced equations by considering an alternative variational problem written in terms of a connection on the horizontal bundle of the underlying lie group. we study also the case that the underlying lie group admits a bi-invariant metric, and consider the special case that the homogeneous space is in fact a riemannian symmetric space. these ideas are applied to geodesics for a rigid body on $so(3)$ to derive geodesic equations on the dual of its lie algebra (a vector space), the heavy-top in $se(3)$ to derive reduced equations of motion on the unit sphere $s^2$, geodesics on $s^2$ as a riemannian symmetric space endowed with a bi-invariant metric and optimal control problems for applications to robotic manipulators.","doi":"","created":1704153600000,"updated":"","authors":["jacob r. goodman","leonardo j. colombo"]}
{"id":"2401.01130","title":"joint generative modeling of scene graphs and images via diffusion   models","categories":"cs.cv","abstract":"in this paper, we present a novel generative task: joint scene graph - image generation. while previous works have explored image generation conditioned on scene graphs or layouts, our task is distinctive and important as it involves generating scene graphs themselves unconditionally from noise, enabling efficient and interpretable control for image generation. our task is challenging, requiring the generation of plausible scene graphs with heterogeneous attributes for nodes (objects) and edges (relations among objects), including continuous object bounding boxes and discrete object and relation categories. we introduce a novel diffusion model, diffusesg, that jointly models the adjacency matrix along with heterogeneous node and edge attributes. we explore various types of encodings for the categorical data, relaxing it into a continuous space. with a graph transformer being the denoiser, diffusesg successively denoises the scene graph representation in a continuous space and discretizes the final representation to generate the clean scene graph. additionally, we introduce an iou regularization to enhance the empirical performance. our model significantly outperforms existing methods in scene graph generation on the visual genome and coco-stuff datasets, both on standard and newly introduced metrics that better capture the problem complexity. moreover, we demonstrate the additional benefits of our model in two downstream applications: 1) excelling in a series of scene graph completion tasks, and 2) improving scene graph detection models by using extra training samples generated from diffusesg.","doi":"","created":1704153600000,"updated":"","authors":["bicheng xu","qi yan","renjie liao","lele wang","leonid sigal"]}
{"id":"2401.01133","title":"a stochastic-milp dispatch optimization model for concentrated solar   thermal under uncertainty","categories":"eess.sy cs.sy","abstract":"concentrated solar thermal (cst) offers a promising solution for large-scale solar energy utilization as thermal energy storage (tes) enables electricity generation independently of daily solar fluctuations, shifting to high-priced electricity intervals. the development of dispatch planning tools is mandatory to account for uncertainties associated with solar irradiation and electricity price forecasts as well as limited storage capacity. this study proposes the stochastic mixed integer linear program (smilp) to maximize expected profit within a specified scenario space. the smilp scenario space is generated by different empirical cumulative distribution function percentiles of the potential solar energy to accumulate in storage and the expected profit is estimated using the sample average approximation (saa) method. smilp exhibits robust performance, however, its computational time poses a challenge. thus, three heuristic solutions are developed which run a set of deterministic optimizations on different historical weather profiles to generate candidate dispatching plans (dps). the candidate dp with the best average performance on all profiles is then selected. the new methods were applied to a case study for a 115 mw cst plant in south australia. when the historical database has a limited set of historical weather profiles, the smilp achieves 6% to 9% higher profit than the closest benchmark when the dp is applied to novel weather conditions. with a large historical weather data, the performance of smilp and heuristic-2 becomes nearly identical because the smilp can only utilize a limited number of trajectories for optimization without becoming computationally infeasible. in this case, heuristic-2 emerges a practical alternative, since it provides similar average profit in a reasonable time (saving about 7 hours in computing time).","doi":"","created":1704153600000,"updated":"","authors":["navid mohammadzadeh","huy truong-ba","michael e. cholette","theodore a. steinberg","giampaolo manzolini"]}
{"id":"2401.01134","title":"hybrid pooling and convolutional network for improving accuracy and   training convergence speed in object detection","categories":"cs.cv","abstract":"this paper introduces hpc-net, a high-precision and rapidly convergent object detection network.","doi":"","created":1704153600000,"updated":"","authors":["shiwen zhao","wei wang","junhui hou","hai wu"]}
{"id":"2401.01135","title":"two families of linear codes with desirable properties from some   functions over finite fields","categories":"cs.it math.it","abstract":"linear codes are widely studied in coding theory as they have nice applications in distributed storage, combinatorics, lattices, cryptography and so on. constructing linear codes with desirable properties is an interesting research topic. in this paper, based on the augmentation technique, we present two families of linear codes from some functions over finite fields. the first family of linear codes is constructed from monomial functions over finite fields. the locality of them is determined and the weight distributions of two subfamilies of the codes are also given. an infinite family of locally recoverable codes which are at least almost optimal and some optimal recoverable codes are obtained from the linear codes. in particular, the two subfamilies of the codes are proved to be both optimally or almost optimally extendable and self-orthogonal. the second family of linear codes is constructed from weakly regular bent functions over finite fields and their weight distribution is determined. this family of codes is proved to have locality 3 for some cases and is conjectured to have locality 2 for other cases. particularly, two families of optimal locally recoverable codes are derived from the linear codes. besides, this family of codes is also proved to be both optimally or almost optimally extendable and self-orthogonal.","doi":"","created":1704153600000,"updated":"2024-01-04","authors":["ziling heng","xiaoru li","yansheng wu","qi wang"]}
{"id":"2401.01140","title":"joint offloading and resource allocation for hybrid cloud and edge   computing in sagins: a decision assisted hybrid action space deep   reinforcement learning approach","categories":"cs.it cs.dc math.it","abstract":"in recent years, the amalgamation of satellite communications and aerial platforms into space-air-ground integrated network (sagins) has emerged as an indispensable area of research for future communications due to the global coverage capacity of low earth orbit (leo) satellites and the flexible deployment of aerial platforms. this paper presents a deep reinforcement learning (drl)-based approach for the joint optimization of offloading and resource allocation in hybrid cloud and multi-access edge computing (mec) scenarios within sagins. the proposed system considers the presence of multiple satellites, clouds and unmanned aerial vehicles (uavs). the multiple tasks from ground users are modeled as directed acyclic graphs (dags). with the goal of reducing energy consumption and latency in mec, we propose a novel multi-agent algorithm based on drl that optimizes both the offloading strategy and the allocation of resources in the mec infrastructure within sagin. a hybrid action algorithm is utilized to address the challenge of hybrid continuous and discrete action space in the proposed problems, and a decision-assisted drl method is adopted to reduce the impact of unavailable actions in the training process of drl. through extensive simulations, the results demonstrate the efficacy of the proposed learning-based scheme, the proposed approach consistently outperforms benchmark schemes, highlighting its superior performance and potential for practical applications.","doi":"","created":1704153600000,"updated":"","authors":["chong huang","gaojie chen","pei xiao","yue xiao","zhu han","jonathon a. chambers"]}
{"id":"2401.01141","title":"spiker+: a framework for the generation of efficient spiking neural   networks fpga accelerators for inference at the edge","categories":"cs.ne cs.ai cs.ar","abstract":"including artificial neural networks in embedded systems at the edge allows applications to exploit artificial intelligence capabilities directly within devices operating at the network periphery. this paper introduces spiker+, a comprehensive framework for generating efficient, low-power, and low-area customized spiking neural networks (snn) accelerators on fpga for inference at the edge. spiker+ presents a configurable multi-layer hardware snn, a library of highly efficient neuron architectures, and a design framework, enabling the development of complex neural network accelerators with few lines of python code. spiker+ is tested on two benchmark datasets, the mnist and the spiking heidelberg digits (shd). on the mnist, it demonstrates competitive performance compared to state-of-the-art snn accelerators. it outperforms them in terms of resource allocation, with a requirement of 7,612 logic cells and 18 block rams (brams), which makes it fit in very small fpga, and power consumption, draining only 180mw for a complete inference on an input image. the latency is comparable to the ones observed in the state-of-the-art, with 780us\/img. to the authors' knowledge, spiker+ is the first snn accelerator tested on the shd. in this case, the accelerator requires 18,268 logic cells and 51 bram, with an overall power consumption of 430mw and a latency of 54 us for a complete inference on input data. this underscores the significance of spiker+ in the hardware-accelerated snn landscape, making it an excellent solution to deploy configurable and tunable snn architectures in resource and power-constrained edge applications.","doi":"","created":1704153600000,"updated":"","authors":["alessio carpegna","alessandro savino","stefano di carlo"]}
{"id":"2401.01143","title":"enhancing communication efficiency of semantic transmission via joint   processing technique","categories":"cs.it math.it","abstract":"this work presents a novel semantic transmission framework in wireless networks, leveraging the joint processing technique. our framework enables multiple cooperating base stations to efficiently transmit semantic information to multiple users simultaneously. to enhance the semantic communication efficiency of the transmission framework, we formulate an optimization problem with the objective of maximizing the semantic spectral efficiency of the framework and propose a lowcomplexity dynamic semantic mapping and resource allocation algorithm. this algorithm, based on deep reinforcement learning and alternative optimization, achieves near-optimal performance while reducing computational complexity. simulation results validate the effectiveness of the proposed algorithm, bridging the research gap and facilitating the practical implementation of semantic communication systems.","doi":"10.1109\/lcomm.2023.3349137","created":1704153600000,"updated":"","authors":["xumin pu","tiantian lei","wanli wen","qianbin chen"]}
{"id":"2401.01145","title":"haaqi-net: a non-intrusive neural music audio quality assessment model   for hearing aids","categories":"eess.as cs.lg cs.sd","abstract":"this paper introduces haaqi-net, a non-intrusive deep learning model for music audio quality assessment tailored for hearing aid users. unlike traditional methods like the hearing aid audio quality index (haaqi), which rely on intrusive comparisons to a reference signal, haaqi-net offers a more accessible and efficient alternative. using a bidirectional long short-term memory (blstm) architecture with attention mechanisms and features from the pre-trained beats model, haaqi-net predicts haaqi scores directly from music audio clips and hearing loss patterns. results show haaqi-net's effectiveness, with predicted scores achieving a linear correlation coefficient (lcc) of 0.9368, a spearman's rank correlation coefficient (srcc) of 0.9486, and a mean squared error (mse) of 0.0064, reducing inference time from 62.52 seconds to 2.54 seconds. although effective, feature extraction via the large beats model incurs computational overhead. to address this, a knowledge distillation strategy creates a student distillbeats model, distilling information from the teacher beats model during haaqi-net training, reducing required parameters. the distilled haaqi-net maintains strong performance with an lcc of 0.9071, an srcc of 0.9307, and an mse of 0.0091, while reducing parameters by 75.85% and inference time by 96.46%. this reduction enhances haaqi-net's efficiency and scalability, making it viable for real-world music audio quality assessment in hearing aid settings. this work also opens avenues for further research into optimizing deep learning models for specific applications, contributing to audio signal processing and quality assessment by providing insights into developing efficient and accurate models for practical applications in hearing aid technology.","doi":"","created":1704153600000,"updated":"2024-06-05","authors":["dyah a. m. g. wisnu","stefano rini","ryandhimas e. zezario","hsin-min wang","yu tsao"]}
{"id":"2401.01146","title":"privacy preserving personal assistant with on-device diarization and   spoken dialogue system for home and beyond","categories":"cs.hc","abstract":"in the age of personal voice assistants, the question of privacy arises. these digital companions often lack memory of past interactions, while relying heavily on the internet for speech processing, raising privacy concerns. modern smartphones now enable on-device speech processing, making cloud-based solutions unnecessary. personal assistants for the elderly should excel at memory recall, especially in medical examinations. the e-vita project developed a versatile conversational application with local processing and speaker recognition. this paper highlights the importance of speaker diarization enriched with sensor data fusion for contextualized conversation preservation. the use cases applied to the e-vita project have shown that truly personalized dialogue is pivotal for individual voice assistants. secure local processing and sensor data fusion ensure virtual companions meet individual user needs without compromising privacy or data security.","doi":"","created":1704153600000,"updated":"","authors":["gérard chollet","hugues sansen","yannis tevissen","jérôme boudy","mossaab hariz","christophe lohr","fathy yassa"]}
{"id":"2401.01148","title":"pac-bayes-chernoff bounds for unbounded losses","categories":"stat.ml cs.lg","abstract":"we introduce a new pac-bayes oracle bound for unbounded losses. this result can be understood as a pac-bayesian version of the cram\\'er-chernoff bound. the proof technique relies on controlling the tails of certain random variables involving the cram\\'er transform of the loss. we highlight several applications of the main theorem. first, we show that our result naturally allows exact optimization of the free parameter on many pac-bayes bounds. second, we recover and generalize previous results. finally, we show that our approach allows working with richer assumptions that result in more informative and potentially tighter bounds. in this direction, we provide a general bound under a new ``model-dependent bounded cgf\" assumption from which we obtain bounds based on parameter norms and log-sobolev inequalities. all these bounds can be minimized to obtain novel posteriors.","doi":"","created":1704153600000,"updated":"2024-02-06","authors":["ioar casado","luis a. ortega","andrés r. masegosa","aritz pérez"]}
{"id":"2401.01149","title":"search games with predictions","categories":"cs.gt math.oc","abstract":"we study search games between a mobile searcher and an immobile hider in which the searcher aims to minimize some payoff, which is either the time to find the hider (the search time), or a normalized search time. we consider a new setting in which the searcher has some potentially erroneous information, or prediction on the hider's position. specifically, we study tradeoffs between the consistency of a search strategy (i.e., its worst case expected payoff assuming the prediction is correct) and the robustness (i.e., the worst case expected payoff assuming that the prediction is adversarially generated). we show how to apply this framework in search games over both discrete and continuous, as well as bounded and unbounded spaces. specifically, we prove optimal consistency\/robustness tradeoffs for three fundamental search games, namely searching in a number of discrete locations, expanding search in a tree network, and searching in the infinite line. our study is the first to address the full power of mixed (randomized) strategies; previous work focused only on deterministic strategies, or relied on stochastic assumptions that do not guarantee worst-case robustness in adversarial situations.","doi":"","created":1704153600000,"updated":"","authors":["spyros angelopoulos","thomas lidbetter","konstantinos panagiotou"]}
{"id":"2401.01150","title":"cxl and the return of scale-up database engines","categories":"cs.db cs.pf","abstract":"the growing trend towards specialization has led to a proliferation of accelerators and alternative processing devices. when embedded in conventional computer architectures, the pcie link connecting the cpu to these devices becomes a bottleneck. several proposals for alternative designs have been put forward, with these efforts having now converged into the compute express link (cxl) specification. cxl is an interconnect protocol on top of pcie with a more modern and powerful interface. while still on version 1.0 in terms of commercial availability, the potential of cxl to radically change the underlying architecture has already attracted considerable attention. this attention has been focused mainly on the possibility of using cxl to build a shared memory system among the machines in a rack. we argue, however, that such benefits are just the beginning of more significant changes that will have a major impact on database engines and data processing systems. in a nutshell, while the cloud favored scale-out approaches, cxl brings back scale-up architectures. in the paper we describe how cxl enables such architectures, and the research challenges associated with the emerging scale-up, heterogeneous hardware platforms.","doi":"10.14778\/3675034.3675047","created":1704153600000,"updated":"","authors":["alberto lerner","gustavo alonso"]}
{"id":"2401.01151","title":"identification of secondary resonances of nonlinear systems using   phase-locked loop testing","categories":"eess.sy cs.sy physics.app-ph","abstract":"one unique feature of nonlinear dynamical systems is the existence of superharmonic and subharmonic resonances in addition to primary resonances. in this study, an effective vibration testing methodology is introduced for the experimental identification of these secondary resonances. the proposed method relies on phase-locked loop control combined with adaptive filters for online fourier decomposition. to this end, the concept of a resonant phase lag is exploited to define the target phase lag to be followed during the experimental continuation process. the method is demonstrated using two systems featuring cubic nonlinearities, namely a numerical duffing oscillator and a physical experiment comprising a clamped-clamped thin beam. the obtained results highlight that the control scheme can accurately characterize secondary resonances as well as track their backbone curves. a particularly salient feature of the developed algorithm is that, starting from the rest position, it facilitates an automatic and smooth dynamic state transfer toward one point of a subharmonic isolated branch, hence, inducing branch switching.","doi":"","created":1704153600000,"updated":"","authors":["tong zhou","gaetan kerschen"]}
{"id":"2401.01152","title":"the social graph based on real data","categories":"cs.si physics.soc-ph","abstract":"in this paper, we propose a model enabling the creation of a social graph corresponding to real society. the procedure uses data describing the real social relations in the community, like marital status or number of kids. results show the power-law behavior of the distribution of links and, typical for small worlds, the independence of the clustering coefficient on the size of the graph.","doi":"10.1007\/978-3-031-36027-5_1","created":1704153600000,"updated":"","authors":["tomasz m. gwizdałła","aleksandra piecuch"]}
{"id":"2401.01154","title":"applying bayesian data analysis for causal inference about requirements   quality: a controlled experiment","categories":"cs.se","abstract":"it is commonly accepted that the quality of requirements specifications impacts subsequent software engineering activities. however, we still lack empirical evidence to support organizations in deciding whether their requirements are good enough or impede subsequent activities. we aim to contribute empirical evidence to the effect that requirements quality defects have on a software engineering activity that depends on this requirement. we conduct a controlled experiment in which 25 participants from industry and university generate domain models from four natural language requirements containing different quality defects. we evaluate the resulting models using both frequentist and bayesian data analysis. contrary to our expectations, our results show that the use of passive voice only has a minor impact on the resulting domain models. the use of ambiguous pronouns, however, shows a strong effect on various properties of the resulting domain models. most notably, ambiguous pronouns lead to incorrect associations in domain models. despite being equally advised against by literature and frequentist methods, the bayesian data analysis shows that the two investigated quality defects have vastly different impacts on software engineering activities and, hence, deserve different levels of attention. our employed method can be further utilized by researchers to improve reliable, detailed empirical evidence on requirements quality.","doi":"","created":1704153600000,"updated":"2024-07-01","authors":["julian frattini","davide fucci","richard torkar","lloyd montgomery","michael unterkalmsteiner","jannik fischbach","daniel mendez"]}
{"id":"2401.01155","title":"deep learning-based detection for marker codes over insertion and   deletion channels","categories":"cs.it cs.lg math.it","abstract":"marker code is an effective coding scheme to protect data from insertions and deletions. it has potential applications in future storage systems, such as dna storage and racetrack memory. when decoding marker codes, perfect channel state information (csi), i.e., insertion and deletion probabilities, are required to detect insertion and deletion errors. sometimes, the perfect csi is not easy to obtain or the accurate channel model is unknown. therefore, it is deserved to develop detecting algorithms for marker code without the knowledge of perfect csi. in this paper, we propose two csi-agnostic detecting algorithms for marker code based on deep learning. the first one is a model-driven deep learning method, which deep unfolds the original iterative detecting algorithm of marker code. in this method, csi become weights in neural networks and these weights can be learned from training data. the second one is a data-driven method which is an end-to-end system based on the deep bidirectional gated recurrent unit network. simulation results show that error performances of the proposed methods are significantly better than that of the original detection algorithm with csi uncertainty. furthermore, the proposed data-driven method exhibits better error performances than other methods for unknown channel models.","doi":"","created":1704153600000,"updated":"","authors":["guochen ma","xiaopeng jiao","jianjun mu","hui han","yaming yang"]}
{"id":"2401.01160","title":"train-free segmentation in mri with cubical persistent homology","categories":"eess.iv cs.cg cs.cv cs.lg","abstract":"we describe a new general method for segmentation in mri scans using topological data analysis (tda), offering several advantages over traditional machine learning approaches. it works in three steps, first identifying the whole object to segment via automatic thresholding, then detecting a distinctive subset whose topology is known in advance, and finally deducing the various components of the segmentation. although convoking classical ideas of tda, such an algorithm has never been proposed separately from deep learning methods. to achieve this, our approach takes into account, in addition to the homology of the image, the localization of representative cycles, a piece of information that seems never to have been exploited in this context. in particular, it offers the ability to perform segmentation without the need for large annotated data sets. tda also provides a more interpretable and stable framework for segmentation by explicitly mapping topological features to segmentation components. by adapting the geometric object to be detected, the algorithm can be adjusted to a wide range of data segmentation challenges. we carefully study the examples of glioblastoma segmentation in brain mri, where a sphere is to be detected, as well as myocardium in cardiac mri, involving a cylinder, and cortical plate detection in fetal brain mri, whose 2d slices are circles. we compare our method to state-of-the-art algorithms.","doi":"","created":1704153600000,"updated":"","authors":["anton françois","raphaël tinarrage"]}
{"id":"2401.01163","title":"nu-class net: a novel approach for video quality enhancement","categories":"cs.cv cs.mm","abstract":"video content has experienced a surge in popularity, asserting its dominance over internet traffic and internet of things (iot) networks. video compression has long been regarded as the primary means of efficiently managing the substantial multimedia traffic generated by video-capturing devices. nevertheless, video compression algorithms entail significant computational demands in order to achieve substantial compression ratios. this complexity presents a formidable challenge when implementing efficient video coding standards in resource-constrained embedded systems, such as iot edge node cameras. to tackle this challenge, this paper introduces nu-class net, an innovative deep-learning model designed to mitigate compression artifacts stemming from lossy compression codecs. this enhancement significantly elevates the perceptible quality of low-bit-rate videos. by employing the nu-class net, the video encoder within the video-capturing node can reduce output quality, thereby generating low-bit-rate videos and effectively curtailing both computation and bandwidth requirements at the edge. on the decoder side, which is typically less encumbered by resource limitations, nu-class net is applied after the video decoder to compensate for artifacts and approximate the quality of the original video. experimental results affirm the efficacy of the proposed model in enhancing the perceptible quality of videos, especially those streamed at low bit rates.","doi":"","created":1704153600000,"updated":"2024-06-03","authors":["parham zilouchian moghaddam","mehdi modarressi","mohammad amin sadeghi"]}
{"id":"2401.01164","title":"distilling local texture features for colorectal tissue classification   in low data regimes","categories":"cs.cv","abstract":"multi-class colorectal tissue classification is a challenging problem that is typically addressed in a setting, where it is assumed that ample amounts of training data is available. however, manual annotation of fine-grained colorectal tissue samples of multiple classes, especially the rare ones like stromal tumor and anal cancer is laborious and expensive. to address this, we propose a knowledge distillation-based approach, named kd-ctcnet, that effectively captures local texture information from few tissue samples, through a distillation loss, to improve the standard cnn features. the resulting enriched feature representation achieves improved classification performance specifically in low data regimes. extensive experiments on two public datasets of colorectal tissues reveal the merits of the proposed contributions, with a consistent gain achieved over different approaches across low data settings. the code and models are publicly available on github.","doi":"10.1007\/978-3-031-45676-3_36","created":1704153600000,"updated":"","authors":["dmitry demidov","roba al majzoub","amandeep kumar","fahad khan"]}
{"id":"2401.01165","title":"reinforcement learning for sar view angle inversion with differentiable   sar renderer","categories":"cs.lg eess.sp","abstract":"the electromagnetic inverse problem has long been a research hotspot. this study aims to reverse radar view angles in synthetic aperture radar (sar) images given a target model. nonetheless, the scarcity of sar data, combined with the intricate background interference and imaging mechanisms, limit the applications of existing learning-based approaches. to address these challenges, we propose an interactive deep reinforcement learning (drl) framework, where an electromagnetic simulator named differentiable sar render (dsr) is embedded to facilitate the interaction between the agent and the environment, simulating a human-like process of angle prediction. specifically, dsr generates sar images at arbitrary view angles in real-time. and the differences in sequential and semantic aspects between the view angle-corresponding images are leveraged to construct the state space in drl, which effectively suppress the complex background interference, enhance the sensitivity to temporal variations, and improve the capability to capture fine-grained information. additionally, in order to maintain the stability and convergence of our method, a series of reward mechanisms, such as memory difference, smoothing and boundary penalty, are utilized to form the final reward function. extensive experiments performed on both simulated and real datasets demonstrate the effectiveness and robustness of our proposed method. when utilized in the cross-domain area, the proposed method greatly mitigates inconsistency between simulated and real domains, outperforming reference methods significantly.","doi":"","created":1704153600000,"updated":"","authors":["yanni wang","hecheng jia","shilei fu","huiping lin","feng xu"]}
{"id":"2401.01168","title":"fedqv: leveraging quadratic voting in federated learning","categories":"cs.cr cs.lg","abstract":"federated learning (fl) permits different parties to collaboratively train a global model without disclosing their respective local labels. a crucial step of fl, that of aggregating local models to produce the global one, shares many similarities with public decision-making, and elections in particular. in that context, a major weakness of fl, namely its vulnerability to poisoning attacks, can be interpreted as a consequence of the one person one vote (henceforth 1p1v) principle underpinning most contemporary aggregation rules. in this paper, we propose fedqv, a novel aggregation algorithm built upon the quadratic voting scheme, recently proposed as a better alternative to 1p1v-based elections. our theoretical analysis establishes that fedqv is a truthful mechanism in which bidding according to one's true valuation is a dominant strategy that achieves a convergence rate that matches those of state-of-the-art methods. furthermore, our empirical analysis using multiple real-world datasets validates the superior performance of fedqv against poisoning attacks. it also shows that combining fedqv with unequal voting ``budgets'' according to a reputation score increases its performance benefits even further. finally, we show that fedqv can be easily combined with byzantine-robust privacy-preserving mechanisms to enhance its robustness against both poisoning and privacy attacks.","doi":"","created":1704153600000,"updated":"2024-04-09","authors":["tianyue chu","nikolaos laoutaris"]}
{"id":"2401.01172","title":"quadratic time-frequency analysis of vibration signals for diagnosing   bearing faults","categories":"cs.lg cs.ai cs.sy eess.sy","abstract":"diagnosis of bearing faults is paramount to reducing maintenance costs and operational breakdowns. bearing faults are primary contributors to machine vibrations, and analyzing their signal morphology offers insights into their health status. unfortunately, existing approaches are optimized for controlled environments, neglecting realistic conditions such as time-varying rotational speeds and the vibration's non-stationary nature. this paper presents a fusion of time-frequency analysis and deep learning techniques to diagnose bearing faults under time-varying speeds and varying noise levels. first, we formulate the bearing fault-induced vibrations and discuss the link between their non-stationarity and the bearing's inherent and operational parameters. we also elucidate quadratic time-frequency distributions and validate their effectiveness in resolving distinctive dynamic patterns associated with different bearing faults. based on this, we design a time-frequency convolutional neural network (tf-cnn) to diagnose various faults in rolling-element bearings. our experimental findings undeniably demonstrate the superior performance of tf-cnn in comparison to recently developed techniques. they also assert its versatility in capturing fault-relevant non-stationary features that couple with speed changes and show its exceptional resilience to noise, consistently surpassing competing methods across various signal-to-noise ratios and performance metrics. altogether, the tf-cnn achieves substantial accuracy improvements up to 15%, in severe noise conditions.","doi":"","created":1704153600000,"updated":"2024-02-08","authors":["mohammad al-sa'd","tuomas jalonen","serkan kiranyaz","moncef gabbouj"]}
{"id":"2401.01173","title":"en3d: an enhanced generative model for sculpting 3d humans from 2d   synthetic data","categories":"cs.cv","abstract":"we present en3d, an enhanced generative scheme for sculpting high-quality 3d human avatars. unlike previous works that rely on scarce 3d datasets or limited 2d collections with imbalanced viewing angles and imprecise pose priors, our approach aims to develop a zero-shot 3d generative scheme capable of producing visually realistic, geometrically accurate and content-wise diverse 3d humans without relying on pre-existing 3d or 2d assets. to address this challenge, we introduce a meticulously crafted workflow that implements accurate physical modeling to learn the enhanced 3d generative model from synthetic 2d data. during inference, we integrate optimization modules to bridge the gap between realistic appearances and coarse 3d shapes. specifically, en3d comprises three modules: a 3d generator that accurately models generalizable 3d humans with realistic appearance from synthesized balanced, diverse, and structured human images; a geometry sculptor that enhances shape quality using multi-view normal constraints for intricate human anatomy; and a texturing module that disentangles explicit texture maps with fidelity and editability, leveraging semantical uv partitioning and a differentiable rasterizer. experimental results show that our approach significantly outperforms prior works in terms of image quality, geometry accuracy and content diversity. we also showcase the applicability of our generated avatars for animation and editing, as well as the scalability of our approach for content-style free adaptation.","doi":"","created":1704153600000,"updated":"","authors":["yifang men","biwen lei","yuan yao","miaomiao cui","zhouhui lian","xuansong xie"]}
{"id":"2401.01175","title":"learning surface scattering parameters from sar images using   differentiable ray tracing","categories":"cs.cv","abstract":"simulating high-resolution synthetic aperture radar (sar) images in complex scenes has consistently presented a significant research challenge. the development of a microwave-domain surface scattering model and its reversibility are poised to play a pivotal role in enhancing the authenticity of sar image simulations and facilitating the reconstruction of target parameters. drawing inspiration from the field of computer graphics, this paper proposes a surface microwave rendering model that comprehensively considers both specular and diffuse contributions. the model is analytically represented by the coherent spatially varying bidirectional scattering distribution function (csvbsdf) based on the kirchhoff approximation (ka) and the perturbation method (spm). and sar imaging is achieved through the synergistic combination of ray tracing and fast mapping projection techniques. furthermore, a differentiable ray tracing (drt) engine based on sar images was constructed for csvbsdf surface scattering parameter learning. within this sar image simulation engine, the use of differentiable reverse ray tracing enables the rapid estimation of parameter gradients from sar images. the effectiveness of this approach has been validated through simulations and comparisons with real sar images. by learning the surface scattering parameters, substantial enhancements in sar image simulation performance under various observation conditions have been demonstrated.","doi":"","created":1704153600000,"updated":"","authors":["jiangtao wei","yixiang luomei","xu zhang","feng xu"]}
{"id":"2401.01176","title":"fundamental limitation of semantic communications: neural estimation for   rate-distortion","categories":"cs.it cs.lg eess.sp math.it","abstract":"this paper studies the fundamental limit of semantic communications over the discrete memoryless channel. we consider the scenario to send a semantic source consisting of an observation state and its corresponding semantic state, both of which are recovered at the receiver. to derive the performance limitation, we adopt the semantic rate-distortion function (srdf) to study the relationship among the minimum compression rate, observation distortion, semantic distortion, and channel capacity. for the case with unknown semantic source distribution, while only a set of the source samples is available, we propose a neural-network-based method by leveraging the generative networks to learn the semantic source distribution. furthermore, for a special case where the semantic state is a deterministic function of the observation, we design a cascade neural network to estimate the srdf. for the case with perfectly known semantic source distribution, we propose a general blahut-arimoto algorithm to effectively compute the srdf. finally, experimental results validate our proposed algorithms for the scenarios with ideal gaussian semantic source and some practical datasets.","doi":"","created":1704153600000,"updated":"","authors":["dongxu li","jianhao huang","chuan huang","xiaoqi qin","han zhang","ping zhang"]}
{"id":"2401.01178","title":"gbss:a global building semantic segmentation dataset for large-scale   remote sensing building extraction","categories":"cs.cv","abstract":"semantic segmentation techniques for extracting building footprints from high-resolution remote sensing images have been widely used in many fields such as urban planning. however, large-scale building extraction demands higher diversity in training samples. in this paper, we construct a global building semantic segmentation (gbss) dataset (the dataset will be released), which comprises 116.9k pairs of samples (about 742k buildings) from six continents. there are significant variations of building samples in terms of size and style, so the dataset can be a more challenging benchmark for evaluating the generalization and robustness of building semantic segmentation models. we validated through quantitative and qualitative comparisons between different datasets, and further confirmed the potential application in the field of transfer learning by conducting experiments on subsets.","doi":"","created":1704153600000,"updated":"","authors":["yuping hu","xin huang","jiayi li","zhen zhang"]}
{"id":"2401.01179","title":"freeze the backbones: a parameter-efficient contrastive approach to   robust medical vision-language pre-training","categories":"cs.cv cs.ai cs.lg","abstract":"modern healthcare often utilises radiographic images alongside textual reports for diagnostics, encouraging the use of vision-language self-supervised learning (vl-ssl) with large pre-trained models to learn versatile medical vision representations. however, most existing vl-ssl frameworks are trained end-to-end, which is computation-heavy and can lose vital prior information embedded in pre-trained encoders. to address both issues, we introduce the backbone-agnostic adaptor framework, which preserves medical knowledge in pre-trained image and text encoders by keeping them frozen, and employs a lightweight adaptor module for cross-modal learning. experiments on medical image classification and segmentation tasks across three datasets reveal that our framework delivers competitive performance while cutting trainable parameters by over 90% compared to current pre-training approaches. notably, when fine-tuned with just 1% of data, adaptor outperforms several transformer-based methods trained on full datasets in medical image segmentation.","doi":"","created":1704153600000,"updated":"","authors":["jiuming qin","che liu","sibo cheng","yike guo","rossella arcucci"]}
{"id":"2401.01180","title":"accurate and efficient urban street tree inventory with deep learning on   mobile phone imagery","categories":"cs.cv cs.ai eess.iv","abstract":"deforestation, a major contributor to climate change, poses detrimental consequences such as agricultural sector disruption, global warming, flash floods, and landslides. conventional approaches to urban street tree inventory suffer from inaccuracies and necessitate specialised equipment. to overcome these challenges, this paper proposes an innovative method that leverages deep learning techniques and mobile phone imaging for urban street tree inventory. our approach utilises a pair of images captured by smartphone cameras to accurately segment tree trunks and compute the diameter at breast height (dbh). compared to traditional methods, our approach exhibits several advantages, including superior accuracy, reduced dependency on specialised equipment, and applicability in hard-to-reach areas. we evaluated our method on a comprehensive dataset of 400 trees and achieved a dbh estimation accuracy with an error rate of less than 2.5%. our method holds significant potential for substantially improving forest management practices. by enhancing the accuracy and efficiency of tree inventory, our model empowers urban management to mitigate the adverse effects of deforestation and climate change.","doi":"","created":1704153600000,"updated":"","authors":["asim khan","umair nawaz","anwaar ulhaq","iqbal gondal","sajid javed"]}
{"id":"2401.01181","title":"query-based knowledge sharing for open-vocabulary multi-label   classification","categories":"cs.cv","abstract":"identifying labels that did not appear during training, known as multi-label zero-shot learning, is a non-trivial task in computer vision. to this end, recent studies have attempted to explore the multi-modal knowledge of vision-language pre-training (vlp) models by knowledge distillation, allowing to recognize unseen labels in an open-vocabulary manner. however, experimental evidence shows that knowledge distillation is suboptimal and provides limited performance gain in unseen label prediction. in this paper, a novel query-based knowledge sharing paradigm is proposed to explore the multi-modal knowledge from the pretrained vlp model for open-vocabulary multi-label classification. specifically, a set of learnable label-agnostic query tokens is trained to extract critical vision knowledge from the input image, and further shared across all labels, allowing them to select tokens of interest as visual clues for recognition. besides, we propose an effective prompt pool for robust label embedding, and reformulate the standard ranking learning into a form of classification to allow the magnitude of feature vectors for matching, which both significantly benefit label recognition. experimental results show that our framework significantly outperforms state-of-the-art methods on zero-shot task by 5.9% and 4.5% in map on the nus-wide and open images, respectively.","doi":"","created":1704153600000,"updated":"","authors":["xuelin zhu","jian liu","dongqi tang","jiawei ge","weijia liu","bo liu","jiuxin cao"]}
{"id":"2401.01183","title":"unifying structured data as graph for data-to-text pre-training","categories":"cs.cl cs.ai","abstract":"data-to-text (d2t) generation aims to transform structured data into natural language text. data-to-text pre-training has proved to be powerful in enhancing d2t generation and yields impressive performances. however, previous pre-training methods either oversimplified structured data into a sequence without considering input structures or designed training objectives tailored for a specific data structure (e.g., table or knowledge graph). in this paper, we unify different types of structured data (i.e., table, key-value data, knowledge graph) into the graph format and cast different data-to-text generation tasks as graph-to-text generation. to effectively exploit the structural information of the input graph, we propose a structure-enhanced pre-training method for d2t generation by designing a structure-enhanced transformer. concretely, we devise a position matrix for the transformer, encoding relative positional information of connected nodes in the input graph. in addition, we propose a new attention matrix to incorporate graph structures into the original transformer by taking the available explicit connectivity structure into account. extensive experiments on six benchmark datasets show the effectiveness of our model. our source codes are available at https:\/\/github.com\/alibabaresearch\/damo-convai\/tree\/main\/unid2t.","doi":"","created":1704153600000,"updated":"","authors":["shujie li","liang li","ruiying geng","min yang","binhua li","guanghu yuan","wanwei he","shao yuan","can ma","fei huang","yongbin li"]}
{"id":"2401.01185","title":"on the uniqueness of bayesian coarse correlated equilibria in standard   first-price and all-pay auctions","categories":"cs.gt","abstract":"we study the bayesian coarse correlated equilibrium (bcce) of continuous and discretised first-price and all-pay auctions under the standard symmetric independent private-values model. our goal is to determine how the canonical bayes-nash equilibrium (bne) of the auction relates to the outcome when all buyers bid following no-regret algorithms. numerical experiments show that in two buyer first-price auctions the wasserstein-$2$ distance of buyers' marginal bid distributions decline as $o(1\/n)$ in the discretisation size in instances where the prior distribution is concave, whereas all-pay auctions exhibit similar behaviour without prior dependence. to explain this convergence to a near-equilibrium, we study uniqueness of the bcce of the continuous auction. our uniqueness results translate to provable convergence of deterministic self-play to a near equilibrium outcome in these auctions. in the all-pay auction, we show that independent of the prior distribution there is a unique bcce with symmetric, differentiable, and increasing bidding strategies, which is equivalent to the unique strict bne. in the first-price auction, we need stronger conditions. either the prior is strictly concave or the learning algorithm has to be restricted to strictly increasing strategies. without such strong assumptions, no-regret algorithms can end up in low-price pooling strategies. this is important because it proves that in repeated first-price auctions such as in display ad actions, algorithmic collusion cannot be ruled out without further assumptions even if all bidders rely on no-regret algorithms.","doi":"","created":1704153600000,"updated":"2024-06-20","authors":["mete şeref ahunbay","martin bichler"]}
{"id":"2401.01189","title":"nid-slam: neural implicit representation-based rgb-d slam in dynamic   environments","categories":"cs.ro cs.ai","abstract":"neural implicit representations have been explored to enhance visual slam algorithms, especially in providing high-fidelity dense map. existing methods operate robustly in static scenes but struggle with the disruption caused by moving objects. in this paper we present nid-slam, which significantly improves the performance of neural slam in dynamic environments. we propose a new approach to enhance inaccurate regions in semantic masks, particularly in marginal areas. utilizing the geometric information present in depth images, this method enables accurate removal of dynamic objects, thereby reducing the probability of camera drift. additionally, we introduce a keyframe selection strategy for dynamic scenes, which enhances camera tracking robustness against large-scale objects and improves the efficiency of mapping. experiments on publicly available rgb-d datasets demonstrate that our method outperforms competitive neural slam approaches in tracking accuracy and mapping quality in dynamic environments.","doi":"","created":1704153600000,"updated":"2024-05-16","authors":["ziheng xu","jianwei niu","qingfeng li","tao ren","chen chen"]}
{"id":"2401.01192","title":"deep-ela: deep exploratory landscape analysis with self-supervised   pretrained transformers for single- and multi-objective continuous   optimization problems","categories":"cs.lg","abstract":"in many recent works, the potential of exploratory landscape analysis (ela) features to numerically characterize, in particular, single-objective continuous optimization problems has been demonstrated. these numerical features provide the input for all kinds of machine learning tasks on continuous optimization problems, ranging, i.a., from high-level property prediction to automated algorithm selection and automated algorithm configuration. without ela features, analyzing and understanding the characteristics of single-objective continuous optimization problems is -- to the best of our knowledge -- very limited.   yet, despite their usefulness, as demonstrated in several past works, ela features suffer from several drawbacks. these include, in particular, (1.) a strong correlation between multiple features, as well as (2.) its very limited applicability to multi-objective continuous optimization problems. as a remedy, recent works proposed deep learning-based approaches as alternatives to ela. in these works, e.g., point-cloud transformers were used to characterize an optimization problem's fitness landscape. however, these approaches require a large amount of labeled training data.   within this work, we propose a hybrid approach, deep-ela, which combines (the benefits of) deep learning and ela features. specifically, we pre-trained four transformers on millions of randomly generated optimization problems to learn deep representations of the landscapes of continuous single- and multi-objective optimization problems. our proposed framework can either be used out-of-the-box for analyzing single- and multi-objective continuous optimization problems, or subsequently fine-tuned to various tasks focussing on algorithm behavior and problem understanding.","doi":"","created":1704153600000,"updated":"2024-07-29","authors":["moritz vinzent seiler","pascal kerschke","heike trautmann"]}
{"id":"2401.01193","title":"further explanations on \"sat requires exhaustive search\"","categories":"cs.cc cs.ds","abstract":"recently, xu and zhou [2023] introduced a constructive approach for exploring computational hardness, proving that sat requires exhaustive search. in light of certain misinterpretations concerning the contributions and proofs in that paper, we focus on providing detailed explanations in this work. we begin by delineating the core innovation of the constructive approach, shedding light on the pivotal concept of algorithm designability. we address the overlooked white-box diagonalization method and highlight the concept of an almost independent solution space. in response to specific misunderstandings, such as the concerns surrounding the assumptions of lemma 3.1, we offer comprehensive clarifications aimed at improving the comprehension of the proof. we are grateful for the feedback received on our prior paper and hope this work can foster a more well-informed discussion.","doi":"","created":1704153600000,"updated":"","authors":["qingxiu dong","guangyan zhou","ke xu"]}
{"id":"2401.01195","title":"deep learning driven buffer-aided cooperative networks for b5g\/6g:   challenges, solutions, and future opportunities","categories":"cs.it cs.dc math.it","abstract":"buffer-aided cooperative networks (bacns) have garnered significant attention due to their potential applications in beyond fifth generation (b5g) or sixth generation (6g) critical scenarios. this article explores various typical application scenarios of buffer-aided relaying in b5g\/6g networks to emphasize the importance of incorporating bacn. additionally, we delve into the crucial technical challenges in bacn, including stringent delay constraints, high reliability, imperfect channel state information (csi), transmission security, and integrated network architecture. to address the challenges, we propose leveraging deep learning-based methods for the design and operation of b5g\/6g networks with bacn, deviating from conventional buffer-aided relay selection approaches. in particular, we present two case studies to demonstrate the efficacy of centralized deep reinforcement learning (drl) and decentralized drl in buffer-aided non-terrestrial networks. finally, we outline future research directions in b5g\/6g that pertain to the utilization of bacn.","doi":"","created":1704153600000,"updated":"","authors":["peng xu","gaojie chen","jianping quan","chong huang","ioannis krikidis","kai-kit wong","chan-byoung chae"]}
{"id":"2401.01197","title":"uncertainty resolution in misinformation detection","categories":"cs.cl cs.ai","abstract":"misinformation poses a variety of risks, such as undermining public trust and distorting factual discourse. large language models (llms) like gpt-4 have been shown effective in mitigating misinformation, particularly in handling statements where enough context is provided. however, they struggle to assess ambiguous or context-deficient statements accurately. this work introduces a new method to resolve uncertainty in such statements. we propose a framework to categorize missing information and publish category labels for the liar-new dataset, which is adaptable to cross-domain content with missing information. we then leverage this framework to generate effective user queries for missing context. compared to baselines, our method improves the rate at which generated questions are answerable by the user by 38 percentage points and classification performance by over 10 percentage points macro f1. thus, this approach may provide a valuable component for future misinformation mitigation pipelines.","doi":"","created":1704153600000,"updated":"","authors":["yury orlovskiy","camille thibault","anne imouza","jean-françois godbout","reihaneh rabbany","kellin pelrine"]}
{"id":"2401.01198","title":"mirror descent for stochastic control problems with measure-valued   controls","categories":"math.oc cs.na math.na math.pr","abstract":"this paper studies the convergence of the mirror descent algorithm for finite horizon stochastic control problems with measure-valued control processes. the control objective involves a convex regularisation function, denoted as $h$, with regularisation strength determined by the weight $\\tau\\ge 0$. the setting covers regularised relaxed control problems. under suitable conditions, we establish the relative smoothness and convexity of the control objective with respect to the bregman divergence of $h$, and prove linear convergence of the algorithm for $\\tau=0$ and exponential convergence for $\\tau>0$. the results apply to common regularisers including relative entropy, $\\chi^2$-divergence, and entropic wasserstein costs. this validates recent reinforcement learning heuristics that adding regularisation accelerates the convergence of gradient methods. the proof exploits careful regularity estimates of backward stochastic differential equations in the bounded mean oscillation norm.","doi":"","created":1704153600000,"updated":"","authors":["bekzhan kerimkulov","david šiška","łukasz szpruch","yufei zhang"]}
{"id":"2401.01199","title":"jma: a general algorithm to craft nearly optimal targeted adversarial   example","categories":"cs.lg cs.ai cs.cv","abstract":"most of the approaches proposed so far to craft targeted adversarial examples against deep learning classifiers are highly suboptimal and typically rely on increasing the likelihood of the target class, thus implicitly focusing on one-hot encoding settings. in this paper, we propose a more general, theoretically sound, targeted attack that resorts to the minimization of a jacobian-induced mahalanobis distance (jma) term, taking into account the effort (in the input space) required to move the latent space representation of the input sample in a given direction. the minimization is solved by exploiting the wolfe duality theorem, reducing the problem to the solution of a non-negative least square (nnls) problem. the proposed algorithm provides an optimal solution to a linearized version of the adversarial example problem originally introduced by szegedy et al. \\cite{szegedy2013intriguing}. the experiments we carried out confirm the generality of the proposed attack which is proven to be effective under a wide variety of output encoding schemes. noticeably, the jma attack is also effective in a multi-label classification scenario, being capable to induce a targeted modification of up to half the labels in a complex multilabel classification scenario with 20 labels, a capability that is out of reach of all the attacks proposed so far. as a further advantage, the jma attack usually requires very few iterations, thus resulting more efficient than existing methods.","doi":"","created":1704153600000,"updated":"","authors":["benedetta tondi","wei guo","mauro barni"]}
{"id":"2401.01200","title":"skin cancer diagnosis using nir spectroscopy data of skin lesions in   vivo using machine learning algorithms","categories":"cs.cv cs.ai","abstract":"skin lesions are classified in benign or malignant. among the malignant, melanoma is a very aggressive cancer and the major cause of deaths. so, early diagnosis of skin cancer is very desired. in the last few years, there is a growing interest in computer aided diagnostic (cad) using most image and clinical data of the lesion. these sources of information present limitations due to their inability to provide information of the molecular structure of the lesion. nir spectroscopy may provide an alternative source of information to automated cad of skin lesions. the most commonly used techniques and classification algorithms used in spectroscopy are principal component analysis (pca), partial least squares - discriminant analysis (pls-da), and support vector machines (svm). nonetheless, there is a growing interest in applying the modern techniques of machine and deep learning (mdl) to spectroscopy. one of the main limitations to apply mdl to spectroscopy is the lack of public datasets. since there is no public dataset of nir spectral data to skin lesions, as far as we know, an effort has been made and a new dataset named nir-sc-ufes, has been collected, annotated and analyzed generating the gold-standard for classification of nir spectral data to skin cancer. next, the machine learning algorithms xgboost, catboost, lightgbm, 1d-convolutional neural network (1d-cnn) were investigated to classify cancer and non-cancer skin lesions. experimental results indicate the best performance obtained by lightgbm with pre-processing using standard normal variate (snv), feature extraction providing values of 0.839 for balanced accuracy, 0.851 for recall, 0.852 for precision, and 0.850 for f-score. the obtained results indicate the first steps in cad of skin lesions aiming the automated triage of patients with skin lesions in vivo using nir spectral data.","doi":"","created":1704153600000,"updated":"","authors":["flavio p. loss","pedro h. da cunha","matheus b. rocha","madson poltronieri zanoni","leandro m. de lima","isadora tavares nascimento","isabella rezende","tania r. p. canuto","luciana de paula vieira","renan rossoni","maria c. s. santos","patricia lyra frasson","wanderson romão","paulo r. filgueiras","renato a. krohling"]}
{"id":"2401.01201","title":"whole-examination ai estimation of fetal biometrics from 20-week   ultrasound scans","categories":"cs.cv cs.lg","abstract":"the current approach to fetal anomaly screening is based on biometric measurements derived from individually selected ultrasound images. in this paper, we introduce a paradigm shift that attains human-level performance in biometric measurement by aggregating automatically extracted biometrics from every frame across an entire scan, with no need for operator intervention. we use a convolutional neural network to classify each frame of an ultrasound video recording. we then measure fetal biometrics in every frame where appropriate anatomy is visible. we use a bayesian method to estimate the true value of each biometric from a large number of measurements and probabilistically reject outliers. we performed a retrospective experiment on 1457 recordings (comprising 48 million frames) of 20-week ultrasound scans, estimated fetal biometrics in those scans and compared our estimates to the measurements sonographers took during the scan. our method achieves human-level performance in estimating fetal biometrics and estimates well-calibrated credible intervals in which the true biometric value is expected to lie.","doi":"","created":1704153600000,"updated":"","authors":["lorenzo venturini","samuel budd","alfonso farruggia","robert wright","jacqueline matthew","thomas g. day","bernhard kainz","reza razavi","jo v. hajnal"]}
{"id":"2401.01204","title":"ppbfl: a privacy protected blockchain-based federated learning model","categories":"cs.cr cs.ai","abstract":"with the rapid development of machine learning and a growing concern for data privacy, federated learning has become a focal point of attention. however, attacks on model parameters and a lack of incentive mechanisms hinder the effectiveness of federated learning. therefore, we propose a privacy protected blockchain-based federated learning model (ppbfl) to enhance the security of federated learning and encourage active participation of nodes in model training. blockchain technology ensures the integrity of model parameters stored in the interplanetary file system (ipfs), providing protection against tampering. within the blockchain, we introduce a proof of training work (potw) consensus algorithm tailored for federated learning, aiming to incentive training nodes. this algorithm rewards nodes with greater computational power, promoting increased participation and effort in the federated learning process. a novel adaptive differential privacy algorithm is simultaneously applied to local and global models. this safeguards the privacy of local data at training clients, preventing malicious nodes from launching inference attacks. additionally, it enhances the security of the global model, preventing potential security degradation resulting from the combination of numerous local models. the possibility of security degradation is derived from the composition theorem. by introducing reverse noise in the global model, a zero-bias estimate of differential privacy noise between local and global models is achieved. furthermore, we propose a new mix transactions mechanism utilizing ring signature technology to better protect the identity privacy of local training clients. security analysis and experimental results demonstrate that ppbfl, compared to baseline methods, not only exhibits superior model performance but also achieves higher security.","doi":"","created":1704153600000,"updated":"2024-01-08","authors":["yang li","chunhe xia","wanshuang lin","tianbo wang"]}
{"id":"2401.01207","title":"towards a simultaneous and granular identity-expression control in   personalized face generation","categories":"cs.cv","abstract":"in human-centric content generation, the pre-trained text-to-image models struggle to produce user-wanted portrait images, which retain the identity of individuals while exhibiting diverse expressions. this paper introduces our efforts towards personalized face generation. to this end, we propose a novel multi-modal face generation framework, capable of simultaneous identity-expression control and more fine-grained expression synthesis. our expression control is so sophisticated that it can be specialized by the fine-grained emotional vocabulary. we devise a novel diffusion model that can undertake the task of simultaneously face swapping and reenactment. due to the entanglement of identity and expression, it's nontrivial to separately and precisely control them in one framework, thus has not been explored yet. to overcome this, we propose several innovative designs in the conditional diffusion model, including balancing identity and expression encoder, improved midpoint sampling, and explicitly background conditioning. extensive experiments have demonstrated the controllability and scalability of the proposed framework, in comparison with state-of-the-art text-to-image, face swapping, and face reenactment methods.","doi":"","created":1704153600000,"updated":"2024-04-06","authors":["renshuai liu","bowen ma","wei zhang","zhipeng hu","changjie fan","tangjie lv","yu ding","xuan cheng"]}
{"id":"2401.01208","title":"fgenet: fine-grained extraction network for congested crowd counting","categories":"cs.cv","abstract":"crowd counting has gained significant popularity due to its practical applications. however, mainstream counting methods ignore precise individual localization and suffer from annotation noise because of counting from estimating density maps. additionally, they also struggle with high-density images.to address these issues, we propose an end-to-end model called fine-grained extraction network (fgenet). different from methods estimating density maps, fgenet directly learns the original coordinate points that represent the precise localization of individuals.this study designs a fusion module, named fine-grained feature pyramid(fgfp), that is used to fuse feature maps extracted by the backbone of fgenet. the fused features are then passed to both regression and classification heads, where the former provides predicted point coordinates for a given image, and the latter determines the confidence level for each predicted point being an individual. at the end, fgenet establishes correspondences between prediction points and ground truth points by employing the hungarian algorithm. for training fgenet, we design a robust loss function, named three-task combination (ttc), to mitigate the impact of annotation noise. extensive experiments are conducted on four widely used crowd counting datasets. experimental results demonstrate the effectiveness of fgenet. notably, our method achieves a remarkable improvement of 3.14 points in mean absolute error (mae) on the shanghaitech part a dataset, showcasing its superiority over the existing state-of-the-art methods. even more impressively, fgenet surpasses previous benchmarks on the ucf\\_cc\\_50 dataset with an astounding enhancement of 30.16 points in mae.","doi":"","created":1704153600000,"updated":"","authors":["hao-yuan ma","li zhang","xiang-yi wei"]}
{"id":"2401.01214","title":"yolo algorithm with hybrid attention feature pyramid network for solder   joint defect detection","categories":"cs.cv","abstract":"traditional manual detection for solder joint defect is no longer applied during industrial production due to low efficiency, inconsistent evaluation, high cost and lack of real-time data. a new approach has been proposed to address the issues of low accuracy, high false detection rates and computational cost of solder joint defect detection in surface mount technology of industrial scenarios. the proposed solution is a hybrid attention mechanism designed specifically for the solder joint defect detection algorithm to improve quality control in the manufacturing process by increasing the accuracy while reducing the computational cost. the hybrid attention mechanism comprises a proposed enhanced multi-head self-attention and coordinate attention mechanisms increase the ability of attention networks to perceive contextual information and enhances the utilization range of network features. the coordinate attention mechanism enhances the connection between different channels and reduces location information loss. the hybrid attention mechanism enhances the capability of the network to perceive long-distance position information and learn local features. the improved algorithm model has good detection ability for solder joint defect detection, with map reaching 91.5%, 4.3% higher than the you only look once version 5 algorithm and better than other comparative algorithms. compared to other versions, mean average precision, precision, recall, and frame per seconds indicators have also improved. the improvement of detection accuracy can be achieved while meeting real-time detection requirements.","doi":"","created":1704153600000,"updated":"","authors":["li ang","siti khatijah nor abdul rahim","raseeda hamzah","raihah aminuddin","gao yousheng"]}
{"id":"2401.01215","title":"analysis of a space-time unfitted finite element method for pdes on   evolving surfaces","categories":"math.na cs.na","abstract":"in this paper we analyze a space-time unfitted finite element method for the discretization of scalar surface partial differential equations on evolving surfaces. for higher order approximations of the evolving surface we use the technique of (iso)parametric mappings for which a level set representation of the evolving surface is essential. we derive basic results in which certain geometric characteristics of the exact space-time surface are related to corresponding ones of the numerical surface approximation. these results are used in a complete error analysis of a higher order space-time tracefem.","doi":"","created":1704153600000,"updated":"","authors":["arnold reusken","hauke sass"]}
{"id":"2401.01216","title":"noise-nerf: hide information in neural radiance fields using trainable   noise","categories":"cs.cv","abstract":"neural radiance fields (nerf) have been proposed as an innovative 3d representation method. while attracting lots of attention, nerf faces critical issues such as information confidentiality and security. steganography is a technique used to embed information in another object as a means of protecting information security. currently, there are few related studies on nerf steganography, facing challenges in low steganography quality, model weight damage, and a limited amount of steganographic information. this paper proposes a novel nerf steganography method based on trainable noise: noise-nerf. furthermore, we propose the adaptive pixel selection strategy and pixel perturbation strategy to improve the steganography quality and efficiency. the extensive experiments on open-source datasets show that noise-nerf provides state-of-the-art performances in both steganography quality and rendering quality, as well as effectiveness in super-resolution image steganography.","doi":"","created":1704153600000,"updated":"","authors":["qinglong huang","yong liao","yanbin hao","pengyuan zhou"]}
{"id":"2401.01217","title":"kces: a workflow containerization scheduling scheme under cloud-edge   collaboration framework","categories":"cs.dc","abstract":"as more iot applications gradually move towards the cloud-edge collaborative mode, the containerized scheduling of workflows extends from the cloud to the edge. however, given the high delay of the communication network, loose coupling of structure, and resource heterogeneity between cloud and edge, workflow containerization scheduling in the cloud-edge scenarios faces the difficulty of resource coordination and application collaboration management. to address these two issues, we propose a kubeedge-cloud-edge-scheduling scheme named kces, a workflow containerization scheduling scheme for the kubeedge cloud-edge framework. the kces includes a cloud-edge workflow scheduling engine for kubeedge and workflow scheduling strategies for task horizontal roaming and vertical offloading. considering the scheduling optimization of cloud-edge workflows, this paper proposes a cloud-edge workflow scheduling model and cloud-edge node model and designs a cloud-edge workflow scheduling engine to maximize cloud-edge resource utilization under the constraint of workflow task delay. a cloud-edge resource hybrid management technology is used to design the cloud-edge resource evaluation and resource allocation algorithms to achieve cloud-edge resource collaboration. based on the ideas of distributed functional roles and the hierarchical division of computing power, the horizontal roaming among the edges and vertical offloading strategies between the cloud and edges for workflow tasks are designed to realize the cloud-edge application collaboration. through a customized iot application workflow instance, experimental results show that kces is superior to the baseline in total workflow duration, average workflow duration, and resource usage and has the capabilities of horizontal roaming and vertical offloading for workflow tasks.","doi":"","created":1704153600000,"updated":"","authors":["chenggang shan","runze gao","qinghua han","zhen yang","jinhui zhang","yuanqing xia"]}
{"id":"2401.01218","title":"self-supervised position debiasing for large language models","categories":"cs.cl cs.ai cs.lg","abstract":"fine-tuning has been demonstrated to be an effective method to improve the domain performance of large language models (llms). however, llms might fit the dataset bias and shortcuts for prediction, leading to poor generation performance. previous works have proven that llms are prone to exhibit position bias, i.e., leveraging information positioned at the beginning or end, or specific positional cues within the input. existing debiasing methods for llms require external bias knowledge or annotated non-biased samples, which is lacking for position debiasing and impractical in reality. in this work, we propose a self-supervised position debiasing (sod) framework to mitigate position bias for llms. sod leverages unsupervised responses from pre-trained llms for debiasing without relying on any external knowledge. to improve the quality of unsupervised responses, we propose an objective alignment (oam) module to prune these responses. experiments on eight datasets and five tasks show that sod consistently outperforms existing methods in mitigating three types of position biases. besides, sod achieves this by sacrificing only a small performance on biased samples, which is general and effective. to facilitate the reproducibility of the results, we share the code of all methods and datasets on https:\/\/github.com\/lzksky\/sod.","doi":"","created":1704153600000,"updated":"2024-06-29","authors":["zhongkun liu","zheng chen","mengqi zhang","zhaochun ren","pengjie ren","zhumin chen"]}
{"id":"2401.01219","title":"distribution matching for multi-task learning of classification tasks: a   large-scale study on faces & beyond","categories":"cs.cv","abstract":"multi-task learning (mtl) is a framework, where multiple related tasks are learned jointly and benefit from a shared representation space, or parameter transfer. to provide sufficient learning support, modern mtl uses annotated data with full, or sufficiently large overlap across tasks, i.e., each input sample is annotated for all, or most of the tasks. however, collecting such annotations is prohibitive in many real applications, and cannot benefit from datasets available for individual tasks. in this work, we challenge this setup and show that mtl can be successful with classification tasks with little, or non-overlapping annotations, or when there is big discrepancy in the size of labeled data per task. we explore task-relatedness for co-annotation and co-training, and propose a novel approach, where knowledge exchange is enabled between the tasks via distribution matching. to demonstrate the general applicability of our method, we conducted diverse case studies in the domains of affective computing, face recognition, species recognition, and shopping item classification using nine datasets. our large-scale study of affective tasks for basic expression recognition and facial action unit detection illustrates that our approach is network agnostic and brings large performance improvements compared to the state-of-the-art in both tasks and across all studied databases. in all case studies, we show that co-training via task-relatedness is advantageous and prevents negative transfer (which occurs when mt model's performance is worse than that of at least one single-task model).","doi":"","created":1704153600000,"updated":"2024-01-03","authors":["dimitrios kollias","viktoriia sharmanska","stefanos zafeiriou"]}
{"id":"2401.01220","title":"solving multiscale dynamical systems by deep learning","categories":"math.na cs.na","abstract":"multiscale dynamical systems, modeled by high-dimensional stiff ordinary differential equations (odes) with wide-ranging characteristic timescales, arise across diverse fields of science and engineering, but their numerical solvers often encounter severe efficiency bottlenecks. this paper introduces a novel deepode method, which consists of a global multiscale sampling method and a fitting by deep neural networks to handle multiscale systems. deepode's primary contribution is to address the multiscale challenge of efficiently uncovering representative training sets by combining the monte carlo method and the ode system's intrinsic evolution without suffering from the ``curse of dimensionality''. the deepode method is validated in multiscale systems from diverse areas, including a predator-prey model, a power system oscillation, a battery electrolyte auto-ignition, and turbulent flames. our methods exhibit strong generalization capabilities to unseen conditions, highlighting the power of deep learning in modeling intricate multiscale dynamical processes across science and engineering domains.","doi":"","created":1704153600000,"updated":"","authors":["zhi-qin john xu","junjie yao","yuxiao yi","liangkai hang","weinan e","yaoyu zhang","tianhan zhang"]}
{"id":"2401.01224","title":"beam-based multiple access for irs-aided millimeter-wave and terahertz   communications","categories":"cs.it eess.sp math.it","abstract":"recently, intelligent reflecting surface (irs)-aided millimeter-wave (mmwave) and terahertz (thz) communications are considered in the wireless community. this paper aims to design a beam-based multiple-access strategy for this new paradigm. its key idea is to make use of multiple sub-arrays over a hybrid digital-analog array to form independent beams, each of which is steered towards the desired direction to mitigate inter-user interference and suppress unwanted signal reflection. the proposed scheme combines the advantages of both orthogonal multiple access (i.e., no inter-user interference) and non-orthogonal multiple access (i.e., full time-frequency resource use). consequently, it can substantially boost the system capacity, as verified by monte-carlo simulations.","doi":"","created":1704153600000,"updated":"","authors":["wei jiang","hans dieter schotten"]}
{"id":"2401.01227","title":"identiface : a vgg based multimodal facial biometric system","categories":"cs.cv cs.ai","abstract":"the development of facial biometric systems has contributed greatly to the development of the computer vision field. nowadays, there's always a need to develop a multimodal system that combines multiple biometric traits in an efficient, meaningful way. in this paper, we introduce \"identiface\" which is a multimodal facial biometric system that combines the core of facial recognition with some of the most important soft biometric traits such as gender, face shape, and emotion. we also focused on developing the system using only vgg-16 inspired architecture with minor changes across different subsystems. this unification allows for simpler integration across modalities. it makes it easier to interpret the learned features between the tasks which gives a good indication about the decision-making process across the facial modalities and potential connection. for the recognition problem, we acquired a 99.2% test accuracy for five classes with high intra-class variations using data collected from the feret database[1]. we achieved 99.4% on our dataset and 95.15% on the public dataset[2] in the gender recognition problem. we were also able to achieve a testing accuracy of 88.03% in the face-shape problem using the celebrity face-shape dataset[3]. finally, we achieved a decent testing accuracy of 66.13% in the emotion task which is considered a very acceptable accuracy compared to related work on the fer2013 dataset[4].","doi":"","created":1704153600000,"updated":"2024-01-10","authors":["mahmoud rabea","hanya ahmed","sohaila mahmoud","nourhan sayed"]}
{"id":"2401.01232","title":"motif-aware riemannian graph neural network with generative-contrastive   learning","categories":"cs.lg","abstract":"graphs are typical non-euclidean data of complex structures. in recent years, riemannian graph representation learning has emerged as an exciting alternative to euclidean ones. however, riemannian methods are still in an early stage: most of them present a single curvature (radius) regardless of structural complexity, suffer from numerical instability due to the exponential\/logarithmic map, and lack the ability to capture motif regularity. in light of the issues above, we propose the problem of \\emph{motif-aware riemannian graph representation learning}, seeking a numerically stable encoder to capture motif regularity in a diverse-curvature manifold without labels. to this end, we present a novel motif-aware riemannian model with generative-contrastive learning (motifrgc), which conducts a minmax game in riemannian manifold in a self-supervised manner. first, we propose a new type of riemannian gcn (d-gcn), in which we construct a diverse-curvature manifold by a product layer with the diversified factor, and replace the exponential\/logarithmic map by a stable kernel layer. second, we introduce a motif-aware riemannian generative-contrastive learning to capture motif regularity in the constructed manifold and learn motif-aware node representation without external labels. empirical results show the superiority of mofitrgc.","doi":"","created":1704153600000,"updated":"","authors":["li sun","zhenhao huang","zixi wang","feiyang wang","hao peng","philip yu"]}
{"id":"2401.01233","title":"graph elimination networks","categories":"cs.lg","abstract":"graph neural networks (gnns) are widely applied across various domains, yet they perform poorly in deep layers. existing research typically attributes this problem to node over-smoothing, where node representations become indistinguishable after multiple rounds of propagation. in this paper, we delve into the neighborhood propagation mechanism of gnns and discover that the real root cause of gnns' performance degradation in deep layers lies in ineffective neighborhood feature propagation. this propagation leads to an exponential growth of a node's current representation at every propagation step, making it extremely challenging to capture valuable dependencies between long-distance nodes. to address this issue, we introduce graph elimination networks (gens), which employ a specific algorithm to eliminate redundancies during neighborhood propagation. we demonstrate that gens can enhance nodes' perception of distant neighborhoods and extend the depth of network propagation. extensive experiments show that gens outperform the state-of-the-art methods on various graph-level and node-level datasets.","doi":"","created":1704153600000,"updated":"","authors":["shuo wang","ge cheng","yun zhang"]}
{"id":"2401.01242","title":"encoding binary events from continuous time series in rooted trees using   contrastive learning","categories":"cs.lg cs.ai cs.si stat.ml","abstract":"broadband infrastructure owners do not always know how their customers are connected in the local networks, which are structured as rooted trees. a recent study is able to infer the topology of a local network using discrete time series data from the leaves of the tree (customers). in this study we propose a contrastive approach for learning a binary event encoder from continuous time series data. as a preliminary result, we show that our approach has some potential in learning a valuable encoder.","doi":"","created":1704153600000,"updated":"","authors":["tobias engelhardt rasmussen","siv sørensen"]}
{"id":"2401.01243","title":"contrastive sequential interaction network learning on co-evolving   riemannian spaces","categories":"cs.lg","abstract":"the sequential interaction network usually find itself in a variety of applications, e.g., recommender system. herein, inferring future interaction is of fundamental importance, and previous efforts are mainly focused on the dynamics in the classic zero-curvature euclidean space. despite the promising results achieved by previous methods, a range of significant issues still largely remains open: on the bipartite nature, is it appropriate to place user and item nodes in one identical space regardless of their inherent difference? on the network dynamics, instead of a fixed curvature space, will the representation spaces evolve when new interactions arrive continuously? on the learning paradigm, can we get rid of the label information costly to acquire? to address the aforementioned issues, we propose a novel contrastive model for sequential interaction network learning on co-evolving riemannian spaces, csincere. to the best of our knowledge, we are the first to introduce a couple of co-evolving representation spaces, rather than a single or static space, and propose a co-contrastive learning for the sequential interaction network. in csincere, we formulate a cross-space aggregation for message-passing across representation spaces of different riemannian geometries, and design a neural curvature estimator based on ricci curvatures for modeling the space evolvement over time. thereafter, we present a reweighed co-contrast between the temporal views of the sequential network, so that the couple of riemannian spaces interact with each other for the interaction prediction without labels. empirical results on 5 public datasets show the superiority of csincere over the state-of-the-art methods.","doi":"","created":1704153600000,"updated":"","authors":["li sun","junda ye","jiawei zhang","yong yang","mingsheng liu","feiyang wang","philip s. yu"]}
{"id":"2401.01244","title":"temporal adaptive rgbt tracking with modality prompt","categories":"cs.cv","abstract":"rgbt tracking has been widely used in various fields such as robotics, surveillance processing, and autonomous driving. existing rgbt trackers fully explore the spatial information between the template and the search region and locate the target based on the appearance matching results. however, these rgbt trackers have very limited exploitation of temporal information, either ignoring temporal information or exploiting it through online sampling and training. the former struggles to cope with the object state changes, while the latter neglects the correlation between spatial and temporal information. to alleviate these limitations, we propose a novel temporal adaptive rgbt tracking framework, named as tatrack. tatrack has a spatio-temporal two-stream structure and captures temporal information by an online updated template, where the two-stream structure refers to the multi-modal feature extraction and cross-modal interaction for the initial template and the online update template respectively. tatrack contributes to comprehensively exploit spatio-temporal information and multi-modal information for target localization. in addition, we design a spatio-temporal interaction (sti) mechanism that bridges two branches and enables cross-modal interaction to span longer time scales. extensive experiments on three popular rgbt tracking benchmarks show that our method achieves state-of-the-art performance, while running at real-time speed.","doi":"","created":1704153600000,"updated":"","authors":["hongyu wang","xiaotao liu","yifan li","meng sun","dian yuan","jing liu"]}
{"id":"2401.01247","title":"deep learning-based computational model for disease identification in   cocoa pods (theobroma cacao l.)","categories":"cs.cv","abstract":"the early identification of diseases in cocoa pods is an important task to guarantee the production of high-quality cocoa. the use of artificial intelligence techniques such as machine learning, computer vision and deep learning are promising solutions to help identify and classify diseases in cocoa pods. in this paper we introduce the development and evaluation of a deep learning computational model applied to the identification of diseases in cocoa pods, focusing on \"monilia\" and \"black pod\" diseases. an exhaustive review of state-of-the-art of computational models was carried out, based on scientific articles related to the identification of plant diseases using computer vision and deep learning techniques. as a result of the search, efficientdet-lite4, an efficient and lightweight model for object detection, was selected. a dataset, including images of both healthy and diseased cocoa pods, has been utilized to train the model to detect and pinpoint disease manifestations with considerable accuracy. significant enhancements in the model training and evaluation demonstrate the capability of recognizing and classifying diseases through image analysis. furthermore, the functionalities of the model were integrated into an android native mobile with an user-friendly interface, allowing to younger or inexperienced farmers a fast and accuracy identification of health status of cocoa pods","doi":"","created":1704153600000,"updated":"","authors":["darlyn buenaño vera","byron oviedo","washington chiriboga casanova","cristian zambrano-vega"]}
{"id":"2401.01253","title":"deplatforming norm-violating influencers on social media reduces overall   online attention toward them","categories":"cs.si cs.cy","abstract":"from politicians to podcast hosts, online platforms have systematically banned (``deplatformed'') influential users for breaking platform guidelines. previous inquiries on the effectiveness of this intervention are inconclusive because 1) they consider only few deplatforming events; 2) they consider only overt engagement traces (e.g., likes and posts) but not passive engagement (e.g., views); 3) they do not consider all the potential places users impacted by the deplatforming event might migrate to. we address these limitations in a longitudinal, quasi-experimental study of 165 deplatforming events targeted at 101 influencers. we collect deplatforming events from reddit posts and then manually curate the data, ensuring the correctness of a large dataset of deplatforming events. then, we link these events to google trends and wikipedia page views, platform-agnostic measures of online attention that capture the general public's interest in specific influencers. through a difference-in-differences approach, we find that deplatforming reduces online attention toward influencers. after 12 months, we estimate that online attention toward deplatformed influencers is reduced by -63% (95% ci [-75%,-46%]) on google and by -43% (95% ci [-57%,-24%]) on wikipedia. further, as we study over a hundred deplatforming events, we can analyze in which cases deplatforming is more or less impactful, revealing nuances about the intervention. notably, we find that both permanent and temporary deplatforming reduce online attention toward influencers; overall, this work contributes to the ongoing effort to map the effectiveness of content moderation interventions, driving platform governance away from speculation.","doi":"","created":1704153600000,"updated":"","authors":["manoel horta ribeiro","shagun jhaver","jordi cluet i martinell","marie reignier-tayar","robert west"]}
{"id":"2401.01256","title":"videodrafter: content-consistent multi-scene video generation with llm","categories":"cs.cv cs.cl","abstract":"the recent innovations and breakthroughs in diffusion models have significantly expanded the possibilities of generating high-quality videos for the given prompts. most existing works tackle the single-scene scenario with only one video event occurring in a single background. extending to generate multi-scene videos nevertheless is not trivial and necessitates to nicely manage the logic in between while preserving the consistent visual appearance of key content across video scenes. in this paper, we propose a novel framework, namely videodrafter, for content-consistent multi-scene video generation. technically, videodrafter leverages large language models (llm) to convert the input prompt into comprehensive multi-scene script that benefits from the logical knowledge learnt by llm. the script for each scene includes a prompt describing the event, the foreground\/background entities, as well as camera movement. videodrafter identifies the common entities throughout the script and asks llm to detail each entity. the resultant entity description is then fed into a text-to-image model to generate a reference image for each entity. finally, videodrafter outputs a multi-scene video by generating each scene video via a diffusion process that takes the reference images, the descriptive prompt of the event and camera movement into account. the diffusion model incorporates the reference images as the condition and alignment to strengthen the content consistency of multi-scene videos. extensive experiments demonstrate that videodrafter outperforms the sota video generation models in terms of visual quality, content consistency, and user preference.","doi":"","created":1704153600000,"updated":"","authors":["fuchen long","zhaofan qiu","ting yao","tao mei"]}
{"id":"2401.01257","title":"profiling programming language learning","categories":"cs.pl","abstract":"this paper documents a year-long experiment to \"profile\" the process of learning a programming language: gathering data to understand what makes a language hard to learn, and using that data to improve the learning process. we added interactive quizzes to the rust programming language, the official textbook for learning rust. over 13 months, 62,526 readers answered questions 1,140,202 times. first, we analyze the trajectories of readers. we find that many readers drop-out of the book early when faced with difficult language concepts like rust's ownership types. second, we use classical test theory and item response theory to analyze the characteristics of quiz questions. we find that better questions are more conceptual in nature, such as asking why a program does not compile vs. whether a program compiles. third, we performed 12 interventions into the book to help readers with difficult questions. we find that on average, interventions improved quiz scores on the targeted questions by +20%. fourth, we show that our technique can likely generalize to languages with smaller user bases by simulating our statistical inferences on small n. these results demonstrate that quizzes are a simple and useful technique for understanding language learning at all scales.","doi":"","created":1704153600000,"updated":"","authors":["will crichton","shriram krishnamurthi"]}
{"id":"2401.01259","title":"do concept bottleneck models obey locality?","categories":"cs.lg cs.ai","abstract":"concept-based methods explain model predictions using human-understandable concepts. these models require accurate concept predictors, yet the faithfulness of existing concept predictors to their underlying concepts is unclear. in this paper, we investigate the faithfulness of concept bottleneck models (cbms), a popular family of concept-based architectures, by looking at whether they respect \"localities\" in datasets. localities involve using only relevant features when predicting a concept's value. when localities are not considered, concepts may be predicted based on spuriously correlated features, degrading performance and robustness. this work examines how cbm predictions change when perturbing model inputs, and reveals that cbms may not capture localities, even when independent concepts are localised to non-overlapping feature subsets. our empirical and theoretical results demonstrate that datasets with correlated concepts may lead to accurate but uninterpretable models that fail to learn localities. overall, we find that cbm interpretability is fragile, as cbms occasionally rely upon spurious features, necessitating further research into the robustness of concept predictors.","doi":"","created":1704153600000,"updated":"2024-05-28","authors":["naveen raman","mateo espinosa zarlenga","juyeon heo","mateja jamnik"]}
{"id":"2401.01262","title":"fairness certification for natural language processing and large   language models","categories":"cs.cl cs.ai cs.cy cs.lg","abstract":"natural language processing (nlp) plays an important role in our daily lives, particularly due to the enormous progress of large language models (llm). however, nlp has many fairness-critical use cases, e.g., as an expert system in recruitment or as an llm-based tutor in education. since nlp is based on human language, potentially harmful biases can diffuse into nlp systems and produce unfair results, discriminate against minorities or generate legal issues. hence, it is important to develop a fairness certification for nlp approaches. we follow a qualitative research approach towards a fairness certification for nlp. in particular, we have reviewed a large body of literature on algorithmic fairness, and we have conducted semi-structured expert interviews with a wide range of experts from that area. we have systematically devised six fairness criteria for nlp, which can be further refined into 18 sub-categories. our criteria offer a foundation for operationalizing and testing processes to certify fairness, both from the perspective of the auditor and the audited organization.","doi":"","created":1704153600000,"updated":"2024-01-03","authors":["vincent freiberger","erik buchmann"]}
{"id":"2401.01263","title":"identification of additive continuous-time systems in open and   closed-loop","categories":"eess.sy cs.sy","abstract":"when identifying electrical, mechanical, or biological systems, parametric continuous-time identification methods can lead to interpretable and parsimonious models when the model structure aligns with the physical properties of the system. traditional linear system identification may not consider the most parsimonious model when relying solely on unfactored transfer functions, which typically result from standard direct approaches. this paper presents a novel identification method that delivers additive models for both open and closed-loop setups. the estimators that are derived are shown to be generically consistent, and can admit the identification of marginally stable additive systems. numerical simulations show the efficacy of the proposed approach, and its performance in identifying a modal representation of a flexible beam is verified using experimental data.","doi":"","created":1704153600000,"updated":"","authors":["rodrigo a. gonzález","koen classens","cristian r. rojas","james s. welsh","tom oomen"]}
{"id":"2401.01265","title":"optimal synthesis of finite state machines with universal gates using   evolutionary algorithm","categories":"cs.ne cs.ai","abstract":"this work presents an optimization method for the synthesis of finite state machines. the focus is on the reduction in the on-chip area and the cost of the circuit. a list of finite state machines from mcnc91 benchmark circuits have been evolved using cartesian genetic programming. on the average, almost 30% of reduction in the total number of gates has been achieved. the effects of some parameters on the evolutionary process have also been discussed in the paper.","doi":"","created":1704153600000,"updated":"","authors":["noor ullah","khawaja m. yahya","irfan ahmed"]}
{"id":"2401.01268","title":"$f$-divergence based classification: beyond the use of cross-entropy","categories":"cs.lg eess.sp","abstract":"in deep learning, classification tasks are formalized as optimization problems often solved via the minimization of the cross-entropy. however, recent advancements in the design of objective functions allow the usage of the $f$-divergence to generalize the formulation of the optimization problem for classification. we adopt a bayesian perspective and formulate the classification task as a maximum a posteriori probability problem. we propose a class of objective functions based on the variational representation of the $f$-divergence. furthermore, driven by the challenge of improving the state-of-the-art approach, we propose a bottom-up method that leads us to the formulation of an objective function corresponding to a novel $f$-divergence referred to as shifted log (sl). we theoretically analyze the objective functions proposed and numerically test them in three application scenarios: toy examples, image datasets, and signal detection\/decoding problems. the analyzed scenarios demonstrate the effectiveness of the proposed approach and that the sl divergence achieves the highest classification accuracy in almost all the considered cases.","doi":"","created":1704153600000,"updated":"2024-05-16","authors":["nicola novello","andrea m. tonello"]}
{"id":"2401.01269","title":"llbezpeky: leveraging large language models for vulnerability detection","categories":"cs.cr cs.ai cs.se","abstract":"despite the continued research and progress in building secure systems, android applications continue to be ridden with vulnerabilities, necessitating effective detection methods. current strategies involving static and dynamic analysis tools come with limitations like overwhelming number of false positives and limited scope of analysis which make either difficult to adopt. over the past years, machine learning based approaches have been extensively explored for vulnerability detection, but its real-world applicability is constrained by data requirements and feature engineering challenges. large language models (llms), with their vast parameters, have shown tremendous potential in understanding semnatics in human as well as programming languages. we dive into the efficacy of llms for detecting vulnerabilities in the context of android security. we focus on building an ai-driven workflow to assist developers in identifying and rectifying vulnerabilities. our experiments show that llms outperform our expectations in finding issues within applications correctly flagging insecure apps in 91.67% of cases in the ghera benchmark. we use inferences from our experiments towards building a robust and actionable vulnerability detection system and demonstrate its effectiveness. our experiments also shed light on how different various simple configurations can affect the true positive (tp) and false positive (fp) rates.","doi":"","created":1704153600000,"updated":"2024-02-13","authors":["noble saji mathews","yelizaveta brus","yousra aafer","meiyappan nagappan","shane mcintosh"]}
{"id":"2401.01270","title":"optimal rates of kernel ridge regression under source condition in large   dimensions","categories":"cs.lg","abstract":"motivated by the studies of neural networks (e.g.,the neural tangent kernel theory), we perform a study on the large-dimensional behavior of kernel ridge regression (krr) where the sample size $n \\asymp d^{\\gamma}$ for some $\\gamma > 0$. given an rkhs $\\mathcal{h}$ associated with an inner product kernel defined on the sphere $\\mathbb{s}^{d}$, we suppose that the true function $f_{\\rho}^{*} \\in [\\mathcal{h}]^{s}$, the interpolation space of $\\mathcal{h}$ with source condition $s>0$. we first determined the exact order (both upper and lower bound) of the generalization error of kernel ridge regression for the optimally chosen regularization parameter $\\lambda$. we then further showed that when $0<s\\le1$, krr is minimax optimal; and when $s>1$, krr is not minimax optimal (a.k.a. he saturation effect). our results illustrate that the curves of rate varying along $\\gamma$ exhibit the periodic plateau behavior and the multiple descent behavior and show how the curves evolve with $s>0$. interestingly, our work provides a unified viewpoint of several recent works on kernel regression in the large-dimensional setting, which correspond to $s=0$ and $s=1$ respectively.","doi":"","created":1704153600000,"updated":"","authors":["haobo zhang","yicheng li","weihao lu","qian lin"]}
{"id":"2401.01272","title":"moc-rvq: multilevel codebook-assisted digital generative semantic   communication","categories":"cs.cv","abstract":"vector quantization-based image semantic communication systems have successfully boosted transmission efficiency, but face a challenge with conflicting requirements between codebook design and digital constellation modulation. traditional codebooks need a wide index range, while modulation favors few discrete states. to address this, we propose a multilevel generative semantic communication system with a two-stage training framework. in the first stage, we train a high-quality codebook, using a multi-head octonary codebook (moc) to compress the index range. we also integrate a residual vector quantization (rvq) mechanism for effective multilevel communication. in the second stage, a noise reduction block (nrb) based on swin transformer is introduced, coupled with the multilevel codebook from the first stage, serving as a high-quality semantic knowledge base (skb) for generative feature restoration. experimental results highlight moc-rvq's superior performance over methods like bpg or jpeg, even without channel error correction coding.","doi":"","created":1704153600000,"updated":"","authors":["yingbin zhou","yaping sun","guanying chen","xiaodong xu","hao chen","binhong huang","shuguang cui","ping zhang"]}
{"id":"2401.01273","title":"learning-based agricultural management in partially observable   environments subject to climate variability","categories":"cs.lg","abstract":"agricultural management, with a particular focus on fertilization strategies, holds a central role in shaping crop yield, economic profitability, and environmental sustainability. while conventional guidelines offer valuable insights, their efficacy diminishes when confronted with extreme weather conditions, such as heatwaves and droughts. in this study, we introduce an innovative framework that integrates deep reinforcement learning (drl) with recurrent neural networks (rnns). leveraging the gym-dssat simulator, we train an intelligent agent to master optimal nitrogen fertilization management. through a series of simulation experiments conducted on corn crops in iowa, we compare partially observable markov decision process (pomdp) models with markov decision process (mdp) models. our research underscores the advantages of utilizing sequential observations in developing more efficient nitrogen input policies. additionally, we explore the impact of climate variability, particularly during extreme weather events, on agricultural outcomes and management. our findings demonstrate the adaptability of fertilization policies to varying climate conditions. notably, a fixed policy exhibits resilience in the face of minor climate fluctuations, leading to commendable corn yields, cost-effectiveness, and environmental conservation. however, our study illuminates the need for agent retraining to acquire new optimal policies under extreme weather events. this research charts a promising course toward adaptable fertilization strategies that can seamlessly align with dynamic climate scenarios, ultimately contributing to the optimization of crop management practices.","doi":"","created":1704153600000,"updated":"","authors":["zhaoan wang","shaoping xiao","junchao li","jun wang"]}
{"id":"2401.01275","title":"charactereval: a chinese benchmark for role-playing conversational agent   evaluation","categories":"cs.cl","abstract":"recently, the advent of large language models (llms) has revolutionized generative agents. among them, role-playing conversational agents (rpcas) attract considerable attention due to their ability to emotionally engage users. however, the absence of a comprehensive benchmark impedes progress in this field. to bridge this gap, we introduce charactereval, a chinese benchmark for comprehensive rpca assessment, complemented by a tailored high-quality dataset. the dataset comprises 1,785 multi-turn role-playing dialogues, encompassing 23,020 examples and featuring 77 characters derived from chinese novels and scripts. it was carefully constructed, beginning with initial dialogue extraction via gpt-4, followed by rigorous human-led quality control, and enhanced with in-depth character profiles sourced from baidu baike. charactereval employs a multifaceted evaluation approach, encompassing thirteen targeted metrics on four dimensions. comprehensive experiments on charactereval demonstrate that chinese llms exhibit more promising capabilities than gpt-4 in chinese role-playing conversation. source code, data source and reward model will be publicly accessible at https:\/\/github.com\/morecry\/charactereval.","doi":"","created":1704153600000,"updated":"2024-01-09","authors":["quan tu","shilong fan","zihang tian","rui yan"]}
{"id":"2401.01280","title":"geqo: ml-accelerated semantic equivalence detection","categories":"cs.db cs.lg","abstract":"large scale analytics engines have become a core dependency for modern data-driven enterprises to derive business insights and drive actions. these engines support a large number of analytic jobs processing huge volumes of data on a daily basis, and workloads are often inundated with overlapping computations across multiple jobs. reusing common computation is crucial for efficient cluster resource utilization and reducing job execution time. detecting common computation is the first and key step for reducing this computational redundancy. however, detecting equivalence on large-scale analytics engines requires efficient and scalable solutions that are fully automated. in addition, to maximize computation reuse, equivalence needs to be detected at the semantic level instead of just the syntactic level (i.e., the ability to detect semantic equivalence of seemingly different-looking queries). unfortunately, existing solutions fall short of satisfying these requirements.   in this paper, we take a major step towards filling this gap by proposing geqo, a portable and lightweight machine-learning-based framework for efficiently identifying semantically equivalent computations at scale. geqo introduces two machine-learning-based filters that quickly prune out nonequivalent subexpressions and employs a semi-supervised learning feedback loop to iteratively improve its model with an intelligent sampling mechanism. further, with its novel database-agnostic featurization method, geqo can transfer the learning from one workload and database to another. our extensive empirical evaluation shows that, on tpc-ds-like queries, geqo yields significant performance gains-up to 200x faster than automated verifiers-and finds up to 2x more equivalences than optimizer and signature-based equivalence detection approaches.","doi":"10.1145\/3626710","created":1704153600000,"updated":"","authors":["brandon haynes","rana alotaibi","anna pavlenko","jyoti leeka","alekh jindal","yuanyuan tian"]}
{"id":"2401.01283","title":"quality and quantity of machine translation references for automatic   metrics","categories":"cs.cl","abstract":"automatic machine translation metrics typically rely on human translations to determine the quality of system translations. common wisdom in the field dictates that the human references should be of very high quality. however, there are no cost-benefit analyses that could be used to guide practitioners who plan to collect references for machine translation evaluation. we find that higher-quality references lead to better metric correlations with humans at the segment-level. having up to 7 references per segment and taking their average (or maximum) helps all metrics. interestingly, the references from vendors of different qualities can be mixed together and improve metric success. higher quality references, however, cost more to create and we frame this as an optimization problem: given a specific budget, what references should be collected to maximize metric success. these findings can be used by evaluators of shared tasks when references need to be created under a certain budget.","doi":"","created":1704153600000,"updated":"2024-04-10","authors":["vilém zouhar","ondřej bojar"]}
{"id":"2401.01285","title":"socially responsible computing in an introductory course","categories":"cs.cy cs.hc","abstract":"given the potential for technology to inflict harm and injustice on society, it is imperative that we cultivate a sense of social responsibility among our students as they progress through the computer science (cs) curriculum. our students need to be able to examine the social complexities in which technology development and use are situated. also, aligning students' personal goals and their ability to achieve them in their field of study is important for promoting motivation and a sense of belonging. promoting communal goals while learning computing can help broaden participation, particularly among groups who have been historically marginalized in computing. keeping these considerations in mind, we piloted an introductory java programming course in which activities engaging students in ethical and socially responsible considerations were integrated across modules. rather than adding social on top of the technical content, our curricular approach seeks to weave them together. the data from the class suggests that the students found the inclusion of the social context in the technical assignments to be more motivating and expressed greater agency in realizing social change. we share our approach to designing this new introductory socially responsible computing course and the students' reflections. we also highlight seven considerations for educators seeking to incorporate socially responsible computing.","doi":"10.1145\/3626252.3630926","created":1704153600000,"updated":"","authors":["aakash gautam","anagha kulkarni","sarah hug","jane lehr","ilmi yoon"]}
{"id":"2401.01286","title":"a comprehensive study of knowledge editing for large language models","categories":"cs.cl cs.ai cs.cv cs.hc cs.lg","abstract":"large language models (llms) have shown extraordinary capabilities in understanding and generating text that closely mirrors human communication. however, a primary limitation lies in the significant computational demands during training, arising from their extensive parameterization. this challenge is further intensified by the dynamic nature of the world, necessitating frequent updates to llms to correct outdated information or integrate new knowledge, thereby ensuring their continued relevance. note that many applications demand continual model adjustments post-training to address deficiencies or undesirable behaviors. there is an increasing interest in efficient, lightweight methods for on-the-fly model modifications. to this end, recent years have seen a burgeoning in the techniques of knowledge editing for llms, which aim to efficiently modify llms' behaviors within specific domains while preserving overall performance across various inputs. in this paper, we first define the knowledge editing problem and then provide a comprehensive review of cutting-edge approaches. drawing inspiration from educational and cognitive research theories, we propose a unified categorization criterion that classifies knowledge editing methods into three groups: resorting to external knowledge, merging knowledge into the model, and editing intrinsic knowledge. furthermore, we introduce a new benchmark, knowedit, for a comprehensive empirical evaluation of representative knowledge editing approaches. additionally, we provide an in-depth analysis of knowledge location, which can give a deeper understanding of the knowledge structures inherent within llms. finally, we discuss several potential applications of knowledge editing, outlining its broad and impactful implications.","doi":"","created":1704153600000,"updated":"2024-03-28","authors":["ningyu zhang","yunzhi yao","bozhong tian","peng wang","shumin deng","mengru wang","zekun xi","shengyu mao","jintian zhang","yuansheng ni","siyuan cheng","ziwen xu","xin xu","jia-chen gu","yong jiang","pengjun xie","fei huang","lei liang","zhiqiang zhang","xiaowei zhu","jun zhou","huajun chen"]}
{"id":"2401.01288","title":"physics-informed generalizable wireless channel modeling with   segmentation and deep learning: fundamentals, methodologies, and challenges","categories":"cs.it cs.ai cs.cv math.it","abstract":"channel modeling is fundamental in advancing wireless systems and has thus attracted considerable research focus. recent trends have seen a growing reliance on data-driven techniques to facilitate the modeling process and yield accurate channel predictions. in this work, we first provide a concise overview of data-driven channel modeling methods, highlighting their limitations. subsequently, we introduce the concept and advantages of physics-informed neural network (pinn)-based modeling and a summary of recent contributions in this area. our findings demonstrate that pinn-based approaches in channel modeling exhibit promising attributes such as generalizability, interpretability, and robustness. we offer a comprehensive architecture for pinn methodology, designed to inform and inspire future model development. a case-study of our recent work on precise indoor channel prediction with semantic segmentation and deep learning is presented. the study concludes by addressing the challenges faced and suggesting potential research directions in this field.","doi":"","created":1704153600000,"updated":"","authors":["ethan zhu","haijian sun","mingyue ji"]}
{"id":"2401.01289","title":"competitive searching over terrains","categories":"cs.cg","abstract":"we study a variant of the searching problem where the environment consists of a known terrain and the goal is to obtain visibility of an unknown target point on the surface of the terrain. the searcher starts on the surface of the terrain and is allowed to fly above the terrain. the goal is to devise a searching strategy that minimizes the competitive ratio, that is, the worst-case ratio between the distance traveled by the searching strategy and the minimum travel distance needed to detect the target. for $1.5$d terrains we show that any searching strategy has a competitive ratio of at least $\\sqrt{82}$ and we present a nearly-optimal searching strategy that achieves a competitive ratio of $3\\sqrt{19\/2} \\approx \\sqrt{82} + 0.19$. this strategy extends directly to the case where the searcher has no knowledge of the terrain beforehand. for $2.5$d terrains we show that the optimal competitive ratio depends on the maximum slope $\\lambda$ of the terrain, and is hence unbounded in general. specifically, we provide a lower bound on the competitive ratio of $\\omega(\\sqrt{\\lambda})$. finally, we complement the lower bound with a searching strategy based on the maximum slope of the known terrain, which achieves a competitive ratio of $o(\\sqrt{\\lambda})$.","doi":"","created":1704153600000,"updated":"","authors":["sarita de berg","nathan van beusekom","max van mulken","kevin verbeek","jules wulms"]}
{"id":"2401.01291","title":"generative ai is already widespread in the public sector","categories":"cs.cy","abstract":"generative ai has the potential to transform how public services are delivered by enhancing productivity and reducing time spent on bureaucracy. furthermore, unlike other types of artificial intelligence, it is a technology that has quickly become widely available for bottom-up adoption: essentially anyone can decide to make use of it in their day to day work. but to what extent is generative ai already in use in the public sector? our survey of 938 public service professionals within the uk (covering education, health, social work and emergency services) seeks to answer this question. we find that use of generative ai systems is already widespread: 45% of respondents were aware of generative ai usage within their area of work, while 22% actively use a generative ai system. public sector professionals were positive about both current use of the technology and its potential to enhance their efficiency and reduce bureaucratic workload in the future. for example, those working in the nhs thought that time spent on bureaucracy could drop from 50% to 30% if generative ai was properly exploited, an equivalent of one day per week (an enormous potential impact). our survey also found a high amount of trust (61%) around generative ai outputs, and a low fear of replacement (16%). while respondents were optimistic overall, areas of concern included feeling like the uk is missing out on opportunities to use ai to improve public services (76%), and only a minority of respondents (32%) felt like there was clear guidance on generative ai usage in their workplaces. in other words, it is clear that generative ai is already transforming the public sector, but uptake is happening in a disorganised fashion without clear guidelines. the uk's public sector urgently needs to develop more systematic methods for taking advantage of the technology.","doi":"","created":1704153600000,"updated":"","authors":["jonathan bright","florence e. enock","saba esnaashari","john francis","youmna hashem","deborah morgan"]}
{"id":"2401.01294","title":"efficient sparse least absolute deviation regression with differential   privacy","categories":"stat.ml cs.lg stat.me","abstract":"in recent years, privacy-preserving machine learning algorithms have attracted increasing attention because of their important applications in many scientific fields. however, in the literature, most privacy-preserving algorithms demand learning objectives to be strongly convex and lipschitz smooth, which thus cannot cover a wide class of robust loss functions (e.g., quantile\/least absolute loss). in this work, we aim to develop a fast privacy-preserving learning solution for a sparse robust regression problem. our learning loss consists of a robust least absolute loss and an $\\ell_1$ sparse penalty term. to fast solve the non-smooth loss under a given privacy budget, we develop a fast robust and privacy-preserving estimation (frappe) algorithm for least absolute deviation regression. our algorithm achieves a fast estimation by reformulating the sparse lad problem as a penalized least square estimation problem and adopts a three-stage noise injection to guarantee the $(\\epsilon,\\delta)$-differential privacy. we show that our algorithm can achieve better privacy and statistical accuracy trade-off compared with the state-of-the-art privacy-preserving regression algorithms. in the end, we conduct experiments to verify the efficiency of our proposed frappe algorithm.","doi":"10.1109\/tifs.2023.3349054","created":1704153600000,"updated":"","authors":["weidong liu","xiaojun mao","xiaofei zhang","xin zhang"]}
{"id":"2401.01302","title":"on the uniqueness and computation of commuting extensions","categories":"cs.ds cs.cc math.ra","abstract":"a tuple (z_1,...,z_p) of matrices of size r is said to be a commuting extension of a tuple (a_1,...,a_p) of matrices of size n <r if the z_i pairwise commute and each a_i sits in the upper left corner of a block decomposition of z_i. this notion was discovered and rediscovered in several contexts including algebraic complexity theory (in strassen's work on tensor rank), in numerical analysis for the construction of cubature formulas and in quantum mechanics for the study of computational methods and the study of the so-called \"quantum zeno dynamics.\" commuting extensions have also attracted the attention of the linear algebra community. in this paper we present 3 types of results:   (i) theorems on the uniqueness of commuting extensions for three matrices or more.   (ii) algorithms for the computation of commuting extensions of minimal size. these algorithms work under the same assumptions as our uniqueness theorems. they are applicable up to r=4n\/3, and are apparently the first provably efficient algorithms for this problem applicable beyond r=n+1.   (iii) a genericity theorem showing that our algorithms and uniqueness theorems can be applied to a wide range of input matrices.","doi":"","created":1704153600000,"updated":"","authors":["pascal koiran"]}
{"id":"2401.01303","title":"integrating edges into u-net models with explainable activation maps for   brain tumor segmentation using mr images","categories":"eess.iv cs.cv cs.lg","abstract":"manual delineation of tumor regions from magnetic resonance (mr) images is time-consuming, requires an expert, and is prone to human error. in recent years, deep learning models have been the go-to approach for the segmentation of brain tumors. u-net and its' variants for semantic segmentation of medical images have achieved good results in the literature. however, u-net and its' variants tend to over-segment tumor regions and may not accurately segment the tumor edges. the edges of the tumor are as important as the tumor regions for accurate diagnosis, surgical precision, and treatment planning. in the proposed work, the authors aim to extract edges from the ground truth using a derivative-like filter followed by edge reconstruction to obtain an edge ground truth in addition to the brain tumor ground truth. utilizing both ground truths, the author studies several u-net and its' variant architectures with and without tumor edges ground truth as a target along with the tumor ground truth for brain tumor segmentation. the author used the brats2020 benchmark dataset to perform the study and the results are tabulated for the dice and hausdorff95 metrics. the mean and median metrics are calculated for the whole tumor (wt), tumor core (tc), and enhancing tumor (et) regions. compared to the baseline u-net and its variants, the models that learned edges along with the tumor regions performed well in core tumor regions in both training and validation datasets. the improved performance of edge-trained models trained on baseline models like u-net and v-net achieved performance similar to baseline state-of-the-art models like swin u-net and hybrid mr-u-net. the edge-target trained models are capable of generating edge maps that can be useful for treatment planning. additionally, for further explainability of the results, the activation map generated by the hybrid mr-u-net has been studied.","doi":"","created":1704153600000,"updated":"","authors":["subin sahayam","umarani jayaraman"]}
{"id":"2401.01304","title":"experimental validation of sensor fusion-based gnss spoofing attack   detection framework for autonomous vehicles","categories":"cs.cr cs.ai","abstract":"in this paper, we validate the performance of the a sensor fusion-based global navigation satellite system (gnss) spoofing attack detection framework for autonomous vehicles (avs). to collect data, a vehicle equipped with a gnss receiver, along with inertial measurement unit (imu) is used. the detection framework incorporates two strategies: the first strategy involves comparing the predicted location shift, which is the distance traveled between two consecutive timestamps, with the inertial sensor-based location shift. for this purpose, data from low-cost in-vehicle inertial sensors such as the accelerometer and gyroscope sensor are fused and fed into a long short-term memory (lstm) neural network. the second strategy employs a random-forest supervised machine learning model to detect and classify turns, distinguishing between left and right turns using the output from the steering angle sensor. in experiments, two types of spoofing attack models: turn-by-turn and wrong turn are simulated. these spoofing attacks are modeled as sql injection attacks, where, upon successful implementation, the navigation system perceives injected spoofed location information as legitimate while being unable to detect legitimate gnss signals. importantly, the imu data remains uncompromised throughout the spoofing attack. to test the effectiveness of the detection framework, experiments are conducted in tuscaloosa, al, mimicking urban road structures. the results demonstrate the framework's ability to detect various sophisticated gnss spoofing attacks, even including slow position drifting attacks. overall, the experimental results showcase the robustness and efficacy of the sensor fusion-based spoofing attack detection approach in safeguarding avs against gnss spoofing threats.","doi":"","created":1704153600000,"updated":"","authors":["sagar dasgupta","kazi hassan shakib","mizanur rahman"]}
{"id":"2401.01305","title":"application of the cartier operator in coding theory","categories":"cs.it math.it","abstract":"the $a$-number is an invariant of the isomorphism class of the $p$-torsion group scheme. we use the cartier operator on $h^0(\\mathcal{a}_2,\\omega^1)$ to find a closed formula for the $a$-number of the form $\\mathcal{a}_2 = v(y^{\\sqrt{q}}+y-x^{\\frac{\\sqrt{q}+1}{2}})$ where $q=p^s$ over the finite field $\\mathbb{f}_{q^2}$. the application of the computed $a$-number in coding theory is illustrated by the relationship between the algebraic properties of the curve and the parameters of codes that are supported by it.","doi":"","created":1704153600000,"updated":"","authors":["vahid nourozi"]}
{"id":"2401.01306","title":"learning solutions to some toy constrained optimization problems in   infinite dimensional hilbert spaces","categories":"math.oc cs.lg","abstract":"in this work we present deep learning implementations of two popular theoretical constrained optimization algorithms in infinite dimensional hilbert spaces, namely, the penalty and the augmented lagrangian methods. we test these algorithms on some toy problems originating in either calculus of variations or physics. we demonstrate that both methods are able to produce decent approximations for the test problems and are comparable in terms of different errors produced. leveraging the common occurrence of the lagrange multiplier update rule being computationally less expensive than solving subproblems in the penalty method, we achieve significant speedups in cases when the output of the constraint function is itself a function.","doi":"","created":1704153600000,"updated":"2024-01-08","authors":["pinak mandal"]}
{"id":"2401.01312","title":"llm harmony: multi-agent communication for problem solving","categories":"cs.ma","abstract":"large language models (llms) have revolutionized natural language processing but exhibit limitations, particularly in autonomously addressing novel challenges such as reasoning and problem-solving. traditional techniques like chain-of-thought prompting necessitate explicit human guidance. this paper introduces a novel multi-agent communication framework, inspired by the camel model, to enhance llms' autonomous problem-solving capabilities. the framework employs multiple llm agents, each with a distinct persona, engaged in role-playing communication, offering a nuanced and adaptable approach to diverse problem scenarios. extensive experimentation demonstrates the framework's superior performance and adaptability, providing valuable insights into the collaborative potential of multiple agents in overcoming the limitations of individual models.","doi":"","created":1704153600000,"updated":"","authors":["sumedh rasal"]}
{"id":"2401.01313","title":"a comprehensive survey of hallucination mitigation techniques in large   language models","categories":"cs.cl","abstract":"as large language models (llms) continue to advance in their ability to write human-like text, a key challenge remains around their tendency to hallucinate generating content that appears factual but is ungrounded. this issue of hallucination is arguably the biggest hindrance to safely deploying these powerful llms into real-world production systems that impact people's lives. the journey toward widespread adoption of llms in practical settings heavily relies on addressing and mitigating hallucinations. unlike traditional ai systems focused on limited tasks, llms have been exposed to vast amounts of online text data during training. while this allows them to display impressive language fluency, it also means they are capable of extrapolating information from the biases in training data, misinterpreting ambiguous prompts, or modifying the information to align superficially with the input. this becomes hugely alarming when we rely on language generation capabilities for sensitive applications, such as summarizing medical records, financial analysis reports, etc. this paper presents a comprehensive survey of over 32 techniques developed to mitigate hallucination in llms. notable among these are retrieval augmented generation (lewis et al, 2021), knowledge retrieval (varshney et al,2023), conli (lei et al, 2023), and cove (dhuliawala et al, 2023). furthermore, we introduce a detailed taxonomy categorizing these methods based on various parameters, such as dataset utilization, common tasks, feedback mechanisms, and retriever types. this classification helps distinguish the diverse approaches specifically designed to tackle hallucination issues in llms. additionally, we analyze the challenges and limitations inherent in these techniques, providing a solid foundation for future research in addressing hallucinations and related phenomena within the realm of llms.","doi":"","created":1704153600000,"updated":"2024-01-08","authors":["s. m towhidul islam tonmoy","s m mehedi zaman","vinija jain","anku rani","vipula rawte","aman chadha","amitava das"]}
{"id":"2401.01314","title":"classifying words with 3-sort automata","categories":"cs.fl","abstract":"grammatical inference consists in learning a language or a grammar from data. in this paper, we consider a number of models for inferring a non-deterministic finite automaton (nfa) with 3 sorts of states, that must accept some words, and reject some other words from a given sample. we then propose a transformation from this 3-sort nfa into weighted-frequency and probabilistic nfa, and we apply the latter to a classification task. the experimental evaluation of our approach shows that the probabilistic nfas can be successfully applied for classification tasks on both real-life and superficial benchmark data sets.","doi":"","created":1704153600000,"updated":"","authors":["tomasz jastrząb","frédéric lardeux","eric monfroy"]}
{"id":"2401.01322","title":"a knowledge compilation map for quantum information","categories":"quant-ph cs.ds","abstract":"quantum computing is finding promising applications in optimization, machine learning and physics, leading to the development of various models for representing quantum information. because these representations are often studied in different contexts (many-body physics, machine learning, formal verification, simulation), little is known about fundamental trade-offs between their succinctness and the runtime of operations to update them. we therefore analytically investigate three widely-used quantum state representations: matrix product states (mps), decision diagrams (dds), and restricted boltzmann machines (rbms). we map the relative succinctness of these data structures and provide the complexity for relevant query and manipulation operations. further, to chart the balance between succinctness and operation efficiency, we extend the concept of rapidity with support for the non-canonical data structures studied in this work, showing in particular that mps is at least as rapid as some dds.   by providing a knowledge compilation map for quantum state representations, this paper contributes to the understanding of the inherent time and space efficiency trade-offs in this area.","doi":"","created":1704153600000,"updated":"","authors":["lieuwe vinkhuijzen","tim coopmans","alfons laarman"]}
{"id":"2401.01324","title":"lower bounds on cardinality of reducts for decision tables from closed   classes","categories":"cs.cc","abstract":"in this paper, we consider classes of decision tables closed under removal of attributes (columns) and changing of decisions attached to rows. for decision tables from closed classes, we study lower bounds on the minimum cardinality of reducts, which are minimal sets of attributes that allow us to recognize, for a given row, the decision attached to it. we assume that the number of rows in decision tables from the closed class is not bounded from above by a constant. we divide the set of such closed classes into two families. in one family, only standard lower bounds $\\omega (\\log $ ${\\rm cl}(t))$ on the minimum cardinality of reducts for decision tables hold, where ${\\rm cl}(t)$ is the number of decision classes in the table $t$. in another family, these bounds can be essentially tightened up to $\\omega ({\\rm cl}(t)^{1\/q})$ for some natural $q$.","doi":"","created":1704153600000,"updated":"","authors":["azimkhon ostonov","mikhail moshkov"]}
{"id":"2401.01325","title":"llm maybe longlm: self-extend llm context window without tuning","categories":"cs.cl cs.ai cs.lg","abstract":"it is well known that llms cannot generalize well to long contexts whose lengths are larger than the training sequence length. this poses challenges when employing llms for processing long input sequences during inference. in this work, we argue that llms themselves have inherent capabilities to handle long contexts without fine-tuning. to achieve this goal, we propose selfextend to extend the context window of llms by constructing bi-level attention information: the grouped attention and the neighbor attention. the grouped attention captures the dependencies among tokens that are far apart, while neighbor attention captures dependencies among adjacent tokens within a specified range. the two-level attentions are computed based on the original model's self-attention mechanism during inference. with minor code modification, our selfextend can effortlessly extend existing llms' context window without any fine-tuning. we conduct comprehensive experiments on multiple benchmarks and the results show that our selfextend can effectively extend existing llms' context window length. the code can be found at \\url{https:\/\/github.com\/datamllab\/longlm}.","doi":"","created":1704153600000,"updated":"2024-07-11","authors":["hongye jin","xiaotian han","jingfeng yang","zhimeng jiang","zirui liu","chia-yuan chang","huiyuan chen","xia hu"]}
{"id":"2401.01326","title":"an autoregressive text-to-graph framework for joint entity and relation   extraction","categories":"cs.cl cs.ai cs.lg","abstract":"in this paper, we propose a novel method for joint entity and relation extraction from unstructured text by framing it as a conditional sequence generation problem. in contrast to conventional generative information extraction models that are left-to-right token-level generators, our approach is \\textit{span-based}. it generates a linearized graph where nodes represent text spans and edges represent relation triplets. our method employs a transformer encoder-decoder architecture with pointing mechanism on a dynamic vocabulary of spans and relation types. our model can capture the structural characteristics and boundaries of entities and relations through span representations while simultaneously grounding the generated output in the original text thanks to the pointing mechanism. evaluation on benchmark datasets validates the effectiveness of our approach, demonstrating competitive results. code is available at https:\/\/github.com\/urchade\/atg.","doi":"","created":1704153600000,"updated":"2024-01-15","authors":["urchade zaratiana","nadi tomeh","pierre holat","thierry charnois"]}
{"id":"2401.01329","title":"algorithm-supervised millimeter wave indoor localization using tiny   neural networks","categories":"eess.sp cs.ni","abstract":"the quasi-optical propagation of millimeter-wave signals enables high-accuracy localization algorithms that employ geometric approaches or machine learning models. however, most algorithms require information on the indoor environment, may entail the collection of large training datasets, or bear an infeasible computational burden for commercial off-the-shelf (cots) devices. in this work, we propose to use tiny neural networks (nns) to learn the relationship between angle difference-of-arrival (adoa) measurements and locations of a receiver in an indoor environment. to relieve training data collection efforts, we resort to a self-supervised approach by bootstrapping the training of our neural network through location estimates obtained from a state-of-the-art localization algorithm. we evaluate our scheme via mmwave measurements from indoor 60-ghz double-directional channel sounding. we process the measurements to yield dominant multipath components, use the corresponding angles to compute adoa values, and finally obtain location fixes. results show that the tiny nn achieves sub-meter errors in 74% of the cases, thus performing as good as or even better than the state-of-the-art algorithm, with significantly lower computational complexity.","doi":"","created":1704153600000,"updated":"2024-07-30","authors":["anish shastri","steve blandino","camillo gentile","chiehping lai","paolo casari"]}
{"id":"2401.01330","title":"trec ikat 2023: the interactive knowledge assistance track overview","categories":"cs.ir cs.ai cs.cl","abstract":"conversational information seeking has evolved rapidly in the last few years with the development of large language models providing the basis for interpreting and responding in a naturalistic manner to user requests. ikat emphasizes the creation and research of conversational search agents that adapt responses based on the user's prior interactions and present context. this means that the same question might yield varied answers, contingent on the user's profile and preferences. the challenge lies in enabling conversational search agents (csa) to incorporate personalized context to effectively guide users through the relevant information to them. ikat's first year attracted seven teams and a total of 24 runs. most of the runs leveraged large language models (llms) in their pipelines, with a few focusing on a generate-then-retrieve approach.","doi":"","created":1704153600000,"updated":"2024-02-22","authors":["mohammad aliannejadi","zahra abbasiantaeb","shubham chatterjee","jeffery dalton","leif azzopardi"]}
{"id":"2401.01335","title":"self-play fine-tuning converts weak language models to strong language   models","categories":"cs.lg cs.ai cs.cl stat.ml","abstract":"harnessing the power of human-annotated data through supervised fine-tuning (sft) is pivotal for advancing large language models (llms). in this paper, we delve into the prospect of growing a strong llm out of a weak one without the need for acquiring additional human-annotated data. we propose a new fine-tuning method called self-play fine-tuning (spin), which starts from a supervised fine-tuned model. at the heart of spin lies a self-play mechanism, where the llm refines its capability by playing against instances of itself. more specifically, the llm generates its own training data from its previous iterations, refining its policy by discerning these self-generated responses from those obtained from human-annotated data. our method progressively elevates the llm from a nascent model to a formidable one, unlocking the full potential of human-annotated demonstration data for sft. theoretically, we prove that the global optimum to the training objective function of our method is achieved only when the llm policy aligns with the target data distribution. empirically, we evaluate our method on several benchmark datasets including the huggingface open llm leaderboard, mt-bench, and datasets from big-bench. our results show that spin can significantly improve the llm's performance across a variety of benchmarks and even outperform models trained through direct preference optimization (dpo) supplemented with extra gpt-4 preference data. this sheds light on the promise of self-play, enabling the achievement of human-level performance in llms without the need for expert opponents. codes are available at https:\/\/github.com\/uclaml\/spin.","doi":"","created":1704153600000,"updated":"2024-06-14","authors":["zixiang chen","yihe deng","huizhuo yuan","kaixuan ji","quanquan gu"]}
{"id":"2401.01337","title":"diagonal gaussian mixture models and higher order tensor decompositions","categories":"math.na cs.na","abstract":"this paper studies how to recover parameters in diagonal gaussian mixture models using tensors. high-order moments of the gaussian mixture model are estimated from samples. they form incomplete symmetric tensors generated by hidden parameters in the model. we propose to use generating polynomials to compute incomplete symmetric tensor approximations. the obtained decomposition is utilized to recover parameters in the model. we prove that our recovered parameters are accurate when the estimated moments are accurate. using high-order moments enables our algorithm to learn gaussian mixtures with more components. for a given model dimension and order, we provide an upper bound of the number of components in the gaussian mixture model that our algorithm can compute.","doi":"","created":1704153600000,"updated":"","authors":["bingni guo","jiawang nie","zi yang"]}
{"id":"2401.01339","title":"street gaussians: modeling dynamic urban scenes with gaussian splatting","categories":"cs.cv cs.gr","abstract":"this paper aims to tackle the problem of modeling dynamic urban streets for autonomous driving scenes. recent methods extend nerf by incorporating tracked vehicle poses to animate vehicles, enabling photo-realistic view synthesis of dynamic urban street scenes. however, significant limitations are their slow training and rendering speed. we introduce street gaussians, a new explicit scene representation that tackles these limitations. specifically, the dynamic urban scene is represented as a set of point clouds equipped with semantic logits and 3d gaussians, each associated with either a foreground vehicle or the background. to model the dynamics of foreground object vehicles, each object point cloud is optimized with optimizable tracked poses, along with a 4d spherical harmonics model for the dynamic appearance. the explicit representation allows easy composition of object vehicles and background, which in turn allows for scene editing operations and rendering at 135 fps (1066 $\\times$ 1600 resolution) within half an hour of training. the proposed method is evaluated on multiple challenging benchmarks, including kitti and waymo open datasets. experiments show that the proposed method consistently outperforms state-of-the-art methods across all datasets. the code will be released to ensure reproducibility.","doi":"","created":1704153600000,"updated":"2024-07-16","authors":["yunzhi yan","haotong lin","chenxu zhou","weijie wang","haiyang sun","kun zhan","xianpeng lang","xiaowei zhou","sida peng"]}
{"id":"2401.01382","title":"exploring multi-modal control in music-driven dance generation","categories":"cs.sd cs.cv eess.as","abstract":"existing music-driven 3d dance generation methods mainly concentrate on high-quality dance generation, but lack sufficient control during the generation process. to address these issues, we propose a unified framework capable of generating high-quality dance movements and supporting multi-modal control, including genre control, semantic control, and spatial control. first, we decouple the dance generation network from the dance control network, thereby avoiding the degradation in dance quality when adding additional control information. second, we design specific control strategies for different control information and integrate them into a unified framework. experimental results show that the proposed dance generation framework outperforms state-of-the-art methods in terms of motion quality and controllability.","doi":"10.1109\/icassp48485.2024.10447825","created":1704067200000,"updated":"","authors":["ronghui li","yuqin dai","yachao zhang","jun li","jian yang","jie guo","xiu li"]}
{"id":"2401.01383","title":"predicting infant brain connectivity with federated multi-trajectory   gnns using scarce data","categories":"q-bio.nc cs.ai cs.cv cs.lg","abstract":"the understanding of the convoluted evolution of infant brain networks during the first postnatal year is pivotal for identifying the dynamics of early brain connectivity development. existing deep learning solutions suffer from three major limitations. first, they cannot generalize to multi-trajectory prediction tasks, where each graph trajectory corresponds to a particular imaging modality or connectivity type (e.g., t1-w mri). second, existing models require extensive training datasets to achieve satisfactory performance which are often challenging to obtain. third, they do not efficiently utilize incomplete time series data. to address these limitations, we introduce fedgmte-net++, a federated graph-based multi-trajectory evolution network. using the power of federation, we aggregate local learnings among diverse hospitals with limited datasets. as a result, we enhance the performance of each hospital's local generative model, while preserving data privacy. the three key innovations of fedgmte-net++ are: (i) presenting the first federated learning framework specifically designed for brain multi-trajectory evolution prediction in a data-scarce environment, (ii) incorporating an auxiliary regularizer in the local objective function to exploit all the longitudinal brain connectivity within the evolution trajectory and maximize data utilization, (iii) introducing a two-step imputation process, comprising a preliminary knn-based precompletion followed by an imputation refinement step that employs regressors to improve similarity scores and refine imputations. our comprehensive experimental results showed the outperformance of fedgmte-net++ in brain multi-trajectory prediction from a single baseline graph in comparison with benchmark methods.","doi":"","created":1704067200000,"updated":"2024-01-08","authors":["michalis pistos","gang li","weili lin","dinggang shen","islem rekik"]}
{"id":"2401.01384","title":"strong transitivity relations and graph neural networks","categories":"cs.si cs.ai cs.lg","abstract":"local neighborhoods play a crucial role in embedding generation in graph-based learning. it is commonly believed that nodes ought to have embeddings that resemble those of their neighbors. in this research, we try to carefully expand the concept of similarity from nearby neighborhoods to the entire graph. we provide an extension of similarity that is based on transitivity relations, which enables graph neural networks (gnns) to capture both global similarities and local similarities over the whole graph. we introduce transitivity graph neural network (transgnn), which more than local node similarities, takes into account global similarities by distinguishing strong transitivity relations from weak ones and exploiting them. we evaluate our model over several real-world datasets and showed that it considerably improves the performance of several well-known gnn models, for tasks such as node classification.","doi":"","created":1704067200000,"updated":"","authors":["yassin mohamadi","mostafa haghir chehreghani"]}
{"id":"2401.01386","title":"tissue artifact segmentation and severity analysis for automated   diagnosis using whole slide images","categories":"eess.iv cs.cv cs.lg","abstract":"traditionally, pathological analysis and diagnosis are performed by manually eyeballing glass slide specimens under a microscope by an expert. the whole slide image is the digital specimen produced from the glass slide. whole slide image enabled specimens to be observed on a computer screen and led to computational pathology where computer vision and artificial intelligence are utilized for automated analysis and diagnosis. with the current computational advancement, the entire whole slide image can be analyzed autonomously without human supervision. however, the analysis could fail or lead to wrong diagnosis if the whole slide image is affected by tissue artifacts such as tissue fold or air bubbles depending on the severity. existing artifact detection methods rely on experts for severity assessment to eliminate artifact affected regions from the analysis. this process is time consuming, exhausting and undermines the goal of automated analysis or removal of artifacts without evaluating their severity, which could result in the loss of diagnostically important data. therefore, it is necessary to detect artifacts and then assess their severity automatically. in this paper, we propose a system that incorporates severity evaluation with artifact detection utilizing convolutional neural networks. the proposed system uses doubleunet to segment artifacts and an ensemble network of six fine tuned convolutional neural network models to determine severity. this method outperformed current state of the art in accuracy by 9 percent for artifact segmentation and achieved a strong correlation of 97 percent with the evaluation of pathologists for severity assessment. the robustness of the system was demonstrated using our proposed heterogeneous dataset and practical usability was ensured by integrating it with an automated analysis system.","doi":"","created":1704067200000,"updated":"2024-03-13","authors":["galib muhammad shahriar himel"]}
{"id":"2401.01387","title":"diffaugment: diffusion based long-tailed visual relationship recognition","categories":"cs.cv","abstract":"the task of visual relationship recognition (vrr) aims to identify relationships between two interacting objects in an image and is particularly challenging due to the widely-spread and highly imbalanced distribution of <subject, relation, object> triplets. to overcome the resultant performance bias in existing vrr approaches, we introduce diffaugment -- a method which first augments the tail classes in the linguistic space by making use of wordnet and then utilizes the generative prowess of diffusion models to expand the visual space for minority classes. we propose a novel hardness-aware component in diffusion which is based upon the hardness of each <s,r,o> triplet and demonstrate the effectiveness of hardness-aware diffusion in generating visual embeddings for the tail classes. we also propose a novel subject and object based seeding strategy for diffusion sampling which improves the discriminative capability of the generated visual embeddings. extensive experimentation on the gqa-lt dataset shows favorable gains in the subject\/object and relation average per-class accuracy using diffusion augmented samples.","doi":"","created":1704067200000,"updated":"2024-03-01","authors":["parul gupta","tuan nguyen","abhinav dhall","munawar hayat","trung le","thanh-toan do"]}
{"id":"2401.01388","title":"directional antenna systems for long-range through-wall human activity   recognition","categories":"cs.cv cs.ai cs.lg","abstract":"wifi channel state information (csi)-based human activity recognition (har) enables contactless, long-range sensing in spatially constrained environments while preserving visual privacy. however, despite the presence of numerous wifi-enabled devices around us, few expose csi to users, resulting in a lack of sensing hardware options. variants of the espressif esp32 have emerged as potential low-cost and easy-to-deploy solutions for wifi csi-based har. in this work, four esp32-s3-based 2.4ghz directional antenna systems are evaluated for their ability to facilitate long-range through-wall har. two promising systems are proposed, one of which combines the esp32-s3 with a directional biquad antenna. this combination represents, to the best of our knowledge, the first demonstration of such a system in wifi-based har. the second system relies on the built-in printed inverted-f antenna (pifa) of the esp32-s3 and achieves directionality through a plane reflector. in a comprehensive evaluation of line-of-sight (los) and non-line-of-sight (nlos) har performance, both systems are deployed in an office environment spanning a distance of 18 meters across five rooms. in this experimental setup, the wallhack1.8k dataset, comprising 1806 csi amplitude spectrograms of human activities, is collected and made publicly available. based on wallhack1.8k, we train activity recognition models using the efficientnetv2 architecture to assess system performance in los and nlos scenarios. for the core nlos activity recognition problem, the biquad antenna and pifa-based systems achieve accuracies of 92.0$\\pm$3.5 and 86.8$\\pm$4.7, respectively, demonstrating the feasibility of long-range through-wall har with the proposed systems.","doi":"","created":1704067200000,"updated":"","authors":["julian strohmayer","martin kampel"]}
{"id":"2401.01391","title":"on optimal sampling for learning sdf using mlps equipped with positional   encoding","categories":"cs.cv cs.gr cs.lg","abstract":"neural implicit fields, such as the neural signed distance field (sdf) of a shape, have emerged as a powerful representation for many applications, e.g., encoding a 3d shape and performing collision detection. typically, implicit fields are encoded by multi-layer perceptrons (mlp) with positional encoding (pe) to capture high-frequency geometric details. however, a notable side effect of such pe-equipped mlps is the noisy artifacts present in the learned implicit fields. while increasing the sampling rate could in general mitigate these artifacts, in this paper we aim to explain this adverse phenomenon through the lens of fourier analysis. we devise a tool to determine the appropriate sampling rate for learning an accurate neural implicit field without undesirable side effects. specifically, we propose a simple yet effective method to estimate the intrinsic frequency of a given network with randomized weights based on the fourier analysis of the network's responses. it is observed that a pe-equipped mlp has an intrinsic frequency much higher than the highest frequency component in the pe layer. sampling against this intrinsic frequency following the nyquist-sannon sampling theorem allows us to determine an appropriate training sampling rate. we empirically show in the setting of sdf fitting that this recommended sampling rate is sufficient to secure accurate fitting results, while further increasing the sampling rate would not further noticeably reduce the fitting error. training pe-equipped mlps simply with our sampling strategy leads to performances superior to the existing methods.","doi":"","created":1704153600000,"updated":"","authors":["guying lin","lei yang","yuan liu","congyi zhang","junhui hou","xiaogang jin","taku komura","john keyser","wenping wang"]}
{"id":"2401.01393","title":"backtracking new q-newton's method, newton's flow, voronoi's diagram and   stochastic root finding","categories":"math.oc cs.lg cs.na math.cv math.ds math.na","abstract":"a new variant of newton's method - named backtracking new q-newton's method (bnqn) - which has strong theoretical guarantee, is easy to implement, and has good experimental performance, was recently introduced by the third author.   experiments performed previously showed some remarkable properties of the basins of attractions for finding roots of polynomials and meromorphic functions, with bnqn. in general, they look more smooth than that of newton's method.   in this paper, we continue to experimentally explore in depth this remarkable phenomenon, and connect bnqn to newton's flow and voronoi's diagram. this link poses a couple of challenging puzzles to be explained. experiments also indicate that bnqn is more robust against random perturbations than newton's method and random relaxed newton's method.","doi":"","created":1704153600000,"updated":"2024-01-08","authors":["john erik fornaess","mi hu","tuyen trung truong","takayuki watanabe"]}
{"id":"2401.01394","title":"unveiling the stealthy threat: analyzing slow drift gps spoofing attacks   for autonomous vehicles in urban environments and enabling the resilience","categories":"cs.cr","abstract":"autonomous vehicles (avs) rely on the global positioning system (gps) or global navigation satellite systems (gnss) for precise (positioning, navigation, and timing) pnt solutions. however, the vulnerability of gps signals to intentional and unintended threats due to their lack of encryption and weak signal strength poses serious risks, thereby reducing the reliability of avs. gps spoofing is a complex and damaging attack that deceives avs by altering gps receivers to calculate false position and tracking information leading to misdirection. this study explores a stealthy slow drift gps spoofing attack, replicating the victim av's satellite reception pattern while changing pseudo ranges to deceive the av, particularly during turns. the attack is designed to gradually deviate from the correct route, making real-time detection challenging and jeopardizing user safety. we present a system and study methodology for constructing covert spoofing attacks on avs, investigating the correlation between original and spoofed pseudo ranges to create effective defenses. by closely following the victim vehicle and using the same satellite signals, the attacker executes the attack precisely. changing the pseudo ranges confuses the av, leading it to incorrect destinations while remaining oblivious to the manipulation. the gradual deviation from the actual route further conceals the attack, hindering its swift identification. the experiments showcase a robust correlation between the original and spoofed pseudo ranges, with r square values varying between 0.99 and 1. this strong correlation facilitates effective evaluation and mitigation of spoofing signals.","doi":"","created":1704153600000,"updated":"","authors":["sagar dasgupta","abdullah ahmed","mizanur rahman","thejesh n. bandi"]}
{"id":"2401.01395","title":"deep autoregressive modeling for land use land cover","categories":"cs.cv cs.lg","abstract":"land use \/ land cover (lulc) modeling is a challenging task due to long-range dependencies between geographic features and distinct spatial patterns related to topography, ecology, and human development. we identify a close connection between modeling of spatial patterns of land use and the task of image inpainting from computer vision and conduct a study of a modified pixelcnn architecture with approximately 19 million parameters for modeling lulc. in comparison with a benchmark spatial statistical model, we find that the former is capable of capturing much richer spatial correlation patterns such as roads and water bodies but does not produce a calibrated predictive distribution, suggesting the need for additional tuning. we find evidence of predictive underdispersion with regard to important ecologically-relevant land use statistics such as patch count and adjacency which can be ameliorated to some extent by manipulating sampling variability.","doi":"","created":1704153600000,"updated":"","authors":["christopher krapu","mark borsuk","ryan calder"]}
{"id":"2401.01398","title":"accelerating black-box molecular property optimization by adaptively   learning sparse subspaces","categories":"q-bio.bm cs.ce cs.lg","abstract":"molecular property optimization (mpo) problems are inherently challenging since they are formulated over discrete, unstructured spaces and the labeling process involves expensive simulations or experiments, which fundamentally limits the amount of available data. bayesian optimization (bo) is a powerful and popular framework for efficient optimization of noisy, black-box objective functions (e.g., measured property values), thus is a potentially attractive framework for mpo. to apply bo to mpo problems, one must select a structured molecular representation that enables construction of a probabilistic surrogate model. many molecular representations have been developed, however, they are all high-dimensional, which introduces important challenges in the bo process -- mainly because the curse of dimensionality makes it difficult to define and perform inference over a suitable class of surrogate models. this challenge has been recently addressed by learning a lower-dimensional encoding of a smile or graph representation of a molecule in an unsupervised manner and then performing bo in the encoded space. in this work, we show that such methods have a tendency to \"get stuck,\" which we hypothesize occurs since the mapping from the encoded space to property values is not necessarily well-modeled by a gaussian process. we argue for an alternative approach that combines numerical molecular descriptors with a sparse axis-aligned gaussian process model, which is capable of rapidly identifying sparse subspaces that are most relevant to modeling the unknown property function. we demonstrate that our proposed method substantially outperforms existing mpo methods on a variety of benchmark and real-world problems. specifically, we show that our method can routinely find near-optimal molecules out of a set of more than $>100$k alternatives within 100 or fewer expensive queries.","doi":"","created":1704153600000,"updated":"","authors":["farshud sorourifar","thomas banker","joel a. paulson"]}
{"id":"2401.01404","title":"scalable network reconstruction in subquadratic time","categories":"cs.ds cs.lg physics.data-an stat.co stat.ml","abstract":"network reconstruction consists in determining the unobserved pairwise couplings between $n$ nodes given only observational data on the resulting behavior that is conditioned on those couplings -- typically a time-series or independent samples from a graphical model. a major obstacle to the scalability of algorithms proposed for this problem is a seemingly unavoidable quadratic complexity of $\\omega(n^2)$, corresponding to the requirement of each possible pairwise coupling being contemplated at least once, despite the fact that most networks of interest are sparse, with a number of non-zero couplings that is only $o(n)$. here we present a general algorithm applicable to a broad range of reconstruction problems that significantly outperforms this quadratic baseline. our algorithm relies on a stochastic second neighbor search (dong et al., 2011) that produces the best edge candidates with high probability, thus bypassing an exhaustive quadratic search. if we rely on the conjecture that the second-neighbor search finishes in log-linear time (baron & darling, 2020; 2022), we demonstrate theoretically that our algorithm finishes in subquadratic time, with a data-dependent complexity loosely upper bounded by $o(n^{3\/2}\\log n)$, but with a more typical log-linear complexity of $o(n\\log^2n)$. in practice, we show that our algorithm achieves a performance that is many orders of magnitude faster than the quadratic baseline -- in a manner consistent with our theoretical analysis -- allows for easy parallelization, and thus enables the reconstruction of networks with hundreds of thousands and even millions of nodes and edges.","doi":"","created":1704153600000,"updated":"2024-05-07","authors":["tiago p. peixoto"]}
{"id":"2401.01405","title":"quantifying the uniqueness of donald trump in presidential discourse","categories":"cs.cl cs.ai cs.cy cs.si","abstract":"does donald trump speak differently from other presidents? if so, in what ways? are these differences confined to any single medium of communication? to investigate these questions, this paper introduces a novel metric of uniqueness based on large language models, develops a new lexicon for divisive speech, and presents a framework for comparing the lexical features of political opponents. applying these tools to a variety of corpora of presidential speeches, we find considerable evidence that trump's speech patterns diverge from those of all major party nominees for the presidency in recent history. some notable findings include trump's employment of particularly divisive and antagonistic language targeting of his political opponents and his patterns of repetition for emphasis. furthermore, trump is significantly more distinctive than his fellow republicans, whose uniqueness values are comparably closer to those of the democrats. these differences hold across a variety of measurement strategies, arise on both the campaign trail and in official presidential addresses, and do not appear to be an artifact of secular time trends.","doi":"","created":1704153600000,"updated":"","authors":["karen zhou","alexander a. meitus","milo chase","grace wang","anne mykland","william howell","chenhao tan"]}
{"id":"2401.01408","title":"cost minimization in multi-cloud systems with runtime microservice   re-orchestration","categories":"cs.ni","abstract":"multi-cloud systems facilitate a cost-efficient and geographically-distributed deployment of microservice-based applications by temporary leasing virtual nodes with diverse pricing models. to preserve the cost-efficiency of multi-cloud deployments, it is essential to redeploy microservices onto the available nodes according to a dynamic resource configuration, which is often performed to better accommodate workload variations. however, this approach leads to frequent service disruption since applications are continuously shutdown and redeployed in order to apply the new resource assignment. to overcome this issue, we propose a re-orchestration scheme that migrates microservice at runtime based on a rolling update scheduling logic. specifically, we propose an integer linear optimization problem that minimizes the cost associated to multi-cloud virtual nodes and that ensures that delay-sensitive microservices are co-located on the same regional cluster. the resulting rescheduling order guarantees no service disruption by repacking microservices between the available nodes without the need to turn off the outdated microservice instance before redeploying the updated version. in addition, we propose a two-step heuristic scheme that effectively approximates the optimal solution at the expense of close-to-zero service disruption and qos violation probability. results show that proposed schemes achieve better performance in terms of cost mitigation, low service disruption and low qos violation probability compared to baseline schemes replicating kubernetes scheduler functionalities.","doi":"10.1109\/icin60470.2024.10494463","created":1704153600000,"updated":"2024-05-08","authors":["marco zambianco","silvio cretti","domenico siracusa"]}
{"id":"2401.01409","title":"design, manufacturing and open-loop control of a soft pneumatic arm","categories":"cs.ro","abstract":"soft robots distinguish themselves from traditional robots by embracing flexible kinematics. because of their recent emergence, there exist numerous uncharted territories, including novel actuators, manufacturing processes, and advanced control methods. this research is centred on the design, fabrication, and control of a pneumatic soft robot. the principal objective is to develop a modular soft robot featuring with multiple segments, each one of three degrees of freedom. this yields to tubular structure with five independent degrees of freedom, enabling motion across three spatial dimensions. physical construction leverages tin-cured silicone and a wax casting method, refined through iterative processes. 3d-printed pla moulds, filled with silicone, yield the desired model, while bladder-like structures, are formed within using solidified paraffin wax positive moulds. for control, an empirically fine-tuned open-loop system is adopted. the project culminates in rigorous testing bending ability and weight carrying capacity and possible applications are discussed.","doi":"10.3390\/act13010036","created":1704153600000,"updated":"","authors":["jorge francisco garcía-samartín","adrián rieker","antonio barrientos"]}
{"id":"2401.01414","title":"vald-md: visual attribution via latent diffusion for medical diagnostics","categories":"eess.iv cs.lg","abstract":"visual attribution in medical imaging seeks to make evident the diagnostically-relevant components of a medical image, in contrast to the more common detection of diseased tissue deployed in standard machine vision pipelines (which are less straightforwardly interpretable\/explainable to clinicians). we here present a novel generative visual attribution technique, one that leverages latent diffusion models in combination with domain-specific large language models, in order to generate normal counterparts of abnormal images. the discrepancy between the two hence gives rise to a mapping indicating the diagnostically-relevant image components. to achieve this, we deploy image priors in conjunction with appropriate conditioning mechanisms in order to control the image generative process, including natural language text prompts acquired from medical science and applied radiology. we perform experiments and quantitatively evaluate our results on the covid-19 radiography database containing labelled chest x-rays with differing pathologies via the frechet inception distance (fid), structural similarity (ssim) and multi scale structural similarity metric (ms-ssim) metrics obtained between real and generated images. the resulting system also exhibits a range of latent capabilities including zero-shot localized disease induction, which are evaluated with real examples from the chexpert dataset.","doi":"","created":1704153600000,"updated":"","authors":["ammar a. siddiqui","santosh tirunagari","tehseen zia","david windridge"]}
{"id":"2401.01416","title":"flexible control flow graph alignment for delivering data-driven   feedback to novice programming learners","categories":"cs.se","abstract":"supporting learners in introductory programming assignments at scale is a necessity. this support includes automated feedback on what learners did incorrectly. existing approaches cast the problem as automatically repairing learners' incorrect programs extrapolating the data from an existing correct program from other learners. however, such approaches are limited because they only compare programs with similar control flow and order of statements. a potentially valuable set of repair feedback from flexible comparisons is thus missing. in this paper, we present several modifications to clara, a data-driven automated repair approach that is open source, to deal with real-world introductory programs. we extend clara's abstract syntax tree processor to handle common introductory programming constructs. additionally, we propose a flexible alignment algorithm over control flow graphs where we enrich nodes with semantic annotations extracted from programs using operations and calls. using this alignment, we modify an incorrect program's control flow graph to match the correct programs to apply clara's original repair process. we evaluate our approach against a baseline on the twenty most popular programming problems in codeforces. our results indicate that flexible alignment has a significantly higher percentage of successful repairs at 46% compared to 5% for baseline clara. our implementation is available at https:\/\/github.com\/towhidabsar\/clara.","doi":"","created":1704153600000,"updated":"","authors":["md towhidul absar chowdhury","maheen riaz contractor","carlos r. rivero"]}
{"id":"2401.01419","title":"to diverge or not to diverge: a morphosyntactic perspective on machine   translation vs human translation","categories":"cs.cl","abstract":"we conduct a large-scale fine-grained comparative analysis of machine translations (mt) against human translations (ht) through the lens of morphosyntactic divergence. across three language pairs and two types of divergence defined as the structural difference between the source and the target, mt is consistently more conservative than ht, with less morphosyntactic diversity, more convergent patterns, and more one-to-one alignments. through analysis on different decoding algorithms, we attribute this discrepancy to the use of beam search that biases mt towards more convergent patterns. this bias is most amplified when the convergent pattern appears around 50% of the time in training data. lastly, we show that for a majority of morphosyntactic divergences, their presence in ht is correlated with decreased mt performance, presenting a greater challenge for mt systems.","doi":"","created":1704153600000,"updated":"","authors":["jiaming luo","colin cherry","george foster"]}
{"id":"2401.01422","title":"linear-quadratic problems in systems and controls via covariance   representations and linear-conic duality: finite-horizon case","categories":"eess.sy cs.sy math.oc","abstract":"linear-quadratic (lq) problems that arise in systems and controls include the classical optimal control problems of the linear quadratic regulator (lqr) in both its deterministic and stochastic forms, as well as $h^\\infty$-analysis (the bounded real lemma), the positive real lemma, and general integral quadratic constraints (iqcs) tests. we present a unified treatment of all of these problems using an approach which converts linear-quadratic problems to matrix-valued linear-linear problems with a positivity constraint. this is done through a system representation where the joint state\/input covariance (the outer product in the deterministic case) matrix is the fundamental object. lq problems then become infinite-dimensional semidefinite programs, and the key tool used is that of linear-conic duality. linear matrix inequalities (lmis) emerge naturally as conal constraints on dual problems. riccati equations characterize extrema of these special lmis, and therefore provide solutions to the dual problems. the state-feedback structure of all optimal signals in these problems emerge out of alignment (complementary slackness) conditions between primal and dual problems. perhaps the new insight gained from this approach is that first lmis, and then second, riccati equations arise naturally in dual, rather than primal problems. furthermore, while traditional lq problems are set up in $l^2$ spaces of signals, their equivalent covariance-representation problems are most naturally set up in $l^1$ spaces of matrix-valued signals.","doi":"","created":1704153600000,"updated":"","authors":["bassam bamieh"]}
{"id":"2401.01423","title":"hadamard integrators for wave equations in time and frequency domain:   eulerian formulations via butterfly algorithms","categories":"math.na cs.na math-ph math.mp","abstract":"starting from the kirchhoff-huygens representation and duhamel's principle of time-domain wave equations, we propose novel butterfly-compressed hadamard integrators for self-adjoint wave equations in both time and frequency domain in an inhomogeneous medium. first, we incorporate the leading term of hadamard's ansatz into the kirchhoff-huygens representation to develop a short-time valid propagator. second, using the fourier transform in time, we derive the corresponding eulerian short-time propagator in frequency domain; on top of this propagator, we further develop a time-frequency-time (tft) method for the cauchy problem of time-domain wave equations. third, we further propose the time-frequency-time-frequency (tftf) method for the corresponding point-source helmholtz equation, which provides green's functions of the helmholtz equation for all angular frequencies within a given frequency band. fourth, to implement tft and tftf methods efficiently, we introduce butterfly algorithms to compress oscillatory integral kernels at different frequencies. as a result, the proposed methods can construct wave field beyond caustics implicitly and advance spatially overturning waves in time naturally with quasi-optimal computational complexity and memory usage. furthermore, once constructed the hadamard integrators can be employed to solve both time-domain wave equations with various initial conditions and frequency-domain wave equations with different point sources. numerical examples for two-dimensional wave equations illustrate the accuracy and efficiency of the proposed methods.","doi":"","created":1704153600000,"updated":"2024-06-04","authors":["yuxiao wei","jin cheng","shingyu leung","robert burridge","jianliang qian"]}
{"id":"2401.01424","title":"age-aware dynamic frame slotted aloha for machine-type communications","categories":"cs.ni cs.sy eess.sy","abstract":"information aging has gained prominence in characterizing communication protocols for timely remote estimation and control applications. this work proposes an age of information (aoi)-aware threshold-based dynamic frame slotted aloha (t-dfsa) for contention resolution in random access machine-type communication networks. unlike conventional dfsa that maximizes the throughput in each frame, the frame length and age-gain threshold in t-dfsa are determined to minimize the normalized average aoi reduction of the network in each frame. at the start of each frame in the proposed protocol, the common access point (ap) stores an estimate of the age-gain distribution of a typical node. depending on the observed status of the slots, age-gains of successful nodes, and maximum available aoi, the ap adjusts its estimation in each frame. the maximum available aoi is exploited to derive the maximum possible age-gain at each frame and thus, to avoid overestimating the age-gain threshold, which may render t-dfsa unstable. numerical results validate our theoretical analysis and demonstrate the effectiveness of the proposed t-dfsa compared to the existing optimal frame slotted aloha, threshold-aloha, and age-based thinning protocols in a considerable range of update generation rates.","doi":"","created":1704153600000,"updated":"","authors":["masoumeh moradian","aresh dadlani","ahmad khonsari","hina tabassum"]}
{"id":"2401.01425","title":"swaptransformer: highway overtaking tactical planner model via imitation   learning on osha dataset","categories":"cs.ai cs.cv cs.lg cs.ro","abstract":"this paper investigates the high-level decision-making problem in highway scenarios regarding lane changing and over-taking other slower vehicles. in particular, this paper aims to improve the travel assist feature for automatic overtaking and lane changes on highways. about 9 million samples including lane images and other dynamic objects are collected in simulation. this data; overtaking on simulated highways (osha) dataset is released to tackle this challenge. to solve this problem, an architecture called swaptransformer is designed and implemented as an imitation learning approach on the osha dataset. moreover, auxiliary tasks such as future points and car distance network predictions are proposed to aid the model in better understanding the surrounding environment. the performance of the proposed solution is compared with a multi-layer perceptron (mlp) and multi-head self-attention networks as baselines in a simulation environment. we also demonstrate the performance of the model with and without auxiliary tasks. all models are evaluated based on different metrics such as time to finish each lap, number of overtakes, and speed difference with speed limit. the evaluation shows that the swaptransformer model outperforms other models in different traffic densities in the inference phase.","doi":"","created":1704153600000,"updated":"","authors":["alireza shamsoshoara","safin b salih","pedram aghazadeh"]}
{"id":"2401.01426","title":"modular learning of deep causal generative models for high-dimensional   causal inference","categories":"cs.lg cs.ai cs.it math.it stat.me stat.ml","abstract":"pearl's causal hierarchy establishes a clear separation between observational, interventional, and counterfactual questions. researchers proposed sound and complete algorithms to compute identifiable causal queries at a given level of the hierarchy using the causal structure and data from the lower levels of the hierarchy. however, most of these algorithms assume that we can accurately estimate the probability distribution of the data, which is an impractical assumption for high-dimensional variables such as images. on the other hand, modern generative deep learning architectures can be trained to learn how to accurately sample from such high-dimensional distributions. especially with the recent rise of foundation models for images, it is desirable to leverage pre-trained models to answer causal queries with such high-dimensional data. to address this, we propose a sequential training algorithm that, given the causal structure and a pre-trained conditional generative model, can train a deep causal generative model, which utilizes the pre-trained model and can provably sample from identifiable interventional and counterfactual distributions. our algorithm, called modular-dcm, uses adversarial training to learn the network weights, and to the best of our knowledge, is the first algorithm that can make use of pre-trained models and provably sample from any identifiable causal query in the presence of latent confounders with high-dimensional data. we demonstrate the utility of our algorithm using semi-synthetic and real-world datasets containing images as variables in the causal structure.","doi":"","created":1704153600000,"updated":"","authors":["md musfiqur rahman","murat kocaoglu"]}
{"id":"2401.01430","title":"automated test production -- systematic literature mapping","categories":"cs.se","abstract":"the broader goal of this research, on the one hand, is to obtain the state of the art in automated test production (atp), to find the open questions and related problems and to track the progress of researchers in the field, and on the other hand is to list and categorize the methods, techniques and tools of atp that meet the needs of practitioners who produce computerized business applications for internal use in their corporations - eventually it can be extended to the needs of practitioners in companies that specialize in producing computer applications for generic use.","doi":"","created":1704153600000,"updated":"","authors":["josé marcos gomes","luis alberto vieira dias"]}
{"id":"2401.01432","title":"impact of dg and survey of pricing mechanism around different states in   usa","categories":"eess.sy cs.sy","abstract":"in this paper, we investigate the impact of the distributed generation (dg) on power transmission grid and pricing strategy for different geographical locations in different states, generally distributed generation (dg) on distribution feeders is known to have an impact on voltage regulation and power quality. a dg might provide voltage and power support in some cases, but most cases cause short term instability voltage, depending on the several variables, including relative dg size and location, power network and load character, so this paper also addressing to the following questions: the different between dg and conventional power station? what are penetration levels of different dg to the power grid and compliances to the ieee relevant standards, discusses unexpected issues with a special emphasis on power protection coordination problems, potential advantage and disadvantage to using dg while distributed generation (dg) allows collection of energy from many sources and may provide lower environmental pollution then we will discuss what would be the main factors affecting electricity prices of dg units at different states.","doi":"","created":1704153600000,"updated":"","authors":["mohsen abedi"]}
{"id":"2401.01433","title":"multiple access techniques for intelligent and multi-functional 6g:   tutorial, survey, and outlook","categories":"cs.it eess.sp math.it","abstract":"multiple access (ma) is a crucial part of any wireless system and refers to techniques that make use of the resource dimensions to serve multiple users\/devices\/machines\/services, ideally in the most efficient way. given the needs of multi-functional wireless networks for integrated communications, sensing, localization, computing, coupled with the surge of machine learning \/ artificial intelligence (ai) in wireless networks, ma techniques are expected to experience a paradigm shift in 6g and beyond. in this paper, we provide a tutorial, survey and outlook of past, emerging and future ma techniques and pay a particular attention to how wireless network intelligence and multi-functionality will lead to a re-thinking of those techniques. the paper starts with an overview of orthogonal, physical layer multicasting, space domain, power domain, ratesplitting, code domain mas, and other domains, and highlight the importance of researching universal multiple access to shrink instead of grow the knowledge tree of ma schemes by providing a unified understanding of ma schemes across all resource dimensions. it then jumps into rethinking ma schemes in the era of wireless network intelligence, covering ai for ma such as ai-empowered resource allocation, optimization, channel estimation, receiver designs, user behavior predictions, and ma for ai such as federated learning\/edge intelligence and over the air computation. we then discuss ma for network multi-functionality and the interplay between ma and integrated sensing, localization, and communications. we finish with studying ma for emerging intelligent applications before presenting a roadmap toward 6g standardization. we also point out numerous directions that are promising for future research.","doi":"","created":1704153600000,"updated":"","authors":["bruno clerckx","yijie mao","zhaohui yang","mingzhe chen","ahmed alkhateeb","liang liu","min qiu","jinhong yuan","vincent w. s. wong","juan montojo"]}
{"id":"2401.01439","title":"off-road lidar intensity based semantic segmentation","categories":"cs.cv cs.ro","abstract":"lidar is used in autonomous driving to provide 3d spatial information and enable accurate perception in off-road environments, aiding in obstacle detection, mapping, and path planning. learning-based lidar semantic segmentation utilizes machine learning techniques to automatically classify objects and regions in lidar point clouds. learning-based models struggle in off-road environments due to the presence of diverse objects with varying colors, textures, and undefined boundaries, which can lead to difficulties in accurately classifying and segmenting objects using traditional geometric-based features. in this paper, we address this problem by harnessing the lidar intensity parameter to enhance object segmentation in off-road environments. our approach was evaluated in the rellis-3d data set and yielded promising results as a preliminary analysis with improved miou for classes \"puddle\" and \"grass\" compared to more complex deep learning-based benchmarks. the methodology was evaluated for compatibility across both velodyne and ouster lidar systems, assuring its cross-platform applicability. this analysis advocates for the incorporation of calibrated intensity as a supplementary input, aiming to enhance the prediction accuracy of learning based semantic segmentation frameworks. https:\/\/github.com\/moonlabiiserb\/lidar-intensity-predictor\/tree\/main","doi":"","created":1704153600000,"updated":"","authors":["kasi viswanath","peng jiang","sujit pb","srikanth saripalli"]}
{"id":"2401.01442","title":"hierarchical over-the-air federated learning with awareness of   interference and data heterogeneity","categories":"cs.it cs.ai cs.lg math.it","abstract":"when implementing hierarchical federated learning over wireless networks, scalability assurance and the ability to handle both interference and device data heterogeneity are crucial. this work introduces a learning method designed to address these challenges, along with a scalable transmission scheme that efficiently uses a single wireless resource through over-the-air computation. to provide resistance against data heterogeneity, we employ gradient aggregations. meanwhile, the impact of interference is minimized through optimized receiver normalizing factors. for this, we model a multi-cluster wireless network using stochastic geometry, and characterize the mean squared error of the aggregation estimations as a function of the network parameters. we show that despite the interference and the data heterogeneity, the proposed scheme achieves high learning accuracy and can significantly outperform the conventional hierarchical algorithm.","doi":"","created":1704153600000,"updated":"","authors":["seyed mohammad azimi-abarghouyi","viktoria fodor"]}
{"id":"2401.01445","title":"indoor obstacle discovery on reflective ground via monocular camera","categories":"cs.cv cs.ro","abstract":"visual obstacle discovery is a key step towards autonomous navigation of indoor mobile robots. successful solutions have many applications in multiple scenes. one of the exceptions is the reflective ground. in this case, the reflections on the floor resemble the true world, which confuses the obstacle discovery and leaves navigation unsuccessful. we argue that the key to this problem lies in obtaining discriminative features for reflections and obstacles. note that obstacle and reflection can be separated by the ground plane in 3d space. with this observation, we firstly introduce a pre-calibration based ground detection scheme that uses robot motion to predict the ground plane. due to the immunity of robot motion to reflection, this scheme avoids failed ground detection caused by reflection. given the detected ground, we design a ground-pixel parallax to describe the location of a pixel relative to the ground. based on this, a unified appearance-geometry feature representation is proposed to describe objects inside rectangular boxes. eventually, based on segmenting by detection framework, an appearance-geometry fusion regressor is designed to utilize the proposed feature to discover the obstacles. it also prevents our model from concentrating too much on parts of obstacles instead of whole obstacles. for evaluation, we introduce a new dataset for obstacle on reflective ground (org), which comprises 15 scenes with various ground reflections, a total of more than 200 image sequences and 3400 rgb images. the pixel-wise annotations of ground and obstacle provide a comparison to our method and other methods. by reducing the misdetection of the reflection, the proposed approach outperforms others. the source code and the dataset will be available at https:\/\/github.com\/xuefengbupt\/indoorobstaclediscovery-rg.","doi":"","created":1704153600000,"updated":"","authors":["feng xue","yicong chang","tianxi wang","yu zhou","anlong ming"]}
{"id":"2401.01448","title":"probmcl: simple probabilistic contrastive learning for multi-label   visual classification","categories":"cs.cv cs.lg","abstract":"multi-label image classification presents a challenging task in many domains, including computer vision and medical imaging. recent advancements have introduced graph-based and transformer-based methods to improve performance and capture label dependencies. however, these methods often include complex modules that entail heavy computation and lack interpretability. in this paper, we propose probabilistic multi-label contrastive learning (probmcl), a novel framework to address these challenges in multi-label image classification tasks. our simple yet effective approach employs supervised contrastive learning, in which samples that share enough labels with an anchor image based on a decision threshold are introduced as a positive set. this structure captures label dependencies by pulling positive pair embeddings together and pushing away negative samples that fall below the threshold. we enhance representation learning by incorporating a mixture density network into contrastive learning and generating gaussian mixture distributions to explore the epistemic uncertainty of the feature encoder. we validate the effectiveness of our framework through experimentation with datasets from the computer vision and medical imaging domains. our method outperforms the existing state-of-the-art methods while achieving a low computational footprint on both datasets. visualization analyses also demonstrate that probmcl-learned classifiers maintain a meaningful semantic topology.","doi":"10.1109\/icassp48485.2024.10447400","created":1704153600000,"updated":"2024-04-12","authors":["ahmad sajedi","samir khaki","yuri a. lawryshyn","konstantinos n. plataniotis"]}
{"id":"2401.01453","title":"the entangled quantum polynomial hierarchy collapses","categories":"quant-ph cs.cc","abstract":"we introduce the entangled quantum polynomial hierarchy $\\mathsf{qeph}$ as the class of problems that are efficiently verifiable given alternating quantum proofs that may be entangled with each other. we prove $\\mathsf{qeph}$ collapses to its second level. in fact, we show that a polynomial number of alternations collapses to just two. as a consequence, $\\mathsf{qeph} = \\mathsf{qrg(1)}$, the class of problems having one-turn quantum refereed games, which is known to be contained in $\\mathsf{pspace}$. this is in contrast to the unentangled quantum polynomial hierarchy $\\mathsf{qph}$, which contains $\\mathsf{qma(2)}$.   we also introduce a generalization of the quantum-classical polynomial hierarchy $\\mathsf{qcph}$ where the provers send probability distributions over strings (instead of strings) and denote it by $\\mathsf{distributionqcph}$. conceptually, this class is intermediate between $\\mathsf{qcph}$ and $\\mathsf{qph}$. we prove $\\mathsf{distributionqcph} = \\mathsf{qcph}$, suggesting that only quantum superposition (not classical probability) increases the computational power of these hierarchies. to prove this equality, we generalize a game-theoretic result of lipton and young (1994) which says that the provers can send distributions that are uniform over a polynomial-size support. we also prove the analogous result for the polynomial hierarchy, i.e., $\\mathsf{distributionph} = \\mathsf{ph}$. these results also rule out certain approaches for showing $\\mathsf{qph}$ collapses.   finally, we show that $\\mathsf{ph}$ and $\\mathsf{qcph}$ are contained in $\\mathsf{qph}$, resolving an open question of gharibian et al. (2022).","doi":"","created":1704153600000,"updated":"","authors":["sabee grewal","justin yirka"]}
{"id":"2401.01454","title":"a survey on autonomous driving datasets: statistics, annotation quality,   and a future outlook","categories":"cs.cv","abstract":"autonomous driving has rapidly developed and shown promising performance due to recent advances in hardware and deep learning techniques. high-quality datasets are fundamental for developing reliable autonomous driving algorithms. previous dataset surveys either focused on a limited number or lacked detailed investigation of dataset characteristics. to this end, we present an exhaustive study of 265 autonomous driving datasets from multiple perspectives, including sensor modalities, data size, tasks, and contextual conditions. we introduce a novel metric to evaluate the impact of datasets, which can also be a guide for creating new datasets. besides, we analyze the annotation processes, existing labeling tools, and the annotation quality of datasets, showing the importance of establishing a standard annotation pipeline. on the other hand, we thoroughly analyze the impact of geographical and adversarial environmental conditions on the performance of autonomous driving systems. moreover, we exhibit the data distribution of several vital datasets and discuss their pros and cons accordingly. finally, we discuss the current challenges and the development trend of the future autonomous driving datasets.","doi":"","created":1704153600000,"updated":"2024-04-23","authors":["mingyu liu","ekim yurtsever","jonathan fossaert","xingcheng zhou","walter zimmer","yuning cui","bare luka zagar","alois c. knoll"]}
{"id":"2401.01456","title":"colorizediffusion: adjustable sketch colorization with reference image   and text","categories":"cs.cv","abstract":"diffusion models have recently demonstrated their effectiveness in generating extremely high-quality images and are now utilized in a wide range of applications, including automatic sketch colorization. although many methods have been developed for guided sketch colorization, there has been limited exploration of the potential conflicts between image prompts and sketch inputs, which can lead to severe deterioration in the results. therefore, this paper exhaustively investigates reference-based sketch colorization models that aim to colorize sketch images using reference color images. we specifically investigate two critical aspects of reference-based diffusion models: the \"distribution problem\", which is a major shortcoming compared to text-based counterparts, and the capability in zero-shot sequential text-based manipulation. we introduce two variations of an image-guided latent diffusion model utilizing different image tokens from the pre-trained clip image encoder and propose corresponding manipulation methods to adjust their results sequentially using weighted text inputs. we conduct comprehensive evaluations of our models through qualitative and quantitative experiments as well as a user study.","doi":"","created":1704153600000,"updated":"2024-07-03","authors":["dingkun yan","liang yuan","erwin wu","yuma nishioka","issei fujishiro","suguru saito"]}
{"id":"2401.01458","title":"concurrent self-testing of neural networks using uncertainty fingerprint","categories":"cs.lg cs.ai cs.et","abstract":"neural networks (nns) are increasingly used in always-on safety-critical applications deployed on hardware accelerators (nn-has) employing various memory technologies. reliable continuous operation of nn is essential for safety-critical applications. during online operation, nns are susceptible to single and multiple permanent and soft errors due to factors such as radiation, aging, and thermal effects. explicit nn-ha testing methods cannot detect transient faults during inference, are unsuitable for always-on applications, and require extensive test vector generation and storage. therefore, in this paper, we propose the \\emph{uncertainty fingerprint} approach representing the online fault status of nn. furthermore, we propose a dual head nn topology specifically designed to produce uncertainty fingerprints and the primary prediction of the nn in \\emph{a single shot}. during the online operation, by matching the uncertainty fingerprint, we can concurrently self-test nns with up to $100\\%$ coverage with a low false positive rate while maintaining a similar performance of the primary task. compared to existing works, memory overhead is reduced by up to $243.7$ mb, multiply and accumulate (mac) operation is reduced by up to $10000\\times$, and false-positive rates are reduced by up to $89\\%$.","doi":"","created":1704153600000,"updated":"","authors":["soyed tuhin ahmed","mehdi b. tahoori"]}
{"id":"2401.01459","title":"outlier ranking in large-scale public health streams","categories":"cs.ai","abstract":"disease control experts inspect public health data streams daily for outliers worth investigating, like those corresponding to data quality issues or disease outbreaks. however, they can only examine a few of the thousands of maximally-tied outliers returned by univariate outlier detection methods applied to large-scale public health data streams. to help experts distinguish the most important outliers from these thousands of tied outliers, we propose a new task for algorithms to rank the outputs of any univariate method applied to each of many streams. our novel algorithm for this task, which leverages hierarchical networks and extreme value analysis, performed the best across traditional outlier detection metrics in a human-expert evaluation using public health data streams. most importantly, experts have used our open-source python implementation since april 2023 and report identifying outliers worth investigating 9.1x faster than their prior baseline. other organizations can readily adapt this implementation to create rankings from the outputs of their tailored univariate methods across large-scale streams.","doi":"","created":1704153600000,"updated":"","authors":["ananya joshi","tina townes","nolan gormley","luke neureiter","roni rosenfeld","bryan wilder"]}
{"id":"2401.01460","title":"point cloud classification via deep set linearized optimal transport","categories":"cs.lg stat.ml","abstract":"we introduce deep set linearized optimal transport, an algorithm designed for the efficient simultaneous embedding of point clouds into an $l^2-$space. this embedding preserves specific low-dimensional structures within the wasserstein space while constructing a classifier to distinguish between various classes of point clouds. our approach is motivated by the observation that $l^2-$distances between optimal transport maps for distinct point clouds, originating from a shared fixed reference distribution, provide an approximation of the wasserstein-2 distance between these point clouds, under certain assumptions. to learn approximations of these transport maps, we employ input convex neural networks (icnns) and establish that, under specific conditions, euclidean distances between samples from these icnns closely mirror wasserstein-2 distances between the true distributions. additionally, we train a discriminator network that attaches weights these samples and creates a permutation invariant classifier to differentiate between different classes of point clouds. we showcase the advantages of our algorithm over the standard deep set approach through experiments on a flow cytometry dataset with a limited number of labeled point clouds.","doi":"","created":1704153600000,"updated":"","authors":["scott mahan","caroline moosmüller","alexander cloninger"]}
{"id":"2401.01461","title":"efficient hybrid zoom using camera fusion on mobile phones","categories":"cs.cv","abstract":"dslr cameras can achieve multiple zoom levels via shifting lens distances or swapping lens types. however, these techniques are not possible on smartphone devices due to space constraints. most smartphone manufacturers adopt a hybrid zoom system: commonly a wide (w) camera at a low zoom level and a telephoto (t) camera at a high zoom level. to simulate zoom levels between w and t, these systems crop and digitally upsample images from w, leading to significant detail loss. in this paper, we propose an efficient system for hybrid zoom super-resolution on mobile devices, which captures a synchronous pair of w and t shots and leverages machine learning models to align and transfer details from t to w. we further develop an adaptive blending method that accounts for depth-of-field mismatches, scene occlusion, flow uncertainty, and alignment errors. to minimize the domain gap, we design a dual-phone camera rig to capture real-world inputs and ground-truths for supervised training. our method generates a 12-megapixel image in 500ms on a mobile platform and compares favorably against state-of-the-art methods under extensive evaluation on real-world scenarios.","doi":"","created":1704153600000,"updated":"","authors":["xiaotong wu","wei-sheng lai","yichang shih","charles herrmann","michael krainin","deqing sun","chia-kai liang"]}
{"id":"2401.01466","title":"human leading or following preferences: effects on human perception of   the robot and the human-robot collaboration","categories":"cs.ro","abstract":"achieving effective and seamless human-robot collaboration requires two key outcomes: enhanced team performance and fostering a positive human perception of both the robot and the collaboration. this paper investigates the capability of the proposed task planning framework to realize these objectives by integrating human leading\/following preference and performance into its task allocation and scheduling processes. we designed a collaborative scenario wherein the robot autonomously collaborates with participants. the outcomes of the user study indicate that the proactive task planning framework successfully attains the aforementioned goals. we also explore the impact of participants' leadership and followership styles on their collaboration. the results reveal intriguing relationships between these factors, which warrant further investigation in future studies.","doi":"","created":1704153600000,"updated":"","authors":["ali noormohammadi-asl","kevin fan","stephen l. smith","kerstin dautenhahn"]}
{"id":"2401.01469","title":"question-answering based summarization of electronic health records   using retrieval augmented generation","categories":"cs.cl cs.ai","abstract":"summarization of electronic health records (ehrs) can substantially minimize 'screen time' for both patients as well as medical personnel. in recent years summarization of ehrs have employed machine learning pipelines using state of the art neural models. however, these models have produced less than adequate results that are attributed to the difficulty of obtaining sufficient annotated data for training. moreover, the requirement to consider the entire content of an ehr in summarization has resulted in poor performance due to the fact that attention mechanisms in modern large language models (llms) adds a quadratic complexity in terms of the size of the input. we propose here a method that mitigates these shortcomings by combining semantic search, retrieval augmented generation (rag) and question-answering using the latest llms. in our approach summarization is the extraction of answers to specific questions that are deemed important by subject-matter experts (smes). our approach is quite efficient; requires minimal to no training; does not suffer from the 'hallucination' problem of llms; and it ensures diversity, since the summary will not have repeated content but diverse answers to specific questions.","doi":"","created":1704153600000,"updated":"","authors":["walid saba","suzanne wendelken","james. shanahan"]}
{"id":"2401.01470","title":"tpc-vit: token propagation controller for efficient vision transformer","categories":"cs.cv cs.ai cs.lg cs.mm cs.ne","abstract":"vision transformers (vits) have achieved promising results on a variety of computer vision tasks, however their quadratic complexity in the number of input tokens has limited their application specially in resource-constrained settings. previous approaches that employ gradual token reduction to address this challenge assume that token redundancy in one layer implies redundancy in all the following layers. we empirically demonstrate that this assumption is often not correct, i.e., tokens that are redundant in one layer can be useful in later layers. we employ this key insight to propose a novel token propagation controller (tpc) that incorporates two different token-distributions, i.e., pause probability and restart probability to control the reduction and reuse of tokens respectively, which results in more efficient token utilization. to improve the estimates of token distributions, we propose a smoothing mechanism that acts as a regularizer and helps remove noisy outliers. furthermore, to improve the training-stability of our proposed tpc, we introduce a model stabilizer that is able to implicitly encode local image structures and minimize accuracy fluctuations during model training. we present extensive experimental results on the imagenet-1k dataset using deit, lv-vit and swin models to demonstrate the effectiveness of our proposed method. for example, compared to baseline models, our proposed method improves the inference speed of the deit-s by 250% while increasing the classification accuracy by 1.0%.","doi":"","created":1704153600000,"updated":"2024-01-08","authors":["wentao zhu"]}
{"id":"2401.01472","title":"studying and recommending information highlighting in stack overflow   answers","categories":"cs.cl cs.ir cs.lg cs.se","abstract":"context: navigating the knowledge of stack overflow (so) remains challenging. to make the posts vivid to users, so allows users to write and edit posts with markdown or html so that users can leverage various formatting styles (e.g., bold, italic, and code) to highlight the important information. nonetheless, there have been limited studies on the highlighted information. objective: we carried out the first large-scale exploratory study on the information highlighted in so answers in our recent study. to extend our previous study, we develop approaches to automatically recommend highlighted content with formatting styles using neural network architectures initially designed for the named entity recognition task. method: in this paper, we studied 31,169,429 answers of stack overflow. for training recommendation models, we choose cnn-based and bert-based models for each type of formatting (i.e., bold, italic, code, and heading) using the information highlighting dataset we collected from so answers. results: our models achieve a precision ranging from 0.50 to 0.72 for different formatting types. it is easier to build a model to recommend code than other types. models for text formatting types (i.e., heading, bold, and italic) suffer low recall. our analysis of failure cases indicates that the majority of the failure cases are due to missing identification. one explanation is that the models are easy to learn the frequent highlighted words while struggling to learn less frequent words (i.g., long-tail knowledge). conclusion: our findings suggest that it is possible to develop recommendation models for highlighting information for answers with different formatting styles on stack overflow.","doi":"","created":1704153600000,"updated":"2024-04-25","authors":["shahla shaan ahmed","shaowei wang","yuan tian","n\/a tse-hsun","n\/a chen","haoxiang zhang"]}
{"id":"2401.01473","title":"self-supervised reflective learning through self-distillation and online   clustering for speaker representation learning","categories":"eess.as cs.sd","abstract":"speaker representation learning is critical for modern voice recognition systems. while supervised learning techniques require extensive labeled data, unsupervised methodologies can leverage vast unlabeled corpora, offering a scalable solution. this paper introduces self-supervised reflective learning (ssrl), a novel paradigm that streamlines existing iterative unsupervised frameworks. ssrl integrates self-supervised knowledge distillation with online clustering to refine pseudo labels and train the model without iterative bottlenecks. specifically, a teacher model continually refines pseudo labels through online clustering, providing dynamic supervision signals to train the student model. the student model undergoes noisy student training with input and model noise to boost its modeling capacity. the teacher model is updated via an exponential moving average of the student, acting as an ensemble of past iterations. further, a pseudo label queue retains historical labels for consistency, and noisy label modeling directs learning towards clean samples. experiments on voxceleb show ssrl's superiority over current iterative approaches, surpassing the performance of a 5-round method in just a single training round. ablation studies validate the contributions of key components like noisy label modeling and pseudo label queues. moreover, consistent improvements in pseudo labeling and the convergence of cluster counts demonstrate ssrl's effectiveness in deciphering unlabeled data. this work marks an important advancement in efficient and accurate speaker representation learning through the novel reflective learning paradigm.","doi":"","created":1704153600000,"updated":"2024-07-15","authors":["danwei cai","zexin cai","ming li"]}
{"id":"2401.01474","title":"demonstrating mobile manipulation in the wild: a metrics-driven approach","categories":"cs.ro","abstract":"we present our general-purpose mobile manipulation system consisting of a custom robot platform and key algorithms spanning perception and planning. to extensively test the system in the wild and benchmark its performance, we choose a grocery shopping scenario in an actual, unmodified grocery store. we derive key performance metrics from detailed robot log data collected during six week-long field tests, spread across 18 months. these objective metrics, gained from complex yet repeatable tests, drive the direction of our research efforts and let us continuously improve our system's performance. we find that thorough end-to-end system-level testing of a complex mobile manipulation system can serve as a reality-check for state-of-the-art methods in robotics. this effectively grounds robotics research efforts in real world needs and challenges, which we deem highly useful for the advancement of the field. to this end, we share our key insights and takeaways to inspire and accelerate similar system-level research projects.","doi":"10.15607\/rss.2023.xix.055","created":1704153600000,"updated":"","authors":["max bajracharya","james borders","richard cheng","dan helmick","lukas kaul","dan kruse","john leichty","jeremy ma","carolyn matl","frank michel","chavdar papazov","josh petersen","krishna shankar","mark tjersland"]}
{"id":"2401.01476","title":"on rank-monotone graph operations and minimal obstruction graphs for the   lov\\'{a}sz--schrijver sdp hierarchy","categories":"cs.dm math.co math.oc","abstract":"we study the lift-and-project rank of the stable set polytopes of graphs with respect to the lov\\'{a}sz--schrijver sdp operator $\\text{ls}_+$, with a particular focus on finding and characterizing the smallest graphs with a given $\\text{ls}_+$-rank (the least number of iterations of the $\\text{ls}_+$ operator on the fractional stable set polytope to compute the stable set polytope). we introduce a generalized vertex-stretching operation that appears to be promising in generating $\\text{ls}_+$-minimal graphs and study its properties. we also provide several new $\\text{ls}_+$-minimal graphs, most notably the first known instances of $12$-vertex graphs with $\\text{ls}_+$-rank $4$, which provides the first advance in this direction since escalante, montelar, and nasini's discovery of a $9$-vertex graph with $\\text{ls}_+$-rank $3$ in 2006.","doi":"","created":1704153600000,"updated":"","authors":["yu hin au","levent tunçel"]}
{"id":"2401.01479","title":"kernel-u-net: symmetric and hierarchical architecture for multivariate   time series forecasting","categories":"cs.lg","abstract":"time series forecasting task predicts future trends based on historical information. transformer-based u-net architectures, despite their success in medical image segmentation, have limitations in both expressiveness and computation efficiency in time series forecasting as evidenced in yformer. to tackle these challenges, we introduce kernel-u-net, a symmetric and hierarchical u-shape neural network architecture. the kernel-u-net encoder compresses gradually input series into latent vectors, and its symmetric decoder subsequently expands these vectors into output series. specifically, kernel-u-net separates the procedure of partitioning input time series into patches from kernel manipulation, thereby providing the convenience of executing customized kernels. our method offers two primary advantages: 1) flexibility in kernel customization to adapt to specific datasets; 2) enhanced computational efficiency, with the complexity of the transformer layer reduced to linear. experiments on seven real-world datasets, considering both multivariate and univariate settings, demonstrate that kernel-u-net's performance either exceeds or meets that of the existing state-of-the-art model patchtst in the majority of cases and outperforms yformer. the source code for kernel-u-net will be made publicly available for further research and application.","doi":"","created":1704153600000,"updated":"2024-02-11","authors":["jiang you","rené natowicz","arben cela","jacob ouanounou","patrick siarry"]}
{"id":"2401.01481","title":"optimizing uav-ugv coalition operations: a hybrid clustering and   multi-agent reinforcement learning approach for path planning in obstructed   environment","categories":"cs.ro cs.ma","abstract":"one of the most critical applications undertaken by coalitions of unmanned aerial vehicles (uavs) and unmanned ground vehicles (ugvs) is reaching predefined targets by following the most time-efficient routes while avoiding collisions. unfortunately, uavs are hampered by limited battery life, and ugvs face challenges in reachability due to obstacles and elevation variations. existing literature primarily focuses on one-to-one coalitions, which constrains the efficiency of reaching targets. in this work, we introduce a novel approach for a uav-ugv coalition with a variable number of vehicles, employing a modified mean-shift clustering algorithm to segment targets into multiple zones. each vehicle utilizes multi-agent deep deterministic policy gradient (maddpg) and multi-agent proximal policy optimization (mappo), two advanced reinforcement learning algorithms, to form an effective coalition for navigating obstructed environments without collisions. this approach of assigning targets to various circular zones, based on density and range, significantly reduces the time required to reach these targets. moreover, introducing variability in the number of uavs and ugvs in a coalition enhances task efficiency by enabling simultaneous multi-target engagement. the results of our experimental evaluation demonstrate that our proposed method substantially surpasses current state-of-the-art techniques, nearly doubling efficiency in terms of target navigation time and task completion rate.","doi":"","created":1704153600000,"updated":"","authors":["shamyo brotee","farhan kabir","md. abdur razzaque","palash roy","md. mamun-or-rashid","md. rafiul hassan","mohammad mehedi hassan"]}
{"id":"2401.01482","title":"incorporating geo-diverse knowledge into prompting for increased   geographical robustness in object recognition","categories":"cs.cv cs.ai cs.lg","abstract":"existing object recognition models have been shown to lack robustness in diverse geographical scenarios due to domain shifts in design and context. class representations need to be adapted to more accurately reflect an object concept under these shifts. in the absence of training data from target geographies, we hypothesize that geographically diverse descriptive knowledge of categories can enhance robustness. for this purpose, we explore the feasibility of probing a large language model for geography-based object knowledge, and we examine the effects of integrating knowledge into zero-shot and learnable soft prompting with clip. within this exploration, we propose geography knowledge regularization to ensure that soft prompts trained on a source set of geographies generalize to an unseen target set. accuracy gains over prompting baselines on dollarstreet while training only on europe data are up to +2.8\/1.2\/1.6 on target data from africa\/asia\/americas, and +4.6 overall on the hardest classes. competitive performance is shown vs. few-shot target training, and analysis is provided to direct future study of geographical robustness.","doi":"","created":1704153600000,"updated":"2024-03-29","authors":["kyle buettner","sina malakouti","xiang lorraine li","adriana kovashka"]}
{"id":"2401.01483","title":"to lead or to follow? adaptive robot task planning in human-robot   collaboration","categories":"cs.ro","abstract":"adaptive task planning is fundamental to ensuring effective and seamless human-robot collaboration. this paper introduces a robot task planning framework that takes into account both human leading\/following preferences and performance, specifically focusing on task allocation and scheduling in collaborative settings. we present a proactive task allocation approach with three primary objectives: enhancing team performance, incorporating human preferences, and upholding a positive human perception of the robot and the collaborative experience. through a user study, involving an autonomous mobile manipulator robot working alongside participants in a collaborative scenario, we confirm that the task planning framework successfully attains all three intended goals, thereby contributing to the advancement of adaptive task planning in human-robot collaboration. this paper mainly focuses on the first two objectives, and we discuss the third objective, participants' perception of the robot, tasks, and collaboration in a companion paper.","doi":"","created":1704153600000,"updated":"","authors":["ali noormohammadi-asl","stephen l. smith","kerstin dautenhahn"]}
{"id":"2401.01484","title":"uncertainty regularized evidential regression","categories":"cs.lg cs.ai","abstract":"the evidential regression network (ern) represents a novel approach that integrates deep learning with dempster-shafer's theory to predict a target and quantify the associated uncertainty. guided by the underlying theory, specific activation functions must be employed to enforce non-negative values, which is a constraint that compromises model performance by limiting its ability to learn from all samples. this paper provides a theoretical analysis of this limitation and introduces an improvement to overcome it. initially, we define the region where the models can't effectively learn from the samples. following this, we thoroughly analyze the ern and investigate this constraint. leveraging the insights from our analysis, we address the limitation by introducing a novel regularization term that empowers the ern to learn from the whole training set. our extensive experiments substantiate our theoretical findings and demonstrate the effectiveness of the proposed solution.","doi":"","created":1704153600000,"updated":"","authors":["kai ye","tiejin chen","hua wei","liang zhan"]}
{"id":"2401.01487","title":"natural language processing and multimodal stock price prediction","categories":"cs.lg cs.cl","abstract":"in the realm of financial decision-making, predicting stock prices is pivotal. artificial intelligence techniques such as long short-term memory networks (lstms), support-vector machines (svms), and natural language processing (nlp) models are commonly employed to predict said prices. this paper utilizes stock percentage change as training data, in contrast to the traditional use of raw currency values, with a focus on analyzing publicly released news articles. the choice of percentage change aims to provide models with context regarding the significance of price fluctuations and overall price change impact on a given stock. the study employs specialized bert natural language processing models to predict stock price trends, with a particular emphasis on various data modalities. the results showcase the capabilities of such strategies with a small natural language processing model to accurately predict overall stock trends, and highlight the effectiveness of certain data features and sector-specific data.","doi":"","created":1704153600000,"updated":"","authors":["kevin taylor","jerry ng"]}
{"id":"2401.01489","title":"the neuron as a direct data-driven controller","categories":"q-bio.nc cs.ai cs.sy eess.sy","abstract":"in the quest to model neuronal function amidst gaps in physiological data, a promising strategy is to develop a normative theory that interprets neuronal physiology as optimizing a computational objective. this study extends the current normative models, which primarily optimize prediction, by conceptualizing neurons as optimal feedback controllers. we posit that neurons, especially those beyond early sensory areas, act as controllers, steering their environment towards a specific desired state through their output. this environment comprises both synaptically interlinked neurons and external motor sensory feedback loops, enabling neurons to evaluate the effectiveness of their control via synaptic feedback. utilizing the novel direct data-driven control (dd-dc) framework, we model neurons as biologically feasible controllers which implicitly identify loop dynamics, infer latent states and optimize control. our dd-dc neuron model explains various neurophysiological phenomena: the shift from potentiation to depression in spike-timing-dependent plasticity (stdp) with its asymmetry, the duration and adaptive nature of feedforward and feedback neuronal filters, the imprecision in spike generation under constant stimulation, and the characteristic operational variability and noise in the brain. our model presents a significant departure from the traditional, feedforward, instant-response mcculloch-pitts-rosenblatt neuron, offering a novel and biologically-informed fundamental unit for constructing neural networks.","doi":"","created":1704153600000,"updated":"","authors":["jason moore","alexander genkin","magnus tournoy","joshua pughe-sanford","rob r. de ruyter van steveninck","dmitri b. chklovskii"]}
{"id":"2401.01491","title":"a hybrid neural network model for predicting the nitrate concentration   in the recirculating aquaculture system","categories":"cs.ce","abstract":"this study was groundbreaking in its application of neural network models for nitrate management in the recirculating aquaculture system (ras). a hybrid neural network model was proposed, which accurately predicted daily nitrate concentration and its trends using six water quality parameters. we conducted a 105-day aquaculture experiment, during which we collected 450 samples from five sets of ras to train our model (c-l-a model) which incorporates convolutional neural network (cnn), long short-term memory (lstm), and self-attention. furthermore, we obtained 90 samples from a standalone ras as the testing data to evaluate the performance of the model in practical applications. the experimental results proved that the c-l-a model accurately predicted nitrate concentration in ras and maintained good performance even with a reduced proportion of training data. we recommend using water quality parameters from the past 7 days to forecast future nitrate concentration, as this timeframe allows the model to achieve maximum generalization capability. additionally, we compared the performance of the c-l-a model with three basic neural network models (cnn, lstm, self-attention) as well as three hybrid neural network models (cnn-lstm, cnn-attention, lstm-attention). the results demonstrated that the c-l-a model (r2=0.956) significantly outperformed the other neural network models (r2=0.901-0.927). our study suggests that the utilization of neural network models, specifically the c-l-a model, could potentially assist the ras industry in conserving resources for daily nitrate monitoring.","doi":"","created":1704153600000,"updated":"2024-01-15","authors":["xiangyu fan","jiaxin lia","yingzhe wang","yingsha qu","hao li","keming qu","zhengguo cui"]}
{"id":"2401.01493","title":"free lunch for federated remote sensing target fine-grained   classification: a parameter-efficient framework","categories":"cs.lg cs.ai cs.cr","abstract":"remote sensing target fine-grained classification (tfgc) is of great significance in both military and civilian fields. due to location differences, growth in data size, and centralized server storage constraints, these data are usually stored under different databases across regions\/countries. however, privacy laws and national security concerns constrain researchers from accessing these sensitive remote sensing images for further analysis. additionally, low-resource remote sensing devices encounter challenges in terms of communication overhead and efficiency when dealing with the ever-increasing data and model scales. to solve the above challenges, this paper proposes a novel privacy-reserving tfgc framework based on federated learning, dubbed prfl. the proposed framework allows each client to learn global and local knowledge to enhance the local representation of private data in environments with extreme statistical heterogeneity (non. independent and identically distributed, iid). thus, it provides highly customized models to clients with differentiated data distributions. moreover, the framework minimizes communication overhead and improves efficiency while ensuring satisfactory performance, thereby enhancing robustness and practical applicability under resource-scarce conditions. we demonstrate the effectiveness of the proposed prfl on the classical tfgc task by leveraging four public datasets.","doi":"","created":1704153600000,"updated":"","authors":["shengchao chen","ting shu","huan zhao","jiahao wang","sufen ren","lina yang"]}
{"id":"2401.01495","title":"a two-stage multimodal emotion recognition model based on graph   contrastive learning","categories":"cs.cl","abstract":"in terms of human-computer interaction, it is becoming more and more important to correctly understand the user's emotional state in a conversation, so the task of multimodal emotion recognition (mer) started to receive more attention. however, existing emotion classification methods usually perform classification only once. sentences are likely to be misclassified in a single round of classification. previous work usually ignores the similarities and differences between different morphological features in the fusion process. to address the above issues, we propose a two-stage emotion recognition model based on graph contrastive learning (ts-gcl). first, we encode the original dataset with different preprocessing modalities. second, a graph contrastive learning (gcl) strategy is introduced for these three modal data with other structures to learn similarities and differences within and between modalities. finally, we use mlp twice to achieve the final emotion classification. this staged classification method can help the model to better focus on different levels of emotional information, thereby improving the performance of the model. extensive experiments show that ts-gcl has superior performance on iemocap and meld datasets compared with previous methods.","doi":"","created":1704153600000,"updated":"","authors":["wei ai","fuchen zhang","tao meng","yuntao shou","hongen shao","keqin li"]}
{"id":"2401.01496","title":"from pixel to slide image: polarization modality-based pathological   diagnosis using representation learning","categories":"eess.iv cs.ai cs.cv","abstract":"thyroid cancer is the most common endocrine malignancy, and accurately distinguishing between benign and malignant thyroid tumors is crucial for developing effective treatment plans in clinical practice. pathologically, thyroid tumors pose diagnostic challenges due to improper specimen sampling. in this study, we have designed a three-stage model using representation learning to integrate pixel-level and slice-level annotations for distinguishing thyroid tumors. this structure includes a pathology structure recognition method to predict structures related to thyroid tumors, an encoder-decoder network to extract pixel-level annotation information by learning the feature representations of image blocks, and an attention-based learning mechanism for the final classification task. this mechanism learns the importance of different image blocks in a pathological region, globally considering the information from each block. in the third stage, all information from the image blocks in a region is aggregated using attention mechanisms, followed by classification to determine the category of the region. experimental results demonstrate that our proposed method can predict microscopic structures more accurately. after color-coding, the method achieves results on unstained pathology slides that approximate the quality of hematoxylin and eosin staining, reducing the need for stained pathology slides. furthermore, by leveraging the concept of indirect measurement and extracting polarized features from structures correlated with lesions, the proposed method can also classify samples where membrane structures cannot be obtained through sampling, providing a potential objective and highly accurate indirect diagnostic technique for thyroid tumors.","doi":"","created":1704153600000,"updated":"","authors":["jia dong","yao yao","yang dong","hui ma"]}
{"id":"2401.01497","title":"a pre-trained sequential recommendation framework: popularity dynamics   for zero-shot transfer","categories":"cs.ir","abstract":"sequential recommenders are crucial to the success of online applications, \\eg e-commerce, video streaming, and social media. while model architectures continue to improve, for every new application domain, we still have to train a new model from scratch for high quality recommendations. on the other hand, pre-trained language and vision models have shown great success in zero-shot or few-shot adaptation to new application domains. inspired by the success of pre-trained models in peer ai fields, we propose a novel pre-trained sequential recommendation framework: preprec. we learn universal item representations by modeling item popularity dynamics. through extensive experiments on five real-world datasets, we show that preprec, without any auxiliary information, can not only zero-shot transfer to a new domain, but achieve competitive performance compared to state-of-the-art sequential recommender models with only a fraction of the model size. in addition, with a simple post-hoc interpolation, preprec can improve the performance of existing sequential recommenders on average by 13.8\\% in recall@10 and 29.5% in ndcg@10. we provide an anonymized implementation of preprec at https:\/\/anonymous.4open.science\/r\/preprec--2f60\/","doi":"","created":1704153600000,"updated":"2024-04-10","authors":["junting wang","praneet rathi","hari sundaram"]}
{"id":"2401.01498","title":"utilizing neural transducers for two-stage text-to-speech via semantic   token prediction","categories":"eess.as cs.cl cs.lg cs.sd","abstract":"we propose a novel text-to-speech (tts) framework centered around a neural transducer. our approach divides the whole tts pipeline into semantic-level sequence-to-sequence (seq2seq) modeling and fine-grained acoustic modeling stages, utilizing discrete semantic tokens obtained from wav2vec2.0 embeddings. for a robust and efficient alignment modeling, we employ a neural transducer named token transducer for the semantic token prediction, benefiting from its hard monotonic alignment constraints. subsequently, a non-autoregressive (nar) speech generator efficiently synthesizes waveforms from these semantic tokens. additionally, a reference speech controls temporal dynamics and acoustic conditions at each stage. this decoupled framework reduces the training complexity of tts while allowing each stage to focus on semantic and acoustic modeling. our experimental results on zero-shot adaptive tts demonstrate that our model surpasses the baseline in terms of speech quality and speaker similarity, both objectively and subjectively. we also delve into the inference speed and prosody control capabilities of our approach, highlighting the potential of neural transducers in tts frameworks.","doi":"","created":1704153600000,"updated":"","authors":["minchan kim","myeonghun jeong","byoung jin choi","semin kim","joun yeop lee","nam soo kim"]}
{"id":"2401.01501","title":"evaluation of automated driving system safety metrics with logged   vehicle trajectory data","categories":"cs.ro","abstract":"real-time safety metrics are important for the automated driving system (ads) to assess the risk of driving situations and to assist the decision-making. although a number of real-time safety metrics have been proposed in the literature, systematic performance evaluation of these safety metrics has been lacking. as different behavioral assumptions are adopted in different safety metrics, it is difficult to compare the safety metrics and evaluate their performance. to overcome this challenge, in this study, we propose an evaluation framework utilizing logged vehicle trajectory data, in that vehicle trajectories for both subject vehicle (sv) and background vehicles (bvs) are obtained and the prediction errors caused by behavioral assumptions can be eliminated. specifically, we examine whether the sv is in a collision unavoidable situation at each moment, given all near-future trajectories of bvs. in this way, we level the ground for a fair comparison of different safety metrics, as a good safety metric should always alarm in advance to the collision unavoidable moment. when trajectory data from a large number of trips are available, we can systematically evaluate and compare different metrics' statistical performance. in the case study, three representative real-time safety metrics, including the time-to-collision (ttc), the pegasus criticality metric (pcm), and the model predictive instantaneous safety metric (mprism), are evaluated using a large-scale simulated trajectory dataset. the proposed evaluation framework is important for researchers, practitioners, and regulators to characterize different metrics, and to select appropriate metrics for different applications. moreover, by conducting failure analysis on moments when a safety metric failed, we can identify its potential weaknesses which are valuable for its potential refinements and improvements.","doi":"","created":1704153600000,"updated":"","authors":["xintao yan","shuo feng","david j. leblanc","carol flannagan","henry x. liu"]}
{"id":"2401.01502","title":"pontryagin neural operator for solving parametric general-sum   differential games","categories":"cs.lg cs.gt cs.ro","abstract":"the values of two-player general-sum differential games are viscosity solutions to hamilton-jacobi-isaacs (hji) equations. value and policy approximations for such games suffer from the curse of dimensionality (cod). alleviating cod through physics-informed neural networks (pinn) encounters convergence issues when differentiable values with large lipschitz constants are present due to state constraints. on top of these challenges, it is often necessary to learn generalizable values and policies across a parametric space of games, e.g., for game parameter inference when information is incomplete. to address these challenges, we propose in this paper a pontryagin-mode neural operator that outperforms the current state-of-the-art hybrid pinn model on safety performance across games with parametric state constraints. our key contribution is the introduction of a costate loss defined on the discrepancy between forward and backward costate rollouts, which are computationally cheap. we show that the costate dynamics, which can reflect state constraint violation, effectively enables the learning of differentiable values with large lipschitz constants, without requiring manually supervised data as suggested by the hybrid pinn model. more importantly, we show that the close relationship between costates and policies makes the former critical in learning feedback control policies with generalizable safety performance.","doi":"","created":1704153600000,"updated":"2024-05-31","authors":["lei zhang","mukesh ghimire","zhe xu","wenlong zhang","yi ren"]}
{"id":"2401.01503","title":"specific emitter identification based on joint variational mode   decomposition","categories":"cs.cr","abstract":"specific emitter identification (sei) technology is significant in device administration scenarios, such as self-organized networking and spectrum management, owing to its high security. for nonlinear and non-stationary electromagnetic signals, sei often employs variational modal decomposition (vmd) to decompose the signal in order to effectively characterize the distinct device fingerprint. however, the trade-off of vmd between the robustness to noise and the ability to preserve signal information has not been investigated in the current literature. moreover, the existing vmd algorithm does not utilize the stability of the intrinsic distortion of emitters within a certain temporal span, consequently constraining its practical applicability in sei. in this paper, we propose a joint variational modal decomposition (jvmd) algorithm, which is an improved version of vmd by simultaneously implementing modal decomposition on multi-frame signals. the consistency of multi-frame signals in terms of the central frequencies and the inherent modal functions (imfs) is exploited, which effectively highlights the distinctive characteristics among emitters and reduces noise. additionally, the complexity of jvmd is analyzed, which is proven to be more computational-friendly than vmd. simulations of both modal decomposition and sei that involve real-world datasets are presented to illustrate that when compared with vmd, the jvmd algorithm improves the accuracy of device classification and the robustness towards noise.","doi":"","created":1704153600000,"updated":"","authors":["xiaofang chen","wenbo xu","yue wang","yan huang"]}
{"id":"2401.01505","title":"sports-qa: a large-scale video question answering benchmark for complex   and professional sports","categories":"cs.cv","abstract":"reasoning over sports videos for question answering is an important task with numerous applications, such as player training and information retrieval. however, this task has not been explored due to the lack of relevant datasets and the challenging nature it presents. most datasets for video question answering (videoqa) focus mainly on general and coarse-grained understanding of daily-life videos, which is not applicable to sports scenarios requiring professional action understanding and fine-grained motion analysis. in this paper, we introduce the first dataset, named sports-qa, specifically designed for the sports videoqa task. the sports-qa dataset includes various types of questions, such as descriptions, chronologies, causalities, and counterfactual conditions, covering multiple sports. furthermore, to address the characteristics of the sports videoqa task, we propose a new auto-focus transformer (aft) capable of automatically focusing on particular scales of temporal information for question answering. we conduct extensive experiments on sports-qa, including baseline studies and the evaluation of different methods. the results demonstrate that our aft achieves state-of-the-art performance.","doi":"","created":1704153600000,"updated":"2024-02-14","authors":["haopeng li","andong deng","qiuhong ke","jun liu","hossein rahmani","yulan guo","bernt schiele","chen chen"]}
{"id":"2401.01506","title":"airi: predicting retention indices and their uncertainties using   artificial intelligence","categories":"cs.lg q-bio.qm","abstract":"the kov\\'ats retention index (ri) is a quantity measured using gas chromatography and commonly used in the identification of chemical structures. creating libraries of observed ri values is a laborious task, so we explore the use of a deep neural network for predicting ri values from structure for standard semipolar columns. this network generated predictions with a mean absolute error of 15.1 and, in a quantification of the tail of the error distribution, a 95th percentile absolute error of 46.5. because of the artificial intelligence retention indices (airi) network's accuracy, it was used to predict ri values for the nist ei-ms spectral libraries. these ri values are used to improve chemical identification methods and the quality of the library. estimating uncertainty is an important practical need when using prediction models. to quantify the uncertainty of our network for each individual prediction, we used the outputs of an ensemble of 8 networks to calculate a predicted standard deviation for each ri value prediction. this predicted standard deviation was corrected to follow the error between observed and predicted ri values. the z scores using these predicted standard deviations had a standard deviation of 1.52 and a 95th percentile absolute z score corresponding to a mean ri value of 42.6.","doi":"10.1021\/acs.jcim.3c01758","created":1704153600000,"updated":"2024-01-17","authors":["lewis y. geer","stephen e. stein","william gary mallard","douglas j. slotta"]}
{"id":"2401.01508","title":"practical guidelines for the selection and evaluation of natural   language processing techniques in requirements engineering","categories":"cs.se","abstract":"natural language processing (nlp) is now a cornerstone of requirements automation. one compelling factor behind the growing adoption of nlp in requirements engineering (re) is the prevalent use of natural language (nl) for specifying requirements in industry. nlp techniques are commonly used for automatically classifying requirements, extracting important information, e.g., domain models and glossary terms, and performing quality assurance tasks, such as ambiguity handling and completeness checking. with so many different nlp solution strategies available and the possibility of applying machine learning alongside, it can be challenging to choose the right strategy for a specific re task and to evaluate the resulting solution in an empirically rigorous manner. in this chapter, we present guidelines for the selection of nlp techniques as well as for their evaluation in the context of re. in particular, we discuss how to choose among different strategies such as traditional nlp, feature-based machine learning, and language-model-based methods. our ultimate hope for this chapter is to serve as a stepping stone, assisting newcomers to nlp4re in quickly initiating themselves into the nlp technologies most pertinent to the re field.","doi":"","created":1704153600000,"updated":"2024-07-16","authors":["mehrdad sabetzadeh","chetan arora"]}
{"id":"2401.01510","title":"answering from sure to uncertain: uncertainty-aware curriculum learning   for video question answering","categories":"cs.cv","abstract":"while significant advancements have been made in video question answering (videoqa), the potential benefits of enhancing model generalization through tailored difficulty scheduling have been largely overlooked in existing research. this paper seeks to bridge that gap by incorporating videoqa into a curriculum learning (cl) framework that progressively trains models from simpler to more complex data. recognizing that conventional self-paced cl methods rely on training loss for difficulty measurement, which might not accurately reflect the intricacies of video-question pairs, we introduce the concept of uncertainty-aware cl. here, uncertainty serves as the guiding principle for dynamically adjusting the difficulty. furthermore, we address the challenge posed by uncertainty by presenting a probabilistic modeling approach for videoqa. specifically, we conceptualize videoqa as a stochastic computation graph, where the hidden representations are treated as stochastic variables. this yields two distinct types of uncertainty: one related to the inherent uncertainty in the data and another pertaining to the model's confidence. in practice, we seamlessly integrate the videoqa model into our framework and conduct comprehensive experiments. the findings affirm that our approach not only achieves enhanced performance but also effectively quantifies uncertainty in the context of videoqa.","doi":"","created":1704153600000,"updated":"","authors":["haopeng li","qiuhong ke","mingming gong","tom drummond"]}
{"id":"2401.01511","title":"enhancing multilingual information retrieval in mixed human resources   environments: a rag model implementation for multicultural enterprise","categories":"cs.ir","abstract":"the advent of large language models has revolutionized information retrieval, ushering in a new era of expansive knowledge accessibility. while these models excel in providing open-world knowledge, effectively extracting answers in diverse linguistic environments with varying levels of literacy remains a formidable challenge. retrieval augmented generation (rag) emerges as a promising solution, bridging the gap between information availability and multilingual comprehension. however, deploying rag models in real-world scenarios demands careful consideration of various factors. this paper addresses the critical challenges associated with implementing rag models in multicultural environments. we delve into essential considerations, including data feeding strategies, timely updates, mitigation of hallucinations, prevention of erroneous responses, and optimization of delivery speed. our work involves the integration of a diverse array of tools, meticulously combined to facilitate the seamless adoption of rag models across languages and literacy levels within a multicultural organizational context. through strategic tweaks in our approaches, we achieve not only effectiveness but also efficiency, ensuring the accelerated and accurate delivery of information in a manner that is tailored to the unique requirements of multilingual and multicultural settings.","doi":"","created":1704153600000,"updated":"","authors":["syed rameel ahmad"]}
{"id":"2401.01512","title":"which syntactic capabilities are statistically learned by masked   language models for code?","categories":"cs.se","abstract":"this paper discusses the limitations of evaluating masked language models (mlms) in code completion tasks. we highlight that relying on accuracy-based measurements may lead to an overestimation of models' capabilities by neglecting the syntax rules of programming languages. to address these issues, we introduce a technique called syntaxeval in which syntactic capabilities are used to enhance the evaluation of mlms. syntaxeval automates the process of masking elements in the model input based on their abstract syntax trees (asts). we conducted a case study on two popular mlms using data from github repositories. our results showed negative causal effects between the node types and mlms' accuracy. we conclude that mlms under study fail to predict some syntactic capabilities.","doi":"10.1145\/3639476.3639768","created":1704153600000,"updated":"2024-02-21","authors":["alejandro velasco","david n. palacio","daniel rodriguez-cardenas","denys poshyvanyk"]}
{"id":"2401.01516","title":"a complete landscape for the price of envy-freeness","categories":"cs.gt","abstract":"we study the efficiency of fair allocations using the well-studied price of fairness concept, which quantitatively measures the worst-case efficiency loss when imposing fairness constraints. previous works provided partial results on the price of fairness with well-known fairness notions such as envy-freeness up to one good (ef1) and envy-freeness up to any good (efx). in this paper, we give a complete characterization for the price of envy-freeness in various settings. in particular, we first consider the two-agent case under the indivisible-goods setting and present tight ratios for the price of ef1 (for scaled utility) and efx (for unscaled utility), which resolve questions left open in the literature. next, we consider the mixed goods setting which concerns a mixture of both divisible and indivisible goods. we focus on envy-freeness for mixed goods (efm), which generalizes both envy-freeness and ef1, as well as its strengthening called envy-freeness up to any good for mixed goods (efxm), which generalizes envy-freeness and efx. to this end, we settle the price of efm and efxm by providing a complete picture of tight bounds for two agents and asymptotically tight bounds for $n$ agents, for both scaled and unscaled utilities.","doi":"","created":1704153600000,"updated":"","authors":["zihao li","shengxin liu","xinhang lu","biaoshuai tao","yichen tao"]}
{"id":"2401.01519","title":"exploring the frontiers of llms in psychological applications: a   comprehensive review","categories":"cs.lg cs.ai","abstract":"this paper explores the frontiers of large language models (llms) in psychology applications. psychology has undergone several theoretical changes, and the current use of artificial intelligence (ai) and machine learning, particularly llms, promises to open up new research directions. we provide a detailed exploration of how llms like chatgpt are transforming psychological research. it discusses the impact of llms across various branches of psychology, including cognitive and behavioral, clinical and counseling, educational and developmental, and social and cultural psychology, highlighting their potential to simulate aspects of human cognition and behavior. the paper delves into the capabilities of these models to emulate human-like text generation, offering innovative tools for literature review, hypothesis generation, experimental design, experimental subjects, data analysis, academic writing, and peer review in psychology. while llms are essential in advancing research methodologies in psychology, the paper also cautions about their technical and ethical challenges. there are issues like data privacy, the ethical implications of using llms in psychological research, and the need for a deeper understanding of these models' limitations. researchers should responsibly use llms in psychological studies, adhering to ethical standards and considering the potential consequences of deploying these technologies in sensitive areas. overall, the article provides a comprehensive overview of the current state of llms in psychology, exploring potential benefits and challenges. it serves as a call to action for researchers to leverage llms' advantages responsibly while addressing associated risks.","doi":"","created":1704153600000,"updated":"2024-03-16","authors":["luoma ke","song tong","peng cheng","kaiping peng"]}
{"id":"2401.01520","title":"s$^{2}$-dms:skip-step diffusion models","categories":"cs.cv cs.lg eess.iv","abstract":"diffusion models have emerged as powerful generative tools, rivaling gans in sample quality and mirroring the likelihood scores of autoregressive models. a subset of these models, exemplified by ddims, exhibit an inherent asymmetry: they are trained over $t$ steps but only sample from a subset of $t$ during generation. this selective sampling approach, though optimized for speed, inadvertently misses out on vital information from the unsampled steps, leading to potential compromises in sample quality. to address this issue, we present the s$^{2}$-dms, which is a new training method by using an innovative $l_{skip}$, meticulously designed to reintegrate the information omitted during the selective sampling phase. the benefits of this approach are manifold: it notably enhances sample quality, is exceptionally simple to implement, requires minimal code modifications, and is flexible enough to be compatible with various sampling algorithms. on the cifar10 dataset, models trained using our algorithm showed an improvement of 3.27% to 14.06% over models trained with traditional methods across various sampling algorithms (ddims, pndms, deis) and different numbers of sampling steps (10, 20, ..., 1000). on the celeba dataset, the improvement ranged from 8.97% to 27.08%. access to the code and additional resources is provided in the github.","doi":"","created":1704153600000,"updated":"2024-01-22","authors":["yixuan wang","shuangyin li"]}
{"id":"2401.01521","title":"quantum leak: timing side-channel attacks on cloud-based quantum   services","categories":"cs.et","abstract":"quantum computing offers significant acceleration capabilities over its classical counterpart in various application domains. consequently, there has been substantial focus on improving quantum computing capabilities. however, to date, the security implications of these quantum computing platforms have been largely overlooked. with the emergence of cloud-based quantum computing services, it is critical to investigate the extension of classical computer security threats to the realm of quantum computing.   in this study, we investigated timing-based side-channel vulnerabilities within ibm's cloud-based quantum service. the proposed attack effectively subverts the confidentiality of the executed quantum algorithm, using a more realistic threat model compared to existing approaches. our experimental results, conducted using ibm's quantum cloud service, demonstrate that with just 10 measurements, it is possible to identify the underlying quantum computer that executed the circuit. moreover, when evaluated using the popular grover circuit, we showcase the ability to leak the quantum oracle with a mere 500 measurements. these findings underline the pressing need to address timing-based vulnerabilities in quantum computing platforms and advocate for enhanced security measures to safeguard sensitive quantum algorithms and data.","doi":"","created":1704153600000,"updated":"","authors":["chao lu","esha telang","aydin aysu","kanad basu"]}
{"id":"2401.01522","title":"lore++: logical location regression network for table structure   recognition with pre-training","categories":"cs.cv","abstract":"table structure recognition (tsr) aims at extracting tables in images into machine-understandable formats. recent methods solve this problem by predicting the adjacency relations of detected cell boxes or learning to directly generate the corresponding markup sequences from the table images. however, existing approaches either count on additional heuristic rules to recover the table structures, or face challenges in capturing long-range dependencies within tables, resulting in increased complexity. in this paper, we propose an alternative paradigm. we model tsr as a logical location regression problem and propose a new tsr framework called lore, standing for logical location regression network, which for the first time regresses logical location as well as spatial location of table cells in a unified network. our proposed lore is conceptually simpler, easier to train, and more accurate than other paradigms of tsr. moreover, inspired by the persuasive success of pre-trained models on a number of computer vision and natural language processing tasks, we propose two pre-training tasks to enrich the spatial and logical representations at the feature level of lore, resulting in an upgraded version called lore++. the incorporation of pre-training in lore++ has proven to enjoy significant advantages, leading to a substantial enhancement in terms of accuracy, generalization, and few-shot capability compared to its predecessor. experiments on standard benchmarks against methods of previous paradigms demonstrate the superiority of lore++, which highlights the potential and promising prospect of the logical location regression paradigm for tsr.","doi":"","created":1704153600000,"updated":"","authors":["rujiao long","hangdi xing","zhibo yang","qi zheng","zhi yu","cong yao","fei huang"]}
{"id":"2401.01523","title":"goat-bench: safety insights to large multimodal models through   meme-based social abuse","categories":"cs.cl cs.ai","abstract":"the exponential growth of social media has profoundly transformed how information is created, disseminated, and absorbed, exceeding any precedent in the digital age. regrettably, this explosion has also spawned a significant increase in the online abuse of memes. evaluating the negative impact of memes is notably challenging, owing to their often subtle and implicit meanings, which are not directly conveyed through the overt text and imagery. in light of this, large multimodal models (lmms) have emerged as a focal point of interest due to their remarkable capabilities in handling diverse multimodal tasks. in response to this development, our paper aims to thoroughly examine the capacity of various lmms (e.g., gpt-4v) to discern and respond to the nuanced aspects of social abuse manifested in memes. we introduce the comprehensive meme benchmark, goat-bench, comprising over 6k varied memes encapsulating themes such as implicit hate speech, sexism, and cyberbullying, etc. utilizing goat-bench, we delve into the ability of lmms to accurately assess hatefulness, misogyny, offensiveness, sarcasm, and harmful content. our extensive experiments across a range of lmms reveal that current models still exhibit a deficiency in safety awareness, showing insensitivity to various forms of implicit abuse. we posit that this shortfall represents a critical impediment to the realization of safe artificial intelligence. the goat-bench and accompanying resources are publicly accessible at https:\/\/goatlmm.github.io\/, contributing to ongoing research in this vital field.","doi":"","created":1704153600000,"updated":"2024-03-01","authors":["hongzhan lin","ziyang luo","bo wang","ruichao yang","jing ma"]}
{"id":"2401.01524","title":"multimodal self-supervised learning for lesion localization","categories":"cs.cv","abstract":"multimodal deep learning utilizing imaging and diagnostic reports has made impressive progress in the field of medical imaging diagnostics, demonstrating a particularly strong capability for auxiliary diagnosis in cases where sufficient annotation information is lacking. nonetheless, localizing diseases accurately without detailed positional annotations remains a challenge. although existing methods have attempted to utilize local information to achieve fine-grained semantic alignment, their capability in extracting the fine-grained semantics of the comprehensive context within reports is limited. to address this problem, a new method is introduced that takes full sentences from textual reports as the basic units for local semantic alignment. this approach combines chest x-ray images with their corresponding textual reports, performing contrastive learning at both global and local levels. the leading results obtained by this method on multiple datasets confirm its efficacy in the task of lesion localization.","doi":"","created":1704153600000,"updated":"2024-03-17","authors":["hao yang","hong-yu zhou","cheng li","weijian huang","jiarun liu","yong liang","shanshan wang"]}
{"id":"2401.01525","title":"expected transaction value optimization for precise marketing in fintech   platforms","categories":"cs.ir","abstract":"fintech platforms facilitated by digital payments are watching growth rapidly, which enable the distribution of mutual funds personalized to individual investors via mobile apps. as the important intermediation of financial products investment, these platforms distribute thousands of mutual funds obtaining impressions under guaranteed delivery (gd) strategy required by fund companies. driven by the profit from fund purchases of users, the platform aims to maximize each transaction amount of customers by promoting mutual funds to these investors who will be interested in. different from the conversions in traditional advertising or e-commerce recommendations, the investment amount in each purchase varies greatly even for the same financial product, which provides a significant challenge for the promotion recommendation of mutual funds. in addition to predicting the click-through rate (ctr) or the conversion rate (cvr) as in traditional recommendations, it is essential for fintech platforms to estimate the customers' purchase amount for each delivered fund and achieve an effective allocation of impressions based on the predicted results to optimize the total expected transaction value (etv). in this paper, we propose an etv optimized customer allocation framework (eoca) that aims to maximize the total etv of recommended funds, under the constraints of gd dealt with fund companies. to the best of our knowledge, it's the first attempt to solve the gd problem for financial product promotions based on customer purchase amount prediction. we conduct extensive experiments on large scale real-world datasets and online tests based on licaitong, tencent wealth management platform, to demonstrate the effectiveness of our proposed eoca framework.","doi":"","created":1704153600000,"updated":"","authors":["yunpeng weng","xing tang","liang chen","dugang liu","xiuqiang he"]}
{"id":"2401.01527","title":"poisoning attacks against recommender systems: a survey","categories":"cs.ir","abstract":"modern recommender systems (rs) have seen substantial success, yet they remain vulnerable to malicious activities, notably poisoning attacks. these attacks involve injecting malicious data into the training datasets of rs, thereby compromising their integrity and manipulating recommendation outcomes for gaining illicit profits. this survey paper provides a systematic and up-to-date review of the research landscape on poisoning attacks against recommendation (par). a novel and comprehensive taxonomy is proposed, categorizing existing par methodologies into three distinct categories: component-specific, goal-driven, and capability probing. for each category, we discuss its mechanism in detail, along with associated methods. furthermore, this paper highlights potential future research avenues in this domain. additionally, to facilitate and benchmark the empirical comparison of par, we introduce an open-source library, arlib, which encompasses a comprehensive collection of par models and common datasets. the library is released at https:\/\/github.com\/coderwzw\/arlib.","doi":"","created":1704153600000,"updated":"2024-01-13","authors":["zongwei wang","min gao","junliang yu","hao ma","hongzhi yin","shazia sadiq"]}
{"id":"2401.01528","title":"improved bandits in many-to-one matching markets with incentive   compatibility","categories":"cs.lg cs.gt","abstract":"two-sided matching markets have been widely studied in the literature due to their rich applications. since participants are usually uncertain about their preferences, online algorithms have recently been adopted to learn them through iterative interactions. an existing work initiates the study of this problem in a many-to-one setting with responsiveness. however, their results are far from optimal and lack guarantees of incentive compatibility. we first extend an existing algorithm for the one-to-one setting to this more general setting and show it achieves a near-optimal bound for player-optimal regret. nevertheless, due to the substantial requirement for collaboration, a single player's deviation could lead to a huge increase in its own cumulative rewards and a linear regret for others. in this paper, we aim to enhance the regret bound in many-to-one markets while ensuring incentive compatibility. we first propose the adaptively explore-then-deferred-acceptance (aetda) algorithm for responsiveness setting and derive an upper bound for player-optimal stable regret while demonstrating its guarantee of incentive compatibility. to the best of our knowledge, it constitutes the first polynomial player-optimal guarantee in matching markets that offers such robust assurances without known $\\delta$, where $\\delta$ is some preference gap among players and arms. we also consider broader substitutable preferences, one of the most general conditions to ensure the existence of a stable matching and cover responsiveness. we devise an online da (oda) algorithm and establish an upper bound for the player-pessimal stable regret for this setting.","doi":"","created":1704153600000,"updated":"2024-06-01","authors":["fang kong","shuai li"]}
{"id":"2401.01529","title":"glance and focus: memory prompting for multi-event video question   answering","categories":"cs.cv","abstract":"video question answering (videoqa) has emerged as a vital tool to evaluate agents' ability to understand human daily behaviors. despite the recent success of large vision language models in many multi-modal tasks, complex situation reasoning over videos involving multiple human-object interaction events still remains challenging. in contrast, humans can easily tackle it by using a series of episode memories as anchors to quickly locate question-related key moments for reasoning. to mimic this effective reasoning strategy, we propose the glance-focus model. one simple way is to apply an action detection model to predict a set of actions as key memories. however, these actions within a closed set vocabulary are hard to generalize to various video domains. instead of that, we train an encoder-decoder to generate a set of dynamic event memories at the glancing stage. apart from using supervised bipartite matching to obtain the event memories, we further design an unsupervised memory generation method to get rid of dependence on event annotations. next, at the focusing stage, these event memories act as a bridge to establish the correlation between the questions with high-level event concepts and low-level lengthy video content. given the question, the model first focuses on the generated key event memory, then focuses on the most relevant moment for reasoning through our designed multi-level cross-attention mechanism. we conduct extensive experiments on four multi-event videoqa benchmarks including star, egotaskqa, agqa, and next-qa. our proposed model achieves state-of-the-art results, surpassing current large models in various challenging reasoning tasks. the code and models are available at https:\/\/github.com\/byz0e\/glance-focus.","doi":"","created":1704153600000,"updated":"","authors":["ziyi bai","ruiping wang","xilin chen"]}
{"id":"2401.01531","title":"will 6g be semantic communications? opportunities and challenges from   task oriented and secure communications to integrated sensing","categories":"cs.ni cs.cr cs.it cs.lg eess.sp math.it","abstract":"this paper explores opportunities and challenges of task (goal)-oriented and semantic communications for next-generation (nextg) communication networks through the integration of multi-task learning. this approach employs deep neural networks representing a dedicated encoder at the transmitter and multiple task-specific decoders at the receiver, collectively trained to handle diverse tasks including semantic information preservation, source input reconstruction, and integrated sensing and communications. to extend the applicability from point-to-point links to multi-receiver settings, we envision the deployment of decoders at various receivers, where decentralized learning addresses the challenges of communication load and privacy concerns, leveraging federated learning techniques that distribute model updates across decentralized nodes. however, the efficacy of this approach is contingent on the robustness of the employed deep learning models. we scrutinize potential vulnerabilities stemming from adversarial attacks during both training and testing phases. these attacks aim to manipulate both the inputs at the encoder at the transmitter and the signals received over the air on the receiver side, highlighting the importance of fortifying semantic communications against potential multi-domain exploits. overall, the joint and robust design of task-oriented communications, semantic communications, and integrated sensing and communications in a multi-task learning framework emerges as the key enabler for context-aware, resource-efficient, and secure communications ultimately needed in nextg network systems.","doi":"","created":1704153600000,"updated":"","authors":["yalin e. sagduyu","tugba erpek","aylin yener","sennur ulukus"]}
{"id":"2401.01537","title":"the art of deception: robust backdoor attack using dynamic stacking of   triggers","categories":"cs.cr cs.ai cs.lg","abstract":"the area of machine learning as a service (mlaas) is experiencing increased implementation due to recent advancements in the ai (artificial intelligence) industry. however, this spike has prompted concerns regarding ai defense mechanisms, specifically regarding potential covert attacks from third-party providers that cannot be entirely trusted. recent research has uncovered that auditory backdoors may use certain modifications as their initiating mechanism. dynamictrigger is introduced as a methodology for carrying out dynamic backdoor attacks that use cleverly designed tweaks to ensure that corrupted samples are indistinguishable from clean. by utilizing fluctuating signal sampling rates and masking speaker identities through dynamic sound triggers (such as the clapping of hands), it is possible to deceive speech recognition systems (asr). our empirical testing demonstrates that dynamictrigger is both potent and stealthy, achieving impressive success rates during covert attacks while maintaining exceptional accuracy with non-poisoned datasets.","doi":"","created":1704153600000,"updated":"2024-06-04","authors":["orson mengara"]}
{"id":"2401.01539","title":"ddpm based x-ray image synthesizer","categories":"eess.iv cs.cv","abstract":"access to high-quality datasets in the medical industry limits machine learning model performance. to address this issue, we propose a denoising diffusion probabilistic model (ddpm) combined with a unet architecture for x-ray image synthesis. focused on pneumonia medical condition, our methodology employs over 3000 pneumonia x-ray images obtained from kaggle for training. results demonstrate the effectiveness of our approach, as the model successfully generated realistic images with low mean squared error (mse). the synthesized images showed distinct differences from non-pneumonia images, highlighting the model's ability to capture key features of positive cases. beyond pneumonia, the applications of this synthesizer extend to various medical conditions, provided an ample dataset is available. the capability to produce high-quality images can potentially enhance machine learning models' performance, aiding in more accurate and efficient medical diagnoses. this innovative ddpm-based x-ray photo synthesizer presents a promising avenue for addressing the scarcity of positive medical image datasets, paving the way for improved medical image analysis and diagnosis in the healthcare industry.","doi":"","created":1704153600000,"updated":"","authors":["praveen mahaulpatha","thulana abeywardane","tomson george"]}
{"id":"2401.01542","title":"adversarial machine learning-enabled anonymization of openwifi data","categories":"cs.ni cs.ai","abstract":"data privacy and protection through anonymization is a critical issue for network operators or data owners before it is forwarded for other possible use of data. with the adoption of artificial intelligence (ai), data anonymization augments the likelihood of covering up necessary sensitive information; preventing data leakage and information loss. openwifi networks are vulnerable to any adversary who is trying to gain access or knowledge on traffic regardless of the knowledge possessed by data owners. the odds for discovery of actual traffic information is addressed by applied conditional tabular generative adversarial network (ctgan). ctgan yields synthetic data; which disguises as actual data but fostering hidden acute information of actual data. in this paper, the similarity assessment of synthetic with actual data is showcased in terms of clustering algorithms followed by a comparison of performance for unsupervised cluster validation metrics. a well-known algorithm, k-means outperforms other algorithms in terms of similarity assessment of synthetic data over real data while achieving nearest scores 0.634, 23714.57, and 0.598 as silhouette, calinski and harabasz and davies bouldin metric respectively. on exploiting a comparative analysis in validation scores among several algorithms, k-means forms the epitome of unsupervised clustering algorithms ensuring explicit usage of synthetic data at the same time a replacement for real data. hence, the experimental results aim to show the viability of using ctgan-generated synthetic data in lieu of publishing anonymized data to be utilized in various applications.","doi":"10.13052\/2794-7254.005","created":1704153600000,"updated":"","authors":["samhita kuili","kareem dabbour","irtiza hasan","andrea herscovich","burak kantarci","marcel chenier","melike erol-kantarci"]}
{"id":"2401.01543","title":"retraining-free model quantization via one-shot weight-coupling learning","categories":"cs.cv","abstract":"quantization is of significance for compressing the over-parameterized deep neural models and deploying them on resource-limited devices. fixed-precision quantization suffers from performance drop due to the limited numerical representation ability. conversely, mixed-precision quantization (mpq) is advocated to compress the model effectively by allocating heterogeneous bit-width for layers. mpq is typically organized into a searching-retraining two-stage process. in this paper, we devise a one-shot training-searching paradigm for mixed-precision model compression. specifically, in the first stage, all potential bit-width configurations are coupled and thus optimized simultaneously within a set of shared weights. however, our observations reveal a previously unseen and severe bit-width interference phenomenon among highly coupled weights during optimization, leading to considerable performance degradation under a high compression ratio. to tackle this problem, we first design a bit-width scheduler to dynamically freeze the most turbulent bit-width of layers during training, to ensure the rest bit-widths converged properly. then, taking inspiration from information theory, we present an information distortion mitigation technique to align the behavior of the bad-performing bit-widths to the well-performing ones. in the second stage, an inference-only greedy search scheme is devised to evaluate the goodness of configurations without introducing any additional training costs. extensive experiments on three representative models and three datasets demonstrate the effectiveness of the proposed method. code can be available on \\href{https:\/\/www.github.com\/1hunters\/retraining-free-quantization}{https:\/\/github.com\/1hunters\/retraining-free-quantization}.","doi":"","created":1704240000000,"updated":"2024-06-14","authors":["chen tang","yuan meng","jiacheng jiang","shuzhao xie","rongwei lu","xinzhu ma","zhi wang","wenwu zhu"]}
{"id":"2401.01544","title":"collaborative perception for connected and autonomous driving:   challenges, possible solutions and opportunities","categories":"cs.cv eess.sp","abstract":"autonomous driving has attracted significant attention from both academia and industries, which is expected to offer a safer and more efficient driving system. however, current autonomous driving systems are mostly based on a single vehicle, which has significant limitations which still poses threats to driving safety. collaborative perception with connected and autonomous vehicles (cavs) shows a promising solution to overcoming these limitations. in this article, we first identify the challenges of collaborative perception, such as data sharing asynchrony, data volume, and pose errors. then, we discuss the possible solutions to address these challenges with various technologies, where the research opportunities are also elaborated. furthermore, we propose a scheme to deal with communication efficiency and latency problems, which is a channel-aware collaborative perception framework to dynamically adjust the communication graph and minimize latency, thereby improving perception performance while increasing communication efficiency. finally, we conduct experiments to demonstrate the effectiveness of our proposed scheme.","doi":"","created":1704240000000,"updated":"","authors":["senkang hu","zhengru fang","yiqin deng","xianhao chen","yuguang fang"]}
{"id":"2401.01545","title":"ddn-slam: real-time dense dynamic neural implicit slam","categories":"cs.cv cs.ro","abstract":"slam systems based on nerf have demonstrated superior performance in rendering quality and scene reconstruction for static environments compared to traditional dense slam. however, they encounter tracking drift and mapping errors in real-world scenarios with dynamic interferences. to address these issues, we introduce ddn-slam, the first real-time dense dynamic neural implicit slam system integrating semantic features. to address dynamic tracking interferences, we propose a feature point segmentation method that combines semantic features with a mixed gaussian distribution model. to avoid incorrect background removal, we propose a mapping strategy based on sparse point cloud sampling and background restoration. we propose a dynamic semantic loss to eliminate dynamic occlusions. experimental results demonstrate that ddn-slam is capable of robustly tracking and producing high-quality reconstructions in dynamic environments, while appropriately preserving potential dynamic objects. compared to existing neural implicit slam systems, the tracking results on dynamic datasets indicate an average 90% improvement in average trajectory error (ate) accuracy.","doi":"","created":1704240000000,"updated":"2024-03-08","authors":["mingrui li","yiming zhou","guangan jiang","tianchen deng","yangyang wang","hongyu wang"]}
{"id":"2401.01548","title":"boosting of implicit neural representation-based image denoiser","categories":"cs.cv","abstract":"implicit neural representation (inr) has emerged as an effective method for unsupervised image denoising. however, inr models are typically overparameterized; consequently, these models are prone to overfitting during learning, resulting in suboptimal results, even noisy ones. to tackle this problem, we propose a general recipe for regularizing inr models in image denoising. in detail, we propose to iteratively substitute the supervision signal with the mean value derived from both the prediction and supervision signal during the learning process. we theoretically prove that such a simple iterative substitute can gradually enhance the signal-to-noise ratio of the supervision signal, thereby benefiting inr models during the learning process. our experimental results demonstrate that inr models can be effectively regularized by the proposed approach, relieving overfitting and boosting image denoising performance.","doi":"","created":1704240000000,"updated":"","authors":["zipei yan","zhengji liu","jizhou li"]}
{"id":"2401.01549","title":"towards modeling uncertainties of self-explaining neural networks via   conformal prediction","categories":"cs.lg","abstract":"despite the recent progress in deep neural networks (dnns), it remains challenging to explain the predictions made by dnns. existing explanation methods for dnns mainly focus on post-hoc explanations where another explanatory model is employed to provide explanations. the fact that post-hoc methods can fail to reveal the actual original reasoning process of dnns raises the need to build dnns with built-in interpretability. motivated by this, many self-explaining neural networks have been proposed to generate not only accurate predictions but also clear and intuitive insights into why a particular decision was made. however, existing self-explaining networks are limited in providing distribution-free uncertainty quantification for the two simultaneously generated prediction outcomes (i.e., a sample's final prediction and its corresponding explanations for interpreting that prediction). importantly, they also fail to establish a connection between the confidence values assigned to the generated explanations in the interpretation layer and those allocated to the final predictions in the ultimate prediction layer. to tackle the aforementioned challenges, in this paper, we design a novel uncertainty modeling framework for self-explaining networks, which not only demonstrates strong distribution-free uncertainty modeling performance for the generated explanations in the interpretation layer but also excels in producing efficient and effective prediction sets for the final predictions based on the informative high-level basis explanations. we perform the theoretical analysis for the proposed framework. extensive experimental evaluation demonstrates the effectiveness of the proposed uncertainty framework.","doi":"","created":1704240000000,"updated":"","authors":["wei qian","chenxu zhao","yangyi li","fenglong ma","chao zhang","mengdi huai"]}
{"id":"2401.01550","title":"atomic cluster expansion without self-interaction","categories":"math.na cs.na physics.comp-ph","abstract":"the atomic cluster expansion (ace) (drautz, phys. rev. b 99, 2019) has been widely applied in high energy physics, quantum mechanics and atomistic modeling to construct many-body interaction models respecting physical symmetries. computational efficiency is achieved by allowing non-physical self-interaction terms in the model. we propose and analyze an efficient method to evaluate and parameterize an orthogonal, or, non-self-interacting cluster expansion model. we present numerical experiments demonstrating improved conditioning and more robust approximation properties than the original expansion in regression tasks both in simplified toy problems and in applications in the machine learning of interatomic potentials.","doi":"","created":1704240000000,"updated":"2024-01-04","authors":["cheuk hin ho","timon s. gutleb","christoph ortner"]}
{"id":"2401.01552","title":"cra-pcn: point cloud completion with intra- and inter-level   cross-resolution transformers","categories":"cs.cv","abstract":"point cloud completion is an indispensable task for recovering complete point clouds due to incompleteness caused by occlusion, limited sensor resolution, etc. the family of coarse-to-fine generation architectures has recently exhibited great success in point cloud completion and gradually became mainstream. in this work, we unveil one of the key ingredients behind these methods: meticulously devised feature extraction operations with explicit cross-resolution aggregation. we present cross-resolution transformer that efficiently performs cross-resolution aggregation with local attention mechanisms. with the help of our recursive designs, the proposed operation can capture more scales of features than common aggregation operations, which is beneficial for capturing fine geometric characteristics. while prior methodologies have ventured into various manifestations of inter-level cross-resolution aggregation, the effectiveness of intra-level one and their combination has not been analyzed. with unified designs, cross-resolution transformer can perform intra- or inter-level cross-resolution aggregation by switching inputs. we integrate two forms of cross-resolution transformers into one up-sampling block for point generation, and following the coarse-to-fine manner, we construct cra-pcn to incrementally predict complete shapes with stacked up-sampling blocks. extensive experiments demonstrate that our method outperforms state-of-the-art methods by a large margin on several widely used benchmarks. codes are available at https:\/\/github.com\/easyry\/cra-pcn.","doi":"10.1609\/aaai.v38i5.28268","created":1704240000000,"updated":"2024-02-14","authors":["yi rong","haoran zhou","lixin yuan","cheng mei","jiahao wang","tong lu"]}
{"id":"2401.01553","title":"multi-modal learning with missing modality in predicting axillary lymph   node metastasis","categories":"eess.iv cs.cv","abstract":"multi-modal learning has attracted widespread attention in medical image analysis. using multi-modal data, whole slide images (wsis) and clinical information, can improve the performance of deep learning models in the diagnosis of axillary lymph node metastasis. however, clinical information is not easy to collect in clinical practice due to privacy concerns, limited resources, lack of interoperability, etc. although patient selection can ensure the training set to have multi-modal data for model development, missing modality of clinical information can appear during test. this normally leads to performance degradation, which limits the use of multi-modal models in the clinic. to alleviate this problem, we propose a bidirectional distillation framework consisting of a multi-modal branch and a single-modal branch. the single-modal branch acquires the complete multi-modal knowledge from the multi-modal branch, while the multi-modal learns the robust features of wsi from the single-modal. we conduct experiments on a public dataset of lymph node metastasis in early breast cancer to validate the method. our approach not only achieves state-of-the-art performance with an auc of 0.861 on the test set without missing data, but also yields an auc of 0.842 when the rate of missing modality is 80\\%. this shows the effectiveness of the approach in dealing with multi-modal data and missing modality. such a model has the potential to improve treatment decision-making for early breast cancer patients who have axillary lymph node metastatic status.","doi":"","created":1704240000000,"updated":"","authors":["shichuan zhang","sunyi zheng","zhongyi shui","honglin li","lin yang"]}
{"id":"2401.01554","title":"randomized searchrank: a semiclassical approach to a quantum search   engine","categories":"quant-ph cs.ni","abstract":"the quantum searchrank algorithm is a promising tool for a future quantum search engine based on pagerank quantization. however, this algorithm loses its functionality when the $n\/m$ ratio between the network size $n$ and the number of marked nodes $m$ is sufficiently large. we propose a modification of the algorithm, replacing the underlying szegedy quantum walk with a semiclassical walk. to maintain the same time complexity as the quantum searchrank algorithm we propose a simplification of the algorithm. this new algorithm is called randomized searchrank, since it corresponds to a quantum walk over a randomized mixed state. the performance of the searchrank algorithms is first analyzed on an example network, and then statistically on a set of different networks of increasing size and different number of marked nodes. on the one hand, to test the search ability of the algorithms, it is computed how the probability of measuring the marked nodes decreases with $n\/m$ for the quantum searchrank, but remarkably it remains at a high value around $0.9$ for our semiclassical algorithms, solving the quantum searchrank problem. the time complexity of the algorithms is also analyzed, obtaining a quadratic speedup with respect to the classical ones. on the other hand, the ranking functionality of the algorithms has been investigated, obtaining a good agreement with the classical pagerank distribution. finally, the dependence of these algorithms on the intrinsic pagerank damping parameter has been clarified. our results suggest that this parameter should be below a threshold so that the execution time does not increase drastically.","doi":"","created":1704240000000,"updated":"","authors":["sergio a. ortega","miguel a. martin-delgado"]}
{"id":"2401.01558","title":"one-step late fusion multi-view clustering with compressed subspace","categories":"cs.cv","abstract":"late fusion multi-view clustering (lfmvc) has become a rapidly growing class of methods in the multi-view clustering (mvc) field, owing to its excellent computational speed and clustering performance. one bottleneck faced by existing late fusion methods is that they are usually aligned to the average kernel function, which makes the clustering performance highly dependent on the quality of datasets. another problem is that they require subsequent k-means clustering after obtaining the consensus partition matrix to get the final discrete labels, and the resulting separation of the label learning and cluster structure optimization processes limits the integrity of these models. to address the above issues, we propose an integrated framework named one-step late fusion multi-view clustering with compressed subspace (os-lfmvc-cs). specifically, we use the consensus subspace to align the partition matrix while optimizing the partition fusion, and utilize the fused partition matrix to guide the learning of discrete labels. a six-step iterative optimization approach with verified convergence is proposed. sufficient experiments on multiple datasets validate the effectiveness and efficiency of our proposed method.","doi":"","created":1704240000000,"updated":"2024-05-28","authors":["qiyuan ou","pei zhang","sihang zhou","en zhu"]}
{"id":"2401.01563","title":"towards multi-objective high-dimensional feature selection via   evolutionary multitasking","categories":"cs.ne","abstract":"evolutionary multitasking (emt) paradigm, an emerging research topic in evolutionary computation, has been successfully applied in solving high-dimensional feature selection (fs) problems recently. however, existing emt-based fs methods suffer from several limitations, such as a single mode of multitask generation, conducting the same generic evolutionary search for all tasks, relying on implicit transfer mechanisms through sole solution encodings, and employing single-objective transformation, which result in inadequate knowledge acquisition, exploitation, and transfer. to this end, this paper develops a novel emt framework for multiobjective high-dimensional feature selection problems, namely mo-fsemt. in particular, multiple auxiliary tasks are constructed by distinct formulation methods to provide diverse search spaces and information representations and then simultaneously addressed with the original task through a multi-slover-based multitask optimization scheme. each task has an independent population with task-specific representations and is solved using separate evolutionary solvers with different biases and search preferences. a task-specific knowledge transfer mechanism is designed to leverage the advantage information of each task, enabling the discovery and effective transmission of high-quality solutions during the search process. comprehensive experimental results demonstrate that our mo-fsemt framework can achieve overall superior performance compared to the state-of-the-art fs methods on 26 datasets. moreover, the ablation studies verify the contributions of different components of the proposed mo-fsemt.","doi":"","created":1704240000000,"updated":"","authors":["yinglan feng","liang feng","songbai liu","sam kwong","kay chen tan"]}
{"id":"2401.01564","title":"deep learning based superposition coded modulation for hierarchical   semantic communications over broadcast channels","categories":"cs.it eess.sp math.it","abstract":"we consider multi-user semantic communications over broadcast channels. while most existing works consider that each receiver requires either the same or independent semantic information, this paper explores the scenario where the semantic information desired by different receivers is different but correlated. in particular, we investigate semantic communications over gaussian broadcast channels where the transmitter has a common observable source but the receivers wish to recover hierarchical semantic information in adaptation to their channel conditions. inspired by the capacity achieving property of superposition codes, we propose a deep learning based superposition coded modulation (deepscm) scheme. specifically, the hierarchical semantic information is first extracted and encoded into basic and enhanced feature vectors. a linear minimum mean square error (lmmse) decorrelator is then developed to obtain a refinement from the enhanced features that is uncorrelated with the basic features. finally, the basic features and their refinement are superposed for broadcasting after probabilistic modulation. experiments are conducted for two-receiver image semantic broadcasting with coarse and fine classification as hierarchical semantic tasks. deepscm outperforms the benchmarking coded-modulation scheme without a superposition structure, especially with large channel disparity and high order modulation. it also approaches the performance upperbound as if there were only one receiver.","doi":"","created":1704240000000,"updated":"2024-06-12","authors":["yufei bo","shuo shao","meixia tao"]}
{"id":"2401.01566","title":"team ielab at trec clinical trial track 2023: enhancing clinical trial   retrieval with neural rankers and large language models","categories":"cs.ir","abstract":"we describe team ielab from csiro and the university of queensland's approach to the 2023 trec clinical trials track. our approach was to use neural rankers but to utilise large language models to overcome the issue of lack of training data for such rankers. specifically, we employ chatgpt to generate relevant patient descriptions for randomly selected clinical trials from the corpus. this synthetic dataset, combined with human-annotated training data from previous years, is used to train both dense and sparse retrievers based on pubmedbert. additionally, a cross-encoder re-ranker is integrated into the system. to further enhance the effectiveness of our approach, we prompting gpt-4 as a trec annotator to provide judgments on our run files. these judgments are subsequently employed to re-rank the results. this architecture tightly integrates strong pubmedbert-based rankers with the aid of sota large language models, demonstrating a new approach to clinical trial retrieval.","doi":"","created":1704240000000,"updated":"","authors":["shengyao zhuang","bevan koopman","guido zuccon"]}
{"id":"2401.01568","title":"a survey of protocol fuzzing","categories":"cs.cr cs.ni","abstract":"communication protocols form the bedrock of our interconnected world, yet vulnerabilities within their implementations pose significant security threats. recent developments have seen a surge in fuzzing-based research dedicated to uncovering these vulnerabilities within protocol implementations. however, there still lacks a systematic overview of protocol fuzzing for answering the essential questions such as what the unique challenges are, how existing works solve them, etc. to bridge this gap, we conducted a comprehensive investigation of related works from both academia and industry. our study includes a detailed summary of the specific challenges in protocol fuzzing, and provides a systematic categorization and overview of existing research efforts. furthermore, we explore and discuss potential future research directions in protocol fuzzing. this survey serves as a foundational guideline for researchers and practitioners in the field.","doi":"","created":1704240000000,"updated":"2024-01-03","authors":["xiaohan zhang","cen zhang","xinghua li","zhengjie du","yuekang li","yaowen zheng","yeting li","bing mao","yang liu","robert h. deng"]}
{"id":"2401.01569","title":"attentionlut: attention fusion-based canonical polyadic lut for   real-time image enhancement","categories":"cs.cv","abstract":"recently, many algorithms have employed image-adaptive lookup tables (luts) to achieve real-time image enhancement. nonetheless, a prevailing trend among existing methods has been the employment of linear combinations of basic luts to formulate image-adaptive luts, which limits the generalization ability of these methods. to address this limitation, we propose a novel framework named attentionlut for real-time image enhancement, which utilizes the attention mechanism to generate image-adaptive luts. our proposed framework consists of three lightweight modules. we begin by employing the global image context feature module to extract image-adaptive features. subsequently, the attention fusion module integrates the image feature with the priori attention feature obtained during training to generate image-adaptive canonical polyadic tensors. finally, the canonical polyadic reconstruction module is deployed to reconstruct image-adaptive residual 3dlut, which is subsequently utilized for enhancing input images. experiments on the benchmark mit-adobe fivek dataset demonstrate that the proposed method achieves better enhancement performance quantitatively and qualitatively than the state-of-the-art methods.","doi":"","created":1704240000000,"updated":"","authors":["kang fu","yicong peng","zicheng zhang","qihang xu","xiaohong liu","jia wang","guangtao zhai"]}
{"id":"2401.01571","title":"codefuse-query: a data-centric static code analysis system for   large-scale organizations","categories":"cs.se cs.pl","abstract":"in the domain of large-scale software development, the demands for dynamic and multifaceted static code analysis exceed the capabilities of traditional tools. to bridge this gap, we present codefuse-query, a system that redefines static code analysis through the fusion of domain optimized system design and logic oriented computation design.   codefuse-query reimagines code analysis as a data computation task, support scanning over 10 billion lines of code daily and more than 300 different tasks. it optimizes resource utilization, prioritizes data reusability, applies incremental code extraction, and introduces tasks types specially for code change, underscoring its domain-optimized design. the system's logic-oriented facet employs datalog, utilizing a unique two-tiered schema, coref, to convert source code into data facts. through godel, a distinctive language, codefuse-query enables formulation of complex tasks as logical expressions, harnessing datalog's declarative prowess.   this paper provides empirical evidence of codefuse-query's transformative approach, demonstrating its robustness, scalability, and efficiency. we also highlight its real-world impact and diverse applications, emphasizing its potential to reshape the landscape of static code analysis in the context of large-scale software development.furthermore, in the spirit of collaboration and advancing the field, our project is open-sourced and the repository is available for public access","doi":"","created":1704240000000,"updated":"","authors":["xiaoheng xie","gang fan","xiaojun lin","ang zhou","shijie li","xunjin zheng","yinan liang","yu zhang","na yu","haokun li","xinyu chen","yingzhuang chen","yi zhen","dejun dong","xianjin fu","jinzhou su","fuxiong pan","pengshuai luo","youzheng feng","ruoxiang hu","jing fan","jinguo zhou","xiao xiao","peng di"]}
{"id":"2401.01572","title":"hallucinations in neural automatic speech recognition: identifying   errors and hallucinatory models","categories":"cs.cl cs.sd eess.as","abstract":"hallucinations are a type of output error produced by deep neural networks. while this has been studied in natural language processing, they have not been researched previously in automatic speech recognition. here, we define hallucinations in asr as transcriptions generated by a model that are semantically unrelated to the source utterance, yet still fluent and coherent. the similarity of hallucinations to probable natural language outputs of the model creates a danger of deception and impacts the credibility of the system. we show that commonly used metrics, such as word error rates, cannot differentiate between hallucinatory and non-hallucinatory models. to address this, we propose a perturbation-based method for assessing the susceptibility of an automatic speech recognition (asr) model to hallucination at test time, which does not require access to the training dataset. we demonstrate that this method helps to distinguish between hallucinatory and non-hallucinatory models that have similar baseline word error rates. we further explore the relationship between the types of asr errors and the types of dataset noise to determine what types of noise are most likely to create hallucinatory outputs. we devise a framework for identifying hallucinations by analysing their semantic connection with the ground truth and their fluency. finally, we discover how to induce hallucinations with a random noise injection to the utterance.","doi":"","created":1704240000000,"updated":"","authors":["rita frieske","bertram e. shi"]}
{"id":"2401.01573","title":"view distribution alignment with progressive adversarial learning for   uav visual geo-localization","categories":"cs.cv","abstract":"unmanned aerial vehicle (uav) visual geo-localization aims to match images of the same geographic target captured from different views, i.e., the uav view and the satellite view. it is very challenging due to the large appearance differences in uav-satellite image pairs. previous works map images captured by uavs and satellites to a shared feature space and employ a classification framework to learn location-dependent features while neglecting the overall distribution shift between the uav view and the satellite view. in this paper, we address these limitations by introducing distribution alignment of the two views to shorten their distance in a common space. specifically, we propose an end-to-end network, called pvda (progressive view distribution alignment). during training, feature encoder, location classifier, and view discriminator are jointly optimized by a novel progressive adversarial learning strategy. competition between feature encoder and view discriminator prompts both of them to be stronger. it turns out that the adversarial learning is progressively emphasized until uav-view images are indistinguishable from satellite-view images. as a result, the proposed pvda becomes powerful in learning location-dependent yet view-invariant features with good scalability towards unseen images of new locations. compared to the state-of-the-art methods, the proposed pvda requires less inference time but has achieved superior performance on the university-1652 dataset.","doi":"","created":1704240000000,"updated":"","authors":["cuiwei liu","jiahao liu","huaijun qiu","zhaokui li","xiangbin shi"]}
{"id":"2401.01574","title":"a transformer-based adaptive semantic aggregation method for uav visual   geo-localization","categories":"cs.cv","abstract":"this paper addresses the task of unmanned aerial vehicles (uav) visual geo-localization, which aims to match images of the same geographic target taken by different platforms, i.e., uavs and satellites. in general, the key to achieving accurate uav-satellite image matching lies in extracting visual features that are robust against viewpoint changes, scale variations, and rotations. current works have shown that part matching is crucial for uav visual geo-localization since part-level representations can capture image details and help to understand the semantic information of scenes. however, the importance of preserving semantic characteristics in part-level representations is not well discussed. in this paper, we introduce a transformer-based adaptive semantic aggregation method that regards parts as the most representative semantics in an image. correlations of image patches to different parts are learned in terms of the transformer's feature map. then our method decomposes part-level features into an adaptive sum of all patch features. by doing this, the learned parts are encouraged to focus on patches with typical semantics. extensive experiments on the university-1652 dataset have shown the superiority of our method over the current works.","doi":"","created":1704240000000,"updated":"","authors":["shishen li","cuiwei liu","huaijun qiu","zhaokui li"]}
{"id":"2401.01575","title":"enhancing generalization of invisible facial privacy cloak via gradient   accumulation","categories":"cs.cv","abstract":"the blooming of social media and face recognition (fr) systems has increased people's concern about privacy and security. a new type of adversarial privacy cloak (class-universal) can be applied to all the images of regular users, to prevent malicious fr systems from acquiring their identity information. in this work, we discover the optimization dilemma in the existing methods -- the local optima problem in large-batch optimization and the gradient information elimination problem in small-batch optimization. to solve these problems, we propose gradient accumulation (ga) to aggregate multiple small-batch gradients into a one-step iterative gradient to enhance the gradient stability and reduce the usage of quantization operations. experiments show that our proposed method achieves high performance on the privacy-commons dataset against black-box face recognition models.","doi":"","created":1704240000000,"updated":"","authors":["xuannan liu","yaoyao zhong","weihong deng","hongzhi shi","xingchen cui","yunfeng yin","dongchao wen"]}
{"id":"2401.01577","title":"test-time personalization with meta prompt for gaze estimation","categories":"cs.cv","abstract":"despite the recent remarkable achievement in gaze estimation, efficient and accurate personalization of gaze estimation without labels is a practical problem but rarely touched on in the literature. to achieve efficient personalization, we take inspiration from the recent advances in natural language processing (nlp) by updating a negligible number of parameters, \"prompts\", at the test time. specifically, the prompt is additionally attached without perturbing original network and can contain less than 1% of a resnet-18's parameters. our experiments show high efficiency of the prompt tuning approach. the proposed one can be 10 times faster in terms of adaptation speed than the methods compared. however, it is non-trivial to update the prompt for personalized gaze estimation without labels. at the test time, it is essential to ensure that the minimizing of particular unsupervised loss leads to the goals of minimizing gaze estimation error. to address this difficulty, we propose to meta-learn the prompt to ensure that its updates align with the goal. our experiments show that the meta-learned prompt can be effectively adapted even with a simple symmetry loss. in addition, we experiment on four cross-dataset validations to show the remarkable advantages of the proposed method. code is available at https:\/\/github.com\/hmarkamcan\/tpgaze.","doi":"","created":1704240000000,"updated":"2024-03-12","authors":["huan liu","julia qi","zhenhao li","mohammad hassanpour","yang wang","konstantinos plataniotis","yuanhao yu"]}
{"id":"2401.01578","title":"context-guided spatio-temporal video grounding","categories":"cs.cv","abstract":"spatio-temporal video grounding (or stvg) task aims at locating a spatio-temporal tube for a specific instance given a text query. despite advancements, current methods easily suffer the distractors or heavy object appearance variations in videos due to insufficient object information from the text, leading to degradation. addressing this, we propose a novel framework, context-guided stvg (cg-stvg), which mines discriminative instance context for object in videos and applies it as a supplementary guidance for target localization. the key of cg-stvg lies in two specially designed modules, including instance context generation (icg), which focuses on discovering visual context information (in both appearance and motion) of the instance, and instance context refinement (icr), which aims to improve the instance context from icg by eliminating irrelevant or even harmful information from the context. during grounding, icg, together with icr, are deployed at each decoding stage of a transformer architecture for instance context learning. particularly, instance context learned from one decoding stage is fed to the next stage, and leveraged as a guidance containing rich and discriminative object feature to enhance the target-awareness in decoding feature, which conversely benefits generating better new instance context for improving localization finally. compared to existing methods, cg-stvg enjoys object information in text query and guidance from mined instance visual context for more accurate target localization. in our experiments on three benchmarks, including hcstvg-v1\/-v2 and vidstg, cg-stvg sets new state-of-the-arts in m_tiou and m_viou on all of them, showing its efficacy. the code will be released at https:\/\/github.com\/henglan\/cgstvg.","doi":"","created":1704240000000,"updated":"","authors":["xin gu","heng fan","yan huang","tiejian luo","libo zhang"]}
{"id":"2401.01579","title":"an invariant information geometric method for high-dimensional online   optimization","categories":"cs.lg cs.ne","abstract":"sample efficiency is crucial in optimization, particularly in black-box scenarios characterized by expensive evaluations and zeroth-order feedback. when computing resources are plentiful, bayesian optimization is often favored over evolution strategies. in this paper, we introduce a full invariance oriented evolution strategies algorithm, derived from its corresponding framework, that effectively rivals the leading bayesian optimization method in tasks with dimensions at the upper limit of bayesian capability. specifically, we first build the framework invigo that fully incorporates historical information while retaining the full invariant and computational complexity. we then exemplify invigo on multi-dimensional gaussian, which gives an invariant and scalable optimizer syncma . the theoretical behavior and advantages of our algorithm over other gaussian-based evolution strategies are further analyzed. finally, we benchmark syncma against leading algorithms in bayesian optimization and evolution strategies on various high dimension tasks, in cluding mujoco locomotion tasks, rover planning task and synthetic functions. in all scenarios, syncma demonstrates great competence, if not dominance, over other algorithms in sample efficiency, showing the underdeveloped potential of property oriented evolution strategies.","doi":"","created":1704240000000,"updated":"","authors":["zhengfei zhang","yunyue wei","yanan sui"]}
{"id":"2401.01583","title":"enhancing representation in medical vision-language foundation models   via multi-scale information extraction techniques","categories":"cs.cv","abstract":"the development of medical vision-language foundation models has attracted significant attention in the field of medicine and healthcare due to their promising prospect in various clinical applications. while previous studies have commonly focused on feature learning at a single learning scale, investigation on integrating multi-scale information is lacking, which may hinder the potential for mutual reinforcement among these features. this paper aims to bridge this gap by proposing a method that effectively exploits multi-scale information to enhance the performance of medical foundation models. the proposed method simultaneously exploits features at the local, instance, modality and global aspects, facilitating comprehensive representation learning within the models. we evaluate the effectiveness of the proposed method on six open-source datasets across different clinical tasks, demonstrating its ability to enhance the performance of medical foundation models.","doi":"","created":1704240000000,"updated":"2024-02-26","authors":["weijian huang","cheng li","hong-yu zhou","jiarun liu","hao yang","yong liang","guangming shi","hairong zheng","shanshan wang"]}
{"id":"2401.01586","title":"time stepping adaptation for subdiffusion problems with non-smooth   right-hand sides","categories":"math.na cs.na","abstract":"we consider a time-fractional subdiffusion equation with a caputo derivative in time, a general second-order elliptic spatial operator, and a right-hand side that is non-smooth in time. the presence of the latter may lead to locking problems in our time stepping procedure recently introduced in [2,4]. hence, a generalized version of the residual barrier is proposed to rectify the issue. we also consider related alternatives to this generalized algorithm, and, furthermore, show that this new residual barrier may be useful in the case of a negative reaction coefficient.","doi":"","created":1704240000000,"updated":"","authors":["sebastian franz","natalia kopteva"]}
{"id":"2401.01587","title":"real-time human fall detection using a lightweight pose estimation   technique","categories":"cs.cv","abstract":"the elderly population is increasing rapidly around the world. there are no enough caretakers for them. use of ai-based in-home medical care systems is gaining momentum due to this. human fall detection is one of the most important tasks of medical care system for the aged people. human fall is a common problem among elderly people. detection of a fall and providing medical help as early as possible is very important to reduce any further complexity. the chances of death and other medical complications can be reduced by detecting and providing medical help as early as possible after the fall. there are many state-of-the-art fall detection techniques available these days, but the majority of them need very high computing power. in this paper, we proposed a lightweight and fast human fall detection system using pose estimation. we used `movenet' for human joins key-points extraction. our proposed method can work in real-time on any low-computing device with any basic camera. all computation can be processed locally, so there is no problem of privacy of the subject. we used two datasets `gmdcsa' and `urfd' for the experiment. we got the sensitivity value of 0.9375 and 0.9167 for the dataset `gmdcsa' and `urfd' respectively. the source code and the dataset gmdcsa of our work are available online to access.","doi":"10.1007\/978-3-031-48879-5","created":1704240000000,"updated":"","authors":["ekram alam","abu sufian","paramartha dutta","marco leo"]}
{"id":"2401.01589","title":"the security and privacy of mobile edge computing: an artificial   intelligence perspective","categories":"cs.cr","abstract":"mobile edge computing (mec) is a new computing paradigm that enables cloud computing and information technology (it) services to be delivered at the network's edge. by shifting the load of cloud computing to individual local servers, mec helps meet the requirements of ultralow latency, localized data processing, and extends the potential of internet of things (iot) for end-users. however, the crosscutting nature of mec and the multidisciplinary components necessary for its deployment have presented additional security and privacy concerns. fortunately, artificial intelligence (ai) algorithms can cope with excessively unpredictable and complex data, which offers a distinct advantage in dealing with sophisticated and developing adversaries in the security industry. hence, in this paper we comprehensively provide a survey of security and privacy in mec from the perspective of ai. on the one hand, we use european telecommunications standards institute (etsi) mec reference architecture as our based framework while merging the software defined network (sdn) and network function virtualization (nfv) to better illustrate a serviceable platform of mec. on the other hand, we focus on new security and privacy issues, as well as potential solutions from the viewpoints of ai. finally, we comprehensively discuss the opportunities and challenges associated with applying ai to mec security and privacy as possible future research directions.","doi":"","created":1704240000000,"updated":"","authors":["cheng wang","zenghui yuan","pan zhou","zichuan xu","ruixuan li","dapeng oliver wu"]}
{"id":"2401.01591","title":"mlip: medical language-image pre-training with masked local   representation learning","categories":"cs.cv","abstract":"existing contrastive language-image pre-training aims to learn a joint representation by matching abundant image-text pairs. however, the number of image-text pairs in medical datasets is usually orders of magnitude smaller than that in natural datasets. besides, medical image-text pairs often involve numerous complex fine-grained correspondences. this paper aims to enhance the data efficiency by introducing multiple-to-multiple local relationship modeling to capture denser supervisions. more specifically, we propose a medical language-image pre-training (mlip) framework, which exploits the limited image-text medical data more efficiently through patch-sentence matching. furthermore, we introduce a masked contrastive learning strategy with semantic integrity estimation to reduce redundancy in images while preserving the underlying semantics. our evaluation results show that mlip outperforms previous work in zero\/few-shot classification and few-shot segmentation tasks by a large margin.","doi":"","created":1704240000000,"updated":"","authors":["jiarun liu","hong-yu zhou","cheng li","weijian huang","hao yang","yong liang","shanshan wang"]}
{"id":"2401.01596","title":"medsumm: a multimodal approach to summarizing code-mixed hindi-english   clinical queries","categories":"cs.ai cs.cl","abstract":"in the healthcare domain, summarizing medical questions posed by patients is critical for improving doctor-patient interactions and medical decision-making. although medical data has grown in complexity and quantity, the current body of research in this domain has primarily concentrated on text-based methods, overlooking the integration of visual cues. also prior works in the area of medical question summarisation have been limited to the english language. this work introduces the task of multimodal medical question summarization for codemixed input in a low-resource setting. to address this gap, we introduce the multimodal medical codemixed question summarization mmcqs dataset, which combines hindi-english codemixed medical queries with visual aids. this integration enriches the representation of a patient's medical condition, providing a more comprehensive perspective. we also propose a framework named medsumm that leverages the power of llms and vlms for this task. by utilizing our mmcqs dataset, we demonstrate the value of integrating visual information from images to improve the creation of medically detailed summaries. this multimodal strategy not only improves healthcare decision-making but also promotes a deeper comprehension of patient queries, paving the way for future exploration in personalized and responsive medical care. our dataset, code, and pre-trained models will be made publicly available.","doi":"","created":1704240000000,"updated":"","authors":["akash ghosh","arkadeep acharya","prince jha","aniket gaudgaul","rajdeep majumdar","sriparna saha","aman chadha","raghav jain","setu sinha","shivani agarwal"]}
{"id":"2401.01597","title":"energy sharing among resources within electrical distribution systems: a   systematic review","categories":"eess.sy cs.sy","abstract":"the rapid increase in electric vehicle (ev) adoption provides a promising solution for reducing carbon emissions and fossil fuel dependency in transportation systems. however, the increasing numbers of evs pose significant challenges to the electrical grids. in addition, the number of distributed energy resources (der) and microgrids (mgs) is increasing on a global scale to meet the energy demand, consequently changing the energy infrastructure. recently, energy-sharing methods have been proposed to share excess energy from ders and evs in electric vehicle charging infrastructure (evci) and mgs. accommodating this sharing mechanism with the existing electrical distribution systems is a critical issue concerning the economic, reliability, and resilience aspects. this study examines the ever-changing field of evci and the critical role of peer-to-peer (p2p) energy trading in mitigating the problems with grid management that result from unorganized ev charging and intermittency in der. also, the possibility of energy sharing in electrical distribution systems for microgrids and evci on various energy-sharing methods and algorithms are discussed in detail. furthermore, the application of market clearing algorithms like game theory, double auction theory, blockchain technology, optimization techniques, machine learning algorithms, and other models from the existing literature are presented. this paper discusses the policies, economic benefits, environmental impacts, societal advantages, and challenges in distribution systems related to sharing in evci and mgs. a roadmap for future research and sharing strategies is provided to guide policymakers, researchers, and industry stakeholders toward a sustainable, resilient, and efficient energy market by integrating p2p technology into evcis and mgs.","doi":"","created":1704240000000,"updated":"","authors":["g hari krishna","k. victor sam moses babu","divyanshi dwivedi","pratyush chakraborty","pradeep kumar yemula","mayukha pal"]}
{"id":"2401.01598","title":"learning prompt with distribution-based feature replay for few-shot   class-incremental learning","categories":"cs.cv","abstract":"few-shot class-incremental learning (fscil) aims to continuously learn new classes based on very limited training data without forgetting the old ones encountered. existing studies solely relied on pure visual networks, while in this paper we solved fscil by leveraging the vision-language model (e.g., clip) and propose a simple yet effective framework, named learning prompt with distribution-based feature replay (lp-dif). we observe that simply using clip for zero-shot evaluation can substantially outperform the most influential methods. then, prompt tuning technique is involved to further improve its adaptation ability, allowing the model to continually capture specific knowledge from each session. to prevent the learnable prompt from forgetting old knowledge in the new session, we propose a pseudo-feature replay approach. specifically, we preserve the old knowledge of each class by maintaining a feature-level gaussian distribution with a diagonal covariance matrix, which is estimated by the image features of training images and synthesized features generated from a vae. when progressing to a new session, pseudo-features are sampled from old-class distributions combined with training images of the current session to optimize the prompt, thus enabling the model to learn new knowledge while retaining old knowledge. experiments on three prevalent benchmarks, i.e., cifar100, mini-imagenet, cub-200, and two more challenging benchmarks, i.e., sun-397 and cub-200$^*$ proposed in this paper showcase the superiority of lp-dif, achieving new state-of-the-art (sota) in fscil. code is publicly available at https:\/\/github.com\/1170300714\/lp-dif.","doi":"","created":1704240000000,"updated":"2024-04-05","authors":["zitong huang","ze chen","zhixing chen","erjin zhou","xinxing xu","rick siow mong goh","yong liu","wangmeng zuo","chunmei feng"]}
{"id":"2401.01599","title":"generalization error curves for analytic spectral algorithms under   power-law decay","categories":"cs.lg math.st stat.th","abstract":"the generalization error curve of certain kernel regression method aims at determining the exact order of generalization error with various source condition, noise level and choice of the regularization parameter rather than the minimax rate. in this work, under mild assumptions, we rigorously provide a full characterization of the generalization error curves of the kernel gradient descent method (and a large class of analytic spectral algorithms) in kernel regression. consequently, we could sharpen the near inconsistency of kernel interpolation and clarify the saturation effects of kernel regression algorithms with higher qualification, etc. thanks to the neural tangent kernel theory, these results greatly improve our understanding of the generalization behavior of training the wide neural networks. a novel technical contribution, the analytic functional argument, might be of independent interest.","doi":"","created":1704240000000,"updated":"2024-07-15","authors":["yicheng li","weiye gan","zuoqiang shi","qian lin"]}
{"id":"2401.01600","title":"pllama: an open-source large language model for plant science","categories":"cs.cl cs.ai cs.ce cs.lg","abstract":"large language models (llms) have exhibited remarkable capabilities in understanding and interacting with natural language across various sectors. however, their effectiveness is limited in specialized areas requiring high accuracy, such as plant science, due to a lack of specific expertise in these fields. this paper introduces pllama, an open-source language model that evolved from llama-2. it's enhanced with a comprehensive database, comprising more than 1.5 million scholarly articles in plant science. this development significantly enriches pllama with extensive knowledge and proficiency in plant and agricultural sciences. our initial tests, involving specific datasets related to plants and agriculture, show that pllama substantially improves its understanding of plant science-related topics. moreover, we have formed an international panel of professionals, including plant scientists, agricultural engineers, and plant breeders. this team plays a crucial role in verifying the accuracy of pllama's responses to various academic inquiries, ensuring its effective and reliable application in the field. to support further research and development, we have made the model's checkpoints and source codes accessible to the scientific community. these resources are available for download at \\url{https:\/\/github.com\/xianjun-yang\/pllama}.","doi":"","created":1704240000000,"updated":"","authors":["xianjun yang","junfeng gao","wenxin xue","erik alexandersson"]}
{"id":"2401.01608","title":"interference management in 5g and beyond networks","categories":"eess.sp cs.ni math.oc","abstract":"during the last decade, wireless data services have had an incredible impact on people's lives in ways we could never have imagined. the number of mobile devices has increased exponentially and data traffic has almost doubled every year. undoubtedly, the rate of growth will continue to be rapid with the explosive increase in demands for data rates, latency, massive connectivity, network reliability, and energy efficiency. in order to manage this level of growth and meet these requirements, the fifth-generation (5g) mobile communications network is envisioned as a revolutionary advancement combining various improvements to previous mobile generation networks and new technologies, including the use of millimeter wavebands (mm-wave), massive multiple-input multipleoutput (mmimo) multi-beam antennas, network densification, dynamic time division duplex (tdd) transmission, and new waveforms with mixed numerologies. new revolutionary features including terahertz (thz) communications and the integration of non-terrestrial networks (ntn) can further improve the performance and signal quality for future 6g networks. however, despite the inevitable benefits of all these key technologies, the heterogeneous and ultra-flexible structure of the 5g and beyond network brings non-orthogonality into the system and generates significant interference that needs to be handled carefully. therefore, it is essential to design effective interference management schemes to mitigate severe and sometimes unpredictable interference in mobile networks. in this paper, we provide a comprehensive review of interference management in 5g and beyond networks and discuss its future evolution. we start with a unified classification and a detailed explanation of the different types of interference and continue by presenting our taxonomy of existing interference management approaches. then, after explaining interference measurement reports and signaling, we provide for each type of interference identified, an in-depth literature review and technical discussion of appropriate management schemes. we finish by discussing the main interference challenges that will be encountered in future 6g networks and by presenting insights on the suggested new interference management approaches, including useful guidelines for an ai-based solution. this review will provide a first-hand guide to the industry in determining the most relevant technology for interference management, and will also allow for consideration of future challenges and research directions.","doi":"","created":1704240000000,"updated":"","authors":["nessrine trabelsi","lamia chaari fourati","chung shue chen"]}
{"id":"2401.01609","title":"entropy-based probing beam selection and beam prediction via deep   learning","categories":"cs.it eess.sp math.it","abstract":"hierarchical beam search in mmwave communications incurs substantial training overhead, necessitating deep learning-enabled beam predictions to effectively leverage channel priors and mitigate this overhead. in this study, we introduce a comprehensive probabilistic model of power distribution in beamspace, and formulate the joint optimization problem of probing beam selection and probabilistic beam prediction as an entropy minimization problem. then, we propose a greedy scheme to iteratively and alternately solve this problem, where a transformer-based beam predictor is trained to estimate the conditional power distribution based on the probing beams and user location within each iteration, and the trained predictor selects an unmeasured beam that minimizes the entropy of remaining beams. to further reduce the number of interactions and the computational complexity of the iterative scheme, we propose a two-stage probing beam selection scheme. firstly, probing beams are selected from a location-specific codebook designed by an entropy-based criterion, and predictions are made with corresponding feedback. secondly, the optimal beam is identified using additional probing beams with the highest predicted power values. simulation results demonstrate the superiority of the proposed schemes compared to hierarchical beam search and beam prediction with uniform probing beams.","doi":"","created":1704240000000,"updated":"","authors":["fan meng","cheng zhang","yongming huang","zhilei zhang","xiaoyu bai","zhaohua lu"]}
{"id":"2401.01614","title":"gpt-4v(ision) is a generalist web agent, if grounded","categories":"cs.ir cs.ai cs.cl cs.cv","abstract":"the recent development on large multimodal models (lmms), especially gpt-4v(ision) and gemini, has been quickly expanding the capability boundaries of multimodal models beyond traditional tasks like image captioning and visual question answering. in this work, we explore the potential of lmms like gpt-4v as a generalist web agent that can follow natural language instructions to complete tasks on any given website. we propose seeact, a generalist web agent that harnesses the power of lmms for integrated visual understanding and acting on the web. we evaluate on the recent mind2web benchmark. in addition to standard offline evaluation on cached websites, we enable a new online evaluation setting by developing a tool that allows running web agents on live websites. we show that gpt-4v presents a great potential for web agents -- it can successfully complete 51.1 of the tasks on live websites if we manually ground its textual plans into actions on the websites. this substantially outperforms text-only llms like gpt-4 or smaller models (flan-t5 and blip-2) specifically fine-tuned for web agents. however, grounding still remains a major challenge. existing lmm grounding strategies like set-of-mark prompting turns out to be not effective for web agents, and the best grounding strategy we develop in this paper leverages both the html structure and visuals. yet, there is still a substantial gap with oracle grounding, leaving ample room for further improvement. all code, data, and evaluation tools are available at https:\/\/github.com\/osu-nlp-group\/seeact.","doi":"","created":1704240000000,"updated":"2024-03-12","authors":["boyuan zheng","boyu gou","jihyung kil","huan sun","yu su"]}
{"id":"2401.01618","title":"nonconforming virtual element method for an incompressible miscible   displacement problem in porous media","categories":"math.na cs.na","abstract":"this article presents a priori error estimates of the miscible displacement of one incompressible fluid by another through a porous medium characterized by a coupled system of nonlinear elliptic and parabolic equations. the study utilizes the $h(\\rm{div})$ conforming virtual element method (vem) for the approximation of the velocity, while a non-conforming virtual element approach is employed for the concentration. the pressure is discretised using the standard piecewise discontinuous polynomial functions. these spatial discretization techniques are combined with a backward euler difference scheme for time discretization. the article also includes numerical results that validate the theoretical estimates presented.","doi":"","created":1704240000000,"updated":"","authors":["sarvesh kumar","devika shylaja"]}
{"id":"2401.01619","title":"several new classes of mds symbol-pair codes derived from matrix-product   codes","categories":"cs.it math.it","abstract":"in order to correct the pair-errors generated during the transmission of modern high-density data storage that the outputs of the channels consist of overlapping pairs of symbols, a new coding scheme named symbol-pair code is proposed. the error-correcting capability of the symbol-pair code is determined by its minimum symbol-pair distance. for such codes, the larger the minimum symbol-pair distance, the better. it is a challenging task to construct symbol-pair codes with optimal parameters, especially, maximum-distance-separable (mds) symbol-pair codes. in this paper, the permutation equivalence codes of matrix-product codes with underlying matrixes of orders 3 and 4 are used to extend the minimum symbol-pair distance, and six new classes of mds symbol-pair codes are derived.","doi":"","created":1704240000000,"updated":"2024-01-15","authors":["xiujing zheng","liqi wang","shixin zhu"]}
{"id":"2401.01620","title":"large language model capabilities in perioperative risk prediction and   prognostication","categories":"cs.ai cs.cl","abstract":"we investigate whether general-domain large language models such as gpt-4 turbo can perform risk stratification and predict post-operative outcome measures using a description of the procedure and a patient's clinical notes derived from the electronic health record. we examine predictive performance on 8 different tasks: prediction of asa physical status classification, hospital admission, icu admission, unplanned admission, hospital mortality, pacu phase 1 duration, hospital duration, and icu duration. few-shot and chain-of-thought prompting improves predictive performance for several of the tasks. we achieve f1 scores of 0.50 for asa physical status classification, 0.81 for icu admission, and 0.86 for hospital mortality. performance on duration prediction tasks were universally poor across all prompt strategies. current generation large language models can assist clinicians in perioperative risk stratification on classification tasks and produce high-quality natural language summaries and explanations.","doi":"","created":1704240000000,"updated":"","authors":["philip chung","christine t fong","andrew m walters","nima aghaeepour","meliha yetisgen","vikas n o'reilly-shah"]}
{"id":"2401.01622","title":"non-atomic arbitrage in decentralized finance","categories":"cs.ce q-fin.gn","abstract":"the prevalence of maximal extractable value (mev) in the ethereum ecosystem has led to a characterization of the latter as a dark forest. studies of mev have thus far largely been restricted to purely on-chain mev, i.e., sandwich attacks, cyclic arbitrage, and liquidations. in this work, we shed light on the prevalence of non-atomic arbitrage on decentralized exchanges (dexes) on the ethereum blockchain. importantly, non-atomic arbitrage exploits price differences between dexes on the ethereum blockchain as well as exchanges outside the ethereum blockchain (i.e., centralized exchanges or dexes on other blockchains). thus, non-atomic arbitrage is a type of mev that involves actions on and off the ethereum blockchain.   in our study of non-atomic arbitrage, we uncover that more than a fourth of the volume on ethereum's biggest five dexes from the merge until 31 october 2023 can likely be attributed to this type of mev. we further highlight that only eleven searchers are responsible for more than 80% of the identified non-atomic arbitrage volume sitting at a staggering $132 billion and draw a connection between the centralization of the block construction market and non-atomic arbitrage. finally, we discuss the security implications of these high-value transactions that account for more than 10% of ethereum's total block value and outline possible mitigations.","doi":"","created":1704240000000,"updated":"2024-04-08","authors":["lioba heimbach","vabuk pahari","eric schertenleib"]}
{"id":"2401.01623","title":"can ai be as creative as humans?","categories":"cs.ai cs.cl","abstract":"creativity serves as a cornerstone for societal progress and innovation. with the rise of advanced generative ai models capable of tasks once reserved for human creativity, the study of ai's creative potential becomes imperative for its responsible development and application. in this paper, we prove in theory that ai can be as creative as humans under the condition that it can properly fit the data generated by human creators. therefore, the debate on ai's creativity is reduced into the question of its ability to fit a sufficient amount of data. to arrive at this conclusion, this paper first addresses the complexities in defining creativity by introducing a new concept called relative creativity. rather than attempting to define creativity universally, we shift the focus to whether ai can match the creative abilities of a hypothetical human. the methodological shift leads to a statistically quantifiable assessment of ai's creativity, term statistical creativity. this concept, statistically comparing the creative abilities of ai with those of specific human groups, facilitates theoretical exploration of ai's creative potential. our analysis reveals that by fitting extensive conditional data without marginalizing out the generative conditions, ai can emerge as a hypothetical new creator. the creator possesses the same creative abilities on par with the human creators it was trained on. building on theoretical findings, we discuss the application in prompt-conditioned autoregressive models, providing a practical means for evaluating creative abilities of generative ai models, such as large language models (llms). additionally, this study provides an actionable training guideline, bridging the theoretical quantification of creativity with practical model training.","doi":"","created":1704240000000,"updated":"2024-01-25","authors":["haonan wang","james zou","michael mozer","anirudh goyal","alex lamb","linjun zhang","weijie j su","zhun deng","michael qizhe xie","hannah brown","kenji kawaguchi"]}
{"id":"2401.01624","title":"context-aware interaction network for rgb-t semantic segmentation","categories":"cs.cv","abstract":"rgb-t semantic segmentation is a key technique for autonomous driving scenes understanding. for the existing rgb-t semantic segmentation methods, however, the effective exploration of the complementary relationship between different modalities is not implemented in the information interaction between multiple levels. to address such an issue, the context-aware interaction network (cainet) is proposed for rgb-t semantic segmentation, which constructs interaction space to exploit auxiliary tasks and global context for explicitly guided learning. specifically, we propose a context-aware complementary reasoning (cacr) module aimed at establishing the complementary relationship between multimodal features with the long-term context in both spatial and channel dimensions. further, considering the importance of global contextual and detailed information, we propose the global context modeling (gcm) module and detail aggregation (da) module, and we introduce specific auxiliary supervision to explicitly guide the context interaction and refine the segmentation map. extensive experiments on two benchmark datasets of mfnet and pst900 demonstrate that the proposed cainet achieves state-of-the-art performance. the code is available at https:\/\/github.com\/yinglv1106\/cainet.","doi":"10.1109\/tmm.2023.3349072","created":1704240000000,"updated":"","authors":["ying lv","zhi liu","gongyang li"]}
{"id":"2401.01625","title":"scala: sparsification-based contrastive learning for anomaly detection   on attributed networks","categories":"cs.si cs.cy cs.lg","abstract":"anomaly detection on attributed networks aims to find the nodes whose behaviors are significantly different from other majority nodes. generally, network data contains information about relationships between entities, and the anomaly is usually embodied in these relationships. therefore, how to comprehensively model complex interaction patterns in networks is still a major focus. it can be observed that anomalies in networks violate the homophily assumption. however, most existing studies only considered this phenomenon obliquely rather than explicitly. besides, the node representation of normal entities can be perturbed easily by the noise relationships introduced by anomalous nodes. to address the above issues, we present a novel contrastive learning framework for anomaly detection on attributed networks, \\textbf{scala}, aiming to improve the embedding quality of the network and provide a new measurement of qualifying the anomaly score for each node by introducing sparsification into the conventional method. extensive experiments are conducted on five benchmark real-world datasets and the results show that scala consistently outperforms all baseline methods significantly.","doi":"","created":1704240000000,"updated":"2024-01-08","authors":["enbo he","yitong hao","yue zhang","guisheng yin","lina yao"]}
{"id":"2401.01626","title":"on the expressive power of graph neural networks","categories":"cs.lg cs.ai","abstract":"the study of graph neural networks has received considerable interest in the past few years. by extending deep learning to graph-structured data, gnns can solve a diverse set of tasks in fields including social science, chemistry, and medicine. the development of gnn architectures has largely been focused on improving empirical performance on tasks like node or graph classification. however, a line of recent work has instead sought to find gnn architectures that have desirable theoretical properties - by studying their expressive power and designing architectures that maximize this expressiveness.   while there is no consensus on the best way to define the expressiveness of a gnn, it can be viewed from several well-motivated perspectives. perhaps the most natural approach is to study the universal approximation properties of gnns, much in the way that this has been studied extensively for mlps. another direction focuses on the extent to which gnns can distinguish between different graph structures, relating this to the graph isomorphism test. besides, a gnn's ability to compute graph properties such as graph moments has been suggested as another form of expressiveness. all of these different definitions are complementary and have yielded different recommendations for gnn architecture choices. in this paper, we would like to give an overview of the notion of \"expressive power\" of gnns and provide some valuable insights regarding the design choices of gnns.","doi":"","created":1704240000000,"updated":"2024-03-08","authors":["ashwin nalwade","kelly marshall","axel eladi","umang sharma"]}
{"id":"2401.01629","title":"synthetic data in ai: challenges, applications, and ethical implications","categories":"cs.lg cs.ai cs.cy","abstract":"in the rapidly evolving field of artificial intelligence, the creation and utilization of synthetic datasets have become increasingly significant. this report delves into the multifaceted aspects of synthetic data, particularly emphasizing the challenges and potential biases these datasets may harbor. it explores the methodologies behind synthetic data generation, spanning traditional statistical models to advanced deep learning techniques, and examines their applications across diverse domains. the report also critically addresses the ethical considerations and legal implications associated with synthetic datasets, highlighting the urgent need for mechanisms to ensure fairness, mitigate biases, and uphold ethical standards in ai development.","doi":"","created":1704240000000,"updated":"","authors":["shuang hao","wenfeng han","tao jiang","yiping li","haonan wu","chunlin zhong","zhangjun zhou","he tang"]}
{"id":"2401.01630","title":"a cybersecurity risk analysis framework for systems with artificial   intelligence components","categories":"cs.ai cs.cr stat.ap","abstract":"the introduction of the european union artificial intelligence act, the nist artificial intelligence risk management framework, and related norms demands a better understanding and implementation of novel risk analysis approaches to evaluate systems with artificial intelligence components. this paper provides a cybersecurity risk analysis framework that can help assessing such systems. we use an illustrative example concerning automated driving systems.","doi":"","created":1704240000000,"updated":"","authors":["jose manuel camacho","aitor couce-vieira","david arroyo","david rios insua"]}
{"id":"2401.01633","title":"quantum polynomial hierarchies: karp-lipton, error reduction, and lower   bounds","categories":"cs.cc quant-ph","abstract":"the polynomial-time hierarchy ($\\mathsf{ph}$) is a staple of classical complexity theory, with applications spanning randomized computation to circuit lower bounds to ''quantum advantage'' analyses for near-term quantum computers. quantumly, however, despite the fact that at least \\emph{four} definitions of quantum $\\mathsf{ph}$ exist, it has been challenging to prove analogues for these of even basic facts from $\\mathsf{ph}$. this work studies three quantum-verifier based generalizations of $\\mathsf{ph}$, two of which are from [gharibian, santha, sikora, sundaram, yirka, 2022] and use classical strings ($\\mathsf{qcph}$) and quantum mixed states ($\\mathsf{qph}$) as proofs, and one of which is new to this work, utilizing quantum pure states ($\\mathsf{pureqph}$) as proofs. we first resolve several open problems from [gsssy22], including a collapse theorem and a karp-lipton theorem for $\\mathsf{qcph}$. then, for our new class $\\mathsf{pureqph}$, we show one-sided error reduction for $\\mathsf{pureqph}$, as well as the first bounds relating these quantum variants of $\\mathsf{ph}$, namely $\\mathsf{qcph}\\subseteq \\mathsf{pureqph} \\subseteq \\mathsf{exp}^{\\mathsf{pp}}$.","doi":"","created":1704240000000,"updated":"","authors":["avantika agarwal","sevag gharibian","venkata koppula","dorian rudolph"]}
{"id":"2401.01636","title":"efficient uavs deployment and resource allocation in uav-relay assisted   public safety networks for video transmission","categories":"cs.ni eess.sp","abstract":"wireless communication highly depends on the cellular ground base station (gbs). a failure of the cellular gbs, fully or partially, during natural or man-made disasters creates a communication gap in the disaster-affected areas. in such situations, public safety communication (psc) can significantly save the national infrastructure, property, and lives. throughout emergencies, the psc can provide mission-critical communication and video transmission services in the affected area. unmanned aerial vehicles (uavs) as flying base stations (uav-bss) are particularly suitable for psc services as they are flexible, mobile, and easily deployable. this manuscript considers a multi-uav-assisted psc network with an observational uav receiving videos from the affected area's ground users (agus) and transmitting them to the nearby gbs via a relay uav. the objective of the proposed study is to maximize the average utility of the video streams generated by the agus upon reaching the gbs. this is achieved by optimizing the positions of the observational and relay uavs, as well as the distribution of communication resources, such as bandwidth, and transmit power, while satisfying the system-designed constraints, such as transmission rate, rate outage probability, transmit power budget, and available bandwidth. to this end, a joint uavs placement and resource allocation problem is mathematically formulated. the proposed problem poses a significant challenge for a solution. considering the block coordinate descent and successive convex approximation techniques, an efficient iterative algorithm is proposed. finally, simulation results are provided which show that our proposed approach outperforms the existing methods.","doi":"10.1109\/access.2024.3350138","created":1704240000000,"updated":"2024-01-03","authors":["naveed khan","ayaz ahmad","abdul wakeel","zeeshan kaleem","bushra rashid","waqas khalid"]}
{"id":"2401.01637","title":"social media ready caption generation for brands","categories":"cs.cl","abstract":"social media advertisements are key for brand marketing, aiming to attract consumers with captivating captions and pictures or logos. while previous research has focused on generating captions for general images, incorporating brand personalities into social media captioning remains unexplored. brand personalities are shown to be affecting consumers' behaviours and social interactions and thus are proven to be a key aspect of marketing strategies. current open-source multimodal llms are not directly suited for this task. hence, we propose a pipeline solution to assist brands in creating engaging social media captions that align with the image and the brand personalities. our architecture is based on two parts: a the first part contains an image captioning model that takes in an image that the brand wants to post online and gives a plain english caption; b the second part takes in the generated caption along with the target brand personality and outputs a catchy personality-aligned social media caption. along with brand personality, our system also gives users the flexibility to provide hashtags, instagram handles, urls, and named entities they want the caption to contain, making the captions more semantically related to the social media handles. comparative evaluations against various baselines demonstrate the effectiveness of our approach, both qualitatively and quantitatively.","doi":"","created":1704240000000,"updated":"","authors":["himanshu maheshwari","koustava goswami","apoorv saxena","balaji vasan srinivasan"]}
{"id":"2401.01640","title":"evaluating fairness in self-supervised and supervised models for   sequential data","categories":"cs.lg cs.cy","abstract":"self-supervised learning (ssl) has become the de facto training paradigm of large models where pre-training is followed by supervised fine-tuning using domain-specific data and labels. hypothesizing that ssl models would learn more generic, hence less biased, representations, this study explores the impact of pre-training and fine-tuning strategies on fairness (i.e., performing equally on different demographic breakdowns). motivated by human-centric applications on real-world timeseries data, we interpret inductive biases on the model, layer, and metric levels by systematically comparing ssl models to their supervised counterparts. our findings demonstrate that ssl has the capacity to achieve performance on par with supervised methods while significantly enhancing fairness--exhibiting up to a 27% increase in fairness with a mere 1% loss in performance through self-supervision. ultimately, this work underscores ssl's potential in human-centric computing, particularly high-stakes, data-scarce application domains like healthcare.","doi":"","created":1704240000000,"updated":"","authors":["sofia yfantidou","dimitris spathis","marios constantinides","athena vakali","daniele quercia","fahim kawsar"]}
{"id":"2401.01641","title":"towards a foundation purchasing model: pretrained generative   autoregression on transaction sequences","categories":"cs.lg","abstract":"machine learning models underpin many modern financial systems for use cases such as fraud detection and churn prediction. most are based on supervised learning with hand-engineered features, which relies heavily on the availability of labelled data. large self-supervised generative models have shown tremendous success in natural language processing and computer vision, yet so far they haven't been adapted to multivariate time series of financial transactions. in this paper, we present a generative pretraining method that can be used to obtain contextualised embeddings of financial transactions. benchmarks on public datasets demonstrate that it outperforms state-of-the-art self-supervised methods on a range of downstream tasks. we additionally perform large-scale pretraining of an embedding model using a corpus of data from 180 issuing banks containing 5.1 billion transactions and apply it to the card fraud detection problem on hold-out datasets. the embedding model significantly improves value detection rate at high precision thresholds and transfers well to out-of-domain distributions.","doi":"10.1145\/3604237.3626850","created":1704240000000,"updated":"2024-01-04","authors":["piotr skalski","david sutton","stuart burrell","iker perez","jason wong"]}
{"id":"2401.01642","title":"blade: box-level supervised amodal segmentation through directed   expansion","categories":"cs.cv","abstract":"perceiving the complete shape of occluded objects is essential for human and machine intelligence. while the amodal segmentation task is to predict the complete mask of partially occluded objects, it is time-consuming and labor-intensive to annotate the pixel-level ground truth amodal masks. box-level supervised amodal segmentation addresses this challenge by relying solely on ground truth bounding boxes and instance classes as supervision, thereby alleviating the need for exhaustive pixel-level annotations. nevertheless, current box-level methodologies encounter limitations in generating low-resolution masks and imprecise boundaries, failing to meet the demands of practical real-world applications. we present a novel solution to tackle this problem by introducing a directed expansion approach from visible masks to corresponding amodal masks. our approach involves a hybrid end-to-end network based on the overlapping region - the area where different instances intersect. diverse segmentation strategies are applied for overlapping regions and non-overlapping regions according to distinct characteristics. to guide the expansion of visible masks, we introduce an elaborately-designed connectivity loss for overlapping regions, which leverages correlations with visible masks and facilitates accurate amodal segmentation. experiments are conducted on several challenging datasets and the results show that our proposed method can outperform existing state-of-the-art methods with large margins.","doi":"10.1609\/aaai.v38i4.28176","created":1704240000000,"updated":"2024-02-25","authors":["zhaochen liu","zhixuan li","tingting jiang"]}
{"id":"2401.01643","title":"s3net: innovating stereo matching and semantic segmentation with a   single-branch semantic stereo network in satellite epipolar imagery","categories":"cs.cv","abstract":"stereo matching and semantic segmentation are significant tasks in binocular satellite 3d reconstruction. however, previous studies primarily view these as independent parallel tasks, lacking an integrated multitask learning framework. this work introduces a solution, the single-branch semantic stereo network (s3net), which innovatively combines semantic segmentation and stereo matching using self-fuse and mutual-fuse modules. unlike preceding methods that utilize semantic or disparity information independently, our method dentifies and leverages the intrinsic link between these two tasks, leading to a more accurate understanding of semantic information and disparity estimation. comparative testing on the us3d dataset proves the effectiveness of our s3net. our model improves the miou in semantic segmentation from 61.38 to 67.39, and reduces the d1-error and average endpoint error (epe) in disparity estimation from 10.051 to 9.579 and 1.439 to 1.403 respectively, surpassing existing competitive methods. our codes are available at:https:\/\/github.com\/cveo\/s3net.","doi":"","created":1704240000000,"updated":"","authors":["qingyuan yang","guanzhou chen","xiaoliang tan","tong wang","jiaqi wang","xiaodong zhang"]}
{"id":"2401.01644","title":"motion control of interactive robotic arms based on mixed reality   development","categories":"cs.ro cs.hc","abstract":"mixed reality (mr) is constantly evolving to inspire new patterns of robot manipulation for more advanced human- robot interaction under the 4th industrial revolution paradigm. consider that mixed reality aims to connect physical and digital worlds to provide special immersive experiences, it is necessary to establish the information exchange platform and robot control systems within the developed mr scenarios. in this work, we mainly present multiple effective motion control methods applied on different interactive robotic arms (e.g., ur5, ur5e, mycobot) for the unity-based development of mr applications, including gui control panel, text input control panel, end-effector object dynamic tracking and ros-unity digital-twin connection.","doi":"","created":1704240000000,"updated":"","authors":["hanxiao chen"]}
{"id":"2401.01646","title":"prototypical information bottlenecking and disentangling for multimodal   cancer survival prediction","categories":"cs.cv","abstract":"multimodal learning significantly benefits cancer survival prediction, especially the integration of pathological images and genomic data. despite advantages of multimodal learning for cancer survival prediction, massive redundancy in multimodal data prevents it from extracting discriminative and compact information: (1) an extensive amount of intra-modal task-unrelated information blurs discriminability, especially for gigapixel whole slide images (wsis) with many patches in pathology and thousands of pathways in genomic data, leading to an ``intra-modal redundancy\" issue. (2) duplicated information among modalities dominates the representation of multimodal data, which makes modality-specific information prone to being ignored, resulting in an ``inter-modal redundancy\" issue. to address these, we propose a new framework, prototypical information bottlenecking and disentangling (pibd), consisting of prototypical information bottleneck (pib) module for intra-modal redundancy and prototypical information disentanglement (pid) module for inter-modal redundancy. specifically, a variant of information bottleneck, pib, is proposed to model prototypes approximating a bunch of instances for different risk levels, which can be used for selection of discriminative instances within modality. pid module decouples entangled multimodal data into compact distinct components: modality-common and modality-specific knowledge, under the guidance of the joint prototypical distribution. extensive experiments on five cancer benchmark datasets demonstrated our superiority over other methods.","doi":"","created":1704240000000,"updated":"2024-02-26","authors":["yilan zhang","yingxue xu","jianqi chen","fengying xie","hao chen"]}
{"id":"2401.01647","title":"signerf: scene integrated generation for neural radiance fields","categories":"cs.cv cs.gr","abstract":"advances in image diffusion models have recently led to notable improvements in the generation of high-quality images. in combination with neural radiance fields (nerfs), they enabled new opportunities in 3d generation. however, most generative 3d approaches are object-centric and applying them to editing existing photorealistic scenes is not trivial. we propose signerf, a novel approach for fast and controllable nerf scene editing and scene-integrated object generation. a new generative update strategy ensures 3d consistency across the edited images, without requiring iterative optimization. we find that depth-conditioned diffusion models inherently possess the capability to generate 3d consistent views by requesting a grid of images instead of single views. based on these insights, we introduce a multi-view reference sheet of modified images. our method updates an image collection consistently based on the reference sheet and refines the original nerf with the newly generated image set in one go. by exploiting the depth conditioning mechanism of the image diffusion model, we gain fine control over the spatial location of the edit and enforce shape guidance by a selected region or an external mesh.","doi":"","created":1704240000000,"updated":"2024-03-27","authors":["jan-niklas dihlmann","andreas engelhardt","hendrik lensch"]}
{"id":"2401.01650","title":"de-confusing pseudo-labels in source-free domain adaptation","categories":"cs.cv","abstract":"source-free domain adaptation (sfda) aims to adapt a source-trained model to an unlabeled target domain without access to the source data. sfda has attracted growing attention in recent years, where existing approaches focus on self-training that usually includes pseudo-labeling techniques. in this paper, we introduce a novel noise-learning approach tailored to address noise distribution in domain adaptation settings and learn to de-confuse the pseudo-labels. more specifically, we learn a noise transition matrix of the pseudo-labels to capture the label corruption of each class and learn the underlying true label distribution. estimating the noise transition matrix enables a better true class-posterior estimation, resulting in better prediction accuracy. we demonstrate the effectiveness of our approach when combined with several sfda methods: shot, shot++, and aad. we obtain state-of-the-art results on three domain adaptation datasets: visda, domainnet, and officehome.","doi":"","created":1704240000000,"updated":"2024-03-13","authors":["idit diamant","amir rosenfeld","idan achituve","jacob goldberger","arnon netzer"]}
{"id":"2401.01651","title":"aigcbench: comprehensive evaluation of image-to-video content generated   by ai","categories":"cs.cv cs.ai","abstract":"the burgeoning field of artificial intelligence generated content (aigc) is witnessing rapid advancements, particularly in video generation. this paper introduces aigcbench, a pioneering comprehensive and scalable benchmark designed to evaluate a variety of video generation tasks, with a primary focus on image-to-video (i2v) generation. aigcbench tackles the limitations of existing benchmarks, which suffer from a lack of diverse datasets, by including a varied and open-domain image-text dataset that evaluates different state-of-the-art algorithms under equivalent conditions. we employ a novel text combiner and gpt-4 to create rich text prompts, which are then used to generate images via advanced text-to-image models. to establish a unified evaluation framework for video generation tasks, our benchmark includes 11 metrics spanning four dimensions to assess algorithm performance. these dimensions are control-video alignment, motion effects, temporal consistency, and video quality. these metrics are both reference video-dependent and video-free, ensuring a comprehensive evaluation strategy. the evaluation standard proposed correlates well with human judgment, providing insights into the strengths and weaknesses of current i2v algorithms. the findings from our extensive experiments aim to stimulate further research and development in the i2v field. aigcbench represents a significant step toward creating standardized benchmarks for the broader aigc landscape, proposing an adaptable and equitable framework for future assessments of video generation tasks. we have open-sourced the dataset and evaluation code on the project website: https:\/\/www.benchcouncil.org\/aigcbench.","doi":"","created":1704240000000,"updated":"2024-01-23","authors":["fanda fan","chunjie luo","wanling gao","jianfeng zhan"]}
{"id":"2401.01652","title":"near real-time data-driven control of virtual reality traffic in open   radio access network","categories":"cs.ni","abstract":"in mobile networks, open radio access network (oran) provides a framework for implementing network slicing that interacts with the resources at the lower layers. both monitoring and radio access network (ran) control is feasible for both 4g and 5g systems. in this work, we consider how data-driven resource allocation in a 4g context can enable adaptive slice allocation to steer the experienced latency of virtual reality (vr) traffic towards a requested latency. we develop an xapp for the near real-time ran intelligent controller (ric) that embeds a heuristic algorithm for latency control, aiming to: (1) maintain latency of a vr stream around a requested value; and (2) improve the available ran allocation to offer higher bit rate to another user. we have experimentally demonstrated the proposed approach in an oran testbed. our results show that the data-driven approach can dynamically follow the variation of the traffic load while satisfying the required latency. this results in 15.8% more resources to secondary users than a latency-equivalent static allocation.","doi":"","created":1704240000000,"updated":"","authors":["andreas casparsen","beatriz soret","jimmy jessen nielsen","petar popovski"]}
{"id":"2401.01654","title":"lesen: label-efficient deep learning for multi-parametric mri-based   visual pathway segmentation","categories":"eess.iv cs.lg","abstract":"recent research has shown the potential of deep learning in multi-parametric mri-based visual pathway (vp) segmentation. however, obtaining labeled data for training is laborious and time-consuming. therefore, it is crucial to develop effective algorithms in situations with limited labeled samples. in this work, we propose a label-efficient deep learning method with self-ensembling (lesen). lesen incorporates supervised and unsupervised losses, enabling the student and teacher models to mutually learn from each other, forming a self-ensembling mean teacher framework. additionally, we introduce a reliable unlabeled sample selection (russ) mechanism to further enhance lesen's effectiveness. our experiments on the human connectome project (hcp) dataset demonstrate the superior performance of our method when compared to state-of-the-art techniques, advancing multimodal vp segmentation for comprehensive analysis in clinical and research settings. the implementation code will be available at: https:\/\/github.com\/aldiak\/semi-supervised-multimodal-visual-pathway- delineation.","doi":"","created":1704240000000,"updated":"","authors":["alou diakite","cheng li","lei xie","yuanjing feng","hua han","shanshan wang"]}
{"id":"2401.01656","title":"deep automated mechanism design for integrating ad auction and   allocation in feed","categories":"cs.gt cs.ai","abstract":"e-commerce platforms usually present an ordered list, mixed with several organic items and an advertisement, in response to each user's page view request. this list, the outcome of ad auction and allocation processes, directly impacts the platform's ad revenue and gross merchandise volume (gmv). specifically, the ad auction determines which ad is displayed and the corresponding payment, while the ad allocation decides the display positions of the advertisement and organic items. the prevalent methods of segregating the ad auction and allocation into two distinct stages face two problems: 1) ad auction does not consider externalities, such as the influence of actual display position and context on ad click-through rate (ctr); 2) the ad allocation, which utilizes the auction-winning ad's payment to determine the display position dynamically, fails to maintain incentive compatibility (ic) for the advertisement. for instance, in the auction stage employing the traditional generalized second price (gsp) , even if the winning ad increases its bid, its payment remains unchanged. this implies that the advertisement cannot secure a better position and thus loses the opportunity to achieve higher utility in the subsequent ad allocation stage. previous research often focused on one of the two stages, neglecting the two-stage problem, which may result in suboptimal outcomes...","doi":"","created":1704240000000,"updated":"2024-04-11","authors":["xuejian li","ze wang","bingqi zhu","fei he","yongkang wang","xingxing wang"]}
{"id":"2401.01657","title":"distributed pose-graph optimization with multi-level partitioning for   collaborative slam","categories":"cs.ro cs.ma","abstract":"the back-end module of distributed collaborative simultaneous localization and mapping (dcslam) requires solving a nonlinear pose graph optimization (pgo) under a distributed setting, also known as se(d)-synchronization. most existing distributed graph optimization algorithms employ a simple sequential partitioning scheme, which may result in unbalanced subgraph dimensions due to the different geographic locations of each robot, and hence imposes extra communication load. moreover, the performance of current riemannian optimization algorithms can be further accelerated. in this letter, we propose a novel distributed pose graph optimization algorithm combining multi-level partitioning with an accelerated riemannian optimization method. firstly, we employ the multi-level graph partitioning algorithm to preprocess the naive pose graph to formulate a balanced optimization problem. in addition, inspired by the accelerated coordinate descent method, we devise an improved riemannian block coordinate descent (irbcd) algorithm and the critical point obtained is globally optimal. finally, we evaluate the effects of four common graph partitioning approaches on the correlation of the inter-subgraphs, and discover that the highest scheme has the best partitioning performance. also, we implement simulations to quantitatively demonstrate that our proposed algorithm outperforms the state-of-the-art distributed pose graph optimization protocols.","doi":"","created":1704240000000,"updated":"2024-03-20","authors":["cunhao li","peng yi","guanghui guo","yiguang hong"]}
{"id":"2401.01659","title":"diffyolo: object detection for anti-noise via yolo and diffusion models","categories":"cs.cv","abstract":"object detection models represented by yolo series have been widely used and have achieved great results on the high quality datasets, but not all the working conditions are ideal. to settle down the problem of locating targets on low quality datasets, the existing methods either train a new object detection network, or need a large collection of low-quality datasets to train. however, we propose a framework in this paper and apply it on the yolo models called diffyolo. specifically, we extract feature maps from the denoising diffusion probabilistic models to enhance the well-trained models, which allows us fine-tune yolo on high-quality datasets and test on low-quality datasets. the results proved this framework can not only prove the performance on noisy datasets, but also prove the detection results on high-quality test datasets. we will supplement more experiments later (with various datasets and network architectures).","doi":"","created":1704240000000,"updated":"","authors":["yichen liu","huajian zhang","daqing gao"]}
{"id":"2401.01662","title":"simultaneous q-space sampling optimization and reconstruction for fast   and high-fidelity diffusion magnetic resonance imaging","categories":"cs.cv","abstract":"diffusion magnetic resonance imaging (dmri) plays a crucial role in the noninvasive investigation of tissue microstructural properties and structural connectivity in the \\textit{in vivo} human brain. however, to effectively capture the intricate characteristics of water diffusion at various directions and scales, it is important to employ comprehensive q-space sampling. unfortunately, this requirement leads to long scan times, limiting the clinical applicability of dmri. to address this challenge, we propose ssor, a simultaneous q-space sampling optimization and reconstruction framework. we jointly optimize a subset of q-space samples using a continuous representation of spherical harmonic functions and a reconstruction network. additionally, we integrate the unique properties of diffusion magnetic resonance imaging (dmri) in both the q-space and image domains by applying $l1$-norm and total-variation regularization. the experiments conducted on hcp data demonstrate that ssor has promising strengths both quantitatively and qualitatively and exhibits robustness to noise.","doi":"","created":1704240000000,"updated":"","authors":["jing yang","jian cheng","cheng li","wenxin fan","juan zou","ruoyou wu","shanshan wang"]}
{"id":"2401.01666","title":"an edge-cloud collaboration framework for generative ai service   provision with synergetic big cloud model and small edge models","categories":"cs.ni","abstract":"generative artificial intelligence (genai) offers various services to users through content creation, which is believed to be one of the most important components in future networks. however, training and deploying big artificial intelligence models (baims) introduces substantial computational and communication overhead.this poses a critical challenge to centralized approaches, due to the need of high-performance computing infrastructure and the reliability, secrecy and timeliness issues in long-distance access of cloud services. therefore, there is an urging need to decentralize the services, partly moving them from the cloud to the edge and establishing native genai services to enable private, timely, and personalized experiences. in this paper, we propose a brand-new bottom-up baim architecture with synergetic big cloud model and small edge models, and design a distributed training framework and a task-oriented deployment scheme for efficient provision of native genai services. the proposed framework can facilitate collaborative intelligence, enhance adaptability, gather edge knowledge and alleviate edge-cloud burden. the effectiveness of the proposed framework is demonstrated through an image generation use case. finally, we outline fundamental research directions to fully exploit the collaborative potential of edge and cloud for native genai and baim applications.","doi":"","created":1704240000000,"updated":"","authors":["yuqing tian","zhaoyang zhang","yuzhi yang","zirui chen","zhaohui yang","richeng jin","tony q. s. quek","kai-kit wong"]}
{"id":"2401.01667","title":"mlps compass: what is learned when mlps are combined with plms?","categories":"cs.cl","abstract":"while transformer-based pre-trained language models and their variants exhibit strong semantic representation capabilities, the question of comprehending the information gain derived from the additional components of plms remains an open question in this field. motivated by recent efforts that prove multilayer-perceptrons (mlps) modules achieving robust structural capture capabilities, even outperforming graph neural networks (gnns), this paper aims to quantify whether simple mlps can further enhance the already potent ability of plms to capture linguistic information. specifically, we design a simple yet effective probing framework containing mlps components based on bert structure and conduct extensive experiments encompassing 10 probing tasks spanning three distinct linguistic levels. the experimental results demonstrate that mlps can indeed enhance the comprehension of linguistic structure by plms. our research provides interpretable and valuable insights into crafting variations of plms utilizing mlps for tasks that emphasize diverse linguistic structures.","doi":"","created":1704240000000,"updated":"","authors":["li zhou","wenyu chen","yong cao","dingyi zeng","wanlong liu","hong qu"]}
{"id":"2401.01673","title":"coded beam training","categories":"cs.it eess.sp math.it","abstract":"in extremely large-scale multiple input multiple output (xl-mimo) systems for future sixth-generation (6g) communications, codebook-based beam training stands out as a promising technology to acquire channel state information (csi). despite their effectiveness, when the pilot overhead is limited, existing beam training methods suffer from significant achievable rate degradation for remote users with low signal-to-noise ratio (snr). to tackle this challenge, leveraging the error-correcting capability of channel codes, we introduce channel coding theory into hierarchical beam training to extend the coverage area. specifically, we establish the duality between hierarchical beam training and channel coding, and the proposed coded beam training scheme serves as a general framework. then, we present two specific implementations exemplified by coded beam training methods based on hamming codes and convolutional codes, during which the beam encoding and decoding processes are refined respectively to better accommodate the beam training problem. simulation results have demonstrated that the proposed coded beam training method can enable reliable beam training performance for remote users with low snr while keeping training overhead low.","doi":"","created":1704240000000,"updated":"2024-03-06","authors":["tianyue zheng","jieao zhu","qiumo yu","yongli yan","linglong dai"]}
{"id":"2401.01674","title":"transformer rgbt tracking with spatio-temporal multimodal tokens","categories":"cs.cv","abstract":"many rgbt tracking researches primarily focus on modal fusion design, while overlooking the effective handling of target appearance changes. while some approaches have introduced historical frames or fuse and replace initial templates to incorporate temporal information, they have the risk of disrupting the original target appearance and accumulating errors over time. to alleviate these limitations, we propose a novel transformer rgbt tracking approach, which mixes spatio-temporal multimodal tokens from the static multimodal templates and multimodal search regions in transformer to handle target appearance changes, for robust rgbt tracking. we introduce independent dynamic template tokens to interact with the search region, embedding temporal information to address appearance changes, while also retaining the involvement of the initial static template tokens in the joint feature extraction process to ensure the preservation of the original reliable target appearance information that prevent deviations from the target appearance caused by traditional temporal updates. we also use attention mechanisms to enhance the target features of multimodal template tokens by incorporating supplementary modal cues, and make the multimodal search region tokens interact with multimodal dynamic template tokens via attention mechanisms, which facilitates the conveyance of multimodal-enhanced target change information. our module is inserted into the transformer backbone network and inherits joint feature extraction, search-template matching, and cross-modal interaction. extensive experiments on three rgbt benchmark datasets show that the proposed approach maintains competitive performance compared to other state-of-the-art tracking algorithms while running at 39.1 fps.","doi":"","created":1704240000000,"updated":"","authors":["dengdi sun","yajie pan","andong lu","chenglong li","bin luo"]}
{"id":"2401.01676","title":"performance evaluation of gps trajectory rasterization methods","categories":"eess.sp cs.cv","abstract":"the availability of the global positioning system (gps) trajectory data is increasing along with the availability of different gps receivers and with the increasing use of various mobility services. gps trajectory is an important data source which is used in traffic density detection, transport mode detection, mapping data inferences with the use of different methods such as image processing and machine learning methods. while the data size increases, efficient representation of this type of data is becoming difficult to be used in these methods. a common approach is the representation of gps trajectory information such as average speed, bearing, etc. in raster image form and applying analysis methods. in this study, we evaluate gps trajectory data rasterization using the spatial join functions of qgis, postgis+qgis, and our iterative spatial structured grid aggregation implementation coded in the python programming language. our implementation is also parallelizable, and this parallelization is also included as the fourth method. according to the results of experiment carried out with an example gps trajectory dataset, qgis method and postgis+qgis method showed relatively low performance with respect to our method using the metric of total processing time. postgis+qgis method achieved the best results for spatial join though its total performance decreased quickly while test area size increases. on the other hand, both of our methods' performances decrease directly proportional to gps point. and our methods' performance can be increased proportional to the increase with the number of processor cores and\/or with multiple computing clusters.","doi":"10.1007\/978-3-030-86653-2_1","created":1704240000000,"updated":"","authors":["necip enes gengec","ergin tari"]}
{"id":"2401.01681","title":"hamiltonicity of schrijver graphs and stable kneser graphs","categories":"math.co cs.dm","abstract":"for integers $k\\geq 1$ and $n\\geq 2k+1$, the schrijver graph $s(n,k)$ has as vertices all $k$-element subsets of $[n]:=\\{1,2,\\ldots,n\\}$ that contain no two cyclically adjacent elements, and an edge between any two disjoint sets. more generally, for integers $k\\geq 1$, $s\\geq 2$, and $n \\geq sk+1$, the $s$-stable kneser graph $s(n,k,s)$ has as vertices all $k$-element subsets of $[n]$ in which any two elements are in cyclical distance at least $s$. we prove that all the graphs $s(n,k,s)$, in particular schrijver graphs $s(n,k)=s(n,k,2)$, admit a hamilton cycle that can be computed in time $\\mathcal{o}(n)$ per generated vertex.","doi":"","created":1704240000000,"updated":"2024-05-31","authors":["torsten mütze","n\/a namrata"]}
{"id":"2401.01684","title":"post-hoc evaluation of nodes influence in information cascades: the case   of coordinated accounts","categories":"cs.si cs.cy physics.soc-ph","abstract":"in the last years, social media has gained an unprecedented amount of attention, playing a pivotal role in shaping the contemporary landscape of communication and connection. however, coordinated inhautentic behaviour (cib), defined as orchestrated efforts by entities to deceive or mislead users about their identity and intentions, has emerged as a tactic to exploit the online discourse. in this study, we quantify the efficacy of cib tactics by defining a general framework for evaluating the influence of a subset of nodes in a directed tree. we design two algorithms that provide optimal and greedy post-hoc placement strategies that lead to maximising the configuration influence. we then consider cascades from information spreading on twitter to compare the observed behaviour with our algorithms. the results show that, according to our model, coordinated accounts are quite inefficient in terms of their network influence, thus suggesting that they may play a less pivotal role than expected. moreover, the causes of these poor results may be found in two separate aspects: a bad placement strategy and a scarcity of resources.","doi":"","created":1704240000000,"updated":"","authors":["niccolò di marco","sara brunetti","matteo cinelli","walter quattrociocchi"]}
{"id":"2401.01685","title":"modality exchange network for retinogeniculate visual pathway   segmentation","categories":"eess.iv cs.cv","abstract":"accurate segmentation of the retinogeniculate visual pathway (rgvp) aids in the diagnosis and treatment of visual disorders by identifying disruptions or abnormalities within the pathway. however, the complex anatomical structure and connectivity of rgvp make it challenging to achieve accurate segmentation. in this study, we propose a novel modality exchange network (me-net) that effectively utilizes multi-modal magnetic resonance (mr) imaging information to enhance rgvp segmentation. our me-net has two main contributions. firstly, we introduce an effective multi-modal soft-exchange technique. specifically, we design a channel and spatially mixed attention module to exchange modality information between t1-weighted and fractional anisotropy mr images. secondly, we propose a cross-fusion module that further enhances the fusion of information between the two modalities. experimental results demonstrate that our method outperforms existing state-of-the-art approaches in terms of rgvp segmentation performance.","doi":"","created":1704240000000,"updated":"","authors":["hua han","cheng li","lei xie","yuanjing feng","alou diakite","shanshan wang"]}
{"id":"2401.01686","title":"odtrack: online dense temporal token learning for visual tracking","categories":"cs.cv","abstract":"online contextual reasoning and association across consecutive video frames are critical to perceive instances in visual tracking. however, most current top-performing trackers persistently lean on sparse temporal relationships between reference and search frames via an offline mode. consequently, they can only interact independently within each image-pair and establish limited temporal correlations. to alleviate the above problem, we propose a simple, flexible and effective video-level tracking pipeline, named \\textbf{odtrack}, which densely associates the contextual relationships of video frames in an online token propagation manner. odtrack receives video frames of arbitrary length to capture the spatio-temporal trajectory relationships of an instance, and compresses the discrimination features (localization information) of a target into a token sequence to achieve frame-to-frame association. this new solution brings the following benefits: 1) the purified token sequences can serve as prompts for the inference in the next video frame, whereby past information is leveraged to guide future inference; 2) the complex online update strategies are effectively avoided by the iterative propagation of token sequences, and thus we can achieve more efficient model representation and computation. odtrack achieves a new \\textit{sota} performance on seven benchmarks, while running at real-time speed. code and models are available at \\url{https:\/\/github.com\/gxnu-zhonglab\/odtrack}.","doi":"","created":1704240000000,"updated":"","authors":["yaozong zheng","bineng zhong","qihua liang","zhiyi mo","shengping zhang","xianxian li"]}
{"id":"2401.01689","title":"the collisional particle-in-cell method for the vlasov-maxwell-landau   equations","categories":"physics.plasm-ph cs.na math.na","abstract":"we introduce an extension of the particle-in-cell (pic) method that captures the landau collisional effects in the vlasov-maxwell-landau equations. the method arises from a regularisation of the variational formulation of the landau equation, leading to a discretisation of the collision operator that conserves mass, charge, momentum, and energy, while increasing the (regularised) entropy. the collisional effects appear as a fully deterministic effective force, thus the method does not require any transport-collision splitting. the scheme can be used in arbitrary dimension, and for a general interaction, including the coulomb case. we validate the scheme on scenarios such as the landau damping, the two-stream instability, and the weibel instability, demonstrating its effectiveness in the numerical simulation of plasma.","doi":"","created":1704240000000,"updated":"2024-03-31","authors":["rafael bailo","josé a. carrillo","jingwei hu"]}
{"id":"2401.01690","title":"zero-shot active learning using self supervised learning","categories":"cs.lg","abstract":"deep learning algorithms are often said to be data hungry. the performance of such algorithms generally improve as more and more annotated data is fed into the model. while collecting unlabelled data is easier (as they can be scraped easily from the internet), annotating them is a tedious and expensive task. given a fixed budget available for data annotation, active learning helps selecting the best subset of data for annotation, such that the deep learning model when trained over that subset will have maximum generalization performance under this budget. in this work, we aim to propose a new active learning approach which is model agnostic as well as one doesn't require an iterative process. we aim to leverage self-supervised learnt features for the task of active learning. the benefit of self-supervised learning, is that one can get useful feature representation of the input data, without having any annotation.","doi":"","created":1704240000000,"updated":"","authors":["abhishek sinha","shreya singh"]}
{"id":"2401.01692","title":"predicting challenge moments from students' discourse: a comparison of   gpt-4 to two traditional natural language processing approaches","categories":"cs.cl cs.cy","abstract":"effective collaboration requires groups to strategically regulate themselves to overcome challenges. research has shown that groups may fail to regulate due to differences in members' perceptions of challenges which may benefit from external support. in this study, we investigated the potential of leveraging three distinct natural language processing models: an expert knowledge rule-based model, a supervised machine learning (ml) model and a large language model (llm), in challenge detection and challenge dimension identification (cognitive, metacognitive, emotional and technical\/other challenges) from student discourse, was investigated. the results show that the supervised ml and the llm approaches performed considerably well in both tasks, in contrast to the rule-based approach, whose efficacy heavily relies on the engineered features by experts. the paper provides an extensive discussion of the three approaches' performance for automated detection and support of students' challenge moments in collaborative learning activities. it argues that, although llms provide many advantages, they are unlikely to be the panacea to issues of the detection and feedback provision of socially shared regulation of learning due to their lack of reliability, as well as issues of validity evaluation, privacy and confabulation. we conclude the paper with a discussion on additional considerations, including model transparency to explore feasible and meaningful analytical feedback for students and educators using llms.","doi":"10.1145\/3636555.3636905","created":1704240000000,"updated":"","authors":["wannapon suraworachet","jennifer seon","mutlu cukurova"]}
{"id":"2401.01693","title":"aid-dti: accelerating high-fidelity diffusion tensor imaging with   detail-preserving model-based deep learning","categories":"cs.cv eess.iv","abstract":"deep learning has shown great potential in accelerating diffusion tensor imaging (dti). nevertheless, existing methods tend to suffer from rician noise and detail loss in reconstructing the dti-derived parametric maps especially when sparsely sampled q-space data are used. this paper proposes a novel method, aid-dti (accelerating high fidelity diffusion tensor imaging), to facilitate fast and accurate dti with only six measurements. aid-dti is equipped with a newly designed singular value decomposition (svd)-based regularizer, which can effectively capture fine details while suppressing noise during network training. experimental results on human connectome project (hcp) data consistently demonstrate that the proposed method estimates dti parameter maps with fine-grained details and outperforms three state-of-the-art methods both quantitatively and qualitatively.","doi":"","created":1704240000000,"updated":"","authors":["wenxin fan","jian cheng","cheng li","xinrui ma","jing yang","juan zou","ruoyou wu","qiegen liu","shanshan wang"]}
{"id":"2401.01698","title":"patterns of persistence and diffusibility across the world's languages","categories":"cs.cl","abstract":"language similarities can be caused by genetic relatedness, areal contact, universality, or chance. colexification, i.e. a type of similarity where a single lexical form is used to convey multiple meanings, is underexplored. in our work, we shed light on the linguistic causes of cross-lingual similarity in colexification and phonology, by exploring genealogical stability (persistence) and contact-induced change (diffusibility). we construct large-scale graphs incorporating semantic, genealogical, phonological and geographical data for 1,966 languages. we then show the potential of this resource, by investigating several established hypotheses from previous work in linguistics, while proposing new ones. our results strongly support a previously established hypothesis in the linguistic literature, while offering contradicting evidence to another. our large scale resource opens for further research across disciplines, e.g.~in multilingual nlp and comparative linguistics.","doi":"","created":1704240000000,"updated":"2024-01-05","authors":["yiyi chen","johannes bjerva"]}
{"id":"2401.01699","title":"wordart designer api: user-driven artistic typography synthesis with   large language models on modelscope","categories":"cs.cv cs.cl cs.mm","abstract":"this paper introduces the wordart designer api, a novel framework for user-driven artistic typography synthesis utilizing large language models (llms) on modelscope. we address the challenge of simplifying artistic typography for non-professionals by offering a dynamic, adaptive, and computationally efficient alternative to traditional rigid templates. our approach leverages the power of llms to understand and interpret user input, facilitating a more intuitive design process. we demonstrate through various case studies how users can articulate their aesthetic preferences and functional requirements, which the system then translates into unique and creative typographic designs. our evaluations indicate significant improvements in user satisfaction, design flexibility, and creative expression over existing systems. the wordart designer api not only democratizes the art of typography but also opens up new possibilities for personalized digital communication and design.","doi":"","created":1704240000000,"updated":"2024-01-12","authors":["jun-yan he","zhi-qi cheng","chenyang li","jingdong sun","wangmeng xiang","yusen hu","xianhui lin","xiaoyang kang","zengke jin","bin luo","yifeng geng","xuansong xie","jingren zhou"]}
{"id":"2401.01701","title":"de-hallucinator: mitigating llm hallucinations in code generation tasks   via iterative grounding","categories":"cs.se","abstract":"large language models (llms) trained on datasets of publicly available source code have established a new state of the art in code generation tasks. however, these models are mostly unaware of the code that exists within a specific project, preventing the models from making good use of existing apis. instead, llms often invent, or \"hallucinate\", non-existent apis or produce variants of already existing code. this paper presents de-hallucinator, a technique that grounds the predictions of an llm through a novel combination of retrieving suitable api references and iteratively querying the model with increasingly suitable context information in the prompt. the approach exploits the observation that predictions by llms often resemble the desired code, but they fail to correctly refer to already existing apis. de-hallucinator automatically identifies project-specific api references related to the model's initial predictions and adds these references into the prompt. unlike retrieval-augmented generation (rag), our approach uses the initial prediction(s) by the model to iteratively retrieve increasingly suitable api references. our evaluation applies the approach to two tasks: predicting api usages in python and generating tests in javascript. we show that de-hallucinator consistently improves the generated code across five llms. in particular, the approach improves the edit distance by 23.3-50.6% and the recall of correctly predicted api usages by 23.9-61.0% for code completion, and improves the number of fixed tests that initially failed because of hallucinations by 63.2%, resulting in a 15.5% increase in statement coverage for test generation.","doi":"","created":1704240000000,"updated":"2024-06-19","authors":["aryaz eghbali","michael pradel"]}
{"id":"2401.01702","title":"image sculpting: precise object editing with 3d geometry control","categories":"cs.gr cs.cv","abstract":"we present image sculpting, a new framework for editing 2d images by incorporating tools from 3d geometry and graphics. this approach differs markedly from existing methods, which are confined to 2d spaces and typically rely on textual instructions, leading to ambiguity and limited control. image sculpting converts 2d objects into 3d, enabling direct interaction with their 3d geometry. post-editing, these objects are re-rendered into 2d, merging into the original image to produce high-fidelity results through a coarse-to-fine enhancement process. the framework supports precise, quantifiable, and physically-plausible editing options such as pose editing, rotation, translation, 3d composition, carving, and serial addition. it marks an initial step towards combining the creative freedom of generative models with the precision of graphics pipelines.","doi":"","created":1704153600000,"updated":"","authors":["jiraphon yenphraphai","xichen pan","sainan liu","daniele panozzo","saining xie"]}
{"id":"2401.01710","title":"epa: neural collapse inspired robust out-of-distribution detector","categories":"cs.lg cs.cr","abstract":"out-of-distribution (ood) detection plays a crucial role in ensuring the security of neural networks. existing works have leveraged the fact that in-distribution (id) samples form a subspace in the feature space, achieving state-of-the-art (sota) performance. however, the comprehensive characteristics of the id subspace still leave under-explored. recently, the discovery of neural collapse ($\\mathcal{nc}$) sheds light on novel properties of the id subspace. leveraging insight from $\\mathcal{nc}$, we observe that the principal angle between the features and the id feature subspace forms a superior representation for measuring the likelihood of ood. building upon this observation, we propose a novel $\\mathcal{nc}$-inspired ood scoring function, named entropy-enhanced principal angle (epa), which integrates both the global characteristic of the id subspace and its inner property. we experimentally compare epa with various sota approaches, validating its superior performance and robustness across different network architectures and ood datasets.","doi":"","created":1704240000000,"updated":"","authors":["jiawei zhang","yufan chen","cheng jin","lei zhu","yuantao gu"]}
{"id":"2401.01711","title":"evaluating large language models in semantic parsing for conversational   question answering over knowledge graphs","categories":"cs.cl cs.ir","abstract":"conversational question answering systems often rely on semantic parsing to enable interactive information retrieval, which involves the generation of structured database queries from a natural language input. for information-seeking conversations about facts stored within a knowledge graph, dialogue utterances are transformed into graph queries in a process that is called knowledge-based conversational question answering. this paper evaluates the performance of large language models that have not been explicitly pre-trained on this task. through a series of experiments on an extensive benchmark dataset, we compare models of varying sizes with different prompting techniques and identify common issue types in the generated output. our results demonstrate that large language models are capable of generating graph queries from dialogues, with significant improvements achievable through few-shot prompting and fine-tuning techniques, especially for smaller models that exhibit lower zero-shot performance.","doi":"","created":1704240000000,"updated":"","authors":["phillip schneider","manuel klettner","kristiina jokinen","elena simperl","florian matthes"]}
{"id":"2401.01717","title":"fact-checking based fake news detection: a review","categories":"cs.cv","abstract":"this paper reviews and summarizes the research results on fact-based fake news from the perspectives of tasks and problems, algorithm strategies, and datasets. first, the paper systematically explains the task definition and core problems of fact-based fake news detection. second, the paper summarizes the existing detection methods based on the algorithm principles. third, the paper analyzes the classic and newly proposed datasets in the field, and summarizes the experimental results on each dataset. finally, the paper summarizes the advantages and disadvantages of existing methods, proposes several challenges that methods in this field may face, and looks forward to the next stage of research. it is hoped that this paper will provide reference for subsequent work in the field.","doi":"","created":1704240000000,"updated":"","authors":["yuzhou yang","yangming zhou","qichao ying","zhenxing qian","dan zeng","liang liu"]}
{"id":"2401.01720","title":"local adaptive clustering based image matching for automatic visual   identification","categories":"cs.cv","abstract":"monitoring cameras are extensively utilized in industrial production to monitor equipment running. with advancements in computer vision, device recognition using image features is viable. this paper presents a vision-assisted identification system that implements real-time automatic equipment labeling through image matching in surveillance videos. the system deploys the orb algorithm to extract image features and the gms algorithm to remove incorrect matching points. according to the principles of clustering and template locality, a method known as local adaptive clustering (lac) has been established to enhance label positioning. this method segments matching templates using the cluster center, which improves the efficiency and stability of labels. the experimental results demonstrate that lac effectively curtails the label drift.","doi":"","created":1704240000000,"updated":"","authors":["zhizhen wang"]}
{"id":"2401.01721","title":"limited feedback on measurements: sharing a codebook or a generative   model?","categories":"cs.it eess.sp math.it","abstract":"discrete fourier transform (dft) codebook-based solutions are well-established for limited feedback schemes in frequency division duplex (fdd) systems. in recent years, data-aided solutions have been shown to achieve higher performance, enabled by the adaptivity of the feedback scheme to the propagation environment of the base station (bs) cell. in particular, a versatile limited feedback scheme utilizing gaussian mixture models (gmms) was recently introduced. the scheme supports multi-user communications, exhibits low complexity, supports parallelization, and offers significant flexibility concerning various system parameters. conceptually, a gmm captures environment knowledge and is subsequently transferred to the mobile terminals (mts) for online inference of feedback information. afterward, the bs designs precoders using either directional information or a generative modeling-based approach. a major shortcoming of recent works is that the assessed system performance is only evaluated through synthetic simulation data that is generally unable to fully characterize the features of real-world environments. it raises the question of how the gmm-based feedback scheme performs on real-world measurement data, especially compared to the well-established dft-based solution. our experiments reveal that the gmm-based feedback scheme tremendously improves the system performance measured in terms of sum-rate, allowing to deploy systems with fewer pilots or feedback bits.","doi":"","created":1704240000000,"updated":"","authors":["nurettin turan","benedikt fesl","michael joham","zhengxiang ma","anthony c. k. soong","baoling sheen","weimin xiao","wolfgang utschick"]}
{"id":"2401.01722","title":"splitting methods for differential equations","categories":"math.na cs.na","abstract":"this overview is devoted to splitting methods, a class of numerical integrators intended for differential equations that can be subdivided into different problems easier to solve than the original system. closely connected with this class of integrators are composition methods, in which one or several low-order schemes are composed to construct higher-order numerical approximations to the exact solution. we analyze in detail the order conditions that have to be satisfied by these classes of methods to achieve a given order, and provide some insight about their qualitative properties in connection with geometric numerical integration and the treatment of highly oscillatory problems. since splitting methods have received considerable attention in the realm of partial differential equations, we also cover this subject in the present survey, with special attention to parabolic equations and their problems. an exhaustive list of methods of different orders is collected and tested on simple examples. finally, some applications of splitting methods in different areas, ranging from celestial mechanics to statistics, are also provided.","doi":"","created":1704240000000,"updated":"2024-05-07","authors":["sergio blanes","fernando casas","ander murua"]}
{"id":"2401.01724","title":"lightweight adaptive feature de-drifting for compressed image   classification","categories":"cs.cv","abstract":"jpeg is a widely used compression scheme to efficiently reduce the volume of transmitted images. the artifacts appear among blocks due to the information loss, which not only affects the quality of images but also harms the subsequent high-level tasks in terms of feature drifting. high-level vision models trained on high-quality images will suffer performance degradation when dealing with compressed images, especially on mobile devices. numerous learning-based jpeg artifact removal methods have been proposed to handle visual artifacts. however, it is not an ideal choice to use these jpeg artifact removal methods as a pre-processing for compressed image classification for the following reasons: 1. these methods are designed for human vision rather than high-level vision models; 2. these methods are not efficient enough to serve as pre-processing on resource-constrained devices. to address these issues, this paper proposes a novel lightweight afd module to boost the performance of pre-trained image classification models when facing compressed images. first, a fde-net is devised to generate the spatial-wise fdm in the dct domain. next, the estimated fdm is transmitted to the fe-net to generate the mapping relationship between degraded features and corresponding high-quality features. a simple but effective repconv block equipped with structural re-parameterization is utilized in fe-net, which enriches feature representation in the training phase while maintaining efficiency in the deployment phase. after training on limited compressed images, the afd-module can serve as a \"plug-and-play\" model for pre-trained classification models to improve their performance on compressed images. experiments demonstrate that our proposed afd module can comprehensively improve the accuracy of the pre-trained classification models and significantly outperform the existing methods.","doi":"","created":1704240000000,"updated":"","authors":["long peng","yang cao","yuejin sun","yang wang"]}
{"id":"2401.01728","title":"ravnest: decentralized asynchronous training on heterogeneous devices","categories":"cs.lg cs.ai cs.dc","abstract":"modern deep learning models, growing larger and more complex, have demonstrated exceptional generalization and accuracy due to training on huge datasets. this trend is expected to continue. however, the increasing size of these models poses challenges in training, as traditional centralized methods are limited by memory constraints at such scales. this paper proposes an asynchronous decentralized training paradigm for large modern deep learning models that harnesses the compute power of regular heterogeneous pcs with limited resources connected across the internet to achieve favourable performance metrics. ravnest facilitates decentralized training by efficiently organizing compute nodes into clusters with similar data transfer rates and compute capabilities, without necessitating that each node hosts the entire model. these clusters engage in $\\textit{zero-bubble asynchronous model parallel}$ training, and a $\\textit{parallel multi-ring all-reduce}$ method is employed to effectively execute global parameter averaging across all clusters. we have framed our asynchronous sgd loss function as a block structured optimization problem with delayed updates and derived an optimal convergence rate of $o\\left(\\frac{1}{\\sqrt{k}}\\right)$. we further discuss linear speedup with respect to the number of participating clusters and the bound on the staleness parameter.","doi":"","created":1704240000000,"updated":"2024-05-23","authors":["anirudh rajiv menon","unnikrishnan menon","kailash ahirwar"]}
{"id":"2401.01729","title":"development of impedance and capacitance based sensors for the   estimation of adulterant ingredients in different bio-consumables","categories":"eess.sy cs.sy","abstract":"electrical impedance spectroscopy (eis) technique is found to be an excellent candidate for bio-sensing and food quality monitoring applications due to its rapid, robust, cost-effective and point-of-care approach. the present research work investigates the implementation of eis technique supported by several optical spectroscopic techniques such as ultraviolet-visible (uv-vis) and fourier transform mid infrared (ft-mir) to detect and quantify several toxic adulterants in foods and bio-consumables. a comprehensive understanding on the background theory related to the study has been developed to analyze the overall polarization of the system and the effect of frequency on complex permittivity of such system have been observed. in the current work, the technique is applied to adulterated saccharides, honey and turmeric samples through a prototype sensing device. all the corresponding measurements have been performed by dipping a custom-made parallel plate conductivity cell with unity cell constant inside the solution under test. eis study exhibited a steady variation of electrical parameters such as impedance, capacitance, conductance and current values with increasing adulterant percentage in the solution. variation in such properties due to adulteration provides a systematic sensor plot through which one can determine their percentage of adulteration in unknown adulterated samples. co-efficient of sensitivity has been extracted from the eis data for adulteration study in terms of one of the measured parameters. the results of uv-vis and ft-mir studies have been used for comparative analyses which corroborate with the eis results, wherever applicable.","doi":"","created":1704240000000,"updated":"","authors":["chirantan das"]}
{"id":"2401.01730","title":"staf: 3d human mesh recovery from video with spatio-temporal alignment   fusion","categories":"cs.cv","abstract":"the recovery of 3d human mesh from monocular images has significantly been developed in recent years. however, existing models usually ignore spatial and temporal information, which might lead to mesh and image misalignment and temporal discontinuity. for this reason, we propose a novel spatio-temporal alignment fusion (staf) model. as a video-based model, it leverages coherence clues from human motion by an attention-based temporal coherence fusion module (tcfm). as for spatial mesh-alignment evidence, we extract fine-grained local information through predicted mesh projection on the feature maps. based on the spatial features, we further introduce a multi-stage adjacent spatial alignment fusion module (safm) to enhance the feature representation of the target frame. in addition to the above, we propose an average pooling module (apm) to allow the model to focus on the entire input sequence rather than just the target frame. this method can remarkably improve the smoothness of recovery results from video. extensive experiments on 3dpw, mpii3d, and h36m demonstrate the superiority of staf. we achieve a state-of-the-art trade-off between precision and smoothness. our code and more video results are on the project page https:\/\/yw0208.github.io\/staf\/","doi":"","created":1704240000000,"updated":"","authors":["wei yao","hongwen zhang","yunlian sun","jinhui tang"]}
{"id":"2401.01732","title":"task and explanation network","categories":"cs.lg cs.ai cs.ne","abstract":"explainability in deep networks has gained increased importance in recent years. we argue herein that an ai must be tasked not just with a task but also with an explanation of why said task was accomplished as such. we present a basic framework -- task and explanation network (tenet) -- which fully integrates task completion and its explanation. we believe that the field of ai as a whole should insist -- quite emphatically -- on explainability.","doi":"","created":1704240000000,"updated":"","authors":["moshe sipper"]}
{"id":"2401.01733","title":"investigating the suitability of concept drift detection for detecting   leakages in water distribution networks","categories":"cs.lg","abstract":"leakages are a major risk in water distribution networks as they cause water loss and increase contamination risks. leakage detection is a difficult task due to the complex dynamics of water distribution networks. in particular, small leakages are hard to detect. from a machine-learning perspective, leakages can be modeled as concept drift. thus, a wide variety of drift detection schemes seems to be a suitable choice for detecting leakages. in this work, we explore the potential of model-loss-based and distribution-based drift detection methods to tackle leakage detection. we additionally discuss the issue of temporal dependencies in the data and propose a way to cope with it when applying distribution-based detection. we evaluate different methods systematically for leakages of different sizes and detection times. additionally, we propose a first drift-detection-based technique for localizing leakages.","doi":"","created":1704240000000,"updated":"","authors":["valerie vaquet","fabian hinder","barbara hammer"]}
{"id":"2401.01734","title":"learning keypoints for robotic cloth manipulation using synthetic data","categories":"cs.cv","abstract":"assistive robots should be able to wash, fold or iron clothes. however, due to the variety, deformability and self-occlusions of clothes, creating robot systems for cloth manipulation is challenging. synthetic data is a promising direction to improve generalization, but the sim-to-real gap limits its effectiveness. to advance the use of synthetic data for cloth manipulation tasks such as robotic folding, we present a synthetic data pipeline to train keypoint detectors for almost-flattened cloth items. to evaluate its performance, we have also collected a real-world dataset. we train detectors for both t-shirts, towels and shorts and obtain an average precision of 64% and an average keypoint distance of 18 pixels. fine-tuning on real-world data improves performance to 74% map and an average distance of only 9 pixels. furthermore, we describe failure modes of the keypoint detectors and compare different approaches to obtain cloth meshes and materials. we also quantify the remaining sim-to-real gap and argue that further improvements to the fidelity of cloth assets will be required to further reduce this gap. the code, dataset and trained models are available","doi":"","created":1704240000000,"updated":"2024-05-21","authors":["thomas lips","victor-louis de gusseme","francis wyffels"]}
{"id":"2401.01735","title":"economics arena for large language models","categories":"cs.gt","abstract":"large language models (llms) have been extensively used as the backbones for general-purpose agents, and some economics literature suggest that llms are capable of playing various types of economics games. following these works, to overcome the limitation of evaluating llms using static benchmarks, we propose to explore competitive games as an evaluation for llms to incorporate multi-players and dynamicise the environment. by varying the game history revealed to llms-based players, we find that most of llms are rational in that they play strategies that can increase their payoffs, but not as rational as indicated by nash equilibria (nes). moreover, when game history are available, certain types of llms, such as gpt-4, can converge faster to the ne strategies, which suggests higher rationality level in comparison to other models. in the meantime, certain types of llms can win more often when game history are available, and we argue that the winning rate reflects the reasoning ability with respect to the strategies of other players. throughout all our experiments, we observe that the ability to strictly follow the game rules described by natural languages also vary among the llms we tested. in this work, we provide an economics arena for the llms research community as a dynamic simulation to test the above-mentioned abilities of llms, i.e. rationality, strategic reasoning ability, and instruction-following capability.","doi":"","created":1704240000000,"updated":"","authors":["shangmin guo","haoran bu","haochuan wang","yi ren","dianbo sui","yuming shang","siting lu"]}
{"id":"2401.01736","title":"few-shot adaptation of multi-modal foundation models: a survey","categories":"cs.cv","abstract":"multi-modal (vision-language) models, such as clip, are replacing traditional supervised pre-training models (e.g., imagenet-based pre-training) as the new generation of visual foundation models. these models with robust and aligned semantic representations learned from billions of internet image-text pairs and can be applied to various downstream tasks in a zero-shot manner. however, in some fine-grained domains like medical imaging and remote sensing, the performance of multi-modal foundation models often leaves much to be desired. consequently, many researchers have begun to explore few-shot adaptation methods for these models, gradually deriving three main technical approaches: 1) prompt-based methods, 2) adapter-based methods, and 3) external knowledge-based methods. nevertheless, this rapidly developing field has produced numerous results without a comprehensive survey to systematically organize the research progress. therefore, in this survey, we introduce and analyze the research advancements in few-shot adaptation methods for multi-modal models, summarizing commonly used datasets and experimental setups, and comparing the results of different methods. in addition, due to the lack of reliable theoretical support for existing methods, we derive the few-shot adaptation generalization error bound for multi-modal models. the theorem reveals that the generalization error of multi-modal foundation models is constrained by three factors: domain gap, model capacity, and sample size. based on this, we propose three possible solutions from the following aspects: 1) adaptive domain generalization, 2) adaptive model selection, and 3) adaptive knowledge utilization.","doi":"","created":1704240000000,"updated":"2024-01-04","authors":["fan liu","tianshu zhang","wenwen dai","wenwen cai","xiaocong zhou","delong chen"]}
{"id":"2401.01738","title":"integrated sensing and communication with massive mimo: a unified tensor   approach for channel and target parameter estimation","categories":"cs.it eess.sp math.it","abstract":"benefitting from the vast spatial degrees of freedom, the amalgamation of integrated sensing and communication (isac) and massive multiple-input multiple-output (mimo) is expected to simultaneously improve spectral and energy efficiencies as well as the sensing capability. however, a large number of antennas deployed in massive mimo-isac raises critical challenges in acquiring both accurate channel state information and target parameter information. to overcome these two challenges with a unified framework, we first analyze their underlying system models and then propose a novel tensor-based approach that addresses both the channel estimation and target sensing problems. specifically, by parameterizing the high-dimensional communication channel exploiting a small number of physical parameters, we associate the channel state information with the sensing parameters of targets in terms of angular, delay, and doppler dimensions. then, we propose a shared training pattern adopting the same time-frequency resources such that both the channel estimation and target parameter estimation can be formulated as a canonical polyadic decomposition problem with a similar mathematical expression. on this basis, we first investigate the uniqueness condition of the tensor factorization and the maximum number of resolvable targets by utilizing the specific vandermonde","doi":"10.1109\/twc.2024.3351856","created":1704240000000,"updated":"","authors":["ruoyu zhang","lei cheng","shuai wang","yi lou","yulong gao","wen wu","derrick wing kwan ng"]}
{"id":"2401.01739","title":"a soft continuum robot with self-controllable variable curvature","categories":"cs.ro","abstract":"this paper introduces a new type of soft continuum robot, called scores, which is capable of self-controlling continuously its curvature at the segment level; in contrast to previous designs which either require external forces or machine elements, or whose variable curvature capabilities are discrete -- depending on the number of locking mechanisms and segments. the ability to have a variable curvature, whose control is continuous and independent from external factors, makes a soft continuum robot more adaptive in constrained environments, similar to what is observed in nature in the elephant's trunk or ostrich's neck for instance which exhibit multiple curvatures. to this end, our soft continuum robot enables reconfigurable variable curvatures utilizing a variable stiffness growing spine based on micro-particle granular jamming for the first time. we detail the design of the proposed robot, presenting its modeling through beam theory and fea simulation -- which is validated through experiments. the robot's versatile bending profiles are then explored in experiments and an application to grasp fruits at different configurations is demonstrated.","doi":"10.1109\/lra.2024.3352359","created":1704240000000,"updated":"2024-01-19","authors":["xinran wang","qiujie lu","dongmyoung lee","zhongxue gan","nicolas rojas"]}
{"id":"2401.01740","title":"minimizing the weighted number of tardy jobs is w[1]-hard","categories":"cs.ds cs.cc","abstract":"we consider the $1||\\sum w_j u_j$ problem, the problem of minimizing the weighted number of tardy jobs on a single machine. this problem is one of the most basic and fundamental problems in scheduling theory, with several different applications both in theory and practice. we prove that $1||\\sum w_j u_j$ is w[1]-hard with respect to the number $p_{\\#}$ of different processing times in the input, as well as with respect to the number $w_{\\#}$ of different weights in the input. this, along with previous work, provides a complete picture for $1||\\sum w_j u_j$ from the perspective of parameterized complexity, as well as almost tight complexity bounds for the problem under the exponential time hypothesis (eth).","doi":"","created":1704240000000,"updated":"","authors":["klaus heeger","danny hermelin"]}
{"id":"2401.01745","title":"explicit stabilized multirate methods for the monodomain model in   cardiac electrophysiology","categories":"math.na cs.na","abstract":"fully explicit stabilized multirate (mrkc) methods are well-suited for the numerical solution of large multiscale systems of stiff ordinary differential equations thanks to their improved stability properties. to demonstrate their efficiency for the numerical solution of stiff, multiscale, nonlinear parabolic pde's, we apply mrkc methods to the monodomain equation from cardiac electrophysiology. in doing so, we propose an improved version, specifically tailored to the monodomain model, which leads to the explicit exponential multirate stabilized (emrkc) method. several numerical experiments are conducted to evaluate the efficiency of both mrkc and emrkc, while taking into account different finite element meshes (structured and unstructured) and realistic ionic models. the new emrkc method typically outperforms a standard implicit-explicit baseline method for cardiac electrophysiology. code profiling and strong scalability results further demonstrate that emrkc is faster and inherently parallel without sacrificing accuracy.","doi":"","created":1704240000000,"updated":"2024-06-24","authors":["giacomo rosilho de souza","marcus j. grote","simone pezzuto","rolf krause"]}
{"id":"2401.01749","title":"few-shot image generation via information transfer from the built   geodesic surface","categories":"cs.cv","abstract":"images generated by most of generative models trained with limited data often exhibit deficiencies in either fidelity, diversity, or both. one effective solution to address the limitation is few-shot generative model adaption. however, the type of approaches typically rely on a large-scale pre-trained model, serving as a source domain, to facilitate information transfer to the target domain. in this paper, we propose a method called information transfer from the built geodesic surface (itbgs), which contains two module: feature augmentation on geodesic surface (fags); interpolation and regularization (i\\&r). with the fags module, a pseudo-source domain is created by projecting image features from the training dataset into the pre-shape space, subsequently generating new features on the geodesic surface. thus, no pre-trained models is needed for the adaption process during the training of generative models with fags. i\\&r module are introduced for supervising the interpolated images and regularizing their relative distances, respectively, to further enhance the quality of generated images. through qualitative and quantitative experiments, we demonstrate that the proposed method consistently achieves optimal or comparable results across a diverse range of semantically distinct datasets, even in extremely few-shot scenarios.","doi":"","created":1704240000000,"updated":"2024-03-02","authors":["yuexing han","liheng ruan","bing wang"]}
{"id":"2401.01750","title":"towards robust semantic segmentation against patch-based attack via   attention refinement","categories":"cs.cv","abstract":"the attention mechanism has been proven effective on various visual tasks in recent years. in the semantic segmentation task, the attention mechanism is applied in various methods, including the case of both convolution neural networks (cnn) and vision transformer (vit) as backbones. however, we observe that the attention mechanism is vulnerable to patch-based adversarial attacks. through the analysis of the effective receptive field, we attribute it to the fact that the wide receptive field brought by global attention may lead to the spread of the adversarial patch. to address this issue, in this paper, we propose a robust attention mechanism (ram) to improve the robustness of the semantic segmentation model, which can notably relieve the vulnerability against patch-based attacks. compared to the vallina attention mechanism, ram introduces two novel modules called max attention suppression and random attention dropout, both of which aim to refine the attention matrix and limit the influence of a single adversarial patch on the semantic segmentation results of other positions. extensive experiments demonstrate the effectiveness of our ram to improve the robustness of semantic segmentation models against various patch-based attack methods under different attack settings.","doi":"","created":1704240000000,"updated":"2024-05-09","authors":["zheng yuan","jie zhang","yude wang","shiguang shan","xilin chen"]}
{"id":"2401.01751","title":"text mining arxiv: a look through quantitative finance papers","categories":"cs.dl cs.ir q-fin.gn","abstract":"this paper explores articles hosted on the arxiv preprint server with the aim to uncover valuable insights hidden in this vast collection of research. employing text mining techniques and through the application of natural language processing methods, we examine the contents of quantitative finance papers posted in arxiv from 1997 to 2022. we extract and analyze crucial information from the entire documents, including the references, to understand the topics trends over time and to find out the most cited researchers and journals on this domain. additionally, we compare numerous algorithms to perform topic modeling, including state-of-the-art approaches.","doi":"","created":1704240000000,"updated":"2024-04-05","authors":["michele leonardo bianchi"]}
{"id":"2401.01752","title":"fulllora-at: efficiently boosting the robustness of pretrained vision   transformers","categories":"cs.cv","abstract":"in recent years, the vision transformer (vit) model has gradually become mainstream in various computer vision tasks, and the robustness of the model has received increasing attention. however, existing large models tend to prioritize performance during training, potentially neglecting the robustness, which may lead to serious security concerns. in this paper, we establish a new challenge: exploring how to use a small number of additional parameters for adversarial finetuning to quickly and effectively enhance the adversarial robustness of a standardly trained model. to address this challenge, we develop the novel lnlora module, incorporating a learnable layer normalization before the conventional lora module, which helps mitigate magnitude differences in parameters between the adversarial and standard training paradigms.   furthermore, we propose the fulllora-at framework by integrating the learnable lnlora modules into all key components of vit-based models while keeping the pretrained model frozen, which can significantly improve the model robustness via adversarial finetuning in a parameter-efficient manner.   extensive experiments on cifar-10, cifar-100, and imagenette demonstrate the superiority of our proposed fulllora-at framework. it achieves comparable robustness with full finetuning while only requiring about 5% of the learnable parameters. this also effectively addresses concerns regarding extra model storage space and enormous training time caused by adversarial finetuning.","doi":"","created":1704240000000,"updated":"","authors":["zheng yuan","jie zhang","shiguang shan"]}
{"id":"2401.01753","title":"a generative ai assistant to accelerate cloud migration","categories":"cs.ai","abstract":"we present a tool that leverages generative ai to accelerate the migration of on-premises applications to the cloud. the cloud migration llm accepts input from the user specifying the parameters of their migration, and outputs a migration strategy with an architecture diagram. a user study suggests that the migration llm can assist inexperienced users in finding the right cloud migration profile, while avoiding complexities of a manual approach.","doi":"","created":1704240000000,"updated":"","authors":["amal vaidya","mohan krishna vankayalapati","jacky chan","senad ibraimoski","sean moran"]}
{"id":"2401.01754","title":"using ai\/ml to find and remediate enterprise secrets in code & document   sharing platforms","categories":"cs.se cs.ai","abstract":"we introduce a new challenge to the software development community: 1) leveraging ai to accurately detect and flag up secrets in code and on popular document sharing platforms that frequently used by developers, such as confluence and 2) automatically remediating the detections (e.g. by suggesting password vault functionality). this is a challenging, and mostly unaddressed task. existing methods leverage heuristics and regular expressions, that can be very noisy, and therefore increase toil on developers. the next step - modifying code itself - to automatically remediate a detection, is a complex task. we introduce two baseline ai models that have good detection performance and propose an automatic mechanism for remediating secrets found in code, opening up the study of this task to the wider community.","doi":"","created":1704240000000,"updated":"","authors":["gregor kerr","david algorry","senad ibraimoski","peter maciver","sean moran"]}
{"id":"2401.01755","title":"incremental fastpitch: chunk-based high quality text to speech","categories":"cs.sd cs.ai eess.as","abstract":"parallel text-to-speech models have been widely applied for real-time speech synthesis, and they offer more controllability and a much faster synthesis process compared with conventional auto-regressive models. although parallel models have benefits in many aspects, they become naturally unfit for incremental synthesis due to their fully parallel architecture such as transformer. in this work, we propose incremental fastpitch, a novel fastpitch variant capable of incrementally producing high-quality mel chunks by improving the architecture with chunk-based fft blocks, training with receptive-field constrained chunk attention masks, and inference with fixed size past model states. experimental results show that our proposal can produce speech quality comparable to the parallel fastpitch, with a significant lower latency that allows even lower response time for real-time speech applications.","doi":"","created":1704240000000,"updated":"","authors":["muyang du","chuan liu","junjie lai"]}
{"id":"2401.01756","title":"fuzzy logic controller design for mobile robot outdoor navigation","categories":"cs.ro cs.sy eess.sy","abstract":"many researchers around the world are researching to get control solutions that enhance robots' ability to navigate in dynamic environments autonomously. however, until these days robots have limited capability and many navigation tasks on earth and other planets have been difficult so far. this paperwork presents the development of a control system for a differential drive-wheeled mobile robot that autonomously controls its position, heading, and speed based on destination information given and surrounding data gathered through mounted proximity and gps sensors. the intelligence of this control system is implemented by using a fuzzy logic algorithm which is a very powerful tool to handle un-modeled systems like the dynamically changing environment dealt with in this research. the fuzzy controller is used to address the problems associated with navigation in an obstacle-strewn environment. such issues include position estimation, path planning, and obstacle avoidance. in this study modeling, design, and simulation of the system have been done. the simulation result shows that the developed mobile robot travels successfully from any location to the destination location without colliding with obstacles.","doi":"","created":1704240000000,"updated":"2024-01-09","authors":["assefinew wondosen","dereje shiferaw"]}
{"id":"2401.01758","title":"notes on the swift method based on shannon wavelets for option pricing   -- revisited","categories":"q-fin.cp cs.na math.na","abstract":"this note revisits the swift method based on shannon wavelets to price european options under models with a known characteristic function in 2023. in particular, it discusses some possible improvements and exposes some concrete drawbacks of the method.","doi":"","created":1704240000000,"updated":"2024-01-07","authors":["fabien le floc'h"]}
{"id":"2401.01759","title":"vga: vision and graph fused attention network for rumor detection","categories":"cs.si cs.cl cs.cv cs.mm","abstract":"with the development of social media, rumors have been spread broadly on social media platforms, causing great harm to society. beside textual information, many rumors also use manipulated images or conceal textual information within images to deceive people and avoid being detected, making multimodal rumor detection be a critical problem. the majority of multimodal rumor detection methods mainly concentrate on extracting features of source claims and their corresponding images, while ignoring the comments of rumors and their propagation structures. these comments and structures imply the wisdom of crowds and are proved to be crucial to debunk rumors. moreover, these methods usually only extract visual features in a basic manner, seldom consider tampering or textual information in images. therefore, in this study, we propose a novel vision and graph fused attention network (vga) for rumor detection to utilize propagation structures among posts so as to obtain the crowd opinions and further explore visual tampering features, as well as the textual information hidden in images. we conduct extensive experiments on three datasets, demonstrating that vga can effectively detect multimodal rumors and outperform state-of-the-art methods significantly.","doi":"","created":1704240000000,"updated":"","authors":["lin bai","caiyan jia","ziying song","chaoqun cui"]}
{"id":"2401.01761","title":"cross-target stance detection by exploiting target analytical   perspectives","categories":"cs.cl","abstract":"cross-target stance detection (ctsd) is an important task, which infers the attitude of the destination target by utilizing annotated data derived from the source target. one important approach in ctsd is to extract domain-invariant features to bridge the knowledge gap between multiple targets. however, the analysis of informal and short text structure, and implicit expressions, complicate the extraction of domain-invariant knowledge. in this paper, we propose a multi-perspective prompt-tuning (mppt) model for ctsd that uses the analysis perspective as a bridge to transfer knowledge. first, we develop a two-stage instruct-based chain-of-thought method (tscot) to elicit target analysis perspectives and provide natural language explanations (nles) from multiple viewpoints by formulating instructions based on large language model (llm). second, we propose a multi-perspective prompt-tuning framework (multipln) to fuse the nles into the stance predictor. extensive experiments results demonstrate the superiority of mppt against the state-of-the-art baseline methods.","doi":"","created":1704240000000,"updated":"2024-01-03","authors":["daijun ding","rong chen","liwen jing","bowen zhang","xu huang","li dong","xiaowen zhao","ge song"]}
{"id":"2401.01762","title":"independent low-rank matrix analysis based on the sinkhorn divergence   source model for blind source separation","categories":"cs.sd eess.as","abstract":"the so-called independent low-rank matrix analysis (ilrma) has demonstrated a great potential for dealing with the problem of determined blind source separation (bss) for audio and speech signals. this method assumes that the spectra from different frequency bands are independent and the spectral coefficients in any frequency band are gaussian distributed. the itakura-saito divergence is then employed to estimate the source model related parameters. in reality, however, the spectral coefficients from different frequency bands may be dependent, which is not considered in the existing ilrma algorithm. this paper presents an improved version of ilrma, which considers the dependency between the spectral coefficients from different frequency bands. the sinkhorn divergence is then exploited to optimize the source model parameters. as a result of using the cross-band information, the bss performance is improved. but the number of parameters to be estimated also increases significantly, and so is the computational complexity. to reduce the algorithm complexity, we apply the kronecker product to decompose the modeling matrix into the product of a number of matrices of much smaller dimensionality. an efficient algorithm is then developed to implement the sinkhorn divergence based bss algorithm and the complexity is reduced by an order of magnitude.","doi":"","created":1704240000000,"updated":"","authors":["jianyu wang","shanzheng guan","jingdong chen","jacob benesty"]}
{"id":"2401.01763","title":"multichannel blind speech source separation with a disjoint constraint   source model","categories":"cs.sd eess.as","abstract":"multichannel convolutive blind speech source separation refers to the problem of separating different speech sources from the observed multichannel mixtures without much a priori information about the mixing system. multichannel nonnegative matrix factorization (mnmf) has been proven to be one of the most powerful separation frameworks and the representative algorithms such as mnmf and the independent low-rank matrix analysis (ilrma) have demonstrated great performance. however, the sparseness properties of speech source signals are not fully taken into account in such a framework. it is well known that speech signals are sparse in nature, which is considered in this work to improve the separation performance. specifically, we utilize the bingham and laplace distributions to formulate a disjoint constraint regularizer, which is subsequently incorporated into both mnmf and ilrma. we then derive majorization-minimization rules for updating parameters related to the source model, resulting in the development of two enhanced algorithms: s-mnmf and s-ilrma. comprehensive simulations are conducted, and the results unequivocally demonstrate the efficacy of our proposed methodologies.","doi":"","created":1704240000000,"updated":"","authors":["jianyu wang","shanzheng guan"]}
{"id":"2401.01772","title":"a novel paradigm for neural computation: x-net with learnable neurons   and adaptable structure","categories":"cs.ai cs.ni","abstract":"multilayer perception (mlp) has permeated various disciplinary domains, ranging from bioinformatics to financial analytics, where their application has become an indispensable facet of contemporary scientific research endeavors. however, mlp has obvious drawbacks. 1), the type of activation function is single and relatively fixed, which leads to poor `representation ability' of the network, and it is often to solve simple problems with complex networks; 2), the network structure is not adaptive, it is easy to cause network structure redundant or insufficient. in this work, we propose a novel neural network paradigm x-net promising to replace mlps. x-net can dynamically learn activation functions individually based on derivative information during training to improve the network's representational ability for specific tasks. at the same time, x-net can precisely adjust the network structure at the neuron level to accommodate tasks of varying complexity and reduce computational costs. we show that x-net outperforms mlps in terms of representational capability. x-net can achieve comparable or even better performance than mlp with much smaller parameters on regression and classification tasks. specifically, in terms of the number of parameters, x-net is only 3% of mlp on average and only 1.1% under some tasks. we also demonstrate x-net's ability to perform scientific discovery on data from various disciplines such as energy, environment, and aerospace, where x-net is shown to help scientists discover new laws of mathematics or physics.","doi":"","created":1704240000000,"updated":"2024-07-12","authors":["yanjie li","weijun li","lina yu","min wu","jinyi liu","wenqiang li","meilan hao","shu wei","yusong deng","liping zhang","xiaoli dong","hong qin","xin ning","yugui zhang","baoli lu","jian xu","shuang li"]}
{"id":"2401.01779","title":"lossy compression of individual sequences revisited: fundamental limits   of finite-state encoders","categories":"cs.it math.it","abstract":"we extend ziv and lempel's model of finite-state encoders to the realm of lossy compression of individual sequences. in particular, the model of the encoder includes a finite-state reconstruction codebook followed by an information lossless finite-state encoder that compresses the reconstruction codeword with no additional distortion. we first derive two different lower bounds to the compression ratio that depend on the number of states of the lossless encoder. both bounds are asymptotically achievable by conceptually simple coding schemes. we then show that when the number of states of the lossless encoder is large enough in terms of the reconstruction block-length, the performance can be improved, sometimes significantly so. in particular, the improved performance is achievable using a random-coding ensemble that is universal, not only in terms of the source sequence, but also in terms of the distortion measure.","doi":"","created":1704240000000,"updated":"","authors":["neri merhav"]}
{"id":"2401.01780","title":"navigating uncertainty: optimizing api dependency for hallucination   reduction in closed-book question answering","categories":"cs.cl cs.ir","abstract":"while large language models (llm) are able to accumulate and restore knowledge, they are still prone to hallucination. especially when faced with factual questions, llm cannot only rely on knowledge stored in parameters to guarantee truthful and correct answers. augmenting these models with the ability to search on external information sources, such as the web, is a promising approach to ground knowledge to retrieve information. however, searching in a large collection of documents introduces additional computational\/time costs. an optimal behavior would be to query external resources only when the llm is not confident about answers. in this paper, we propose a new llm able to self-estimate if it is able to answer directly or needs to request an external tool. we investigate a supervised approach by introducing a hallucination masking mechanism in which labels are generated using a close book question-answering task. in addition, we propose to leverage parameter-efficient fine-tuning techniques to train our model on a small amount of data. our model directly provides answers for $78.2\\%$ of the known queries and opts to search for $77.2\\%$ of the unknown ones. this results in the api being utilized only $62\\%$ of the time.","doi":"","created":1704240000000,"updated":"","authors":["pierre erbacher","louis falissar","vincent guigue","laure soulier"]}
{"id":"2401.01781","title":"evaluating trustworthiness of online news publishers via article   classification","categories":"cs.ir","abstract":"the proliferation of low-quality online information in today's era has underscored the need for robust and automatic mechanisms to evaluate the trustworthiness of online news publishers. in this paper, we analyse the trustworthiness of online news media outlets by leveraging a dataset of 4033 news stories from 40 different sources. we aim to infer the trustworthiness level of the source based on the classification of individual articles' content. the trust labels are obtained from newsguard, a journalistic organization that evaluates news sources using well-established editorial and publishing criteria. the results indicate that the classification model is highly effective in classifying the trustworthiness levels of the news articles. this research has practical applications in alerting readers to potentially untrustworthy news sources, assisting journalistic organizations in evaluating new or unfamiliar media outlets and supporting the selection of articles for their trustworthiness assessment.","doi":"","created":1704240000000,"updated":"","authors":["john bianchi","manuel pratelli","marinella petrocchi","fabio pinelli"]}
{"id":"2401.01782","title":"profiling the carbon footprint of performance bugs","categories":"cs.se","abstract":"much debate nowadays is devoted to the impacts of modern information and communication technology on global carbon emissions. green information and communication technology is a paradigm creating a sustainable and environmentally friendly computing field that tries to minimize the adverse effects on the environment. green information and communication technology are under constant development nowadays. thus, in this paper, we undertake the problem of performance bugs that, until recently, have never been studied so profoundly. we assume that inappropriate software implementations can have a crucial influence on global carbon emissions. here, we classify those performance bugs and develop inappropriate implementations of four programs written in c++. to mitigate these simulated performance bugs, measuring software and hardware methods that can estimate the increased carbon footprint properly were proposed.","doi":"","created":1704240000000,"updated":"","authors":["iztok fister","dušan fister","vili podgorelec","iztok fister"]}
{"id":"2401.01783","title":"approximating numerical fluxes using fourier neural operators for   hyperbolic conservation laws","categories":"math.na cs.lg cs.na","abstract":"traditionally, classical numerical schemes have been employed to solve partial differential equations (pdes) using computational methods. recently, neural network-based methods have emerged. despite these advancements, neural network-based methods, such as physics-informed neural networks (pinns) and neural operators, exhibit deficiencies in robustness and generalization. to address these issues, numerous studies have integrated classical numerical frameworks with machine learning techniques, incorporating neural networks into parts of traditional numerical methods. in this study, we focus on hyperbolic conservation laws by replacing traditional numerical fluxes with neural operators. to this end, we developed loss functions inspired by established numerical schemes related to conservation laws and approximated numerical fluxes using fourier neural operators (fnos). our experiments demonstrated that our approach combines the strengths of both traditional numerical schemes and fnos, outperforming standard fno methods in several respects. for instance, we demonstrate that our method is robust, has resolution invariance, and is feasible as a data-driven method. in particular, our method can make continuous predictions over time and exhibits superior generalization capabilities with out-of-distribution (ood) samples, which are challenges that existing neural operator methods encounter.","doi":"","created":1704240000000,"updated":"2024-05-13","authors":["taeyoung kim","myungjoo kang"]}
{"id":"2401.01786","title":"an experimental sorting method for improving metagenomic data encoding","categories":"cs.it math.it q-bio.gn","abstract":"minimizing data storage poses a significant challenge in large-scale metagenomic projects. in this paper, we present a new method for improving the encoding of fastq files generated by metagenomic sequencing. this method incorporates metagenomic classification followed by a recursive filter for clustering reads by dna sequence similarity to improve the overall reference-free compression. in the results, we show an overall improvement in the compression of several datasets. as hypothesized, we show a progressive compression gain for higher coverage depth and number of identified species. additionally, we provide an implementation that is freely available at https:\/\/github.com\/cobilab\/mizar and can be customized to work with other fastq compression tools.","doi":"","created":1704240000000,"updated":"","authors":["diogo pratas","armando j. pinho"]}
{"id":"2401.01787","title":"impact of ris on outage probability and ergodic rate in wireless powered   communication","categories":"cs.it cs.ni math.it","abstract":"wireless powered communication (wpc) combines information and energy transmission for energy-constrained nodes. reconfigurable intelligent surfaces (riss) are capable of controlling radio signals in a dynamic and goal-oriented manner. this paper investigates the combination of ris and wpc to enhance the performance of an energy-constrained user. using an ris, a base station, and a wireless user transmit energy and information signals, respectively. we derive closed-form expressions for outage probability and secrecy rate to analyze the performance of the proposed framework. based on the theoretical analysis and simulation results, valuable insights are revealed and parameter selection is demonstrated.","doi":"","created":1704240000000,"updated":"","authors":["waqas khalid","manish nair","trinh van chien","heejung yu"]}
{"id":"2401.01788","title":"applications of machine learning and iot for outdoor air pollution   monitoring and prediction: a systematic literature review","categories":"cs.lg cs.ai","abstract":"according to the world health organization (who), air pollution kills seven million people every year. outdoor air pollution is a major environmental health problem affecting low, middle, and high-income countries. in the past few years, the research community has explored iot-enabled machine learning applications for outdoor air pollution prediction. the general objective of this paper is to systematically review applications of machine learning and internet of things (iot) for outdoor air pollution prediction and the combination of monitoring sensors and input features used. two research questions were formulated for this review. 1086 publications were collected in the initial prisma stage. after the screening and eligibility phases, 37 papers were selected for inclusion. a cost-based analysis was conducted on the findings to highlight high-cost monitoring, low-cost iot and hybrid enabled prediction. three methods of prediction were identified: time series, feature-based and spatio-temporal. this review's findings identify major limitations in applications found in the literature, namely lack of coverage, lack of diversity of data and lack of inclusion of context-specific features. this review proposes directions for future research and underlines practical implications in healthcare, urban planning, global synergy and smart cities.","doi":"","created":1704240000000,"updated":"","authors":["ihsane gryech","chaimae assad","mounir ghogho","abdellatif kobbane"]}
{"id":"2401.01789","title":"deep learning the hurst parameter of linear fractional processes and   assessing its reliability","categories":"stat.ml cs.ai cs.lg","abstract":"this research explores the reliability of deep learning, specifically long short-term memory (lstm) networks, for estimating the hurst parameter in fractional stochastic processes. the study focuses on three types of processes: fractional brownian motion (fbm), fractional ornstein-uhlenbeck (fou) process, and linear fractional stable motions (lfsm). the work involves a fast generation of extensive datasets for fbm and fou to train the lstm network on a large volume of data in a feasible time. the study analyses the accuracy of the lstm network's hurst parameter estimation regarding various performance measures like rmse, mae, mre, and quantiles of the absolute and relative errors. it finds that lstm outperforms the traditional statistical methods in the case of fbm and fou processes; however, it has limited accuracy on lfsm processes. the research also delves into the implications of training length and valuation sequence length on the lstm's performance. the methodology is applied by estimating the hurst parameter in li-ion battery degradation data and obtaining confidence bounds for the estimation. the study concludes that while deep learning methods show promise in parameter estimation of fractional processes, their effectiveness is contingent on the process type and the quality of training data.","doi":"","created":1704240000000,"updated":"","authors":["dániel boros","bálint csanády","iván ivkovic","lóránt nagy","andrás lukács","lászló márkus"]}
{"id":"2401.01791","title":"moonshot: optimizing chain-based rotating leader bft via optimistic   proposals","categories":"cs.dc cs.ni","abstract":"existing chain-based rotating-leader bft smr protocols for the partially synchronous network model with constant commit latencies incur block periods of at least $2\\delta$ (where $\\delta$ is the message transmission latency). while a protocol with a block period of $\\delta$ exists under the synchronous model, its commit latency is linear in the size of the system.   to close this gap, we present the first chain-based bft smr protocols with $\\delta$ delay between the proposals of consecutive honest leaders and commit latencies of $3\\delta$. we present three protocols for the partially synchronous model under different notions of optimistic responsiveness, two of which implement pipelining. all of our protocols achieve reorg resilience and two have short view lengths; properties that many existing chain-based bft smr protocols lack. we present an evaluation of our protocols in a wide-area network wherein they demonstrate significant increases in throughput and reductions in latency compared to the state-of-the-art, jolteon. our results also demonstrate that techniques commonly employed to reduce communication complexity$\\unicode{x2014}$such as vote-pipelining and the use of designated vote-aggregators$\\unicode{x2014}$actually reduce practical performance in many settings.","doi":"","created":1704240000000,"updated":"2024-04-19","authors":["isaac doidge","raghavendra ramesh","nibesh shrestha","joshua tobkin"]}
{"id":"2401.01792","title":"comosvc: consistency model-based singing voice conversion","categories":"eess.as cs.ai cs.lg cs.sd","abstract":"the diffusion-based singing voice conversion (svc) methods have achieved remarkable performances, producing natural audios with high similarity to the target timbre. however, the iterative sampling process results in slow inference speed, and acceleration thus becomes crucial. in this paper, we propose comosvc, a consistency model-based svc method, which aims to achieve both high-quality generation and high-speed sampling. a diffusion-based teacher model is first specially designed for svc, and a student model is further distilled under self-consistency properties to achieve one-step sampling. experiments on a single nvidia gtx4090 gpu reveal that although comosvc has a significantly faster inference speed than the state-of-the-art (sota) diffusion-based svc system, it still achieves comparable or superior conversion performance based on both subjective and objective metrics. audio samples and codes are available at https:\/\/comosvc.github.io\/.","doi":"","created":1704240000000,"updated":"","authors":["yiwen lu","zhen ye","wei xue","xu tan","qifeng liu","yike guo"]}
{"id":"2401.01796","title":"understanding engagement with platform safety technology for reducing   exposure to online harms","categories":"cs.cy","abstract":"user facing 'platform safety technology' encompasses an array of tools offered by platforms to help people protect themselves from harm, for example allowing people to report content and unfollow or block other users. these tools are an increasingly important part of online safety: in the uk, legislation has made it a requirement for large platforms to offer them. however, little is known about user engagement with such tools. we present findings from a nationally representative survey of uk adults covering their awareness of and experiences with seven common safety technologies. we show that experience of online harms is widespread, with 67% of people having seen what they perceived as harmful content online; 26% of people have also had at least one piece of content removed by content moderation. use of safety technologies is also high, with more than 80\\% of people having used at least one. awareness of specific tools is varied, with people more likely to be aware of 'post-hoc' safety tools, such as reporting, than preventative measures. however, satisfaction with safety technologies is generally low. people who have previously seen online harms are more likely to use safety tools, implying a 'learning the hard way' route to engagement. those higher in digital literacy are also more likely to use some of these tools, raising concerns about the accessibility of these technologies to all users. additionally, women are more likely to engage in particular types of online 'safety work'. we discuss the implications of our results for those seeking a safer online environment.","doi":"","created":1704240000000,"updated":"","authors":["jonathan bright","florence e. enock","pica johansson","helen z. margetts","francesca stevens"]}
{"id":"2401.01798","title":"micro-macro parareal, from odes to sdes and back again","categories":"math.na cs.na stat.co","abstract":"in this paper, we are concerned with the micro-macro parareal algorithm for the simulation of initial-value problems. in this algorithm, a coarse (fast) solver is applied sequentially over the time domain, and a fine (time-consuming) solver is applied as a corrector in parallel over smaller chunks of the time interval. moreover, the coarse solver acts on a reduced state variable, which is coupled to the fine state variable through appropriate coupling operators. we first provide a contribution to the convergence analysis of the micro-macro parareal method for multiscale linear ordinary differential equations (odes). then, we extend a variant of the micro-macro parareal algorithm for scalar stochastic differential equations (sdes) to higher-dimensional sdes.","doi":"","created":1704240000000,"updated":"","authors":["ignace bossuyt","stefan vandewalle","giovanni samaey"]}
{"id":"2401.01799","title":"optimization and identification of lattice quantizers","categories":"cs.it math-ph math.it math.mg math.mp","abstract":"lattices with minimal normalized second moments are designed using a new numerical optimization algorithm. starting from a random lower-triangular generator matrix and applying stochastic gradient descent, all elements are updated towards the negative gradient, which makes it the most efficient algorithm proposed so far for this purpose. a graphical illustration of the theta series, called theta image, is introduced and shown to be a powerful tool for converting numerical lattice representations into their underlying exact forms. as a proof of concept, optimized lattices are designed in dimensions up to 16. in all dimensions, the algorithm converges to either the previously best known lattice or a better one. the dual of the 15-dimensional laminated lattice is conjectured to be optimal in its dimension and its exact normalized second moment is computed.","doi":"","created":1704240000000,"updated":"2024-06-23","authors":["erik agrell","daniel pook-kolb","bruce allen"]}
{"id":"2401.01801","title":"a quatum inspired neural network for geometric modeling","categories":"cs.lg cs.ai physics.comp-ph","abstract":"by conceiving physical systems as 3d many-body point clouds, geometric graph neural networks (gnns), such as se(3)\/e(3) equivalent gnns, have showcased promising performance. in particular, their effective message-passing mechanics make them adept at modeling molecules and crystalline materials. however, current geometric gnns only offer a mean-field approximation of the many-body system, encapsulated within two-body message passing, thus falling short in capturing intricate relationships within these geometric graphs. to address this limitation, tensor networks, widely employed by computational physics to handle manybody systems using high-order tensors, have been introduced. nevertheless, integrating these tensorized networks into the message-passing framework of gnns faces scalability and symmetry conservation (e.g., permutation and rotation) challenges. in response, we introduce an innovative equivariant matrix product state (mps)-based message-passing strategy, through achieving an efficient implementation of the tensor contraction operation. our method effectively models complex many-body relationships, suppressing mean-field approximations, and captures symmetries within geometric graphs. importantly, it seamlessly replaces the standard message-passing and layer-aggregation modules intrinsic to geometric gnns. we empirically validate the superior accuracy of our approach on benchmark tasks, including predicting classical newton systems and quantum tensor hamiltonian matrices. to our knowledge, our approach represents the inaugural utilization of parameterized geometric tensor networks.","doi":"","created":1704240000000,"updated":"2024-01-28","authors":["weitao du","shengchao liu","xuecang zhang"]}
{"id":"2401.01808","title":"amused: an open muse reproduction","categories":"cs.cv","abstract":"we present amused, an open-source, lightweight masked image model (mim) for text-to-image generation based on muse. with 10 percent of muse's parameters, amused is focused on fast image generation. we believe mim is under-explored compared to latent diffusion, the prevailing approach for text-to-image generation. compared to latent diffusion, mim requires fewer inference steps and is more interpretable. additionally, mim can be fine-tuned to learn additional styles with only a single image. we hope to encourage further exploration of mim by demonstrating its effectiveness on large-scale text-to-image generation and releasing reproducible training code. we also release checkpoints for two models which directly produce images at 256x256 and 512x512 resolutions.","doi":"","created":1704240000000,"updated":"","authors":["suraj patil","william berman","robin rombach","patrick von platen"]}
{"id":"2401.01813","title":"signal processing in the retina: interpretable graph classifier to   predict ganglion cell responses","categories":"cs.lg eess.iv q-bio.nc q-bio.qm","abstract":"it is a popular hypothesis in neuroscience that ganglion cells in the retina are activated by selectively detecting visual features in an observed scene. while ganglion cell firings can be predicted via data-trained deep neural nets, the networks remain indecipherable, thus providing little understanding of the cells' underlying operations. to extract knowledge from the cell firings, in this paper we learn an interpretable graph-based classifier from data to predict the firings of ganglion cells in response to visual stimuli. specifically, we learn a positive semi-definite (psd) metric matrix $\\mathbf{m} \\succeq 0$ that defines mahalanobis distances between graph nodes (visual events) endowed with pre-computed feature vectors; the computed inter-node distances lead to edge weights and a combinatorial graph that is amenable to binary classification. mathematically, we define the objective of metric matrix $\\mathbf{m}$ optimization using a graph adaptation of large margin nearest neighbor (lmnn), which is rewritten as a semi-definite programming (sdp) problem. we solve it efficiently via a fast approximation called gershgorin disc perfect alignment (gdpa) linearization. the learned metric matrix $\\mathbf{m}$ provides interpretability: important features are identified along $\\mathbf{m}$'s diagonal, and their mutual relationships are inferred from off-diagonal terms. our fast metric learning framework can be applied to other biological systems with pre-chosen features that require interpretation.","doi":"10.1109\/ojsp.2023.3349111","created":1704240000000,"updated":"","authors":["yasaman parhizkar","gene cheung","andrew w. eckford"]}
{"id":"2401.01814","title":"large language models relearn removed concepts","categories":"cs.ai","abstract":"advances in model editing through neuron pruning hold promise for removing undesirable concepts from large language models. however, it remains unclear whether models have the capacity to reacquire pruned concepts after editing. to investigate this, we evaluate concept relearning in models by tracking concept saliency and similarity in pruned neurons during retraining. our findings reveal that models can quickly regain performance post-pruning by relocating advanced concepts to earlier layers and reallocating pruned concepts to primed neurons with similar semantics. this demonstrates that models exhibit polysemantic capacities and can blend old and new concepts in individual neurons. while neuron pruning provides interpretability into model concepts, our results highlight the challenges of permanent concept removal for improved model \\textit{safety}. monitoring concept reemergence and developing techniques to mitigate relearning of unsafe concepts will be important directions for more robust model editing. overall, our work strongly demonstrates the resilience and fluidity of concept representations in llms post concept removal.","doi":"","created":1704240000000,"updated":"","authors":["michelle lo","shay b. cohen","fazl barez"]}
{"id":"2401.01817","title":"many-objective-optimized semi-automated robotic disassembly sequences","categories":"cs.ro","abstract":"this study tasckles the problem of many-objective sequence optimization for semi-automated robotic disassembly operations. to this end, we employ a many-objective genetic algorithm (maoga) algorithm inspired by the non-dominated sorting genetic algorithm (nsga)-iii, along with robotic-disassembly-oriented constraints and objective functions derived from geometrical and robot simulations using 3-dimensional (3d) geometrical information stored in a 3d computer-aided design (cad) model of the target product. the maoga begins by generating a set of initial chromosomes based on a contact and connection graph (ccg), rather than random chromosomes, to avoid falling into a local minimum and yield repeatable convergence. the optimization imposes constraints on feasibility and stability as well as objective functions regarding difficulty, efficiency, prioritization, and allocability to generate a sequence that satisfies many preferred conditions under mandatory requirements for semi-automated robotic disassembly. the nsga-iii-inspired maoga also utilizes non-dominated sorting and niching with reference lines to further encourage steady and stable exploration and uniformly lower the overall evaluation values. our sequence generation experiments for a complex product (36 parts) demonstrated that the proposed method can consistently produce feasible and stable sequences with a 100% success rate, bringing the multiple preferred conditions closer to the optimal solution required for semi-automated robotic disassembly operations.","doi":"","created":1704240000000,"updated":"","authors":["takuya kiyokawa","kensuke harada","weiwei wan","tomoki ishikura","naoya miyaji","genichiro matsuda"]}
{"id":"2401.01818","title":"sens3: multisensory database of finger-surface interactions and   corresponding sensations","categories":"cs.hc eess.sp","abstract":"the growing demand for natural interactions with technology underscores the importance of achieving realistic touch sensations in digital environments. realizing this goal highly depends on comprehensive databases of finger-surface interactions, which need further development. here, we present sens3 -- www.sens3.net -- an extensive open-access repository of multisensory data acquired from fifty surfaces when two participants explored them with their fingertips through static contact, pressing, tapping, and sliding. sens3 encompasses high-fidelity visual, audio, and haptic information recorded during these interactions, including videos, sounds, contact forces, torques, positions, accelerations, skin temperature, heat flux, and surface photographs. additionally, it incorporates thirteen participants' psychophysical sensation ratings (rough-smooth, flat-bumpy, sticky-slippery, hot-cold, regular-irregular, fine-coarse, hard-soft, and wet-dry) while exploring these surfaces freely. designed with an open-ended framework, sens3 has the potential to be expanded with additional textures and participants. we anticipate that sens3 will be valuable for advancing multisensory texture rendering, user experience development, and touch sensing in robotics.","doi":"","created":1704240000000,"updated":"2024-07-01","authors":["jagan k. balasubramanian","bence l. kodak","yasemin vardar"]}
{"id":"2401.01822","title":"hawkrover: an autonomous mmwave vehicular communication testbed with   multi-sensor fusion and deep learning","categories":"cs.it cs.cv math.it","abstract":"connected and automated vehicles (cavs) have become a transformative technology that can change our daily life. currently, millimeter-wave (mmwave) bands are identified as the promising cav connectivity solution. while it can provide high data rate, their realization faces many challenges such as high attenuation during mmwave signal propagation and mobility management. existing solution has to initiate pilot signal to measure channel information, then apply signal processing to calculate the best narrow beam towards the receiver end to guarantee sufficient signal power. this process takes significant overhead and time, hence not suitable for vehicles. in this study, we propose an autonomous and low-cost testbed to collect extensive co-located mmwave signal and other sensors data such as lidar (light detection and ranging), cameras, ultrasonic, etc, traditionally for ``automated'', to facilitate mmwave vehicular communications. intuitively, these sensors can build a 3d map around the vehicle and signal propagation path can be estimated, eliminating iterative the process via pilot signals. this multimodal data fusion, together with ai, is expected to bring significant advances in ``connected'' research.","doi":"","created":1704240000000,"updated":"2024-01-04","authors":["ethan zhu","haijian sun","mingyue ji"]}
{"id":"2401.01823","title":"detours for navigating instructional videos","categories":"cs.cv","abstract":"we introduce the video detours problem for navigating instructional videos. given a source video and a natural language query asking to alter the how-to video's current path of execution in a certain way, the goal is to find a related ''detour video'' that satisfies the requested alteration. to address this challenge, we propose viddetours, a novel video-language approach that learns to retrieve the targeted temporal segments from a large repository of how-to's using video-and-text conditioned queries. furthermore, we devise a language-based pipeline that exploits how-to video narration text to create weakly supervised training data. we demonstrate our idea applied to the domain of how-to cooking videos, where a user can detour from their current recipe to find steps with alternate ingredients, tools, and techniques. validating on a ground truth annotated dataset of 16k samples, we show our model's significant improvements over best available methods for video retrieval and question answering, with recall rates exceeding the state of the art by 35%.","doi":"","created":1704240000000,"updated":"2024-05-04","authors":["kumar ashutosh","zihui xue","tushar nagarajan","kristen grauman"]}
{"id":"2401.01825","title":"physio: an llm-based physiotherapy advisor","categories":"cs.cl cs.ir","abstract":"the capabilities of the most recent language models have increased the interest in integrating them into real-world applications. however, the fact that these models generate plausible, yet incorrect text poses a constraint when considering their use in several domains. healthcare is a prime example of a domain where text-generative trustworthiness is a hard requirement to safeguard patient well-being. in this paper, we present physio, a chat-based application for physical rehabilitation. physio is capable of making an initial diagnosis while citing reliable health sources to support the information provided. furthermore, drawing upon external knowledge databases, physio can recommend rehabilitation exercises and over-the-counter medication for symptom relief. by combining these features, physio can leverage the power of generative models for language processing while also conditioning its response on dependable and verifiable sources. a live demo of physio is available at https:\/\/physio.inesctec.pt.","doi":"10.1007\/978-3-031-56069-9_16","created":1704240000000,"updated":"","authors":["rúben almeida","hugo sousa","luís f. cunha","nuno guimarães","ricardo campos","alípio jorge"]}
{"id":"2401.01826","title":"data-driven power modeling and monitoring via hardware performance   counters tracking","categories":"cs.pf cs.os","abstract":"in the current high-performance and embedded computing era, full-stack energy-centric design is paramount. use cases require increasingly high performance at an affordable power budget, often under real-time constraints. extreme heterogeneity and parallelism address these issues but greatly complicate online power consumption assessment, which is essential for dynamic hardware and software stack adaptations. we introduce a novel architecture-agnostic power modeling methodology with state-of-the-art accuracy, low overhead, and high responsiveness. our methodology identifies the best performance monitoring counters (pmcs) to model the power consumption of each hardware sub-system at each dynamic voltage and frequency scaling (dvfs) state. the individual linear models are combined into a complete model that effectively describes the power consumption of the whole system, achieving high accuracy and low overhead. our evaluation reports an average estimation error of 7.5 % for power consumption and 1.3 % for energy. furthermore, we propose runmeter, an open-source, pmc-based monitoring framework integrated into the linux kernel. runmeter manages pmc samples collection and manipulation, efficiently evaluating our power models at runtime. with a time overhead of only 0.7 % in the worst case, runmeter provides responsive and accurate power measurements directly in the kernel, which can be employed for actuation policies such as dynamic power management (dpm) and power-aware task scheduling.","doi":"","created":1704240000000,"updated":"","authors":["sergio mazzola","gabriele ara","thomas benz","björn forsberg","tommaso cucinotta","luca benini"]}
{"id":"2401.01827","title":"moonshot: towards controllable video generation and editing with   multimodal conditions","categories":"cs.cv","abstract":"most existing video diffusion models (vdms) are limited to mere text conditions. thereby, they are usually lacking in control over visual appearance and geometry structure of the generated videos. this work presents moonshot, a new video generation model that conditions simultaneously on multimodal inputs of image and text. the model builts upon a core module, called multimodal video block (mvb), which consists of conventional spatialtemporal layers for representing video features, and a decoupled cross-attention layer to address image and text inputs for appearance conditioning. in addition, we carefully design the model architecture such that it can optionally integrate with pre-trained image controlnet modules for geometry visual conditions, without needing of extra training overhead as opposed to prior methods. experiments show that with versatile multimodal conditioning mechanisms, moonshot demonstrates significant improvement on visual quality and temporal consistency compared to existing models. in addition, the model can be easily repurposed for a variety of generative applications, such as personalized video generation, image animation and video editing, unveiling its potential to serve as a fundamental architecture for controllable video generation. models will be made public on https:\/\/github.com\/salesforce\/lavis.","doi":"","created":1704240000000,"updated":"","authors":["david junhao zhang","dongxu li","hung le","mike zheng shou","caiming xiong","doyen sahoo"]}
{"id":"2401.01828","title":"physics-informed appliance signatures generator for energy   disaggregation","categories":"eess.sy cs.sy eess.sp","abstract":"energy disaggregation is a promising solution to access detailed information on energy consumption in a household, by itemizing its total energy consumption. however, in real-world applications, overfitting remains a challenging problem for data-driven disaggregation methods. first, the available real-world datasets are biased towards the most frequently used appliances. second, both real and synthetic publicly-available datasets are limited in number of appliances, which may not be sufficient for a disaggregation algorithm to learn complex relations among different types of appliances and their states. to address the lack of appliance data, we propose two physics-informed data generators: one for high sampling rate signals (khz) and another for low sampling rate signals (hz). these generators rely on prior knowledge of the physics of appliance energy consumption, and are capable of simulating a virtually unlimited number of different appliances and their corresponding signatures for any time period. both methods involve defining a mathematical model, selecting centroids corresponding to individual appliances, sampling model parameters around each centroid, and finally substituting the obtained parameters into the mathematical model. additionally, by using principal component analysis and kullback-leibler divergence, we demonstrate that our methods significantly outperform the previous approaches.","doi":"10.1109\/ei259745.2023.10513031","created":1704240000000,"updated":"","authors":["ilia kamyshev","sahar moghimian hoosh","henni ouerdane"]}
{"id":"2401.01830","title":"iterative mask filling: an effective text augmentation method using   masked language modeling","categories":"cs.cl cs.ai cs.lg","abstract":"data augmentation is an effective technique for improving the performance of machine learning models. however, it has not been explored as extensively in natural language processing (nlp) as it has in computer vision. in this paper, we propose a novel text augmentation method that leverages the fill-mask feature of the transformer-based bert model. our method involves iteratively masking words in a sentence and replacing them with language model predictions. we have tested our proposed method on various nlp tasks and found it to be effective in many cases. our results are presented along with a comparison to existing augmentation methods. experimental results show that our proposed method significantly improves performance, especially on topic classification datasets.","doi":"10.1007\/978-3-031-50920-9_35","created":1704240000000,"updated":"","authors":["himmet toprak kesgin","mehmet fatih amasyali"]}
{"id":"2401.01831","title":"immersive serious games for learning physics concepts: the case of   density","categories":"cs.gr","abstract":"training students in basic concepts of physics, such as the ones related to mass, volume, or density, is much more complicated than just stating the underlying definitions and laws. one of the reasons for this is that most students have deeply rooted delusions and misconceptions about the behavior of objects, sometimes close to magical thinking. many innovative and promising technologies, in particular virtual reality (vr), can be used to enhance student learning. we compared the effectiveness of a serious immersive game in teaching the concept of density in various conditions: a 2d version in an embedded web browser and a 3d immersive game in vr. we also developed a specific questionnaire to assess students' knowledge improvement. primary results have shown an increase in learning efficiency using vr. also, most students were able to see the shortcomings of their initial theories and revise them, which means that they improved their understanding of this topic.","doi":"10.1007\/978-3-030-90739-6_12","created":1704240000000,"updated":"","authors":["iuliia zhurakovskaia","jeanne vézien","cécile de hosson","patrick bourdot"]}
{"id":"2401.01832","title":"teaching with a companion: the case of gravity","categories":"cs.gr cs.hc","abstract":"virtual reality (vr) has repeatedly proven its effectiveness in student learning. however, despite its benefits, the student equipped with a personal headset remains isolated from the real world while immersed in a virtual space and the classic student-teacher model of learning is difficult to transpose in such a situation. this study aims to bring the teacher back into the learning process when students use a vr headset. we describe the benefits of using a companion for educational purposes, taking as a test case the concept of gravity. we present an experimental setup designed to compare three different teaching contexts: with a physically present real teacher, using a live video of the teacher, and with a vr avatar of the teacher. we designed and evaluated three scenarios to teach the concept of gravity: an introduction to the concept of free fall, a parabolic trajectory workshop and a final exercise combining both approaches. due to sanitary conditions, only pre-tests are reported. the results showed that the effectiveness of using the vr simulations for learning and the self-confidence level of the students increased as well. the interviews show that the students ranked the teaching modes in this order: vr companion mode, video communication and real teacher.","doi":"10.1109\/icalt55010.2022.00108","created":1704240000000,"updated":"","authors":["iuliia zhurakovskaia","jeanne vezien","patrick bourdot"]}
{"id":"2401.01835","title":"concurrent brainstorming & hypothesis satisfying: an iterative framework   for enhanced retrieval-augmented generation (r2cbr3h-sr)","categories":"cs.it cs.ai cs.ir math.it","abstract":"addressing the complexity of comprehensive information retrieval, this study introduces an innovative, iterative retrieval-augmented generation system. our approach uniquely integrates a vector-space driven re-ranking mechanism with concurrent brainstorming to expedite the retrieval of highly relevant documents, thereby streamlining the generation of potential queries. this sets the stage for our novel hybrid process, which synergistically combines hypothesis formulation with satisfying decision-making strategy to determine content adequacy, leveraging a chain of thought-based prompting technique. this unified hypothesize-satisfied phase intelligently distills information to ascertain whether user queries have been satisfactorily addressed. upon reaching this criterion, the system refines its output into a concise representation, maximizing conceptual density with minimal verbosity. the iterative nature of the workflow enhances process efficiency and accuracy. crucially, the concurrency within the brainstorming phase significantly accelerates recursive operations, facilitating rapid convergence to solution satisfaction. compared to conventional methods, our system demonstrates a marked improvement in computational time and cost-effectiveness. this research advances the state-of-the-art in intelligent retrieval systems, setting a new benchmark for resource-efficient information extraction and abstraction in knowledge-intensive applications.","doi":"","created":1704240000000,"updated":"","authors":["arash shahmansoori"]}
{"id":"2401.01836","title":"neural control: concurrent system identification and control learning   with neural ode","categories":"cs.ai","abstract":"controlling continuous-time dynamical systems is generally a two step process: first, identify or model the system dynamics with differential equations, then, minimize the control objectives to achieve optimal control function and optimal state trajectories. however, any inaccuracy in dynamics modeling will lead to sub-optimality in the resulting control function. to address this, we propose a neural ode based method for controlling unknown dynamical systems, denoted as neural control (nc), which combines dynamics identification and optimal control learning using a coupled neural ode. through an intriguing interplay between the two neural networks in coupled neural ode structure, our model concurrently learns system dynamics as well as optimal controls that guides towards target states. our experiments demonstrate the effectiveness of our model for learning optimal control of unknown dynamical systems. codes available at https:\/\/github.com\/chichengmessi\/neural_ode_control\/tree\/main","doi":"","created":1704240000000,"updated":"2024-04-22","authors":["cheng chi"]}
{"id":"2401.01839","title":"frequency domain modality-invariant feature learning for   visible-infrared person re-identification","categories":"cs.cv","abstract":"visible-infrared person re-identification (vi-reid) is challenging due to the significant cross-modality discrepancies between visible and infrared images. while existing methods have focused on designing complex network architectures or using metric learning constraints to learn modality-invariant features, they often overlook which specific component of the image causes the modality discrepancy problem. in this paper, we first reveal that the difference in the amplitude component of visible and infrared images is the primary factor that causes the modality discrepancy and further propose a novel frequency domain modality-invariant feature learning framework (fdmnet) to reduce modality discrepancy from the frequency domain perspective. our framework introduces two novel modules, namely the instance-adaptive amplitude filter (iaf) module and the phrase-preserving normalization (ppnorm) module, to enhance the modality-invariant amplitude component and suppress the modality-specific component at both the image- and feature-levels. extensive experimental results on two standard benchmarks, sysu-mm01 and regdb, demonstrate the superior performance of our fdmnet against state-of-the-art methods.","doi":"","created":1704240000000,"updated":"2024-01-03","authors":["yulin li","tianzhu zhang","yongdong zhang"]}
{"id":"2401.01841","title":"act as you learn: adaptive decision-making in non-stationary markov   decision processes","categories":"cs.ai cs.lg","abstract":"a fundamental (and largely open) challenge in sequential decision-making is dealing with non-stationary environments, where exogenous environmental conditions change over time. such problems are traditionally modeled as non-stationary markov decision processes (nsmdp). however, existing approaches for decision-making in nsmdps have two major shortcomings: first, they assume that the updated environmental dynamics at the current time are known (although future dynamics can change); and second, planning is largely pessimistic, i.e., the agent acts ``safely'' to account for the non-stationary evolution of the environment. we argue that both these assumptions are invalid in practice -- updated environmental conditions are rarely known, and as the agent interacts with the environment, it can learn about the updated dynamics and avoid being pessimistic, at least in states whose dynamics it is confident about. we present a heuristic search algorithm called \\textit{adaptive monte carlo tree search (ada-mcts)} that addresses these challenges. we show that the agent can learn the updated dynamics of the environment over time and then act as it learns, i.e., if the agent is in a region of the state space about which it has updated knowledge, it can avoid being pessimistic. to quantify ``updated knowledge,'' we disintegrate the aleatoric and epistemic uncertainty in the agent's updated belief and show how the agent can use these estimates for decision-making. we compare the proposed approach with the multiple state-of-the-art approaches in decision-making across multiple well-established open-source problems and empirically show that our approach is faster and highly adaptive without sacrificing safety.","doi":"","created":1704240000000,"updated":"2024-01-21","authors":["baiting luo","yunuo zhang","abhishek dubey","ayan mukhopadhyay"]}
{"id":"2401.01842","title":"wasserstein nonnegative tensor factorization with manifold   regularization","categories":"cs.lg","abstract":"nonnegative tensor factorization (ntf) has become an important tool for feature extraction and part-based representation with preserved intrinsic structure information from nonnegative high-order data. however, the original ntf methods utilize euclidean or kullback-leibler divergence as the loss function which treats each feature equally leading to the neglect of the side-information of features. to utilize correlation information of features and manifold information of samples, we introduce wasserstein manifold nonnegative tensor factorization (wmntf), which minimizes the wasserstein distance between the distribution of input tensorial data and the distribution of reconstruction. although some researches about wasserstein distance have been proposed in nonnegative matrix factorization (nmf), they ignore the spatial structure information of higher-order data. we use wasserstein distance (a.k.a earth mover's distance or optimal transport distance) as a metric and add a graph regularizer to a latent factor. experimental results demonstrate the effectiveness of the proposed method compared with other nmf and ntf methods.","doi":"","created":1704240000000,"updated":"","authors":["jianyu wang","linruize tang"]}
{"id":"2401.01843","title":"investigating semi-supervised learning algorithms in text datasets","categories":"cs.cl cs.ai cs.lg","abstract":"using large training datasets enhances the generalization capabilities of neural networks. semi-supervised learning (ssl) is useful when there are few labeled data and a lot of unlabeled data. ssl methods that use data augmentation are most successful for image datasets. in contrast, texts do not have consistent augmentation methods as images. consequently, methods that use augmentation are not as effective in text data as they are in image data. in this study, we compared ssl algorithms that do not require augmentation; these are self-training, co-training, tri-training, and tri-training with disagreement. in the experiments, we used 4 different text datasets for different tasks. we examined the algorithms from a variety of perspectives by asking experiment questions and suggested several improvements. among the algorithms, tri-training with disagreement showed the closest performance to the oracle; however, performance gap shows that new semi-supervised algorithms or improvements in existing methods are needed.","doi":"10.1109\/asyu56188.2022.9925410","created":1704240000000,"updated":"2024-01-07","authors":["himmet toprak kesgin","mehmet fatih amasyali"]}
{"id":"2401.01846","title":"dgdnn: decoupled graph diffusion neural network for stock movement   prediction","categories":"cs.lg cs.ne","abstract":"forecasting future stock trends remains challenging for academia and industry due to stochastic inter-stock dynamics and hierarchical intra-stock dynamics influencing stock prices. in recent years, graph neural networks have achieved remarkable performance in this problem by formulating multiple stocks as graph-structured data. however, most of these approaches rely on artificially defined factors to construct static stock graphs, which fail to capture the intrinsic interdependencies between stocks that rapidly evolve. in addition, these methods often ignore the hierarchical features of the stocks and lose distinctive information within. in this work, we propose a novel graph learning approach implemented without expert knowledge to address these issues. first, our approach automatically constructs dynamic stock graphs by entropy-driven edge generation from a signal processing perspective. then, we further learn task-optimal dependencies between stocks via a generalized graph diffusion process on constructed stock graphs. last, a decoupled representation learning scheme is adopted to capture distinctive hierarchical intra-stock features. experimental results demonstrate substantial improvements over state-of-the-art baselines on real-world datasets. moreover, the ablation study and sensitivity study further illustrate the effectiveness of the proposed method in modeling the time-evolving inter-stock and intra-stock dynamics.","doi":"10.5220\/0012406400003636","created":1704240000000,"updated":"","authors":["zinuo you","zijian shi","hongbo bo","john cartlidge","li zhang","yan ge"]}
{"id":"2401.01851","title":"the power of training: how different neural network setups influence the   energy demand","categories":"cs.lg cs.ai cs.pf","abstract":"this work offers a heuristic evaluation of the effects of variations in machine learning training regimes and learning paradigms on the energy consumption of computing, especially hpc hardware with a life-cycle aware perspective. while increasing data availability and innovation in high-performance hardware fuels the training of sophisticated models, it also fosters the fading perception of energy consumption and carbon emission. therefore, the goal of this work is to raise awareness about the energy impact of general training parameters and processes, from learning rate over batch size to knowledge transfer. multiple setups with different hyperparameter configurations are evaluated on three different hardware systems. among many results, we have found out that even with the same model and hardware to reach the same accuracy, improperly set training hyperparameters consume up to 5 times the energy of the optimal setup. we also extensively examined the energy-saving benefits of learning paradigms including recycling knowledge through pretraining and sharing knowledge through multitask training.","doi":"","created":1704240000000,"updated":"2024-05-08","authors":["daniel geißler","bo zhou","mengxi liu","sungho suh","paul lukowicz"]}
{"id":"2401.01854","title":"multilingual instruction tuning with just a pinch of multilinguality","categories":"cs.cl cs.ai cs.lg","abstract":"as instruction-tuned large language models (llms) gain global adoption, their ability to follow instructions in multiple languages becomes increasingly crucial. in this work, we investigate how multilinguality during instruction tuning of a multilingual llm affects instruction-following across languages from the pre-training corpus. we first show that many languages transfer some instruction-following capabilities to other languages from even monolingual tuning. furthermore, we find that only 40 multilingual examples integrated in an english tuning set substantially improve multilingual instruction-following, both in seen and unseen languages during tuning. in general, we observe that models tuned on multilingual mixtures exhibit comparable or superior performance in multiple languages compared to monolingually tuned models, despite training on 10x fewer examples in those languages. finally, we find that diversifying the instruction tuning set with even just 2-4 languages significantly improves cross-lingual generalization. our results suggest that building massively multilingual instruction-tuned models can be done with only a very small set of multilingual instruction-responses.","doi":"","created":1704240000000,"updated":"2024-05-21","authors":["uri shaham","jonathan herzig","roee aharoni","idan szpektor","reut tsarfaty","matan eyal"]}
{"id":"2401.01855","title":"transformer neural autoregressive flows","categories":"cs.lg","abstract":"density estimation, a central problem in machine learning, can be performed using normalizing flows (nfs). nfs comprise a sequence of invertible transformations, that turn a complex target distribution into a simple one, by exploiting the change of variables theorem. neural autoregressive flows (nafs) and block neural autoregressive flows (b-nafs) are arguably the most perfomant members of the nf family. however, they suffer scalability issues and training instability due to the constraints imposed on the network structure. in this paper, we propose a novel solution to these challenges by exploiting transformers to define a new class of neural flows called transformer neural autoregressive flows (t-nafs). t-nafs treat each dimension of a random variable as a separate input token, using attention masking to enforce an autoregressive constraint. we take an amortization-inspired approach where the transformer outputs the parameters of an invertible transformation. the experimental results demonstrate that t-nafs consistently match or outperform nafs and b-nafs across multiple datasets from the uci benchmark. remarkably, t-nafs achieve these results using an order of magnitude fewer parameters than previous approaches, without composing multiple flows.","doi":"","created":1704240000000,"updated":"","authors":["massimiliano patacchiola","aliaksandra shysheya","katja hofmann","richard e. turner"]}
{"id":"2401.01857","title":"optimal cross-learning for contextual bandits with unknown context   distributions","categories":"cs.lg stat.ml","abstract":"we consider the problem of designing contextual bandit algorithms in the ``cross-learning'' setting of balseiro et al., where the learner observes the loss for the action they play in all possible contexts, not just the context of the current round. we specifically consider the setting where losses are chosen adversarially and contexts are sampled i.i.d. from an unknown distribution. in this setting, we resolve an open problem of balseiro et al. by providing an efficient algorithm with a nearly tight (up to logarithmic factors) regret bound of $\\widetilde{o}(\\sqrt{tk})$, independent of the number of contexts. as a consequence, we obtain the first nearly tight regret bounds for the problems of learning to bid in first-price auctions (under unknown value distributions) and sleeping bandits with a stochastic action set.   at the core of our algorithm is a novel technique for coordinating the execution of a learning algorithm over multiple epochs in such a way to remove correlations between estimation of the unknown distribution and the actions played by the algorithm. this technique may be of independent interest for other learning problems involving estimation of an unknown context distribution.","doi":"","created":1704240000000,"updated":"","authors":["jon schneider","julian zimmert"]}
{"id":"2401.01858","title":"synthetic dataset of id and travel document","categories":"cs.cv","abstract":"this paper presents a new synthetic dataset of id and travel documents, called sidtd. the sidtd dataset is created to help training and evaluating forged id documents detection systems. such a dataset has become a necessity as id documents contain personal information and a public dataset of real documents can not be released. moreover, forged documents are scarce, compared to legit ones, and the way they are generated varies from one fraudster to another resulting in a class of high intra-variability. in this paper we trained state-of-the-art models on this dataset and we compare them to the performance achieved in larger, but private, datasets. the creation of this dataset will help to document image analysis community to progress in the task of id document verification.","doi":"","created":1704240000000,"updated":"","authors":["carlos boned","maxime talarmain","nabil ghanmi","guillaume chiron","sanket biswas","ahmad montaser awal","oriol ramos terrades"]}
{"id":"2401.01862","title":"a vision check-up for language models","categories":"cs.cv cs.cl cs.lg","abstract":"what does learning to model relationships between strings teach large language models (llms) about the visual world? we systematically evaluate llms' abilities to generate and recognize an assortment of visual concepts of increasing complexity and then demonstrate how a preliminary visual representation learning system can be trained using models of text. as language models lack the ability to consume or output visual information as pixels, we use code to represent images in our study. although llm-generated images do not look like natural images, results on image generation and the ability of models to correct these generated images indicate that precise modeling of strings can teach language models about numerous aspects of the visual world. furthermore, experiments on self-supervised visual representation learning, utilizing images generated with text models, highlight the potential to train vision models capable of making semantic assessments of natural images using just llms.","doi":"","created":1704240000000,"updated":"","authors":["pratyusha sharma","tamar rott shaham","manel baradad","stephanie fu","adrian rodriguez-munoz","shivam duggal","phillip isola","antonio torralba"]}
{"id":"2401.01865","title":"attackers reveal their arsenal: an investigation of adversarial   techniques in cti reports","categories":"cs.cr","abstract":"context: cybersecurity vendors often publish cyber threat intelligence (cti) reports, referring to the written artifacts on technical and forensic analysis of the techniques used by the malware in apt attacks. objective: the goal of this research is to inform cybersecurity practitioners about how adversaries form cyberattacks through an analysis of adversarial techniques documented in cyberthreat intelligence reports. dataset: we use 594 adversarial techniques cataloged in mitre att\\&ck. we systematically construct a set of 667 cti reports that mitre att\\&ck used as citations in the descriptions of the cataloged adversarial techniques. methodology: we analyze the frequency and trend of adversarial techniques, followed by a qualitative analysis of the implementation of techniques. next, we perform association rule mining to identify pairs of techniques recurring in apt attacks. we then perform qualitative analysis to identify the underlying relations among the techniques in the recurring pairs. findings: the set of 667 cti reports documents 10,370 techniques in total, and we identify 19 prevalent techniques accounting for 37.3\\% of documented techniques. we also identify 425 statistically significant recurring pairs and seven types of relations among the techniques in these pairs. the top three among the seven relationships suggest that techniques used by the malware inter-relate with one another in terms of (a) abusing or affecting the same system assets, (b) executing in sequences, and (c) overlapping in their implementations. overall, the study quantifies how adversaries leverage techniques through malware in apt attacks based on publicly reported documents. we advocate organizations prioritize their defense against the identified prevalent techniques and actively hunt for potential malicious intrusion based on the identified pairs of techniques.","doi":"","created":1704240000000,"updated":"","authors":["md rayhanur rahman","setu kumar basak","rezvan mahdavi hezaveh","laurie williams"]}
{"id":"2401.01867","title":"dataset difficulty and the role of inductive bias","categories":"cs.lg","abstract":"motivated by the goals of dataset pruning and defect identification, a growing body of methods have been developed to score individual examples within a dataset. these methods, which we call \"example difficulty scores\", are typically used to rank or categorize examples, but the consistency of rankings between different training runs, scoring methods, and model architectures is generally unknown. to determine how example rankings vary due to these random and controlled effects, we systematically compare different formulations of scores over a range of runs and model architectures. we find that scores largely share the following traits: they are noisy over individual runs of a model, strongly correlated with a single notion of difficulty, and reveal examples that range from being highly sensitive to insensitive to the inductive biases of certain model architectures. drawing from statistical genetics, we develop a simple method for fingerprinting model architectures using a few sensitive examples. these findings guide practitioners in maximizing the consistency of their scores (e.g. by choosing appropriate scoring methods, number of runs, and subsets of examples), and establishes comprehensive baselines for evaluating scores in the future.","doi":"","created":1704240000000,"updated":"","authors":["devin kwok","nikhil anand","jonathan frankle","gintare karolina dziugaite","david rolnick"]}
{"id":"2401.01868","title":"step length measurement in the wild using fmcw radar","categories":"cs.cv cs.ai","abstract":"with an aging population, numerous assistive and monitoring technologies are under development to enable older adults to age in place. to facilitate aging in place predicting risk factors such as falls, and hospitalization and providing early interventions are important. much of the work on ambient monitoring for risk prediction has centered on gait speed analysis, utilizing privacy-preserving sensors like radar. despite compelling evidence that monitoring step length, in addition to gait speed, is crucial for predicting risk, radar-based methods have not explored step length measurement in the home. furthermore, laboratory experiments on step length measurement using radars are limited to proof of concept studies with few healthy subjects. to address this gap, a radar-based step length measurement system for the home is proposed based on detection and tracking using radar point cloud, followed by doppler speed profiling of the torso to obtain step lengths in the home. the proposed method was evaluated in a clinical environment, involving 35 frail older adults, to establish its validity. additionally, the method was assessed in people's homes, with 21 frail older adults who had participated in the clinical assessment. the proposed radar-based step length measurement method was compared to the gold standard zeno walkway gait analysis system, revealing a 4.5cm\/8.3% error in a clinical setting. furthermore, it exhibited excellent reliability (icc(2,k)=0.91, 95% ci 0.82 to 0.96) in uncontrolled home settings. the method also proved accurate in uncontrolled home settings, as indicated by a strong agreement (icc(3,k)=0.81 (95% ci 0.53 to 0.92)) between home measurements and in-clinic assessments.","doi":"","created":1704240000000,"updated":"","authors":["parthipan siva","alexander wong","patricia hewston","george ioannidis","dr. jonathan adachi","dr. alexander rabinovich","andrea lee","alexandra papaioannou"]}
{"id":"2401.01869","title":"on the hardness of learning under symmetries","categories":"cs.lg cs.ds math.st stat.ml stat.th","abstract":"we study the problem of learning equivariant neural networks via gradient descent. the incorporation of known symmetries (\"equivariance\") into neural nets has empirically improved the performance of learning pipelines, in domains ranging from biology to computer vision. however, a rich yet separate line of learning theoretic research has demonstrated that actually learning shallow, fully-connected (i.e. non-symmetric) networks has exponential complexity in the correlational statistical query (csq) model, a framework encompassing gradient descent. in this work, we ask: are known problem symmetries sufficient to alleviate the fundamental hardness of learning neural nets with gradient descent? we answer this question in the negative. in particular, we give lower bounds for shallow graph neural networks, convolutional networks, invariant polynomials, and frame-averaged networks for permutation subgroups, which all scale either superpolynomially or exponentially in the relevant input dimension. therefore, in spite of the significant inductive bias imparted via symmetry, actually learning the complete classes of functions represented by equivariant neural networks via gradient descent remains hard.","doi":"","created":1704240000000,"updated":"","authors":["bobak t. kiani","thien le","hannah lawrence","stefanie jegelka","melanie weber"]}
{"id":"2401.01874","title":"graph neural networks for surfactant multi-property prediction","categories":"physics.chem-ph cs.lg","abstract":"surfactants are of high importance in different industrial sectors such as cosmetics, detergents, oil recovery and drug delivery systems. therefore, many quantitative structure-property relationship (qspr) models have been developed for surfactants. each predictive model typically focuses on one surfactant class, mostly nonionics. graph neural networks (gnns) have exhibited a great predictive performance for property prediction of ionic liquids, polymers and drugs in general. specifically for surfactants, gnns can successfully predict critical micelle concentration (cmc), a key surfactant property associated with micellization. a key factor in the predictive ability of qspr and gnn models is the data available for training. based on extensive literature search, we create the largest available cmc database with 429 molecules and the first large data collection for surface excess concentration ($\\gamma$$_{m}$), another surfactant property associated with foaming, with 164 molecules. then, we develop gnn models to predict the cmc and $\\gamma$$_{m}$ and we explore different learning approaches, i.e., single- and multi-task learning, as well as different training strategies, namely ensemble and transfer learning. we find that a multi-task gnn with ensemble learning trained on all $\\gamma$$_{m}$ and cmc data performs best. finally, we test the ability of our cmc model to generalize on industrial grade pure component surfactants. the gnn yields highly accurate predictions for cmc, showing great potential for future industrial applications.","doi":"10.1016\/j.colsurfa.2024.134133","created":1704240000000,"updated":"","authors":["christoforos brozos","jan g. rittig","sandip bhattacharya","elie akanny","christina kohlmann","alexander mitsos"]}
{"id":"2401.01879","title":"theoretical guarantees on the best-of-n alignment policy","categories":"cs.lg cs.cl cs.it math.it","abstract":"a simple and effective method for the alignment of generative models is the best-of-$n$ policy, where $n$ samples are drawn from a base policy, and ranked based on a reward function, and the highest ranking one is selected. a commonly used analytical expression in the literature claims that the kl divergence between the best-of-$n$ policy and the base policy is equal to $\\log (n) - (n-1)\/n.$ we disprove the validity of this claim, and show that it is an upper bound on the actual kl divergence. we also explore the tightness of this upper bound in different regimes. finally, we propose a new estimator for the kl divergence and empirically show that it provides a tight approximation through a few examples.","doi":"","created":1704240000000,"updated":"","authors":["ahmad beirami","alekh agarwal","jonathan berant","alexander d'amour","jacob eisenstein","chirag nagpal","ananda theertha suresh"]}
{"id":"2401.01881","title":"robust control barrier functions using uncertainty estimation with   application to mobile robots","categories":"eess.sy cs.ro cs.sy","abstract":"model uncertainty poses a significant challenge to the implementation of safety-critical control systems. with this as motivation, this paper proposes a safe control design approach that guarantees the robustness of nonlinear feedback systems in the presence of matched or unmatched unmodelled system dynamics and external disturbances. our approach couples control barrier functions (cbfs) with a new uncertainty\/disturbance estimator to ensure robust safety against input and state-dependent model uncertainties. we prove upper bounds on the estimator's error and estimated outputs. we use an uncertainty estimator-based composite feedback control law to adaptively improve robust control performance under hard safety constraints by compensating for the matched uncertainty. then, we robustify existing cbf constraints with this uncertainty estimate and the estimation error bounds to ensure robust safety via a quadratic program (cbf-qp). we also extend our method to higher-order cbfs (hocbfs) to achieve safety under unmatched uncertainty, which causes relative degree differences with respect to control input and disturbance. we assume the relative degree difference is at most one, resulting in a second-order cone (soc) condition. the proposed robust hocbfs method is demonstrated in a simulation of an uncertain elastic actuator control problem. finally, the efficacy of our method is experimentally demonstrated on a tracked robot with slope-induced matched and unmatched perturbations.","doi":"","created":1704240000000,"updated":"","authors":["ersin das","joel w. burdick"]}
{"id":"2401.01883","title":"mining temporal attack patterns from cyberthreat intelligence reports","categories":"cs.cr cs.ir cs.lg cs.se","abstract":"defending from cyberattacks requires practitioners to operate on high-level adversary behavior. cyberthreat intelligence (cti) reports on past cyberattack incidents describe the chain of malicious actions with respect to time. to avoid repeating cyberattack incidents, practitioners must proactively identify and defend against recurring chain of actions - which we refer to as temporal attack patterns. automatically mining the patterns among actions provides structured and actionable information on the adversary behavior of past cyberattacks. the goal of this paper is to aid security practitioners in prioritizing and proactive defense against cyberattacks by mining temporal attack patterns from cyberthreat intelligence reports. to this end, we propose chronocti, an automated pipeline for mining temporal attack patterns from cyberthreat intelligence (cti) reports of past cyberattacks. to construct chronocti, we build the ground truth dataset of temporal attack patterns and apply state-of-the-art large language models, natural language processing, and machine learning techniques. we apply chronocti on a set of 713 cti reports, where we identify 124 temporal attack patterns - which we categorize into nine pattern categories. we identify that the most prevalent pattern category is to trick victim users into executing malicious code to initiate the attack, followed by bypassing the anti-malware system in the victim network. based on the observed patterns, we advocate organizations to train users about cybersecurity best practices, introduce immutable operating systems with limited functionalities, and enforce multi-user authentications. moreover, we advocate practitioners to leverage the automated mining capability of chronocti and design countermeasures against the recurring attack patterns.","doi":"","created":1704240000000,"updated":"","authors":["md rayhanur rahman","brandon wroblewski","quinn matthews","brantley morgan","tim menzies","laurie williams"]}
{"id":"2401.01884","title":"a rewriting-logic-with-smt-based formal analysis and parameter synthesis   framework for parametric time petri nets","categories":"cs.lo","abstract":"this paper presents a concrete and a symbolic rewriting logic semantics for parametric time petri nets with inhibitor arcs (pitpns), a flexible model of timed systems where parameters are allowed in firing bounds. we prove that our semantics is bisimilar to the \"standard\" semantics of pitpns. this allows us to use the rewriting logic tool maude, combined with smt solving, to provide sound and complete formal analyses for pitpns. we develop and implement a new general folding approach for symbolic reachability, so that maude-with-smt reachability analysis terminates whenever the parametric state-class graph of the pitpn is finite. our work opens up the possibility of using the many formal analysis capabilities of maude -- including full ltl model checking, analysis with user-defined analysis strategies, and even statistical model checking -- for such nets. we illustrate this by explaining how almost all formal analysis and parameter synthesis methods supported by the state-of-the-art pitpn tool romeo can be performed using maude with smt. in addition, we also support analysis and parameter synthesis from parametric initial markings, as well as full ltl model checking and analysis with user-defined execution strategies. experiments show that our methods outperform romeo in many cases.","doi":"","created":1704240000000,"updated":"2024-04-05","authors":["jaime arias","kyungmin bae","carlos olarte","peter csaba ölveczky","laure petrucci"]}
{"id":"2401.01885","title":"from audio to photoreal embodiment: synthesizing humans in conversations","categories":"cs.cv","abstract":"we present a framework for generating full-bodied photorealistic avatars that gesture according to the conversational dynamics of a dyadic interaction. given speech audio, we output multiple possibilities of gestural motion for an individual, including face, body, and hands. the key behind our method is in combining the benefits of sample diversity from vector quantization with the high-frequency details obtained through diffusion to generate more dynamic, expressive motion. we visualize the generated motion using highly photorealistic avatars that can express crucial nuances in gestures (e.g. sneers and smirks). to facilitate this line of research, we introduce a first-of-its-kind multi-view conversational dataset that allows for photorealistic reconstruction. experiments show our model generates appropriate and diverse gestures, outperforming both diffusion- and vq-only methods. furthermore, our perceptual evaluation highlights the importance of photorealism (vs. meshes) in accurately assessing subtle motion details in conversational gestures. code and dataset available online.","doi":"","created":1704240000000,"updated":"","authors":["evonne ng","javier romero","timur bagautdinov","shaojie bai","trevor darrell","angjoo kanazawa","alexander richard"]}
{"id":"2401.01887","title":"leap-vo: long-term effective any point tracking for visual odometry","categories":"cs.cv","abstract":"visual odometry estimates the motion of a moving camera based on visual input. existing methods, mostly focusing on two-view point tracking, often ignore the rich temporal context in the image sequence, thereby overlooking the global motion patterns and providing no assessment of the full trajectory reliability. these shortcomings hinder performance in scenarios with occlusion, dynamic objects, and low-texture areas. to address these challenges, we present the long-term effective any point tracking (leap) module. leap innovatively combines visual, inter-track, and temporal cues with mindfully selected anchors for dynamic track estimation. moreover, leap's temporal probabilistic formulation integrates distribution updates into a learnable iterative refinement module to reason about point-wise uncertainty. based on these traits, we develop leap-vo, a robust visual odometry system adept at handling occlusions and dynamic scenes. our mindful integration showcases a novel practice by employing long-term point tracking as the front-end. extensive experiments demonstrate that the proposed pipeline significantly outperforms existing baselines across various visual odometry benchmarks.","doi":"","created":1704240000000,"updated":"2024-06-12","authors":["weirong chen","le chen","rui wang","marc pollefeys"]}
{"id":"2401.01891","title":"architectural design for secure smart contract development","categories":"cs.cr","abstract":"as time progresses, the need for more secure applications grows exponentially. the different types of sensitive information that is being transferred virtually has sparked a rise in systems that leverage blockchain. different sectors are beginning to use this disruptive technology to evaluate the risks and benefits. sectors like finance, medicine, higher education, and wireless communication have research regarding blockchain. futhermore, the need for security standards in this area of research is pivotal. in recent past, several attacks on blockchain infrastructures have resulted in hundreds of millions dollars lost and sensitive information compromised. some of these attacks include dao attacks, bzx attacks, and parity multisignature wallet double attacks which targeted vulnerabilities within smart contracts on the ethereum network. these attacks exposed the weaknesses of current smart contract development practices which has led to the increase in distrust and adoption of systems that leverage blockchain for its functionality. in this paper, i identify common software vulnerabilities and attacks on blockchain infrastructures, thoroughly detail the smart contract development process and propose a model for ensuring a stronger security standard for future systems leveraging smart contracts. the purpose for proposing a model is to promote trust among end users in the system which is a foundational element for blockchain adoption in the future.","doi":"10.54941\/ahfe1003726","created":1704240000000,"updated":"","authors":["myles lewis","chris crawford"]}
{"id":"2401.01911","title":"backdoor attack on unpaired medical image-text foundation models: a   pilot study on medclip","categories":"cs.cv cs.lg","abstract":"in recent years, foundation models (fms) have solidified their role as cornerstone advancements in the deep learning domain. by extracting intricate patterns from vast datasets, these models consistently achieve state-of-the-art results across a spectrum of downstream tasks, all without necessitating extensive computational resources. notably, medclip, a vision-language contrastive learning-based medical fm, has been designed using unpaired image-text training. while the medical domain has often adopted unpaired training to amplify data, the exploration of potential security concerns linked to this approach hasn't kept pace with its practical usage. notably, the augmentation capabilities inherent in unpaired training also indicate that minor label discrepancies can result in significant model deviations. in this study, we frame this label discrepancy as a backdoor attack problem. we further analyze its impact on medical fms throughout the fm supply chain. our evaluation primarily revolves around medclip, emblematic of medical fm employing the unpaired strategy. we begin with an exploration of vulnerabilities in medclip stemming from unpaired image-text matching, termed badmatch. badmatch is achieved using a modest set of wrongly labeled data. subsequently, we disrupt medclip's contrastive learning through baddist-assisted badmatch by introducing a bad-distance between the embeddings of clean and poisoned data. additionally, combined with badmatch and baddist, the attacking pipeline consistently fends off backdoor assaults across diverse model designs, datasets, and triggers. also, our findings reveal that current defense strategies are insufficient in detecting these latent threats in medical fms' supply chains.","doi":"","created":1704067200000,"updated":"","authors":["ruinan jin","chun-yin huang","chenyu you","xiaoxiao li"]}
{"id":"2401.01912","title":"shrinking your timestep: towards low-latency neuromorphic object   recognition with spiking neural network","categories":"cs.cv cs.lg eess.iv","abstract":"neuromorphic object recognition with spiking neural networks (snns) is the cornerstone of low-power neuromorphic computing. however, existing snns suffer from significant latency, utilizing 10 to 40 timesteps or more, to recognize neuromorphic objects. at low latencies, the performance of existing snns is drastically degraded. in this work, we propose the shrinking snn (ssnn) to achieve low-latency neuromorphic object recognition without reducing performance. concretely, we alleviate the temporal redundancy in snns by dividing snns into multiple stages with progressively shrinking timesteps, which significantly reduces the inference latency. during timestep shrinkage, the temporal transformer smoothly transforms the temporal scale and preserves the information maximally. moreover, we add multiple early classifiers to the snn during training to mitigate the mismatch between the surrogate gradient and the true gradient, as well as the gradient vanishing\/exploding, thus eliminating the performance degradation at low latency. extensive experiments on neuromorphic datasets, cifar10-dvs, n-caltech101, and dvs-gesture have revealed that ssnn is able to improve the baseline accuracy by 6.55% ~ 21.41%. with only 5 average timesteps and without any data augmentation, ssnn is able to achieve an accuracy of 73.63% on cifar10-dvs. this work presents a heterogeneous temporal scale snn and provides valuable insights into the development of high-performance, low-latency snns.","doi":"","created":1704067200000,"updated":"","authors":["yongqi ding","lin zuo","mengmeng jing","pei he","yongjun xiao"]}
{"id":"2401.01914","title":"scattering from time-modulated subwavelength resonators","categories":"math-ph cs.na math.ap math.mp math.na physics.optics","abstract":"we consider wave scattering from a system of highly contrasting resonators with time-modulated material parameters. in this setting, the wave equation reduces to a system of coupled helmholtz equations that models the scattering problem. we consider the one-dimensional setting. in order to understand the energy of the system, we prove a novel higher-order discrete, capacitance matrix approximation of the subwavelength resonant quasifrequencies. further, we perform numerical experiments to support and illustrate our analytical results and show how periodically time-dependent material parameters affect the scattered wave field.","doi":"","created":1704153600000,"updated":"","authors":["habib ammari","jinghao cao","erik orvehed hiltunen","liora rueff"]}
{"id":"2401.01916","title":"astrollama-chat: scaling astrollama with conversational and diverse   datasets","categories":"astro-ph.im astro-ph.co astro-ph.ga astro-ph.sr cs.cl cs.lg","abstract":"we explore the potential of enhancing llm performance in astronomy-focused question-answering through targeted, continual pre-training. by employing a compact 7b-parameter llama-2 model and focusing exclusively on a curated set of astronomy corpora -- comprising abstracts, introductions, and conclusions -- we achieve notable improvements in specialized topic comprehension. while general llms like gpt-4 excel in broader question-answering scenarios due to superior reasoning capabilities, our findings suggest that continual pre-training with limited resources can still enhance model performance on specialized topics. additionally, we present an extension of astrollama: the fine-tuning of the 7b llama model on a domain-specific conversational dataset, culminating in the release of the chat-enabled astrollama for community use. comprehensive quantitative benchmarking is currently in progress and will be detailed in an upcoming full paper. the model, astrollama-chat, is now available at https:\/\/huggingface.co\/universetbd, providing the first open-source conversational ai tool tailored for the astronomy community.","doi":"","created":1704153600000,"updated":"2024-01-05","authors":["ernest perkowski","rui pan","tuan dung nguyen","yuan-sen ting","sandor kruk","tong zhang","charlie o'neill","maja jablonska","zechang sun","michael j. smith","huiling liu","kevin schawinski","kartheik iyer","ioana ciucă for universetbd"]}
{"id":"2401.01918","title":"distilling temporal knowledge with masked feature reconstruction for 3d   object detection","categories":"cs.cv","abstract":"striking a balance between precision and efficiency presents a prominent challenge in the bird's-eye-view (bev) 3d object detection. although previous camera-based bev methods achieved remarkable performance by incorporating long-term temporal information, most of them still face the problem of low efficiency. one potential solution is knowledge distillation. existing distillation methods only focus on reconstructing spatial features, while overlooking temporal knowledge. to this end, we propose tempdistiller, a temporal knowledge distiller, to acquire long-term memory from a teacher detector when provided with a limited number of frames. specifically, a reconstruction target is formulated by integrating long-term temporal knowledge through self-attention operation applied to feature teachers. subsequently, novel features are generated for masked student features via a generator. ultimately, we utilize this reconstruction target to reconstruct the student features. in addition, we also explore temporal relational knowledge when inputting full frames for the student model. we verify the effectiveness of the proposed method on the nuscenes benchmark. the experimental results show our method obtain an enhancement of +1.6 map and +1.1 nds compared to the baseline, a speed improvement of approximately 6 fps after compressing temporal knowledge, and the most accurate velocity estimation.","doi":"","created":1704240000000,"updated":"2024-01-08","authors":["haowen zheng","dong cao","jintao xu","rui ai","weihao gu","yang yang","yanyan liang"]}
{"id":"2401.01921","title":"the cytnx library for tensor networks","categories":"cs.ms cond-mat.str-el","abstract":"we introduce a tensor network library designed for classical and quantum physics simulations called cytnx (pronounced as sci-tens). this library provides almost an identical interface and syntax for both c++ and python, allowing users to effortlessly switch between two languages. aiming at a quick learning process for new users of tensor network algorithms, the interfaces resemble the popular python scientific libraries like numpy, scipy, and pytorch. not only multiple global abelian symmetries can be easily defined and implemented, cytnx also provides a new tool called network that allows users to store large tensor networks and perform tensor network contractions in an optimal order automatically. with the integration of cuquantum, tensor calculations can also be executed efficiently on gpus. we present benchmark results for tensor operations on both devices, cpu and gpu. we also discuss features and higher-level interfaces to be added in the future.","doi":"","created":1704240000000,"updated":"","authors":["kai-hsin wu","chang-teng lin","ke hsu","hao-ti hung","manuel schneider","chia-min chung","ying-jer kao","pochung chen"]}
{"id":"2401.01922","title":"unsupervised object-centric learning from multiple unspecified   viewpoints","categories":"cs.cv cs.lg","abstract":"visual scenes are extremely diverse, not only because there are infinite possible combinations of objects and backgrounds but also because the observations of the same scene may vary greatly with the change of viewpoints. when observing a multi-object visual scene from multiple viewpoints, humans can perceive the scene compositionally from each viewpoint while achieving the so-called ``object constancy'' across different viewpoints, even though the exact viewpoints are untold. this ability is essential for humans to identify the same object while moving and to learn from vision efficiently. it is intriguing to design models that have a similar ability. in this paper, we consider a novel problem of learning compositional scene representations from multiple unspecified (i.e., unknown and unrelated) viewpoints without using any supervision and propose a deep generative model which separates latent representations into a viewpoint-independent part and a viewpoint-dependent part to solve this problem. during the inference, latent representations are randomly initialized and iteratively updated by integrating the information in different viewpoints with neural networks. experiments on several specifically designed synthetic datasets have shown that the proposed method can effectively learn from multiple unspecified viewpoints.","doi":"","created":1704240000000,"updated":"","authors":["jinyang yuan","tonglin chen","zhimeng shen","bin li","xiangyang xue"]}
{"id":"2401.01923","title":"iot in the era of generative ai: vision and challenges","categories":"cs.dc cs.lg cs.ni","abstract":"equipped with sensing, networking, and computing capabilities, internet of things (iot) such as smartphones, wearables, smart speakers, and household robots have been seamlessly weaved into our daily lives. recent advancements in generative ai exemplified by gpt, llama, dall-e, and stable difussion hold immense promise to push iot to the next level. in this article, we share our vision and views on the benefits that generative ai brings to iot, and discuss some of the most important applications of generative ai in iot-related domains. fully harnessing generative ai in iot is a complex challenge. we identify some of the most critical challenges including high resource demands of the generative ai models, prompt engineering, on-device inference, offloading, on-device fine-tuning, federated learning, security, as well as development tools and benchmarks, and discuss current gaps as well as promising opportunities on enabling generative ai for iot. we hope this article can inspire new research on iot in the era of generative ai.","doi":"","created":1704240000000,"updated":"2024-01-05","authors":["xin wang","zhongwei wan","arvin hekmati","mingyu zong","samiul alam","mi zhang","bhaskar krishnamachari"]}
{"id":"2401.01943","title":"generalist embedding models are better at short-context clinical   semantic search than specialized embedding models","categories":"cs.cl cs.ai","abstract":"the increasing use of tools and solutions based on large language models (llms) for various tasks in the medical domain has become a prominent trend. their use in this highly critical and sensitive domain has thus raised important questions about their robustness, especially in response to variations in input, and the reliability of the generated outputs. this study addresses these questions by constructing a textual dataset based on the icd-10-cm code descriptions, widely used in us hospitals and containing many clinical terms, and their easily reproducible rephrasing. we then benchmarked existing embedding models, either generalist or specialized in the clinical domain, in a semantic search task where the goal was to correctly match the rephrased text to the original description. our results showed that generalist models performed better than clinical models, suggesting that existing clinical specialized models are more sensitive to small changes in input that confuse them. the highlighted problem of specialized models may be due to the fact that they have not been trained on sufficient data, and in particular on datasets that are not diverse enough to have a reliable global language understanding, which is still necessary for accurate handling of medical documents.","doi":"","created":1704240000000,"updated":"2024-01-06","authors":["jean-baptiste excoffier","tom roehr","alexei figueroa","jens-michalis papaioannou","keno bressem","matthieu ortala"]}
{"id":"2401.01948","title":"persistent components in canny's resultant","categories":"cs.sc math.ag","abstract":"when using resultants for elimination, one standard issue is that the resultant vanishes if the variety contains components of dimension larger than the expected dimension. j. canny proposed an elegant construction, generalized characteristic polynomial, to address this issue by symbolically perturbing the system before the resultant computation. such perturbed resultant would typically involve artefact components only loosely related to the geometry of the variety of interest. for removing these components, j.m. rojas proposed to take the greatest common divisor of the results of two different perturbations. in this paper, we investigate this construction, and show that the extra components persistent under taking different perturbations must come either from singularities or from positive-dimensional fibers.","doi":"","created":1704240000000,"updated":"","authors":["gleb pogudin"]}
{"id":"2401.01951","title":"can we generate realistic hands only using convolution?","categories":"cs.cv cs.ai cs.lg","abstract":"the enduring inability of image generative models to recreate intricate geometric features, such as those present in human hands and fingers has been an ongoing problem in image generation for nearly a decade. while strides have been made by increasing model sizes and diversifying training datasets, this issue remains prevalent across all models, from denoising diffusion models to generative adversarial networks (gan), pointing to a fundamental shortcoming in the underlying architectures. in this paper, we demonstrate how this problem can be mitigated by augmenting convolution layers geometric capabilities through providing them with a single input channel incorporating the relative $n$-dimensional cartesian coordinate system. we show that this drastically improves quality of hand and face images generated by gans and variational autoencoders (vae).","doi":"","created":1704240000000,"updated":"","authors":["mehran hosseini","peyman hosseini"]}
{"id":"2401.01952","title":"instruct-imagen: image generation with multi-modal instruction","categories":"cs.cv cs.ai cs.cl","abstract":"this paper presents instruct-imagen, a model that tackles heterogeneous image generation tasks and generalizes across unseen tasks. we introduce *multi-modal instruction* for image generation, a task representation articulating a range of generation intents with precision. it uses natural language to amalgamate disparate modalities (e.g., text, edge, style, subject, etc.), such that abundant generation intents can be standardized in a uniform format.   we then build instruct-imagen by fine-tuning a pre-trained text-to-image diffusion model with a two-stage framework. first, we adapt the model using the retrieval-augmented training, to enhance model's capabilities to ground its generation on external multimodal context. subsequently, we fine-tune the adapted model on diverse image generation tasks that requires vision-language understanding (e.g., subject-driven generation, etc.), each paired with a multi-modal instruction encapsulating the task's essence. human evaluation on various image generation datasets reveals that instruct-imagen matches or surpasses prior task-specific models in-domain and demonstrates promising generalization to unseen and more complex tasks.","doi":"","created":1704240000000,"updated":"","authors":["hexiang hu","kelvin c. k. chan","yu-chuan su","wenhu chen","yandong li","kihyuk sohn","yang zhao","xue ben","boqing gong","william cohen","ming-wei chang","xuhui jia"]}
{"id":"2401.01954","title":"word-representability of graphs with respect to split recomposition","categories":"cs.dm math.co","abstract":"in this work, we show that the class of word-representable graphs is closed under split recomposition and determine the representation number of the graph obtained by recomposing two word-representable graphs. accordingly, we show that the class of parity graphs is word-representable. further, we obtain a characteristic property by which the recomposition of comparability graphs is a comparability graph. consequently, we also establish the permutation-representation number (prn) of the resulting comparability graph. we also introduce a subclass of comparability graphs, called prn-irreducible graphs. we provide a criterion such that the split recomposition of two prn-irreducible graphs is a comparability graph and determine the prn of the resultant graph.","doi":"","created":1704240000000,"updated":"","authors":["tithi dwary","k. v. krishna"]}
{"id":"2401.01955","title":"multi-case: a transformer-based ethics-aware multimodal investigative   intelligence framework","categories":"cs.hc cs.mm","abstract":"ai-driven models are increasingly deployed in operational analytics solutions, for instance, in investigative journalism or the intelligence community. current approaches face two primary challenges: ethical and privacy concerns, as well as difficulties in efficiently combining heterogeneous data sources for multimodal analytics. to tackle the challenge of multimodal analytics, we present multi-case, a holistic visual analytics framework tailored towards ethics-aware and multimodal intelligence exploration, designed in collaboration with domain experts. it leverages an equal joint agency between human and ai to explore and assess heterogeneous information spaces, checking and balancing automation through visual analytics. multi-case operates on a fully-integrated data model and features type-specific analysis with multiple linked components, including a combined search, annotated text view, and graph-based analysis. parts of the underlying entity detection are based on a roberta-based language model, which we tailored towards user requirements through fine-tuning. an overarching knowledge exploration graph combines all information streams, provides in-situ explanations, transparent source attribution, and facilitates effective exploration. to assess our approach, we conducted a comprehensive set of evaluations: we benchmarked the underlying language model on relevant ner tasks, achieving state-of-the-art performance. the demonstrator was assessed according to intelligence capability assessments, while the methodology was evaluated according to ethics design guidelines. as a case study, we present our framework in an investigative journalism setting, supporting war crime investigations. finally, we conduct a formative user evaluation with domain experts in law enforcement. our evaluations confirm that our framework facilitates human agency and steering in security-sensitive applications.","doi":"","created":1704240000000,"updated":"","authors":["maximilian t. fischer","yannick metz","lucas joos","matthias miller","daniel a. keim"]}
{"id":"2401.01960","title":"shadow blade: a tool to interact with attack vectors","categories":"cs.cr","abstract":"the increased demand of cyber security professionals has also increased the development of new platforms and tools that help those professionals to improve their offensive skills. one of these platforms is hackthebox, an online cyber security training platform that delivers a controlled and safe environment for those professionals to explore virtual machines in a capture the flag (ctf) competition style.   most of the tools used in a ctf, or even on real-world penetration testing (pentest), were developed for specific reasons so each tool usually has different input and output formats. these different formats make it hard for cyber security professionals and ctf competitors to develop an attack graph. in order to help cyber security professionals and ctf competitors to discover, select and exploit an attack vector, this paper presents shadow blade, a tool to aid users to interact with their attack vectors.","doi":"","created":1704240000000,"updated":"","authors":["ariel r. ril","daniel dalalana bertoglio","avelino f. zorzo"]}
{"id":"2401.01963","title":"integrated cyber-physical resiliency for power grids under iot-enabled   dynamic botnet attacks","categories":"eess.sy cs.sy","abstract":"the wide adoption of internet of things (iot)-enabled energy devices improves the quality of life, but simultaneously, it enlarges the attack surface of the power grid system. the adversary can gain illegitimate control of a large number of these devices and use them as a means to compromise the physical grid operation, a mechanism known as the iot botnet attack. this paper aims to improve the resiliency of cyber-physical power grids to such attacks. specifically, we use an epidemic model to understand the dynamic botnet formation, which facilitates the assessment of the cyber layer vulnerability of the grid. the attacker aims to exploit this vulnerability to enable a successful physical compromise, while the system operator's goal is to ensure a normal operation of the grid by mitigating cyber risks. we develop a cross-layer game-theoretic framework for strategic decision-making to enhance cyber-physical grid resiliency. the cyber-layer game guides the system operator on how to defend against the botnet attacker as the first layer of defense, while the dynamic game strategy at the physical layer further counteracts the adversarial behavior in real time for improved physical resilience. a number of case studies on the ieee-39 bus system are used to corroborate the devised approach.","doi":"","created":1704240000000,"updated":"","authors":["yuhan zhao","juntao chen","quanyan zhu"]}
{"id":"2401.01967","title":"a mechanistic understanding of alignment algorithms: a case study on dpo   and toxicity","categories":"cs.cl cs.ai","abstract":"while alignment algorithms are now commonly used to tune pre-trained language models towards a user's preferences, we lack explanations for the underlying mechanisms in which models become ``aligned'', thus making it difficult to explain phenomena like jailbreaks. in this work we study a popular algorithm, direct preference optimization (dpo), and the mechanisms by which it reduces toxicity. namely, we first study how toxicity is represented and elicited in a pre-trained language model, gpt2-medium. we then apply dpo with a carefully crafted pairwise dataset to reduce toxicity. we examine how the resulting model averts toxic outputs, and find that capabilities learned from pre-training are not removed, but rather bypassed. we use this insight to demonstrate a simple method to un-align the model, reverting it back to its toxic behavior.","doi":"","created":1704240000000,"updated":"","authors":["andrew lee","xiaoyan bai","itamar pres","martin wattenberg","jonathan k. kummerfeld","rada mihalcea"]}
{"id":"2401.01970","title":"fmgs: foundation model embedded 3d gaussian splatting for holistic 3d   scene understanding","categories":"cs.cv cs.ai","abstract":"precisely perceiving the geometric and semantic properties of real-world 3d objects is crucial for the continued evolution of augmented reality and robotic applications. to this end, we present foundation model embedded gaussian splatting (fmgs), which incorporates vision-language embeddings of foundation models into 3d gaussian splatting (gs). the key contribution of this work is an efficient method to reconstruct and represent 3d vision-language models. this is achieved by distilling feature maps generated from image-based foundation models into those rendered from our 3d model. to ensure high-quality rendering and fast training, we introduce a novel scene representation by integrating strengths from both gs and multi-resolution hash encodings (mhe). our effective training procedure also introduces a pixel alignment loss that makes the rendered feature distance of the same semantic entities close, following the pixel-level semantic boundaries. our results demonstrate remarkable multi-view semantic consistency, facilitating diverse downstream tasks, beating state-of-the-art methods by 10.2 percent on open-vocabulary language-based object detection, despite that we are 851x faster for inference. this research explores the intersection of vision, language, and 3d scene representation, paving the way for enhanced scene understanding in uncontrolled real-world environments. we plan to release the code on the project page.","doi":"","created":1704240000000,"updated":"2024-05-03","authors":["xingxing zuo","pouya samangouei","yunwen zhou","yan di","mingyang li"]}
{"id":"2401.01972","title":"on approximate opacity of stochastic control systems","categories":"eess.sy cs.sy","abstract":"this paper investigates an important class of information-flow security property called opacity for stochastic control systems. opacity captures whether a system's secret behavior (a subset of the system's behavior that is considered to be critical) can be kept from outside observers. existing works on opacity for control systems only provide a binary characterization of the system's security level by determining whether the system is opaque or not. in this work, we introduce a quantifiable measure of opacity that considers the likelihood of satisfying opacity for stochastic control systems modeled as general markov decision processes (gmdps). we also propose verification methods tailored to the new notions of opacity for finite gmdps by using value iteration techniques. then, a new notion called approximate opacity-preserving stochastic simulation relation is proposed, which captures the distance between two systems' behaviors in terms of preserving opacity. based on this new system relation, we show that one can verify opacity for stochastic control systems using their abstractions (modeled as finite gmdps). we also discuss how to construct such abstractions for a class of gmdps under certain stability conditions.","doi":"","created":1704240000000,"updated":"","authors":["siyuan liu","xiang yin","dimos v. dimarogonas","majid zamani"]}
{"id":"2401.01974","title":"towards truly zero-shot compositional visual reasoning with llms as   programmers","categories":"cs.cv cs.ai cs.lg","abstract":"visual reasoning is dominated by end-to-end neural networks scaled to billions of model parameters and training examples. however, even the largest models struggle with compositional reasoning, generalization, fine-grained spatial and temporal reasoning, and counting. visual reasoning with large language models (llms) as controllers can, in principle, address these limitations by decomposing the task and solving subtasks by orchestrating a set of (visual) tools. recently, these models achieved great performance on tasks such as compositional visual question answering, visual grounding, and video temporal reasoning. nevertheless, in their current form, these models heavily rely on human engineering of in-context examples in the prompt, which are often dataset- and task-specific and require significant labor by highly skilled programmers. in this work, we present a framework that mitigates these issues by introducing spatially and temporally abstract routines and by leveraging a small number of labeled examples to automatically generate in-context examples, thereby avoiding human-created in-context examples. on a number of visual reasoning tasks, we show that our framework leads to consistent gains in performance, makes llms as controllers setup more robust, and removes the need for human engineering of in-context examples.","doi":"","created":1704240000000,"updated":"2024-05-14","authors":["aleksandar stanić","sergi caelles","michael tschannen"]}
{"id":"2401.01975","title":"eigenvalues distributions and control theory","categories":"math.na cs.na math.sp","abstract":"this work deals with the isogeometric galerkin discretization of the eigenvalue problem related to the laplace operator subject to homogeneous dirichlet boundary conditions on bounded intervals. this paper uses glt theory to study the behavior of the gap of discrete spectra toward the uniform gap condition needed for the uniform boundary observability\/controllability problems. the analysis refers to a regular $b$-spline basis and concave or convex reparametrizations. under suitable assumptions on the reparametrization transformation, we prove that structure emerges within the distribution of the eigenvalues once we reframe the problem into glt-symbol analysis. we also demonstrate numerically, that the necessary average gap condition proposed in \\cite{bianchi2018spectral} is not equivalent to the uniform gap condition. however, by improving the result in \\cite{bianchi2021analysis} we construct sufficient criteria that guarantee the uniform gap property.","doi":"","created":1704240000000,"updated":"","authors":["n. lamsahel","a. el akri","a. ratnani"]}
{"id":"2401.01978","title":"tailor: size recommendations for high-end fashion marketplaces","categories":"cs.ir cs.lg","abstract":"in the ever-changing and dynamic realm of high-end fashion marketplaces, providing accurate and personalized size recommendations has become a critical aspect. meeting customer expectations in this regard is not only crucial for ensuring their satisfaction but also plays a pivotal role in driving customer retention, which is a key metric for the success of any fashion retailer. we propose a novel sequence classification approach to address this problem, integrating implicit (add2bag) and explicit (returnreason) user signals. our approach comprises two distinct models: one employs lstms to encode the user signals, while the other leverages an attention mechanism. our best model outperforms sfnet, improving accuracy by 45.7%. by using add2bag interactions we increase the user coverage by 24.5% when compared with only using orders. moreover, we evaluate the models' usability in real-time recommendation scenarios by conducting experiments to measure their latency performance.","doi":"","created":1704240000000,"updated":"","authors":["alexandre candeias","ivo silva","vitor sousa","josé marcelino"]}
{"id":"2401.01981","title":"beyond regrets: geometric metrics for bayesian optimization","categories":"cs.lg stat.ml","abstract":"bayesian optimization is a principled optimization strategy for a black-box objective function. it shows its effectiveness in a wide variety of real-world applications such as scientific discovery and experimental design. in general, the performance of bayesian optimization is reported through regret-based metrics such as instantaneous, simple, and cumulative regrets. these metrics only rely on function evaluations, so that they do not consider geometric relationships between query points and global solutions, or query points themselves. notably, they cannot discriminate if multiple global solutions are successfully found. moreover, they do not evaluate bayesian optimization's abilities to exploit and explore a search space given. to tackle these issues, we propose four new geometric metrics, i.e., precision, recall, average degree, and average distance. these metrics allow us to compare bayesian optimization algorithms considering the geometry of both query points and global optima, or query points. however, they are accompanied by an extra parameter, which needs to be carefully determined. we therefore devise the parameter-free forms of the respective metrics by integrating out the additional parameter. finally, we empirically validate that our proposed metrics can provide more delicate interpretation of bayesian optimization algorithms, on top of assessment via the conventional metrics.","doi":"","created":1704240000000,"updated":"2024-03-11","authors":["jungtaek kim"]}
{"id":"2401.01984","title":"aupimo: redefining visual anomaly detection benchmarks with high speed   and low tolerance","categories":"cs.cv","abstract":"recent advances in visual anomaly detection research have seen auroc and aupro scores on public benchmark datasets such as mvtec and visa converge towards perfect recall, giving the impression that these benchmarks are near-solved. however, high auroc and aupro scores do not always reflect qualitative performance, which limits the validity of these metrics in real-world applications. we argue that the artificial ceiling imposed by the lack of an adequate evaluation metric restrains progression of the field, and it is crucial that we revisit the evaluation metrics used to rate our algorithms. in response, we introduce per-image overlap (pimo), a novel metric that addresses the shortcomings of auroc and aupro. pimo retains the recall-based nature of the existing metrics but introduces two distinctions: the assignment of curves (and respective area under the curve) is per-image, and its x-axis relies solely on normal images. measuring recall per image simplifies instance score indexing and is more robust to noisy annotations. as we show, it also accelerates computation and enables the usage of statistical tests to compare models. by imposing low tolerance for false positives on normal images, pimo provides an enhanced model validation procedure and highlights performance variations across datasets. our experiments demonstrate that pimo offers practical advantages and nuanced performance insights that redefine anomaly detection benchmarks -- notably challenging the perception that mvtec ad and visa datasets have been solved by contemporary models. available on github: https:\/\/github.com\/jpcbertoldo\/aupimo.","doi":"","created":1704240000000,"updated":"2024-02-08","authors":["joao p. c. bertoldo","dick ameln","ashwin vaidya","samet akçay"]}
{"id":"2401.01987","title":"representation learning of multivariate time series using attention and   adversarial training","categories":"cs.lg","abstract":"a critical factor in trustworthy machine learning is to develop robust representations of the training data. only under this guarantee methods are legitimate to artificially generate data, for example, to counteract imbalanced datasets or provide counterfactual explanations for blackbox decision-making systems. in recent years, generative adversarial networks (gans) have shown considerable results in forming stable representations and generating realistic data. while many applications focus on generating image data, less effort has been made in generating time series data, especially multivariate signals. in this work, a transformer-based autoencoder is proposed that is regularized using an adversarial training scheme to generate artificial multivariate time series signals. the representation is evaluated using t-sne visualizations, dynamic time warping (dtw) and entropy scores. our results indicate that the generated signals exhibit higher similarity to an exemplary dataset than using a convolutional network approach.","doi":"","created":1704240000000,"updated":"","authors":["leon scharwächter","sebastian otte"]}
{"id":"2401.01988","title":"hierarchical clustering in ${\\lambda}$cdm cosmologies via persistence   energy","categories":"astro-ph.co cs.cg math.at stat.ml","abstract":"in this research, we investigate the structural evolution of the cosmic web, employing advanced methodologies from topological data analysis. our approach involves leveraging lite, an innovative method from recent literature that embeds persistence diagrams into elements of vector spaces. utilizing this methodology, we analyze three quintessential cosmic structures: clusters, filaments, and voids. a central discovery is the correlation between \\textit{persistence energy} and redshift values, linking persistent homology with cosmic evolution and providing insights into the dynamics of cosmic structures.","doi":"","created":1704240000000,"updated":"2024-01-08","authors":["michael etienne van huffel","leonardo aldo alejandro barberi","tobias sagis"]}
{"id":"2401.01989","title":"revisiting zero-shot abstractive summarization in the era of large   language models from the perspective of position bias","categories":"cs.cl cs.ai","abstract":"we characterize and study zero-shot abstractive summarization in large language models (llms) by measuring position bias, which we propose as a general formulation of the more restrictive lead bias phenomenon studied previously in the literature. position bias captures the tendency of a model unfairly prioritizing information from certain parts of the input text over others, leading to undesirable behavior. through numerous experiments on four diverse real-world datasets, we study position bias in multiple llm models such as gpt 3.5-turbo, llama-2, and dolly-v2, as well as state-of-the-art pretrained encoder-decoder abstractive summarization models such as pegasus and bart. our findings lead to novel insights and discussion on performance and position bias of models for zero-shot summarization tasks.","doi":"","created":1704240000000,"updated":"2024-03-18","authors":["anshuman chhabra","hadi askari","prasant mohapatra"]}
{"id":"2401.01990","title":"gps-ssl: guided positive sampling to inject prior into self-supervised   learning","categories":"cs.cv cs.ai cs.lg","abstract":"we propose guided positive sampling self-supervised learning (gps-ssl), a general method to inject a priori knowledge into self-supervised learning (ssl) positive samples selection. current ssl methods leverage data-augmentations (da) for generating positive samples and incorporate prior knowledge - an incorrect, or too weak da will drastically reduce the quality of the learned representation. gps-ssl proposes instead to design a metric space where euclidean distances become a meaningful proxy for semantic relationship. in that space, it is now possible to generate positive samples from nearest neighbor sampling. any prior knowledge can now be embedded into that metric space independently from the employed da. from its simplicity, gps-ssl is applicable to any ssl method, e.g. simclr or byol. a key benefit of gps-ssl is in reducing the pressure in tailoring strong das. for example gps-ssl reaches 85.58% on cifar10 with weak da while the baseline only reaches 37.51%. we therefore move a step forward towards the goal of making ssl less reliant on da. we also show that even when using strong das, gps-ssl outperforms the baselines on under-studied domains. we evaluate gps-ssl along with multiple baseline ssl methods on numerous downstream datasets from different domains when the models use strong or minimal data augmentations. we hope that gps-ssl will open new avenues in studying how to inject a priori knowledge into ssl in a principled manner.","doi":"","created":1704240000000,"updated":"2024-01-09","authors":["aarash feizi","randall balestriero","adriana romero-soriano","reihaneh rabbany"]}
{"id":"2401.01991","title":"dapps ecosystems: mapping the network structure of smart contract   interactions","categories":"cs.cy cs.cr cs.it cs.se math.it","abstract":"in recent years, decentralized applications (dapps) built on blockchain platforms such as ethereum and coded in languages such as solidity, have gained attention for their potential to disrupt traditional centralized systems. despite their rapid adoption, limited research has been conducted to understand the underlying code structure of these applications. in particular, each dapp is composed of multiple smart contracts, each containing a number of functions that can be called to trigger a specific event, e.g., a token transfer. in this paper, we reconstruct and analyse the network of contracts and functions calls within the dapp, which is helpful to unveil vulnerabilities that can be exploited by malicious attackers. we show how decentralization is architecturally implemented, identifying common development patterns and anomalies that could influence the system's robustness and efficiency. we find a consistent network structure characterized by modular, self-sufficient contracts and a complex web of function interactions, indicating common coding practices across the blockchain community. critically, a small number of key functions within each dapp play a pivotal role in maintaining network connectivity, making them potential targets for cyber attacks and highlighting the need for robust security measures.","doi":"","created":1704240000000,"updated":"","authors":["sabrina aufiero","giacomo ibba","silvia bartolucci","giuseppe destefanis","rumyana neykova","marco ortu"]}
{"id":"2401.01993","title":"on time-indexing as inductive bias in deep rl for sequential   manipulation tasks","categories":"cs.ro cs.ai","abstract":"while solving complex manipulation tasks, manipulation policies often need to learn a set of diverse skills to accomplish these tasks. the set of skills is often quite multimodal - each one may have a quite distinct distribution of actions and states. standard deep policy-learning algorithms often model policies as deep neural networks with a single output head (deterministic or stochastic). this structure requires the network to learn to switch between modes internally, which can lead to lower sample efficiency and poor performance. in this paper we explore a simple structure which is conducive to skill learning required for so many of the manipulation tasks. specifically, we propose a policy architecture that sequentially executes different action heads for fixed durations, enabling the learning of primitive skills such as reaching and grasping. our empirical evaluation on the metaworld tasks reveals that this simple structure outperforms standard policy learning methods, highlighting its potential for improved skill acquisition.","doi":"","created":1704240000000,"updated":"","authors":["m. nomaan qureshi","ben eisner","david held"]}
{"id":"2401.01996","title":"mean-field assisted deep boltzmann learning with probabilistic computers","categories":"cs.et cs.ar cs.lg cs.ne","abstract":"despite their appeal as physics-inspired, energy-based and generative nature, general boltzmann machines (bm) are considered intractable to train. this belief led to simplified models of bms with restricted intralayer connections or layer-by-layer training of deep bms. recent developments in domain-specific hardware -- specifically probabilistic computers (p-computer) with probabilistic bits (p-bit) -- may change established wisdom on the tractability of deep bms. in this paper, we show that deep and unrestricted bms can be trained using p-computers generating hundreds of billions of markov chain monte carlo (mcmc) samples per second, on sparse networks developed originally for use in d-wave's annealers. to maximize the efficiency of learning the p-computer, we introduce two families of mean-field theory assisted learning algorithms, or xmfts (x = naive and hierarchical). the xmfts are used to estimate the averages and correlations during the positive phase of the contrastive divergence (cd) algorithm and our custom-designed p-computer is used to estimate the averages and correlations in the negative phase. a custom field-programmable-gate array (fpga) emulation of the p-computer architecture takes up to 45 billion flips per second, allowing the implementation of cd-$n$ where $n$ can be of the order of millions, unlike rbms where $n$ is typically 1 or 2. experiments on the full mnist dataset with the combined algorithm show that the positive phase can be efficiently computed by xmfts without much degradation when the negative phase is computed by the p-computer. our algorithm can be used in other scalable ising machines and its variants can be used to train bms, previously thought to be intractable.","doi":"","created":1704240000000,"updated":"","authors":["shuvro chowdhury","shaila niazi","kerem y. camsari"]}
{"id":"2401.02001","title":"close to human-level agreement: tracing journeys of violent speech in   incel posts with gpt-4-enhanced annotations","categories":"cs.si","abstract":"this study investigates the prevalence of violent language on incels.is. it evaluates gpt models (gpt-3.5 and gpt-4) for content analysis in social sciences, focusing on the impact of varying prompts and batch sizes on coding quality for the detection of violent speech. we scraped over 6.9m posts from incels.is and categorized a random sample into non-violent, explicitly violent, and implicitly violent content. two human coders annotated 3,028 posts, which we used to tune and evaluate gpt-3.5 and gpt-4 models across different prompts and batch sizes regarding coding reliability. the best-performing gpt-4 model annotated an additional 30,000 posts for further analysis.   our findings indicate an overall increase in violent speech overtime on incels.is, both at the community and individual level, particularly among more engaged users. while directed violent language decreases, non-directed violent language increases, and self-harm content shows a decline, especially after 2.5 years of user activity. we find substantial agreement between both human coders (k = .65), while the best gpt-4 model yields good agreement with both human coders (k = 0.54 for human a and k = 0.62 for human b). weighted and macro f1 scores further support this alignment.   overall, this research provides practical means for accurately identifying violent language at a large scale that can aid content moderation and facilitate next-step research into the causal mechanism and potential mitigations of violent expression and radicalization in communities like incels.is.","doi":"","created":1704240000000,"updated":"","authors":["daniel matter","miriam schirmer","nir grinberg","jürgen pfeffer"]}
{"id":"2401.02008","title":"two-stage surrogate modeling for data-driven design optimization with   application to composite microstructure generation","categories":"cs.lg cs.ce","abstract":"this paper introduces a novel two-stage machine learning-based surrogate modeling framework to address inverse problems in scientific and engineering fields. in the first stage of the proposed framework, a machine learning model termed the \"learner\" identifies a limited set of candidates within the input design space whose predicted outputs closely align with desired outcomes. subsequently, in the second stage, a separate surrogate model, functioning as an \"evaluator,\" is employed to assess the reduced candidate space generated in the first stage. this evaluation process eliminates inaccurate and uncertain solutions, guided by a user-defined coverage level. the framework's distinctive contribution is the integration of conformal inference, providing a versatile and efficient approach that can be widely applicable. to demonstrate the effectiveness of the proposed framework compared to conventional single-stage inverse problems, we conduct several benchmark tests and investigate an engineering application focused on the micromechanical modeling of fiber-reinforced composites. the results affirm the superiority of our proposed framework, as it consistently produces more reliable solutions. therefore, the introduced framework offers a unique perspective on fostering interactions between machine learning-based surrogate models in real-world applications.","doi":"","created":1704240000000,"updated":"","authors":["farhad pourkamali-anaraki","jamal f. husseini","evan j. pineda","brett a. bednarcyk","scott e. stapleton"]}
{"id":"2401.02009","title":"self-contrast: better reflection through inconsistent solving   perspectives","categories":"cs.cl cs.ai","abstract":"the reflection capacity of large language model (llm) has garnered extensive attention. a post-hoc prompting strategy, e.g., reflexion and self-refine, refines llm's response based on self-evaluated or external feedback. however, recent research indicates without external feedback, llm's intrinsic reflection is unstable. our investigation unveils that the key bottleneck is the quality of the self-evaluated feedback. we find llms often exhibit overconfidence or high randomness when self-evaluate, offering stubborn or inconsistent feedback, which causes poor reflection. to remedy this, we advocate self-contrast: it adaptively explores diverse solving perspectives tailored to the request, contrasts the differences, and summarizes these discrepancies into a checklist which could be used to re-examine and eliminate discrepancies. our method endows llm with diverse perspectives to alleviate stubborn biases. moreover, their discrepancies indicate potential errors or inherent uncertainties that llm often overlooks. reflecting upon these can catalyze more accurate and stable reflection. experiments conducted on a series of reasoning and translation tasks with different llms serve to underscore the effectiveness and generality of our strategy.","doi":"","created":1704240000000,"updated":"2024-06-06","authors":["wenqi zhang","yongliang shen","linjuan wu","qiuying peng","jun wang","yueting zhuang","weiming lu"]}
{"id":"2401.02011","title":"decentralized multi-task online convex optimization under random link   failures","categories":"cs.lg math.oc","abstract":"decentralized optimization methods often entail information exchange between neighbors. transmission failures can happen due to network congestion, hardware\/software issues, communication outage, and other factors. in this paper, we investigate the random link failure problem in decentralized multi-task online convex optimization, where agents have individual decisions that are coupled with each other via pairwise constraints. although widely used in constrained optimization, conventional saddle-point algorithms are not directly applicable here because of random packet dropping. to address this issue, we develop a robust decentralized saddle-point algorithm against random link failures with heterogeneous probabilities by replacing the missing decisions of neighbors with their latest received values. then, by judiciously bounding the accumulated deviation stemming from this replacement, we first establish that our algorithm achieves $\\mathcal{o}(\\sqrt{t})$ regret and $\\mathcal{o}(t^\\frac{3}{4})$ constraint violations for the full information scenario, where the complete information on the local cost function is revealed to each agent at the end of each time slot. these two bounds match, in order sense, the performance bounds of algorithms with perfect communications. further, we extend our algorithm and analysis to the two-point bandit feedback scenario, where only the values of the local cost function at two random points are disclosed to each agent sequentially. performance bounds of the same orders as the full information case are derived. finally, we corroborate the efficacy of the proposed algorithms and the analytical results through numerical simulations.","doi":"","created":1704240000000,"updated":"","authors":["wenjing yan","xuanyu cao"]}
{"id":"2401.02012","title":"fast & fair: efficient second-order robust optimization for fairness in   machine learning","categories":"cs.lg cs.cy cs.na math.na","abstract":"this project explores adversarial training techniques to develop fairer deep neural networks (dnns) to mitigate the inherent bias they are known to exhibit. dnns are susceptible to inheriting bias with respect to sensitive attributes such as race and gender, which can lead to life-altering outcomes (e.g., demographic bias in facial recognition software used to arrest a suspect). we propose a robust optimization problem, which we demonstrate can improve fairness in several datasets, both synthetic and real-world, using an affine linear model. leveraging second order information, we are able to find a solution to our optimization problem more efficiently than a purely first order method.","doi":"","created":1704240000000,"updated":"","authors":["allen minch","hung anh vu","anne marie warren"]}
{"id":"2401.02013","title":"switchtab: switched autoencoders are effective tabular learners","categories":"cs.lg","abstract":"self-supervised representation learning methods have achieved significant success in computer vision and natural language processing, where data samples exhibit explicit spatial or semantic dependencies. however, applying these methods to tabular data is challenging due to the less pronounced dependencies among data samples. in this paper, we address this limitation by introducing switchtab, a novel self-supervised method specifically designed to capture latent dependencies in tabular data. switchtab leverages an asymmetric encoder-decoder framework to decouple mutual and salient features among data pairs, resulting in more representative embeddings. these embeddings, in turn, contribute to better decision boundaries and lead to improved results in downstream tasks. to validate the effectiveness of switchtab, we conduct extensive experiments across various domains involving tabular data. the results showcase superior performance in end-to-end prediction tasks with fine-tuning. moreover, we demonstrate that pre-trained salient embeddings can be utilized as plug-and-play features to enhance the performance of various traditional classification methods (e.g., logistic regression, xgboost, etc.). lastly, we highlight the capability of switchtab to create explainable representations through visualization of decoupled mutual and salient features in the latent space.","doi":"","created":1704240000000,"updated":"","authors":["jing wu","suiyao chen","qi zhao","renat sergazinov","chen li","shengjie liu","chongchao zhao","tianpei xie","hanqing guo","cheng ji","daniel cociorva","hakan brunzel"]}
{"id":"2401.02014","title":"enhancing zero-shot multi-speaker tts with negated speaker   representations","categories":"cs.sd eess.as","abstract":"zero-shot multi-speaker tts aims to synthesize speech with the voice of a chosen target speaker without any fine-tuning. prevailing methods, however, encounter limitations at adapting to new speakers of out-of-domain settings, primarily due to inadequate speaker disentanglement and content leakage. to overcome these constraints, we propose an innovative negation feature learning paradigm that models decoupled speaker attributes as deviations from the complete audio representation by utilizing the subtraction operation. by eliminating superfluous content information from the speaker representation, our negation scheme not only mitigates content leakage, thereby enhancing synthesis robustness, but also improves speaker fidelity. in addition, to facilitate the learning of diverse speaker attributes, we leverage multi-stream transformers, which retain multiple hypotheses and instigate a training paradigm akin to ensemble learning. to unify these hypotheses and realize the final speaker representation, we employ attention pooling. finally, in light of the imperative to generate target text utterances in the desired voice, we adopt adaptive layer normalizations to effectively fuse the previously generated speaker representation with the target text representations, as opposed to mere concatenation of the text and audio modalities. extensive experiments and validations substantiate the efficacy of our proposed approach in preserving and harnessing speaker-specific attributes vis-`a-vis alternative baseline models.","doi":"","created":1704240000000,"updated":"2024-03-05","authors":["yejin jeon","yunsu kim","gary geunbae lee"]}
{"id":"2401.02015","title":"improving diffusion-based image synthesis with context prediction","categories":"cs.cv cs.ai cs.lg","abstract":"diffusion models are a new class of generative models, and have dramatically promoted image generation with unprecedented quality and diversity. existing diffusion models mainly try to reconstruct input image from a corrupted one with a pixel-wise or feature-wise constraint along spatial axes. however, such point-based reconstruction may fail to make each predicted pixel\/feature fully preserve its neighborhood context, impairing diffusion-based image synthesis. as a powerful source of automatic supervisory signal, context has been well studied for learning representations. inspired by this, we for the first time propose conprediff to improve diffusion-based image synthesis with context prediction. we explicitly reinforce each point to predict its neighborhood context (i.e., multi-stride features\/tokens\/pixels) with a context decoder at the end of diffusion denoising blocks in training stage, and remove the decoder for inference. in this way, each point can better reconstruct itself by preserving its semantic connections with neighborhood context. this new paradigm of conprediff can generalize to arbitrary discrete and continuous diffusion backbones without introducing extra parameters in sampling procedure. extensive experiments are conducted on unconditional image generation, text-to-image generation and image inpainting tasks. our conprediff consistently outperforms previous methods and achieves a new sota text-to-image generation results on ms-coco, with a zero-shot fid score of 6.21.","doi":"","created":1704240000000,"updated":"","authors":["ling yang","jingwei liu","shenda hong","zhilong zhang","zhilin huang","zheming cai","wentao zhang","bin cui"]}
{"id":"2401.02016","title":"deeponet based preconditioning strategies for solving parametric linear   systems of equations","categories":"math.na cs.na","abstract":"we introduce a new class of hybrid preconditioners for solving parametric linear systems of equations. the proposed preconditioners are constructed by hybridizing the deep operator network, namely deeponet, with standard iterative methods. exploiting the spectral bias, deeponet-based components are harnessed to address low-frequency error components, while conventional iterative methods are employed to mitigate high-frequency error components. our preconditioning framework comprises two distinct hybridization approaches: direct preconditioning (dp) and trunk basis (tb) approaches. in the dp approach, deeponet is used to approximate an action of an inverse operator to a vector during each preconditioning step. in contrast, the tb approach extracts basis functions from the trained deeponet to construct a map to a smaller subspace, in which the low-frequency component of the error can be effectively eliminated. our numerical results demonstrate that utilizing the tb approach enhances the convergence of krylov methods by a large margin compared to standard non-hybrid preconditioning strategies. moreover, the proposed hybrid preconditioners exhibit robustness across a wide range of model parameters and problem resolutions.","doi":"","created":1704240000000,"updated":"2024-01-09","authors":["alena kopaničáková","george em karniadakis"]}
{"id":"2401.02019","title":"from function to distribution modeling: a pac-generative approach to   offline optimization","categories":"cs.lg","abstract":"this paper considers the problem of offline optimization, where the objective function is unknown except for a collection of ``offline\" data examples. while recent years have seen a flurry of work on applying various machine learning techniques to the offline optimization problem, the majority of these work focused on learning a surrogate of the unknown objective function and then applying existing optimization algorithms. while the idea of modeling the unknown objective function is intuitive and appealing, from the learning point of view it also makes it very difficult to tune the objective of the learner according to the objective of optimization. instead of learning and then optimizing the unknown objective function, in this paper we take on a less intuitive but more direct view that optimization can be thought of as a process of sampling from a generative model. to learn an effective generative model from the offline data examples, we consider the standard technique of ``re-weighting\", and our main technical contribution is a probably approximately correct (pac) lower bound on the natural optimization objective, which allows us to jointly learn a weight function and a score-based generative model. the robustly competitive performance of the proposed approach is demonstrated via empirical studies using the standard offline optimization benchmarks.","doi":"","created":1704240000000,"updated":"","authors":["qiang zhang","ruida zhou","yang shen","tie liu"]}
{"id":"2401.02020","title":"spikformer v2: join the high accuracy club on imagenet with an snn   ticket","categories":"cs.ne cs.cv cs.lg","abstract":"spiking neural networks (snns), known for their biologically plausible architecture, face the challenge of limited performance. the self-attention mechanism, which is the cornerstone of the high-performance transformer and also a biologically inspired structure, is absent in existing snns. to this end, we explore the potential of leveraging both self-attention capability and biological properties of snns, and propose a novel spiking self-attention (ssa) and spiking transformer (spikformer). the ssa mechanism eliminates the need for softmax and captures the sparse visual feature employing spike-based query, key, and value. this sparse computation without multiplication makes ssa efficient and energy-saving. further, we develop a spiking convolutional stem (scs) with supplementary convolutional layers to enhance the architecture of spikformer. the spikformer enhanced with the scs is referred to as spikformer v2. to train larger and deeper spikformer v2, we introduce a pioneering exploration of self-supervised learning (ssl) within the snn. specifically, we pre-train spikformer v2 with masking and reconstruction style inspired by the mainstream self-supervised transformer, and then finetune the spikformer v2 on the image classification on imagenet. extensive experiments show that spikformer v2 outperforms other previous surrogate training and ann2snn methods. an 8-layer spikformer v2 achieves an accuracy of 80.38% using 4 time steps, and after ssl, a 172m 16-layer spikformer v2 reaches an accuracy of 81.10% with just 1 time step. to the best of our knowledge, this is the first time that the snn achieves 80+% accuracy on imagenet. the code will be available at spikformer v2.","doi":"","created":1704240000000,"updated":"","authors":["zhaokun zhou","kaiwei che","wei fang","keyu tian","yuesheng zhu","shuicheng yan","yonghong tian","li yuan"]}
{"id":"2401.02023","title":"on complexity of stability analysis in higher-order ecological networks   through tensor decompositions","categories":"eess.sy cs.na cs.sy math.na math.oc","abstract":"complex ecological networks are often characterized by intricate interactions that extend beyond pairwise relationships. understanding the stability of higher-order ecological networks is salient for species coexistence, biodiversity, and community persistence. in this article, we present complexity analyses for determining the linear stability of higher-order ecological networks through tensor decompositions. we are interested in the higher-order generalized lotka-volterra model, which captures high-order interactions using tensors of varying orders. to efficiently compute jacobian matrices and thus determine stability in large ecological networks, we exploit various tensor decompositions, including higher-order singular value decomposition, canonical polyadic decomposition, and tensor train decomposition, accompanied by in-depth computational and memory complexity analyses. we demonstrate the effectiveness of our framework with numerical examples.","doi":"","created":1704240000000,"updated":"2024-04-03","authors":["anqi dong","can chen"]}
{"id":"2401.02029","title":"examining the challenges in archiving instagram","categories":"cs.dl","abstract":"to prevent the spread of disinformation on instagram, we need to study the accounts and content of disinformation actors. however, due to their malicious nature, instagram often bans accounts that are responsible for spreading disinformation, making these accounts inaccessible from the live web. the only way we can study the content of banned accounts is through public web archives such as the internet archive. however, there are many issues present with archiving instagram pages. specifically, we focused on the issue that many wayback machine instagram mementos redirect to the instagram login page. in this study, we determined that mementos of instagram account pages on the wayback machine began redirecting to the instagram login page in august 2019. we also found that instagram mementos on archive.today, arquivo.pt, and perma.cc are also not well archived in terms of quantity and quality. moreover, we were unsuccessful in all our attempts to archive katy perry's instagram account page on archive.today, arquivo.pt, and conifer. although in the minority, replayable instagram mementos exist in public archives and contain valuable data for studying disinformation on instagram. with that in mind, we developed a python script to web scrape instagram mementos. as of august 2023, the python script can scrape wayback machine archives of instagram account pages between november 7, 2012 and june 8, 2018.","doi":"","created":1704240000000,"updated":"","authors":["rachel zheng","michele c. weigle"]}
{"id":"2401.02030","title":"travelers: a scalable fair ordering bft system","categories":"cs.cr cs.ni","abstract":"many blockchain platform are subject to maximal value extraction (mev), and users on the platform are losing money while sending transactions because the transaction order can be manipulated to extract value from them. consensus protocols have been augmented with different notion of fair ordering in order to counter the problem. out of all practical protocols, the most efficient bft consensus requires $o(ntl + n^2t)$ communication complexity, where $n$ is number node, $t$ is number of transactions and $l$ is average transaction size. in this work, we propose a new system of bft fair ordering protocols, travelers, that substantially reduce the communication complexity. the proposed system of protocols satisfy a new notion of fair ordering, called probabilistic fair ordering, which is an extension to some existing notions of fairness. the new notion allows a small probability of error $\\epsilon$, that adversary can insert some transactions at any location in a block, but for the remaining $1-\\epsilon$ the a modified version of ordering linearizability holds. our mechanism neither require a dissemination network nor direct submissions to all consensus nodes. the key innovation comes from a routing protocol, that is both flexible and efficient. we construct a protocol with $o(c\\log({n})tl + n^2)$ communication complexity with $\\epsilon = 1\/n^c$ for some system parameter $c\\ge 1$.","doi":"","created":1704240000000,"updated":"","authors":["bowen xue","sreeram kannan"]}
{"id":"2401.02031","title":"spy-watermark: robust invisible watermarking for backdoor attack","categories":"cs.cv","abstract":"backdoor attack aims to deceive a victim model when facing backdoor instances while maintaining its performance on benign data. current methods use manual patterns or special perturbations as triggers, while they often overlook the robustness against data corruption, making backdoor attacks easy to defend in practice. to address this issue, we propose a novel backdoor attack method named spy-watermark, which remains effective when facing data collapse and backdoor defense. therein, we introduce a learnable watermark embedded in the latent domain of images, serving as the trigger. then, we search for a watermark that can withstand collapse during image decoding, cooperating with several anti-collapse operations to further enhance the resilience of our trigger against data corruption. extensive experiments are conducted on cifar10, gtsrb, and imagenet datasets, demonstrating that spy-watermark overtakes ten state-of-the-art methods in terms of robustness and stealthiness.","doi":"","created":1704240000000,"updated":"","authors":["ruofei wang","renjie wan","zongyu guo","qing guo","rui huang"]}
{"id":"2401.02032","title":"diffusionedge: diffusion probabilistic model for crisp edge detection","categories":"cs.cv","abstract":"limited by the encoder-decoder architecture, learning-based edge detectors usually have difficulty predicting edge maps that satisfy both correctness and crispness. with the recent success of the diffusion probabilistic model (dpm), we found it is especially suitable for accurate and crisp edge detection since the denoising process is directly applied to the original image size. therefore, we propose the first diffusion model for the task of general edge detection, which we call diffusionedge. to avoid expensive computational resources while retaining the final performance, we apply dpm in the latent space and enable the classic cross-entropy loss which is uncertainty-aware in pixel level to directly optimize the parameters in latent space in a distillation manner. we also adopt a decoupled architecture to speed up the denoising process and propose a corresponding adaptive fourier filter to adjust the latent features of specific frequencies. with all the technical designs, diffusionedge can be stably trained with limited resources, predicting crisp and accurate edge maps with much fewer augmentation strategies. extensive experiments on four edge detection benchmarks demonstrate the superiority of diffusionedge both in correctness and crispness. on the nyudv2 dataset, compared to the second best, we increase the ods, ois (without post-processing) and ac by 30.2%, 28.1% and 65.1%, respectively. code: https:\/\/github.com\/guhuangai\/diffusionedge.","doi":"","created":1704240000000,"updated":"2024-01-09","authors":["yunfan ye","kai xu","yuhang huang","renjiao yi","zhiping cai"]}
{"id":"2401.02033","title":"automated test production -- systematic literature review","categories":"cs.se","abstract":"identifying the main contributions related to the automated test production (atp) of computer programs and providing an overview about models, methodologies and tools used for this purpose is the aim of this systematic literature review (slr). the results will enable a comprehensive analysis and insight to evaluate their applicability. a previously produced systematic literature mapping (slm) contributed to the formulation of the ``research questions'' and parameters for the definition of the qualitative analysis protocol of this review.","doi":"","created":1704240000000,"updated":"","authors":["josé marcos gomes","luis alberto vieira dias"]}
{"id":"2401.02034","title":"text2mdt: extracting medical decision trees from medical texts","categories":"cs.cl","abstract":"knowledge of the medical decision process, which can be modeled as medical decision trees (mdts), is critical to build clinical decision support systems. however, the current mdt construction methods rely heavily on time-consuming and laborious manual annotation. in this work, we propose a novel task, text2mdt, to explore the automatic extraction of mdts from medical texts such as medical guidelines and textbooks. we normalize the form of the mdt and create an annotated text-to-mdt dataset in chinese with the participation of medical experts. we investigate two different methods for the text2mdt tasks: (a) an end-to-end framework which only relies on a gpt style large language models (llm) instruction tuning to generate all the node information and tree structures. (b) the pipeline framework which decomposes the text2mdt task to three subtasks. experiments on our text2mdt dataset demonstrate that: (a) the end-to-end method basd on llms (7b parameters or larger) show promising results, and successfully outperform the pipeline methods. (b) the chain-of-thought (cot) prompting method \\cite{wei2022chainot} can improve the performance of the fine-tuned llms on the text2mdt test set. (c) the lightweight pipelined method based on encoder-based pretrained models can perform comparably with llms with model complexity two magnititudes smaller. our text2mdt dataset is open-sourced at \\url{https:\/\/tianchi.aliyun.com\/dataset\/95414}, and the source codes are open-sourced at \\url{https:\/\/github.com\/michael-wzhu\/text2dt}.","doi":"","created":1704240000000,"updated":"","authors":["wei zhu","wenfeng li","xing tian","pengfei wang","xiaoling wang","jin chen","yuanbin wu","yuan ni","guotong xie"]}
{"id":"2401.02035","title":"efficient information geometry approach for massive mimo-ofdm channel   estimation","categories":"cs.it math.it","abstract":"we investigate the channel estimation for massive multiple-input multiple-output orthogonal frequency division multiplexing (mimo-ofdm) systems. we revisit the information geometry approach (iga) for massive mimo-ofdm channel estimation. by using the constant magnitude property of the entries of the measurement matrix, we find that the second-order natural parameters of the distributions on all the auxiliary manifolds are equivalent to each other, and the first-order natural parameters are asymptotically equivalent to each other at the fixed point. motivated by these results, we simplify the process of iga and propose an efficient iga (eiga) for massive mimo-ofdm channel estimation, which allows efficient implementation with fast fourier transformation (fft). we then establish a sufficient condition of its convergence and accordingly find a range of the damping factor for the convergence. we show that this range of damping factor is sufficiently wide by using the specific properties of the measurement matrices. further, we prove that at the fixed point, the a posteriori mean obtained by eiga is asymptotically optimal. simulations confirm that eiga can achieve the optimal performance with low complexity in a limited number of iterations.","doi":"","created":1704240000000,"updated":"2024-06-03","authors":["jiyuan yang","yan chen","mingrui fan","an-an lu","wen zhong","xiqi gao","xiaohu you","xiang-gen xia","dirk slock"]}
{"id":"2401.02037","title":"simplified information geometry approach for massive mimo-ofdm channel   estimation -- part ii: convergence analysis","categories":"cs.it math.it","abstract":"in part ii of this two-part paper, we prove the convergence of the simplified information geometry approach (siga) proposed in part i. for a general bayesian inference problem, we first show that the iteration of the common second-order natural parameter (sonp) is separated from that of the common first-order natural parameter (fonp). hence, the convergence of the common sonp can be checked independently. we show that with the initialization satisfying a specific but large range, the common sonp is convergent regardless of the value of the damping factor. for the common fonp, we establish a sufficient condition of its convergence and prove that the convergence of the common fonp relies on the spectral radius of a particular matrix related to the damping factor. we give the range of the damping factor that guarantees the convergence in the worst case. further, we determine the range of the damping factor for massive mimo-ofdm channel estimation by using the specific properties of the measurement matrices. simulation results are provided to confirm the theoretical results.","doi":"","created":1704240000000,"updated":"2024-06-03","authors":["jiyuan yang","yan chen","mingrui fan","xiqi gao","xiang-gen xia","dirk slock"]}
{"id":"2401.02038","title":"understanding llms: a comprehensive overview from training to inference","categories":"cs.cl","abstract":"the introduction of chatgpt has led to a significant increase in the utilization of large language models (llms) for addressing downstream tasks. there's an increasing focus on cost-efficient training and deployment within this context. low-cost training and deployment of llms represent the future development trend. this paper reviews the evolution of large language model training techniques and inference deployment technologies aligned with this emerging trend. the discussion on training includes various aspects, including data preprocessing, training architecture, pre-training tasks, parallel training, and relevant content related to model fine-tuning. on the inference side, the paper covers topics such as model compression, parallel computation, memory scheduling, and structural optimization. it also explores llms' utilization and provides insights into their future development.","doi":"","created":1704240000000,"updated":"2024-01-05","authors":["yiheng liu","hao he","tianle han","xu zhang","mengyuan liu","jiaming tian","yutong zhang","jiaqi wang","xiaohui gao","tianyang zhong","yi pan","shaochen xu","zihao wu","zhengliang liu","xin zhang","shu zhang","xintao hu","tuo zhang","ning qiang","tianming liu","bao ge"]}
{"id":"2401.02041","title":"efficient cloud-edge collaborative inference for object   re-identification","categories":"cs.cv","abstract":"current object re-identification (reid) system follows the centralized processing paradigm, i.e., all computations are conducted in the cloud server and edge devices are only used to capture and send images. as the number of videos experiences a rapid escalation, this paradigm has become impractical due to the finite computational resources. in such a scenario, the reid system should be converted to fit in the cloud-edge collaborative processing paradigm, which is crucial to boost the scalability and practicality of reid systems. however, current relevant work lacks research on this issue, making it challenging for reid methods to be adapted effectively. therefore, we pioneer a cloud-edge collaborative inference framework for reid systems and particularly propose a distribution-aware correlation modeling network (dacm) to make the desired image return to the cloud server as soon as possible via learning to model the spatial-temporal correlations among instances. dacm embeds the spatial-temporal correlations implicitly included in the timestamps into a graph structure, and it can be applied in the cloud to regulate the size of the upload window and on the edge device to adjust the sequence of images, respectively. traditional reid methods can be combined with dacm seamlessly, enabling their application within our proposed edge-cloud collaborative framework. extensive experiments demonstrate that our method obviously reduces transmission overhead and significantly improves performance. we will release our code and model.","doi":"","created":1704240000000,"updated":"","authors":["chuanming wang","yuxin yang","mengshi qi","huadong ma"]}
{"id":"2401.02043","title":"signal detection for ultra-massive mimo: an information geometry   approach","categories":"cs.it math.it","abstract":"in this paper, we propose an information geometry approach (iga) for signal detection (sd) in ultra-massive multiple-input multiple-output (mimo) systems. we formulate the signal detection as obtaining the marginals of the a posteriori probability distribution of the transmitted symbol vector. then, a maximization of the a posteriori marginals (mpm) for signal detection can be performed. with the information geometry theory, we calculate the approximations of the a posteriori marginals. it is formulated as an iterative m-projection process between submanifolds with different constraints. we then apply the central-limit-theorem (clt) to simplify the calculation of the m-projection since the direct calculation of the m-projection is of exponential-complexity. with the clt, we obtain an approximate solution of the m-projection, which is asymptotically accurate. simulation results demonstrate that the proposed iga-sd emerges as a promising and efficient method to implement the signal detector in ultra-massive mimo systems.","doi":"","created":1704240000000,"updated":"","authors":["jiyuan yang","yan chen","xiqi gao","dirk slock","xiang-gen xia"]}
{"id":"2401.02044","title":"multi-modal vision-language model for generalizable annotation-free   pathology localization and clinical diagnosis","categories":"cs.cv","abstract":"defining pathologies automatically from medical images aids the understanding of the emergence and progression of diseases, and such an ability is crucial in clinical diagnostics. however, existing deep learning models heavily rely on expert annotations and lack generalization capabilities in open clinical environments. in this study, we present a generalizable vision-language model for annotation-free pathology localization (afloc). the core strength of afloc lies in its extensive multi-level semantic structure-based contrastive learning, which comprehensively aligns multi-granularity medical concepts from reports with abundant image features, to adapt to the diverse expressions of pathologies and unseen pathologies without the reliance on image annotations from experts. we demonstrate the proof of concept on chest x-ray images, with extensive experimental validation across 6 distinct external datasets, encompassing 13 types of chest pathologies. the results demonstrate that afloc surpasses state-of-the-art methods in pathology localization and classification, and even outperforms the human benchmark in locating 5 different pathologies. additionally, we further verify its generalization ability by applying it to retinal fundus images. our approach showcases afloc's versatilities and underscores its suitability for clinical diagnosis in complex clinical environments.","doi":"","created":1704240000000,"updated":"2024-07-18","authors":["hao yang","hong-yu zhou","zhihuan li","yuanxu gao","cheng li","weijian huang","jiarun liu","hairong zheng","kang zhang","shanshan wang"]}
{"id":"2401.02046","title":"ctc blank triggered dynamic layer-skipping for efficient ctc-based   speech recognition","categories":"eess.as cs.sd","abstract":"deploying end-to-end speech recognition models with limited computing resources remains challenging, despite their impressive performance. given the gradual increase in model size and the wide range of model applications, selectively executing model components for different inputs to improve the inference efficiency is of great interest. in this paper, we propose a dynamic layer-skipping method that leverages the ctc blank output from intermediate layers to trigger the skipping of the last few encoder layers for frames with high blank probabilities. furthermore, we factorize the ctc output distribution and perform knowledge distillation on intermediate layers to reduce computation and improve recognition accuracy. experimental results show that by utilizing the ctc blank, the encoder layer depth can be adjusted dynamically, resulting in 29% acceleration of the ctc model inference with minor performance degradation.","doi":"","created":1704240000000,"updated":"","authors":["junfeng hou","peiyao wang","jincheng zhang","meng yang","minwei feng","jingcheng yin"]}
{"id":"2401.02047","title":"covid19 vaccine acceptance and deprivation in us counties","categories":"cs.si physics.soc-ph","abstract":"this report explores the central question of how socioeconomic status affects covid19 vaccination rates in the united states, using existing open-source data. in general, a negative correlation exists between area deprivation index (adi) of a county and first dose, primary series and booster vaccination rates. higher area deprivation correlated with polled vaccine hesitancy and lower search interest in vaccine interest, intention to vaccinate or concern about safety of vaccination. positive correlations between adi and certain mental health search trends were noted. no clear correlation between deprivation index and accessibility to vaccination sites were observed. in a small data sample, county level housing assistance policies and public information campaigns were noted to positively influence vaccine follow through rates. finally, random forest, linear regression and knn models were explored to validate the use of the above features for vaccine acceptance prediction.","doi":"","created":1704240000000,"updated":"","authors":["zi iun lai","jun yang ang"]}
{"id":"2401.02050","title":"some gr\\\"onwall inequalities for a class of discretizations of time   fractional equations on nonuniform meshes","categories":"math.na cs.na","abstract":"we consider the completely positive discretizations of fractional ordinary differential equations (fodes) on nonuniform meshes. making use of the resolvents for nonuniform meshes, we first establish comparison principles for the discretizations. then we prove some discrete gr\\\"onwall inequalities using the comparison principles and careful analysis of the solutions to the time continuous fodes. our results do not have any restrictions on the step size ratio. the gr\\\"onwall inequalities for dissipative equations can be used to obtain the uniform-in-time error control and decay estimates of the numerical solutions. the gr\\\"onwall inequalities are then applied to subdiffusion problems and the time fractional allen-cahn equations for illustration.","doi":"","created":1704240000000,"updated":"","authors":["yuanyuan feng","lei li","jian-guo liu","tao tang"]}
{"id":"2401.02051","title":"evolution of heuristics: towards efficient automatic algorithm design   using large language model","categories":"cs.ne cs.ai","abstract":"heuristics are widely used for dealing with complex search and optimization problems. however, manual design of heuristics can be often very labour extensive and requires rich working experience and knowledge. this paper proposes evolution of heuristic (eoh), a novel evolutionary paradigm that leverages both large language models (llms) and evolutionary computation (ec) methods for automatic heuristic design (ahd). eoh represents the ideas of heuristics in natural language, termed thoughts. they are then translated into executable codes by llms. the evolution of both thoughts and codes in an evolutionary search framework makes it very effective and efficient for generating high-performance heuristics. experiments on three widely studied combinatorial optimization benchmark problems demonstrate that eoh outperforms commonly used handcrafted heuristics and other recent ahd methods including funsearch. particularly, the heuristic produced by eoh with a low computational budget (in terms of the number of queries to llms) significantly outperforms widely-used human hand-crafted baseline algorithms for the online bin packing problem.","doi":"","created":1704240000000,"updated":"2024-06-01","authors":["fei liu","xialiang tong","mingxuan yuan","xi lin","fu luo","zhenkun wang","zhichao lu","qingfu zhang"]}
{"id":"2401.02054","title":"less conservative robust reference governors and their applications","categories":"eess.sy cs.sy","abstract":"the applications of reference governors to systems with unmeasured set-bounded disturbances can lead to conservative solutions. this conservatism can be reduced by estimating the disturbance from output measurements and canceling it in the nominal control law. in this paper, a reference governor based on such an approach is considered and time-varying, disturbance and state estimation errors bounding sets are derived. consequently, the traditional implementation of a reference governor, which exploits a constraint admissible positively-invariant set of constant commands and initial states, is replaced by one which utilizes a time-dependent sequence of similar sets (which are not necessary nested). examples are reported which include two applications to longitudinal control of aircraft that illustrate handling of elevator uncertainty and wing icing.","doi":"","created":1704240000000,"updated":"","authors":["miguel castroviejo-fernandez","huayi li","andrés cotorruelo","emanuele garone","ilya kolmanovsky"]}
{"id":"2401.02058","title":"neural collapse for cross-entropy class-imbalanced learning with   unconstrained relu feature model","categories":"cs.lg stat.ml","abstract":"the current paradigm of training deep neural networks for classification tasks includes minimizing the empirical risk that pushes the training loss value towards zero, even after the training error has been vanished. in this terminal phase of training, it has been observed that the last-layer features collapse to their class-means and these class-means converge to the vertices of a simplex equiangular tight frame (etf). this phenomenon is termed as neural collapse (nc). to theoretically understand this phenomenon, recent works employ a simplified unconstrained feature model to prove that nc emerges at the global solutions of the training problem. however, when the training dataset is class-imbalanced, some nc properties will no longer be true. for example, the class-means geometry will skew away from the simplex etf when the loss converges. in this paper, we generalize nc to imbalanced regime for cross-entropy loss under the unconstrained relu feature model. we prove that, while the within-class features collapse property still holds in this setting, the class-means will converge to a structure consisting of orthogonal vectors with different lengths. furthermore, we find that the classifier weights are aligned to the scaled and centered class-means with scaling factors depend on the number of training samples of each class, which generalizes nc in the class-balanced setting. we empirically prove our results through experiments on practical architectures and dataset.","doi":"","created":1704240000000,"updated":"2024-06-06","authors":["hien dang","tho tran","tan nguyen","nhat ho"]}
{"id":"2401.02059","title":"seamless digital engineering: a grand challenge driven by needs","categories":"eess.sy cs.sy","abstract":"digital engineering currently relies on costly and often bespoke integration of disparate software products to assemble the authoritative source of truth of the system-of-interest. tools not originally designed to work together become an acknowledged system-of-systems, with their own separate feature roadmaps, deprecation, and support timelines. the resulting brittleness and conglomeration of disparate interfaces in the digital engineering ecosystem of an organization drains resources and impairs efficiency and efficacy. if model-based systems engineering were applied to this problem, a complete system architecture model would be defined, and a purpose-built computing system-of-systems would be constructed to satisfy stakeholder needs. we have decades of research in computer science, cybersecurity, software and systems engineering, and human-computer interaction from which to draw that informs the design of a seamless digital engineering tooling system, but it would require starting from a clean slate while carefully adopting existing standards. in this paper, this problem space and solution space are characterized, defining and identifying seamless digital engineering as a grand challenge in digital engineering research.","doi":"","created":1704240000000,"updated":"","authors":["james s. wheaton","daniel r. herber"]}
{"id":"2401.02062","title":"u-trustworthy models.reliability, competence, and confidence in   decision-making","categories":"stat.ml cs.lg","abstract":"with growing concerns regarding bias and discrimination in predictive models, the ai community has increasingly focused on assessing ai system trustworthiness. conventionally, trustworthy ai literature relies on the probabilistic framework and calibration as prerequisites for trustworthiness. in this work, we depart from this viewpoint by proposing a novel trust framework inspired by the philosophy literature on trust. we present a precise mathematical definition of trustworthiness, termed $\\mathcal{u}$-trustworthiness, specifically tailored for a subset of tasks aimed at maximizing a utility function. we argue that a model's $\\mathcal{u}$-trustworthiness is contingent upon its ability to maximize bayes utility within this task subset. our first set of results challenges the probabilistic framework by demonstrating its potential to favor less trustworthy models and introduce the risk of misleading trustworthiness assessments. within the context of $\\mathcal{u}$-trustworthiness, we prove that properly-ranked models are inherently $\\mathcal{u}$-trustworthy. furthermore, we advocate for the adoption of the auc metric as the preferred measure of trustworthiness. by offering both theoretical guarantees and experimental validation, auc enables robust evaluation of trustworthiness, thereby enhancing model selection and hyperparameter tuning to yield more trustworthy outcomes.","doi":"","created":1704240000000,"updated":"","authors":["ritwik vashistha","arya farahi"]}
{"id":"2401.02069","title":"local discontinuous galerkin methods for solving convection-diffusion   and cahn-hilliard equations on surfaces","categories":"math.na cs.na","abstract":"local discontinuous galerkin methods are developed for solving second order and fourth order time-dependent partial differential equations defined on static 2d manifolds. these schemes are second-order accurate with surfaces triangulized by planar triangles and careful design of numerical fluxes. the schemes are proven to be energy stable. various numerical experiments are provided to validate the new schemes.","doi":"","created":1704326400000,"updated":"","authors":["shixin xu","zhiliang xu"]}
{"id":"2401.02070","title":"spatiotemporal monitoring of epidemics via solution of a coefficient   inverse problem","categories":"math.na cs.na","abstract":"let s,i and r be susceptible, infected and recovered populations in a city affected by an epidemic. the sir model of lee, liu, tembine, li and osher, \\emph{siam j. appl. math.},~81, 190--207, 2021 of the spatiotemoral spread of epidemics is considered. this model consists of a system of three nonlinear coupled parabolic partial differential equations with respect to the space and time dependent functions s,i and r. for the first time, a coefficient inverse problem (cip) for this system is posed. the so-called \\textquotedblleft convexification\" numerical method for this inverse problem is constructed. the presence of the carleman weight function (cwf) in the resulting regularization functional ensures the global convergence of the gradient descent method of the minimization of this functional to the true solution of the cip, as long as the noise level tends to zero. the cwf is the function, which is used as the weight in the carleman estimate for the corresponding partial differential operator. numerical studies demonstrate an accurate reconstruction of unknown coefficients as well as s,i,r functions inside of that city. as a by-product, uniqueness theorem for this cip is proven. since the minimal measured input data are required, then the proposed methodology has a potential of a significant decrease of the cost of monitoring of epidemics.","doi":"","created":1704326400000,"updated":"","authors":["michael v. klibanov","jingzhi li","zhipeng yang"]}
{"id":"2401.02071","title":"joint beamforming and offloading design for integrated sensing,   communication and computation system","categories":"cs.it eess.sp math.it","abstract":"mobile edge computing (mec) is powerful to alleviate the heavy computing tasks in integrated sensing and communication (isac) systems. in this paper, we investigate joint beamforming and offloading design in a three-tier integrated sensing, communication and computation (iscc) framework comprising one cloud server, multiple mobile edge servers, and multiple terminals. while executing sensing tasks, the user terminals can optionally offload sensing data to either mec server or cloud servers. to minimize the execution latency, we jointly optimize the transmit beamforming matrices and offloading decision variables under the constraint of sensing performance. an alternating optimization algorithm based on multidimensional fractional programming is proposed to tackle the non-convex problem. simulation results demonstrates the superiority of the proposed mechanism in terms of convergence and task execution latency reduction, compared with the state-of-the-art two-tier iscc framework.","doi":"","created":1704326400000,"updated":"2024-01-26","authors":["peng liu","zesong fei","xinyi wang","yiqing zhou","yan zhang","fan liu"]}
{"id":"2401.02072","title":"ice-grt: instruction context enhancement by generative reinforcement   based transformers","categories":"cs.cl","abstract":"the emergence of large language models (llms) such as chatgpt and llama encounter limitations in domain-specific tasks, with these models often lacking depth and accuracy in specialized areas, and exhibiting a decrease in general capabilities when fine-tuned, particularly analysis ability in small sized models. to address these gaps, we introduce ice-grt, utilizing reinforcement learning from human feedback (rlhf) grounded in proximal policy optimization (ppo), demonstrating remarkable ability in in-domain scenarios without compromising general task performance. our exploration of ice-grt highlights its understanding and reasoning ability to not only generate robust answers but also to provide detailed analyses of the reasons behind the answer. this capability marks a significant progression beyond the scope of supervised fine-tuning models. the success of ice-grt is dependent on several crucial factors, including appropriate data, reward size scaling, kl-control, advantage normalization, etc. the ice-grt model exhibits state-of-the-art performance in domain-specific tasks and across 12 general language tasks against equivalent size and even larger size llms, highlighting the effectiveness of our approach. we provide a comprehensive analysis of the ice-grt, underscoring the significant advancements it brings to the field of llm.","doi":"","created":1704326400000,"updated":"","authors":["chen zheng","ke sun","da tang","yukun ma","yuyu zhang","chenguang xi","xun zhou"]}
{"id":"2401.02076","title":"leveraging sam for single-source domain generalization in medical image   segmentation","categories":"cs.cv","abstract":"domain generalization (dg) aims to reduce domain shifts between domains to achieve promising performance on the unseen target domain, which has been widely practiced in medical image segmentation. single-source domain generalization (sdg) is the most challenging setting that trains on only one source domain. although existing methods have made considerable progress on sdg of medical image segmentation, the performances are still far from the applicable standards when faced with a relatively large domain shift. in this paper, we leverage the segment anything model (sam) to sdg to greatly improve the ability of generalization. specifically, we introduce a parallel framework, the source images are sent into the sam module and normal segmentation module respectively. to reduce the calculation resources, we apply a merging strategy before sending images to the sam module. we extract the bounding boxes from the segmentation module and send the refined version as prompts to the sam module. we evaluate our model on a classic dg dataset and achieve competitive results compared to other state-of-the-art dg methods. furthermore, we conducted a series of ablation experiments to prove the effectiveness of the proposed method. the code is publicly available at https:\/\/github.com\/sarihust\/sammed.","doi":"","created":1704326400000,"updated":"","authors":["hanhui wang","huaize ye","yi xia","xueyan zhang"]}
{"id":"2401.02077","title":"characterizations and constructions of linear intersection pairs of   cyclic codes over finite fields","categories":"cs.it math.it","abstract":"linear intersection pairs of linear codes have become of interest due to their nice algebraic properties and wide applications. in this paper, we focus on linear intersection pairs of cyclic codes over finite fields. some properties of cyclotomic cosets in cyclic groups are presented as key tools in the study of such linear intersection pairs. characterization and constructions of two cyclic codes of a fixed intersecting dimension are given in terms of their generator polynomials and cyclotomic cosets. in some cases, constructions of two cyclic codes of a fixed intersecting subcode are presented as well. based on the theoretical characterization, some numerical examples of linear intersection pairs of cyclic codes with good parameters are illustrated.","doi":"","created":1704326400000,"updated":"","authors":["somphong jitman"]}
{"id":"2401.02078","title":"a complete characterization of spectra of the randic matrix of   level-wise regular trees","categories":"math.co cs.dm","abstract":"let $g$ be a simple finite connected graph with vertex set $v(g) = \\{v_1,v_2,\\ldots,v_n\\}$. denote the degree of vertex $v_i$ by $d_i$ for all $1 \\leq i \\leq n$. the randi\\'c matrix of $g$, denoted by $r(g) = [r_{i,j}]$, is the $n \\times n$ matrix whose $(i,j)$-entry $r_{i,j}$ is $r_{i,j} = 1\/\\sqrt{d_id_j}$ if $v_i$ and $v_j$ are adjacent in $g$ and 0 otherwise. a tree is a connected acyclic graph. a level-wise regular tree is a tree rooted at one vertex $r$ or two (adjacent) vertices $r$ and $r'$ in which all vertices with the minimum distance $i$ from $r$ or $r'$ have the same degree $m_i$ for $0 \\leq i \\leq h$, where $h$ is the height of $t$. in this paper, we give a complete characterization of the eigenvalues with their multiplicity of the randi\\'c matrix of level-wise regular trees. we prove that the eigenvalues of the randi\\'c matrix of a level-wise regular tree are the eigenvalues of the particular tridiagonal matrices, which are formed using the degree sequence $(m_0,m_1,\\ldots,m_{h-1})$ of level-wise regular trees.","doi":"","created":1704326400000,"updated":"","authors":["punit vadher","devsi bantva"]}
{"id":"2401.02080","title":"energy based diffusion generator for efficient sampling of boltzmann   distributions","categories":"cs.lg stat.co stat.ml","abstract":"we introduce a novel sampler called the energy based diffusion generator for generating samples from arbitrary target distributions. the sampling model employs a structure similar to a variational autoencoder, utilizing a decoder to transform latent variables from a simple distribution into random variables approximating the target distribution, and we design an encoder based on the diffusion model. leveraging the powerful modeling capacity of the diffusion model for complex distributions, we can obtain an accurate variational estimate of the kullback-leibler divergence between the distributions of the generated samples and the target. moreover, we propose a decoder based on generalized hamiltonian dynamics to further enhance sampling performance. through empirical evaluation, we demonstrate the effectiveness of our method across various complex distribution functions, showcasing its superiority compared to existing methods.","doi":"","created":1704326400000,"updated":"","authors":["yan wang","ling guo","hao wu","tao zhou"]}
{"id":"2401.02081","title":"performance trade-off and joint waveform design for mimo-ofdm dfrc   systems","categories":"cs.it eess.sp math.it","abstract":"dual-functional radar-communication (dfrc) has attracted considerable attention. this paper considers the frequency-selective multipath fading environment and proposes dfrc waveform design strategies based on multiple-input and multiple-output (mimo) and orthogonal frequency division multiplexing (ofdm) techniques. in the proposed waveform design strategies, the cramer-rao bound (crb) of the radar system, the inter-stream interference (isi) and the achievable rate of the communication system, are respectively considered as the performance metrics. in this paper, we focus on the performance trade-off between the radar system and the communication system, and the optimization problems are formulated. in the isi minimization based waveform design strategy, the optimization problem is convex and can be easily solved. in the achievable rate maximization based waveform design strategy, we propose a water-filling (wf) and sequential quadratic programming (sqp) based algorithm to derive the covariance matrix and the precoding matrix. simulation results validate the proposed dfrc waveform designs and show that the achievable rate maximization based strategy has a better performance than the isi minimization based strategy.","doi":"","created":1704326400000,"updated":"","authors":["tianchen liu","liang wu","bo an","zaichen zhang","jian dang","jiangzhou wang"]}
{"id":"2401.02083","title":"outage analysis for active reconfigurable intelligent surface-enhanced   wireless powered communication networks","categories":"cs.ni","abstract":"wireless powered communication (wpc) involves the integration of energy harvesting and data transmission. this allows devices to communicate without constant battery replacements or wired power sources. reconfigurable intelligent surfaces (riss) can dynamically manipulate radio signals. in this paper, we explore the use of active elements to mitigate double-fading challenges inherent in ris-aided links. we enhance the reliability performance for an energy-constrained user by combining active ris and wpc. the theoretical closed-form analysis, which includes transmission rate, harvested energy, and outage probability, provides valuable insights that inform parameter selection.","doi":"","created":1704326400000,"updated":"","authors":["waqas khalid","heejung yu","alexandros-apostolos a. boulogeorgos"]}
{"id":"2401.02086","title":"view-based explanations for graph neural networks","categories":"cs.lg cs.db","abstract":"generating explanations for graph neural networks (gnns) has been studied to understand their behavior in analytical tasks such as graph classification. existing approaches aim to understand the overall results of gnns rather than providing explanations for specific class labels of interest, and may return explanation structures that are hard to access, nor directly queryable.we propose gvex, a novel paradigm that generates graph views for explanation. (1) we design a two-tier explanation structure called explanation views. an explanation view consists of a set of graph patterns and a set of induced explanation subgraphs. given a database g of multiple graphs and a specific class label l assigned by a gnn-based classifier m, it concisely describes the fraction of g that best explains why l is assigned by m. (2) we propose quality measures and formulate an optimization problem to compute optimal explanation views for gnn explanation. we show that the problem is $\\sigma^2_p$-hard. (3) we present two algorithms. the first one follows an explain-and-summarize strategy that first generates high-quality explanation subgraphs which best explain gnns in terms of feature influence maximization, and then performs a summarization step to generate patterns. we show that this strategy provides an approximation ratio of 1\/2. our second algorithm performs a single-pass to an input node stream in batches to incrementally maintain explanation views, having an anytime quality guarantee of 1\/4 approximation. using real-world benchmark data, we experimentally demonstrate the effectiveness, efficiency, and scalability of gvex. through case studies, we showcase the practical applications of gvex.","doi":"10.1145\/3639295","created":1704326400000,"updated":"2024-01-07","authors":["tingyang chen","dazhuo qiu","yinghui wu","arijit khan","xiangyu ke","yunjun gao"]}
{"id":"2401.02088","title":"re-evaluating the memory-balanced pipeline parallelism: bpipe","categories":"cs.lg cs.cl cs.dc","abstract":"pipeline parallelism is an essential technique in the training of large-scale transformer models. however, it suffers from imbalanced memory consumption, leading to insufficient memory utilization. the bpipe technique was proposed to address this issue and has proven effective in the gpt-3 model. nevertheless, our experiments have not yielded similar benefits for llama training. additionally, bpipe only yields negligible benefits for gpt-3 training when applying flash attention. we analyze the underlying causes of the divergent performance of bpipe on gpt-3 and llama. furthermore, we introduce a novel method to estimate the performance of bpipe.","doi":"","created":1704326400000,"updated":"","authors":["mincong huang","chao wang","chi ma","yineng zhang","peng zhang","lei yu"]}
{"id":"2401.02090","title":"moduleguard:understanding and detecting module conflicts in python   ecosystem","categories":"cs.se","abstract":"python has become one of the most popular programming languages for software development due to its simplicity, readability, and versatility. as the python ecosystem grows, developers face increasing challenges in avoiding module conflicts, which occur when different packages have the same namespace modules. unfortunately, existing work has neither investigated the module conflict comprehensively nor provided tools to detect the conflict. therefore, this paper systematically investigates the module conflict problem and its impact on the python ecosystem. we propose a novel technique called instsimulator, which leverages semantics and installation simulation to achieve accurate and efficient module extraction. based on this, we implement a tool called moduleguard to detect module conflicts for the python ecosystem. for the study, we first collect 97 mc issues, classify the characteristics and causes of these mc issues, summarize three different conflict patterns, and analyze their potential threats. then, we conducted a large-scale analysis of the whole pypi ecosystem (4.2 million packages) and github popular projects (3,711 projects) to detect each mc pattern and analyze their potential impact. we discovered that module conflicts still impact numerous tpls and github projects. this is primarily due to developers' lack of understanding of the modules within their direct dependencies, not to mention the modules of the transitive dependencies. our work reveals python's shortcomings in handling naming conflicts and provides a tool and guidelines for developers to detect conflicts.","doi":"10.1145\/3597503.3639221","created":1704326400000,"updated":"","authors":["ruofan zhu","xingyu wang","chengwei liu","zhengzi xu","wenbo shen","rui chang","yang liu"]}
{"id":"2401.02091","title":"termination of rewriting on reversible boolean circuits as a free   3-category problem","categories":"cs.lo math.ct","abstract":"reversible boolean circuits are an interesting computational model under many aspects and in different fields, ranging from reversible computing to quantum computing. our contribution is to describe a specific class of reversible boolean circuits - which is as expressive as classical circuits - as a bi-dimensional diagrammatic programming language. we uniformly represent the reversible boolean circuits we focus on as a free 3-category toff. this formalism allows us to incorporate the representation of circuits and of rewriting rules on them, and to prove termination of rewriting. termination follows from defining a non-identities-preserving functor from our free 3-category toff into a suitable 3-category move that traces the \"moves\" applied to wires inside circuits.","doi":"","created":1704326400000,"updated":"","authors":["adriano barile","stefano berardi","luca roversi"]}
{"id":"2401.02092","title":"k-winners-take-all ensemble neural network","categories":"cs.ne cs.ai","abstract":"ensembling is one approach that improves the performance of a neural network by combining a number of independent neural networks, usually by either averaging or summing up their individual outputs. we modify this ensembling approach by training the sub-networks concurrently instead of independently. this concurrent training of sub-networks leads them to cooperate with each other, and we refer to them as \"cooperative ensemble\". meanwhile, the mixture-of-experts approach improves a neural network performance by dividing up a given dataset to its sub-networks. it then uses a gating network that assigns a specialization to each of its sub-networks called \"experts\". we improve on these aforementioned ways for combining a group of neural networks by using a k-winners-take-all (kwta) activation function, that acts as the combination method for the outputs of each sub-network in the ensemble. we refer to this proposed model as \"kwta ensemble neural networks\" (kwta-enn). with the kwta activation function, the losing neurons of the sub-networks are inhibited while the winning neurons are retained. this results in sub-networks having some form of specialization but also sharing knowledge with one another. we compare our approach with the cooperative ensemble and mixture-of-experts, where we used a feed-forward neural network with one hidden layer having 100 neurons as the sub-network architecture. our approach yields a better performance compared to the baseline models, reaching the following test accuracies on benchmark datasets: 98.34% on mnist, 88.06% on fashion-mnist, 91.56% on kmnist, and 95.97% on wdbc.","doi":"10.1007\/978-3-030-92270-2_22","created":1704326400000,"updated":"","authors":["abien fred agarap","arnulfo p. azcarraga"]}
{"id":"2401.02093","title":"a new approach to convergence analysis of iterative models with optimal   error bounds","categories":"math.na cs.na","abstract":"in this paper, we study a new approach related to the convergence analysis of ishikawa-type iterative models to a common fixed point of two non-expansive mappings in banach spaces. the main novelty of our contribution lies in the so-called \\emph{optimal error bounds}, which established some necessary and sufficient conditions for convergence and derived both the error estimates and bounds on the convergence rates for iterative schemes. although a special interest here is devoted to the ishikawa and modified ishikawa iterative sequences, the theory of \\emph{optimal error bounds} proposed in this paper can also be favorably applied to various types of iterative models to approximate common fixed points of non-expansive mappings.","doi":"","created":1704326400000,"updated":"","authors":["minh-phuong tran","thanh-nhan nguyen","thai-hung nguyen","tan-phuc nguyen","tien-khai nguyen","cong-duy-nguyen nguyen","trung-hieu huynh"]}
{"id":"2401.02094","title":"pilora: prototype guided incremental lora for federated   class-incremental learning","categories":"cs.cv","abstract":"existing federated learning methods have effectively dealt with decentralized learning in scenarios involving data privacy and non-iid data. however, in real-world situations, each client dynamically learns new classes, requiring the global model to classify all seen classes. to effectively mitigate catastrophic forgetting and data heterogeneity under low communication costs, we propose a simple and effective method named pilora. on the one hand, we adopt prototype learning to learn better feature representations and leverage the heuristic information between prototypes and class features to design a prototype re-weight module to solve the classifier bias caused by data heterogeneity without retraining the classifier. on the other hand, we view incremental learning as the process of learning distinct task vectors and encoding them within different lora parameters. accordingly, we propose incremental lora to mitigate catastrophic forgetting. experimental results on standard datasets indicate that our method outperforms the state-of-the-art approaches significantly. more importantly, our method exhibits strong robustness and superiority in different settings and degrees of data heterogeneity. the code is available at \\url{https:\/\/github.com\/ghy0501\/pilora}.","doi":"","created":1704326400000,"updated":"2024-07-15","authors":["haiyang guo","fei zhu","wenzhuo liu","xu-yao zhang","cheng-lin liu"]}
{"id":"2401.02095","title":"politics and propaganda on social media: how twitter and meta moderate   state-linked information operations","categories":"cs.si","abstract":"why do social media corporations (smcs) engage in state-linked information operations? social media can significantly influence the global political landscape, allowing governments and other political entities to engage in concerted information operations, shaping or manipulating domestic and foreign political agendas. in response to state-linked political manipulation tactics on social media, twitter and meta carried out take-down operations against propaganda networks, accusing them of interfering foreign elections, organizing disinformation campaigns, manipulating political debates and many other issues. this research investigates the two smcs' policy orientation to explain which factors can affect these two companies' reaction against state-linked information operations. we find that good governance indicators such as democracy are significant elements of smcs' country-focus. this article also examines whether meta and twitter's attention to political regime characteristics is influenced by international political alignments. this research illuminates recent trends in smcs' take-down operations and illuminating interplay between geopolitics and domestic regime characteristics.","doi":"","created":1704326400000,"updated":"","authors":["nihat mugurtay","umut duygu","onur varol"]}
{"id":"2401.02097","title":"preserving image properties through initializations in diffusion models","categories":"cs.cv","abstract":"retail photography imposes specific requirements on images. for instance, images may need uniform background colors, consistent model poses, centered products, and consistent lighting. minor deviations from these standards impact a site's aesthetic appeal, making the images unsuitable for use. we show that stable diffusion methods, as currently applied, do not respect these requirements. the usual practice of training the denoiser with a very noisy image and starting inference with a sample of pure noise leads to inconsistent generated images during inference. this inconsistency occurs because it is easy to tell the difference between samples of the training and inference distributions. as a result, a network trained with centered retail product images with uniform backgrounds generates images with erratic backgrounds. the problem is easily fixed by initializing inference with samples from an approximation of noisy images. however, in using such an approximation, the joint distribution of text and noisy image at inference time still slightly differs from that at training time. this discrepancy is corrected by training the network with samples from the approximate noisy image distribution. extensive experiments on real application data show significant qualitative and quantitative improvements in performance from adopting these procedures. finally, our procedure can interact well with other control-based methods to further enhance the controllability of diffusion-based methods.","doi":"","created":1704326400000,"updated":"","authors":["jeffrey zhang","shao-yu chang","kedan li","david forsyth"]}
{"id":"2401.02099","title":"oceanship: a large-scale dataset for underwater audio target recognition","categories":"cs.cv cs.sd eess.as","abstract":"the recognition of underwater audio plays a significant role in identifying a vessel while it is in motion. underwater target recognition tasks have a wide range of applications in areas such as marine environmental protection, detection of ship radiated noise, underwater noise control, and coastal vessel dispatch. the traditional uatr task involves training a network to extract features from audio data and predict the vessel type. the current uatr dataset exhibits shortcomings in both duration and sample quantity. in this paper, we propose oceanship, a large-scale and diverse underwater audio dataset. this dataset comprises 15 categories, spans a total duration of 121 hours, and includes comprehensive annotation information such as coordinates, velocity, vessel types, and timestamps. we compiled the dataset by crawling and organizing original communication data from the ocean communication network (onc) database between 2021 and 2022. while audio retrieval tasks are well-established in general audio classification, they have not been explored in the context of underwater audio recognition. leveraging the oceanship dataset, we introduce a baseline model named oceannet for underwater audio retrieval. this model achieves a recall at 1 (r@1) accuracy of 67.11% and a recall at 5 (r@5) accuracy of 99.13% on the deepship dataset.","doi":"","created":1704326400000,"updated":"2024-06-10","authors":["zeyu li","suncheng xiang","tong yu","jingsheng gao","jiacheng ruan","yanping hu","ting liu","yuzhuo fu"]}
{"id":"2401.02105","title":"perceptions of humanoid robots in caregiving: a study of skilled nursing   home and long term care administrators","categories":"cs.cy cs.hc cs.ro","abstract":"as the aging population increases and the shortage of healthcare workers increases, the need to examine other means for caring for the aging population increases. one such means is the use of humanoid robots to care for social, emotional, and physical wellbeing of the people above 65. understanding skilled and long term care nursing home administrators' perspectives on humanoid robots in caregiving is crucial as their insights shape the implementation of robots and their potential impact on resident well-being and quality of life. this authors surveyed two hundred and sixty nine nursing homes executives to understand their perspectives on the use of humanoid robots in their nursing home facilities. the data was coded and results revealed that the executives were keen on exploring other avenues for care such as robotics that would enhance their nursing homes abilities to care for their residents. qualitative analysis reveals diverse perspectives on integrating humanoid robots in nursing homes. while acknowledging benefits like improved engagement and staff support, concerns persist about costs, impacts on human interaction, and doubts about robot effectiveness. this highlights complex barriers financial, technical, and human and emphasizes the need for strategic implementation. it underscores the importance of thorough training, role clarity, and showcasing technology benefits to ensure efficiency and satisfaction among staff and residents.","doi":"","created":1704326400000,"updated":"","authors":["rana imtiaz","arshia khan"]}
{"id":"2401.02106","title":"cadmium zinc telluride (czt) photon counting detector characterisation   for soft tissue imaging","categories":"physics.ins-det cs.lg eess.iv physics.med-ph","abstract":"the use of photon counting detection technology has resulted in significant x-ray imaging research interest in recent years. computed tomography (ct) scanners can benefit from photon-counting detectors, which are new technology with the potential to overcome key limitations of conventional ct detectors. researchers are still studying the effectiveness and sensitivity of semiconductor detector materials in photon counting detectors for detecting soft tissue contrasts. this study aimed to characterize the performance of the cadmium zinc telluride photon counting detector in identifying various tissues. an optimal frame rate per second (fps) of czt detector was evaluated by setting the x-ray tube voltage and current at 25 kev, 35 kev and 0.5 ma, 1.0 ma respectively by keeping the optimum fps fixed, the detector energy thresholds were set in small steps from 15 kev to 35 kev and the currents were set for x-ray tubes in ranges of 0.1 ma to 1.0 ma to find the relationship between voltage and current of the x-ray source and counts per second (cps). the samples i.e., fat, liver, muscles, paraffin wax, and contrast media were stacked at six different thickness levels in a stair-step chamber made from plexi-glass. x-ray transmission at six different thicknesses of tissue samples was also examined for five different energy (regions) thresholds (21 kev, 25 kev, 29 kev, 31 kev, and 45 kev) to determine the effect on count per second (cps). in this study, 12 frames per second is found to be the optimum frame rate per second (fps) based on the spectral response of an x-ray source and cps has a linear relationship with x-ray tube current as well. it was also noted that a sample's thickness also affects its x-ray transmission at different energy thresholds. a high sensitivity and linearity of the detectors make them suitable for use in both preclinical and medical applications.","doi":"","created":1704326400000,"updated":"2024-01-05","authors":["k. hameed","rafidah zainon","mahbubunnabi tamal"]}
{"id":"2401.02110","title":"significance of anatomical constraints in virtual try-on","categories":"cs.cv","abstract":"the system of virtual try-on (vton) allows a user to try a product virtually. in general, a vton system takes a clothing source and a person's image to predict the try-on output of the person in the given clothing. although existing methods perform well for simple poses, in case of bent or crossed arms posture or when there is a significant difference between the alignment of the source clothing and the pose of the target person, these methods fail by generating inaccurate clothing deformations. in the vton methods that employ thin plate spline (tps) based clothing transformations, this mainly occurs for two reasons - (1)~the second-order smoothness constraint of tps that restricts the bending of the object plane. (2)~overlaps among different clothing parts (e.g., sleeves and torso) can not be modeled by a single tps transformation, as it assumes the clothing as a single planar object; therefore, disregards the independence of movement of different clothing parts. to this end, we make two major contributions. concerning the bending limitations of tps, we propose a human anatomy-aware geometric (atag) transformation. regarding the overlap issue, we propose a part-based warping approach that divides the clothing into independently warpable parts to warp them separately and later combine them. extensive analysis shows the efficacy of this approach.","doi":"","created":1704326400000,"updated":"","authors":["debapriya roy","sanchayan santra","diganta mukherjee","bhabatosh chanda"]}
{"id":"2401.02113","title":"source-free online domain adaptive semantic segmentation of satellite   images under image degradation","categories":"cs.cv","abstract":"online adaptation to distribution shifts in satellite image segmentation stands as a crucial yet underexplored problem. in this paper, we address source-free and online domain adaptation, i.e., test-time adaptation (tta), for satellite images, with the focus on mitigating distribution shifts caused by various forms of image degradation. towards achieving this goal, we propose a novel tta approach involving two effective strategies. first, we progressively estimate the global batch normalization (bn) statistics of the target distribution with incoming data stream. leveraging these statistics during inference has the ability to effectively reduce domain gap. furthermore, we enhance prediction quality by refining the predicted masks using global class centers. both strategies employ dynamic momentum for fast and stable convergence. notably, our method is backpropagation-free and hence fast and lightweight, making it highly suitable for on-the-fly adaptation to new domain. through comprehensive experiments across various domain adaptation scenarios, we demonstrate the robust performance of our method.","doi":"","created":1704326400000,"updated":"","authors":["fahim faisal niloy","kishor kumar bhaumik","simon s. woo"]}
{"id":"2401.02114","title":"chebyshev subdivision and reduction methods for solving multivariable   systems of equations","categories":"math.na cs.na math.ag","abstract":"we present a new algorithm for finding isolated zeros of a system of real-valued functions in a bounded interval in $\\mathbb{r}^n$. it uses the chebyshev proxy method combined with a mixture of subdivision, reduction methods, and elimination checks that leverage special properties of chebyshev polynomials. we prove the method has r-quadratic convergence locally near simple zeros of the system. we also analyze the temporal complexity and the numerical stability of the algorithm and provide numerical evidence in dimensions up to three that the method is both fast and accurate on a wide range of problems. the algorithm should also work well in higher dimensions. our tests show that the algorithm outperforms other standard methods on this problem of finding all real zeros in a bounded domain. our python implementation of the algorithm is publicly available.","doi":"","created":1704326400000,"updated":"","authors":["erik parkinson","kate wall","jane slagle","daniel treuhaft","xander de la bruere","samuel goldrup","timothy keith","peter call","tyler j. jarvis"]}
{"id":"2401.02115","title":"using llm to select the right sql query from candidates","categories":"cs.cl","abstract":"text-to-sql models can generate a list of candidate sql queries, and the best query is often in the candidate list, but not at the top of the list. an effective re-rank method can select the right sql query from the candidate list and improve the model's performance. previous studies on code generation automatically generate test cases and use them to re-rank candidate codes. however, automatic test case generation for text-to-sql is an understudied field. we propose an automatic test case generation method that first generates a database and then uses llms to predict the ground truth, which is the expected execution results of the ground truth sql query on this database. to reduce the difficulty for llms to predict, we conduct experiments to search for ways to generate easy databases for llms and design easy-to-understand prompts. based on our test case generation method, we propose a re-rank method to select the right sql query from the candidate list. given a candidate list, our method can generate test cases and re-rank the candidate list according to their pass numbers on these test cases and their generation probabilities. the experiment results on the validation dataset of spider show that the performance of some state-of-the-art models can get a 3.6\\% improvement after applying our re-rank method.","doi":"","created":1704326400000,"updated":"","authors":["zhenwen li","tao xie"]}
{"id":"2401.02116","title":"starling: an i\/o-efficient disk-resident graph index framework for   high-dimensional vector similarity search on data segment","categories":"cs.db cs.ir","abstract":"high-dimensional vector similarity search (hvss) is gaining prominence as a powerful tool for various data science and ai applications. as vector data scales up, in-memory indexes pose a significant challenge due to the substantial increase in main memory requirements. a potential solution involves leveraging disk-based implementation, which stores and searches vector data on high-performance devices like nvme ssds. however, implementing hvss for data segments proves to be intricate in vector databases where a single machine comprises multiple segments for system scalability. in this context, each segment operates with limited memory and disk space, necessitating a delicate balance between accuracy, efficiency, and space cost. existing disk-based methods fall short as they do not holistically address all these requirements simultaneously. in this paper, we present starling, an i\/o-efficient disk-resident graph index framework that optimizes data layout and search strategy within the segment. it has two primary components: (1) a data layout incorporating an in-memory navigation graph and a reordered disk-based graph with enhanced locality, reducing the search path length and minimizing disk bandwidth wastage; and (2) a block search strategy designed to minimize costly disk i\/o operations during vector query execution. through extensive experiments, we validate the effectiveness, efficiency, and scalability of starling. on a data segment with 2gb memory and 10gb disk capacity, starling can accommodate up to 33 million vectors in 128 dimensions, offering hvss with over 0.9 average precision and top-10 recall rate, and latency under 1 millisecond. the results showcase starling's superior performance, exhibiting 43.9$\\times$ higher throughput with 98% lower query latency compared to state-of-the-art methods while maintaining the same level of accuracy.","doi":"10.1145\/3639269","created":1704326400000,"updated":"2024-03-02","authors":["mengzhao wang","weizhi xu","xiaomeng yi","songlin wu","zhangyang peng","xiangyu ke","yunjun gao","xiaoliang xu","rentong guo","charles xie"]}
{"id":"2401.02117","title":"mobile aloha: learning bimanual mobile manipulation with low-cost   whole-body teleoperation","categories":"cs.ro cs.ai cs.cv cs.lg cs.sy eess.sy","abstract":"imitation learning from human demonstrations has shown impressive performance in robotics. however, most results focus on table-top manipulation, lacking the mobility and dexterity necessary for generally useful tasks. in this work, we develop a system for imitating mobile manipulation tasks that are bimanual and require whole-body control. we first present mobile aloha, a low-cost and whole-body teleoperation system for data collection. it augments the aloha system with a mobile base, and a whole-body teleoperation interface. using data collected with mobile aloha, we then perform supervised behavior cloning and find that co-training with existing static aloha datasets boosts performance on mobile manipulation tasks. with 50 demonstrations for each task, co-training can increase success rates by up to 90%, allowing mobile aloha to autonomously complete complex mobile manipulation tasks such as sauteing and serving a piece of shrimp, opening a two-door wall cabinet to store heavy cooking pots, calling and entering an elevator, and lightly rinsing a used pan using a kitchen faucet. project website: https:\/\/mobile-aloha.github.io","doi":"","created":1704326400000,"updated":"","authors":["zipeng fu","tony z. zhao","chelsea finn"]}
{"id":"2401.02118","title":"radio map-based spectrum sharing for joint communication and sensing","categories":"cs.it eess.sp math.it","abstract":"the sixth-generation (6g) network is expected to provide both communication and sensing (c&s) services. however, spectrum scarcity poses a major challenge to the harmonious coexistence of c&s systems. without effective cooperation, the interference resulting from spectrum sharing impairs the performance of both systems. this paper addresses c&s interference within a distributed network. different from traditional schemes that require pilot-based high-frequency interactions between c&s systems, we introduce a third party named the radio map to provide the large-scale channel state information (csi). with large-scale csi, we optimize the transmit power of c&s systems to maximize the signal-to-interference-plus-noise ratio (sinr) for the radar detection, while meeting the ergodic rate requirement of the interfered user. given the non-convexity of both the objective and constraint, we employ the techniques of auxiliary-function-based scaling and fractional programming for simplification. subsequently, we propose an iterative algorithm to solve this problem. simulation results corroborate our idea that the extrinsic information, i.e., positions and surroundings, is effective to decouple c&s interference.","doi":"","created":1704326400000,"updated":"2024-06-27","authors":["xionran fang","wei feng","yunfei chen","dingxi yang","ning ge","zhiyong feng","yue gao"]}
{"id":"2401.02120","title":"quadratic discontinuous galerkin methods for unilateral contact problem","categories":"math.na cs.na math.ap","abstract":"in this article, we employ discontinuous galerkin (dg) methods for the finite element approximation of the frictionless unilateral contact problem using quadratic finite elements over simplicial triangulation. we first establish an optimal \\textit{a priori} error estimates under the appropriate regularity assumption on the exact solution $\\b{u}$. further, we analyze \\textit{a posteriori} error estimates in the dg norm wherein, the reliability and efficiency of the proposed \\textit{a posteriori} error estimator is addressed. the suitable construction of discrete lagrange multiplier $\\b{\\lambda_h}$ and some intermediate operators play a key role in developing \\textit{a posteriori} error analysis. numerical results presented on uniform and adaptive meshes illustrate and confirm the theoretical findings.","doi":"","created":1704326400000,"updated":"","authors":["kamana porwal","tanvi wadhawan"]}
{"id":"2401.02122","title":"peft for speech: unveiling optimal placement, merging strategies, and   ensemble techniques","categories":"cs.cl cs.sd eess.as","abstract":"parameter-efficient fine-tuning (peft) is increasingly recognized as an effective method in speech processing. however, the optimal approach and the placement of peft methods remain inconclusive. our study conducts extensive experiments to compare different peft methods and their layer-wise placement adapting differentiable architecture search (darts). we also explore the use of ensemble learning to leverage diverse peft strategies. the results reveal that darts does not outperform the baseline approach, which involves inserting the same peft method into all layers of a self-supervised learning (ssl) model. in contrast, an ensemble learning approach, particularly one employing majority voting, demonstrates superior performance. our statistical evidence indicates that different peft methods learn in varied ways. this variation might explain why the synergistic integration of various peft methods through ensemble learning can harness their unique learning capabilities more effectively compared to individual layer-wise optimization.","doi":"","created":1704326400000,"updated":"2024-02-07","authors":["tzu-han lin","how-shing wang","hao-yung weng","kuang-chen peng","zih-ching chen","hung-yi lee"]}
{"id":"2401.02124","title":"acp-esm: a novel framework for classification of anticancer peptides   using protein-oriented transformer approach","categories":"q-bio.bm cs.ai cs.ce cs.lg","abstract":"anticancer peptides (acps) are a class of molecules that have gained significant attention in the field of cancer research and therapy. acps are short chains of amino acids, the building blocks of proteins, and they possess the ability to selectively target and kill cancer cells. one of the key advantages of acps is their ability to selectively target cancer cells while sparing healthy cells to a greater extent. this selectivity is often attributed to differences in the surface properties of cancer cells compared to normal cells. that is why acps are being investigated as potential candidates for cancer therapy. acps may be used alone or in combination with other treatment modalities like chemotherapy and radiation therapy. while acps hold promise as a novel approach to cancer treatment, there are challenges to overcome, including optimizing their stability, improving selectivity, and enhancing their delivery to cancer cells, continuous increasing in number of peptide sequences, developing a reliable and precise prediction model. in this work, we propose an efficient transformer-based framework to identify anticancer peptides for by performing accurate a reliable and precise prediction model. for this purpose, four different transformer models, namely esm, protbert, biobert, and scibert are employed to detect anticancer peptides from amino acid sequences. to demonstrate the contribution of the proposed framework, extensive experiments are carried on widely-used datasets in the literature, two versions of anticp2, cacp-deepgram, acp-740. experiment results show the usage of proposed model enhances classification accuracy when compared to the state-of-the-art studies. the proposed framework, esm, exhibits 96.45 of accuracy for anticp2 dataset, 97.66 of accuracy for cacp-deepgram dataset, and 88.51 of accuracy for acp-740 dataset, thence determining new state-of-the-art.","doi":"","created":1704326400000,"updated":"","authors":["zeynep hilal kilimci","mustafa yalcin"]}
{"id":"2401.02126","title":"unified diffusion-based rigid and non-rigid editing with text and image   guidance","categories":"cs.cv","abstract":"existing text-to-image editing methods tend to excel either in rigid or non-rigid editing but encounter challenges when combining both, resulting in misaligned outputs with the provided text prompts. in addition, integrating reference images for control remains challenging. to address these issues, we present a versatile image editing framework capable of executing both rigid and non-rigid edits, guided by either textual prompts or reference images. we leverage a dual-path injection scheme to handle diverse editing scenarios and introduce an integrated self-attention mechanism for fusion of appearance and structural information. to mitigate potential visual artifacts, we further employ latent fusion techniques to adjust intermediate latents. compared to previous work, our approach represents a significant advance in achieving precise and versatile image editing. comprehensive experiments validate the efficacy of our method, showcasing competitive or superior results in text-based editing and appearance transfer tasks, encompassing both rigid and non-rigid settings.","doi":"","created":1704326400000,"updated":"","authors":["jiacheng wang","ping liu","wei xu"]}
{"id":"2401.02130","title":"spectral-based graph neural networks for complementary item   recommendation","categories":"cs.ir cs.si","abstract":"modeling complementary relationships greatly helps recommender systems to accurately and promptly recommend the subsequent items when one item is purchased. unlike traditional similar relationships, items with complementary relationships may be purchased successively (such as iphone and airpods pro), and they not only share relevance but also exhibit dissimilarity. since the two attributes are opposites, modeling complementary relationships is challenging. previous attempts to exploit these relationships have either ignored or oversimplified the dissimilarity attribute, resulting in ineffective modeling and an inability to balance the two attributes. since graph neural networks (gnns) can capture the relevance and dissimilarity between nodes in the spectral domain, we can leverage spectral-based gnns to effectively understand and model complementary relationships. in this study, we present a novel approach called spectral-based complementary graph neural networks (scomgnn) that utilizes the spectral properties of complementary item graphs. we make the first observation that complementary relationships consist of low-frequency and mid-frequency components, corresponding to the relevance and dissimilarity attributes, respectively. based on this spectral observation, we design spectral graph convolutional networks with low-pass and mid-pass filters to capture the low-frequency and mid-frequency components. additionally, we propose a two-stage attention mechanism to adaptively integrate and balance the two attributes. experimental results on four e-commerce datasets demonstrate the effectiveness of our model, with scomgnn significantly outperforming existing baseline models.","doi":"","created":1704326400000,"updated":"2024-02-05","authors":["haitong luo","xuying meng","suhang wang","hanyun cao","weiyao zhang","yequan wang","yujun zhang"]}
{"id":"2401.02132","title":"dcr-consistency: divide-conquer-reasoning for consistency evaluation and   improvement of large language models","categories":"cs.cl cs.ai","abstract":"evaluating the quality and variability of text generated by large language models (llms) poses a significant, yet unresolved research challenge. traditional evaluation methods, such as rouge and bertscore, which measure token similarity, often fail to capture the holistic semantic equivalence. this results in a low correlation with human judgments and intuition, which is especially problematic in high-stakes applications like healthcare and finance where reliability, safety, and robust decision-making are highly critical. this work proposes dcr, an automated framework for evaluating and improving the consistency of llm-generated texts using a divide-conquer-reasoning approach. unlike existing llm-based evaluators that operate at the paragraph level, our method employs a divide-and-conquer evaluator (dce) that breaks down the paragraph-to-paragraph comparison between two generated responses into individual sentence-to-paragraph comparisons, each evaluated based on predefined criteria. to facilitate this approach, we introduce an automatic metric converter (amc) that translates the output from dce into an interpretable numeric score. beyond the consistency evaluation, we further present a reason-assisted improver (rai) that leverages the analytical reasons with explanations identified by dce to generate new responses aimed at reducing these inconsistencies. through comprehensive and systematic empirical analysis, we show that our approach outperforms state-of-the-art methods by a large margin (e.g., +19.3% and +24.3% on the summeval dataset) in evaluating the consistency of llm generation across multiple benchmarks in semantic, factual, and summarization consistency tasks. our approach also substantially reduces nearly 90% of output inconsistencies, showing promise for effective hallucination mitigation.","doi":"","created":1704326400000,"updated":"","authors":["wendi cui","jiaxin zhang","zhuohang li","lopez damien","kamalika das","bradley malin","sricharan kumar"]}
{"id":"2401.02135","title":"poscuda: position based convolution for unlearnable audio datasets","categories":"cs.sd cs.cr cs.lg eess.as","abstract":"deep learning models require large amounts of clean data to acheive good performance. to avoid the cost of expensive data acquisition, researchers use the abundant data available on the internet. this raises significant privacy concerns on the potential misuse of personal data for model training without authorisation. recent works such as cuda propose solutions to this problem by adding class-wise blurs to make datasets unlearnable, i.e a model can never use the acquired dataset for learning. however these methods often reduce the quality of the data making it useless for practical applications. we introduce poscuda, a position based convolution for creating unlearnable audio datasets. poscuda uses class-wise convolutions on small patches of audio. the location of the patches are based on a private key for each class, hence the model learns the relations between positional blurs and labels, while failing to generalize. we empirically show that poscuda can achieve unlearnability while maintaining the quality of the original audio datasets. our proposed method is also robust to different audio feature representations such as mfcc, raw audio and different architectures such as transformers, convolutional networks etc.","doi":"","created":1704326400000,"updated":"","authors":["vignesh gokul","shlomo dubnov"]}
{"id":"2401.02137","title":"sycoca: symmetrizing contrastive captioners with attentive masking for   multimodal alignment","categories":"cs.cv cs.ai","abstract":"multimodal alignment between language and vision is the fundamental topic in current vision-language model research. contrastive captioners (coca), as a representative method, integrates contrastive language-image pretraining (clip) and image caption (ic) into a unified framework, resulting in impressive results. clip imposes a bidirectional constraints on global representation of entire images and sentences. although ic conducts an unidirectional image-to-text generation on local representation, it lacks any constraint on local text-to-image reconstruction, which limits the ability to understand images at a fine-grained level when aligned with texts. to achieve multimodal alignment from both global and local perspectives, this paper proposes symmetrizing contrastive captioners (sycoca), which introduces bidirectional interactions on images and texts across the global and local representation levels. specifically, we expand a text-guided masked image modeling (tg-mim) head based on itc and ic heads. the improved sycoca can further leverage textual cues to reconstruct contextual images and visual cues to predict textual contents. when implementing bidirectional local interactions, the local contents of images tend to be cluttered or unrelated to their textual descriptions. thus, we employ an attentive masking strategy to select effective image patches for interaction. extensive experiments on five vision-language tasks, including image-text retrieval, image-captioning, visual question answering, and zero-shot\/finetuned image classification, validate the effectiveness of our proposed method.","doi":"","created":1704326400000,"updated":"","authors":["ziping ma","furong xu","jian liu","ming yang","qingpei guo"]}
{"id":"2401.02138","title":"explore human parsing modality for action recognition","categories":"cs.cv","abstract":"multimodal-based action recognition methods have achieved high success using pose and rgb modality. however, skeletons sequences lack appearance depiction and rgb images suffer irrelevant noise due to modality limitations. to address this, we introduce human parsing feature map as a novel modality, since it can selectively retain effective semantic features of the body parts, while filtering out most irrelevant noise. we propose a new dual-branch framework called ensemble human parsing and pose network (epp-net), which is the first to leverage both skeletons and human parsing modalities for action recognition. the first human pose branch feeds robust skeletons in graph convolutional network to model pose features, while the second human parsing branch also leverages depictive parsing feature maps to model parsing festures via convolutional backbones. the two high-level features will be effectively combined through a late fusion strategy for better action recognition. extensive experiments on ntu rgb+d and ntu rgb+d 120 benchmarks consistently verify the effectiveness of our proposed epp-net, which outperforms the existing action recognition methods. our code is available at: https:\/\/github.com\/liujf69\/epp-net-action.","doi":"","created":1704326400000,"updated":"","authors":["jinfu liu","runwei ding","yuhang wen","nan dai","fanyang meng","shen zhao","mengyuan liu"]}
{"id":"2401.02141","title":"bayesian intrinsic groupwise image registration: unsupervised   disentanglement of anatomy and geometry","categories":"cs.cv","abstract":"this article presents a general bayesian learning framework for multi-modal groupwise registration on medical images. the method builds on probabilistic modelling of the image generative process, where the underlying common anatomy and geometric variations of the observed images are explicitly disentangled as latent variables. thus, groupwise registration is achieved through the solution to bayesian inference. we propose a novel hierarchical variational auto-encoding architecture to realize the inference procedure of the latent variables, where the registration parameters can be calculated in a mathematically interpretable fashion. remarkably, this new paradigm can learn groupwise registration in an unsupervised closed-loop self-reconstruction process, sparing the burden of designing complex intensity-based similarity measures. the computationally efficient disentangled architecture is also inherently scalable and flexible, allowing for groupwise registration on large-scale image groups with variable sizes. furthermore, the inferred structural representations from disentanglement learning are capable of capturing the latent anatomy of the observations with visual semantics. extensive experiments were conducted to validate the proposed framework, including four datasets from cardiac, brain and abdominal medical images. the results have demonstrated the superiority of our method over conventional similarity-based approaches in terms of accuracy, efficiency, scalability and interpretability.","doi":"","created":1704326400000,"updated":"","authors":["xinzhe luo","xin wang","linda shapiro","chun yuan","jianfeng feng","xiahai zhuang"]}
{"id":"2401.02142","title":"guess:gradually enriching synthesis for text-driven human motion   generation","categories":"cs.cv","abstract":"in this paper, we propose a novel cascaded diffusion-based generative framework for text-driven human motion synthesis, which exploits a strategy named gradually enriching synthesis (guess as its abbreviation). the strategy sets up generation objectives by grouping body joints of detailed skeletons in close semantic proximity together and then replacing each of such joint group with a single body-part node. such an operation recursively abstracts a human pose to coarser and coarser skeletons at multiple granularity levels. with gradually increasing the abstraction level, human motion becomes more and more concise and stable, significantly benefiting the cross-modal motion synthesis task. the whole text-driven human motion synthesis problem is then divided into multiple abstraction levels and solved with a multi-stage generation framework with a cascaded latent diffusion model: an initial generator first generates the coarsest human motion guess from a given text description; then, a series of successive generators gradually enrich the motion details based on the textual description and the previous synthesized results. notably, we further integrate guess with the proposed dynamic multi-condition fusion mechanism to dynamically balance the cooperative effects of the given textual condition and synthesized coarse motion prompt in different generation stages. extensive experiments on large-scale datasets verify that guess outperforms existing state-of-the-art methods by large margins in terms of accuracy, realisticness, and diversity. code is available at https:\/\/github.com\/xuehao-gao\/guess.","doi":"","created":1704326400000,"updated":"2024-01-05","authors":["xuehao gao","yang yang","zhenyu xie","shaoyi du","zhongqian sun","yang wu"]}
{"id":"2401.02143","title":"graph neural networks for tabular data learning: a survey with taxonomy   and directions","categories":"cs.lg cs.ai cs.ir cs.si","abstract":"in this survey, we dive into tabular data learning (tdl) using graph neural networks (gnns), a domain where deep learning-based approaches have increasingly shown superior performance in both classification and regression tasks compared to traditional methods. the survey highlights a critical gap in deep neural tdl methods: the underrepresentation of latent correlations among data instances and feature values. gnns, with their innate capability to model intricate relationships and interactions between diverse elements of tabular data, have garnered significant interest and application across various tdl domains. our survey provides a systematic review of the methods involved in designing and implementing gnns for tdl (gnn4tdl). it encompasses a detailed investigation into the foundational aspects and an overview of gnn-based tdl methods, offering insights into their evolving landscape. we present a comprehensive taxonomy focused on constructing graph structures and representation learning within gnn-based tdl methods. in addition, the survey examines various training plans, emphasizing the integration of auxiliary tasks to enhance the effectiveness of instance representations. a critical part of our discussion is dedicated to the practical application of gnns across a spectrum of gnn4tdl scenarios, demonstrating their versatility and impact. lastly, we discuss the limitations and propose future research directions, aiming to spur advancements in gnn4tdl. this survey serves as a resource for researchers and practitioners, offering a thorough understanding of gnns' role in revolutionizing tdl and pointing towards future innovations in this promising area.","doi":"","created":1704326400000,"updated":"","authors":["cheng-te li","yu-che tsai","chih-yao chen","jay chiehen liao"]}
{"id":"2401.02147","title":"exploring boundary of gpt-4v on marine analysis: a preliminary case   study","categories":"cs.cl cs.cv","abstract":"large language models (llms) have demonstrated a powerful ability to answer various queries as a general-purpose assistant. the continuous multi-modal large language models (mllm) empower llms with the ability to perceive visual signals. the launch of gpt-4 (generative pre-trained transformers) has generated significant interest in the research communities. gpt-4v(ison) has demonstrated significant power in both academia and industry fields, as a focal point in a new artificial intelligence generation. though significant success was achieved by gpt-4v, exploring mllms in domain-specific analysis (e.g., marine analysis) that required domain-specific knowledge and expertise has gained less attention. in this study, we carry out the preliminary and comprehensive case study of utilizing gpt-4v for marine analysis. this report conducts a systematic evaluation of existing gpt-4v, assessing the performance of gpt-4v on marine research and also setting a new standard for future developments in mllms. the experimental results of gpt-4v show that the responses generated by gpt-4v are still far away from satisfying the domain-specific requirements of the marine professions. all images and prompts used in this study will be available at https:\/\/github.com\/hkust-vgd\/marine_gpt-4v_eval","doi":"","created":1704326400000,"updated":"","authors":["ziqiang zheng","yiwei chen","jipeng zhang","tuan-anh vu","huimin zeng","yue him wong tim","sai-kit yeung"]}
{"id":"2401.02150","title":"marginal debiased network for fair visual recognition","categories":"cs.cv","abstract":"deep neural networks (dnns) are often prone to learn the spurious correlations between target classes and bias attributes, like gender and race, inherent in a major portion of training data (bias-aligned samples), thus showing unfair behavior and arising controversy in the modern pluralistic and egalitarian society. in this paper, we propose a novel marginal debiased network (mdn) to learn debiased representations. more specifically, a marginal softmax loss (msl) is designed by introducing the idea of margin penalty into the fairness problem, which assigns a larger margin for bias-conflicting samples (data without spurious correlations) than for bias-aligned ones, so as to deemphasize the spurious correlations and improve generalization on unbiased test criteria. to determine the margins, our mdn is optimized through a meta learning framework. we propose a meta equalized loss (mel) to perceive the model fairness, and adaptively update the margin parameters by metaoptimization which requires the trained model guided by the optimal margins should minimize mel computed on an unbiased meta-validation set. extensive experiments on biasedmnist, corrupted cifar-10, celeba and utk-face datasets demonstrate that our mdn can achieve a remarkable performance on under-represented samples and obtain superior debiased results against the previous approaches.","doi":"","created":1704326400000,"updated":"","authors":["mei wang","weihong deng","sen su"]}
{"id":"2401.02151","title":"frequency-adaptive pan-sharpening with mixture of experts","categories":"cs.cv","abstract":"pan-sharpening involves reconstructing missing high-frequency information in multi-spectral images with low spatial resolution, using a higher-resolution panchromatic image as guidance. although the inborn connection with frequency domain, existing pan-sharpening research has not almost investigated the potential solution upon frequency domain. to this end, we propose a novel frequency adaptive mixture of experts (fame) learning framework for pan-sharpening, which consists of three key components: the adaptive frequency separation prediction module, the sub-frequency learning expert module, and the expert mixture module. in detail, the first leverages the discrete cosine transform to perform frequency separation by predicting the frequency mask. on the basis of generated mask, the second with low-frequency moe and high-frequency moe takes account for enabling the effective low-frequency and high-frequency information reconstruction. followed by, the final fusion module dynamically weights high-frequency and low-frequency moe knowledge to adapt to remote sensing images with significant content variations. quantitative and qualitative experiments over multiple datasets demonstrate that our method performs the best against other state-of-the-art ones and comprises a strong generalization ability for real-world scenes. code will be made publicly at \\url{https:\/\/github.com\/alexhe101\/fame-net}.","doi":"","created":1704326400000,"updated":"","authors":["xuanhua he","keyu yan","rui li","chengjun xie","jie zhang","man zhou"]}
{"id":"2401.02152","title":"estimating continuous data of wrist joint angles using ultrasound images","categories":"cs.hc cs.ro eess.sp","abstract":"ultrasound imaging has recently been introduced as a sensing interface for joint motion estimation. the use of ultrasound images as an estimation method is expected to improve the control performance of assistive devices and human--machine interfaces. this study aimed to estimate continuous wrist joint angles using ultrasound images. specifically, in an experiment, joint angle information was obtained during extension--flexion movements, and ultrasound images of the associated muscles were acquired. using the features obtained from ultrasound images, a multivariate linear regression model was used to estimate the joint angles. the coordinates of the feature points obtained using optical flow from the ultrasound images were used as explanatory variables of the multivariate linear regression model. the model was trained and tested for each trial by each participant to verify the estimation accuracy. the results show that the mean and standard deviation of the estimation accuracy for all trials were root mean square error (rmse)=1.82 $\\pm$ 0.54 deg and coefficient of determination (r2)=0.985 $\\pm$ 0.009. our method achieves a highly accurate estimation of joint angles compared with previous studies using other signals, such as surface electromyography, while the multivariate linear regression model is simple and both computational and model training costs are low.","doi":"","created":1704326400000,"updated":"","authors":["yo kobayashi","yoshihiro katagi"]}
{"id":"2401.02153","title":"unit testing in asp revisited: language and test-driven development   environment","categories":"cs.se cs.ai","abstract":"unit testing frameworks are nowadays considered a best practice, included in almost all modern software development processes, to achieve rapid development of correct specifications. knowledge representation and reasoning paradigms such as answer set programming (asp), that have been used in industry-level applications, are not an exception. indeed, the first unit testing specification language for asp was proposed in 2011 as a feature of the aspide development environment. later, a more portable unit testing language was included in the lana annotation language. in this paper we revisit both languages and tools for unit testing in asp. we propose a new unit test specification language that allows one to inline tests within asp programs, and we identify the computational complexity of the tasks associated with checking the various program-correctness assertions. test-case specifications are transparent to the traditional evaluation, but can be interpreted by a specific testing tool. thus, we present a novel environment supporting test driven development of asp programs.","doi":"","created":1704326400000,"updated":"","authors":["giovanni amendola","tobias berei","giuseppe mazzotta","francesco ricca"]}
{"id":"2401.02154","title":"disentangle estimation of causal effects from cross-silo data","categories":"cs.lg cs.ai cs.cr stat.me","abstract":"estimating causal effects among different events is of great importance to critical fields such as drug development. nevertheless, the data features associated with events may be distributed across various silos and remain private within respective parties, impeding direct information exchange between them. this, in turn, can result in biased estimations of local causal effects, which rely on the characteristics of only a subset of the covariates. to tackle this challenge, we introduce an innovative disentangle architecture designed to facilitate the seamless cross-silo transmission of model parameters, enriched with causal mechanisms, through a combination of shared and private branches. besides, we introduce global constraints into the equation to effectively mitigate bias within the various missing domains, thereby elevating the accuracy of our causal effect estimation. extensive experiments conducted on new semi-synthetic datasets show that our method outperforms state-of-the-art baselines.","doi":"","created":1704326400000,"updated":"","authors":["yuxuan liu","haozhao wang","shuang wang","zhiming he","wenchao xu","jialiang zhu","fan yang"]}
{"id":"2401.02158","title":"shayona@smm4h23: covid-19 self diagnosis classification using bert and   lightgbm models","categories":"cs.cl cs.ai","abstract":"this paper describes approaches and results for shared task 1 and 4 of smmh4-23 by team shayona. shared task-1 was binary classification of english tweets self-reporting a covid-19 diagnosis, and shared task-4 was binary classification of english reddit posts self-reporting a social anxiety disorder diagnosis. our team has achieved the highest f1-score 0.94 in task-1 among all participants. we have leveraged the transformer model (bert) in combination with the lightgbm model for both tasks.","doi":"","created":1704326400000,"updated":"","authors":["rushi chavda","darshan makwana","vraj patel","anupam shukla"]}
{"id":"2401.02160","title":"human-in-the-loop policy optimization for preference-based   multi-objective reinforcement learning","categories":"cs.ne","abstract":"multi-objective reinforcement learning (morl) aims to find a set of high-performing and diverse policies that address trade-offs between multiple conflicting objectives. however, in practice, decision makers (dms) often deploy only one or a limited number of trade-off policies. providing too many diversified trade-off policies to the dm not only significantly increases their workload but also introduces noise in multi-criterion decision-making. with this in mind, we propose a human-in-the-loop policy optimization framework for preference-based morl that interactively identifies policies of interest. our method proactively learns the dm's implicit preference information without requiring any a priori knowledge, which is often unavailable in real-world black-box decision scenarios. the learned preference information is used to progressively guide policy optimization towards policies of interest. we evaluate our approach against three conventional morl algorithms that do not consider preference information and four state-of-the-art preference-based morl algorithms on two morl environments for robot control and smart grid management. experimental results fully demonstrate the effectiveness of our proposed method in comparison to the other peer algorithms.","doi":"","created":1704326400000,"updated":"","authors":["ke li","han guo"]}
{"id":"2401.02161","title":"enhancing raw-to-srgb with decoupled style structure in fourier domain","categories":"cs.cv","abstract":"raw to srgb mapping, which aims to convert raw images from smartphones into rgb form equivalent to that of digital single-lens reflex (dslr) cameras, has become an important area of research. however, current methods often ignore the difference between cell phone raw images and dslr camera rgb images, a difference that goes beyond the color matrix and extends to spatial structure due to resolution variations. recent methods directly rebuild color mapping and spatial structure via shared deep representation, limiting optimal performance. inspired by image signal processing (isp) pipeline, which distinguishes image restoration and enhancement, we present a novel neural isp framework, named fourierisp. this approach breaks the image down into style and structure within the frequency domain, allowing for independent optimization. fourierisp is comprised of three subnetworks: phase enhance subnet for structural refinement, amplitude refine subnet for color learning, and color adaptation subnet for blending them in a smooth manner. this approach sharpens both color and structure, and extensive evaluations across varied datasets confirm that our approach realizes state-of-the-art results. code will be available at ~\\url{https:\/\/github.com\/alexhe101\/fourierisp}.","doi":"","created":1704326400000,"updated":"","authors":["xuanhua he","tao hu","guoli wang","zejin wang","run wang","qian zhang","keyu yan","ziyi chen","rui li","chenjun xie","jie zhang","man zhou"]}
{"id":"2401.02162","title":"frequency domain nuances mining for visible-infrared person   re-identification","categories":"cs.cv","abstract":"the key of visible-infrared person re-identification (vireid) lies in how to minimize the modality discrepancy between visible and infrared images. existing methods mainly exploit the spatial information while ignoring the discriminative frequency information. to address this issue, this paper aims to reduce the modality discrepancy from the frequency domain perspective. specifically, we propose a novel frequency domain nuances mining (fdnm) method to explore the cross-modality frequency domain information, which mainly includes an amplitude guided phase (agp) module and an amplitude nuances mining (anm) module. these two modules are mutually beneficial to jointly explore frequency domain visible-infrared nuances, thereby effectively reducing the modality discrepancy in the frequency domain. besides, we propose a center-guided nuances mining loss to encourage the anm module to preserve discriminative identity information while discovering diverse cross-modality nuances. extensive experiments show that the proposed fdnm has significant advantages in improving the performance of vireid. specifically, our method outperforms the second-best method by 5.2\\% in rank-1 accuracy and 5.8\\% in map on the sysu-mm01 dataset under the indoor search mode, respectively. besides, we also validate the effectiveness and generalization of our method on the challenging visible-infrared face recognition task. \\textcolor{magenta}{the code will be available.}","doi":"","created":1704326400000,"updated":"2024-01-09","authors":["yukang zhang","yang lu","yan yan","hanzi wang","xuelong li"]}
{"id":"2401.02163","title":"enumerating m-length walks in directed graphs with constant delay","categories":"cs.ds","abstract":"in this paper, we provide a novel enumeration algorithm for the set of all walks of a given length within a directed graph. our algorithm has worst-case constant delay between outputting succinct representations of such walks, after a preprocessing step requiring linear time relative to the size of the graph. we apply these results to the problem of enumerating succinct representations of the strings of a given length from a prefix-closed regular language (languages accepted by a finite automaton which has final states only).","doi":"","created":1704326400000,"updated":"2024-01-05","authors":["duncan adamson","pawel gawrychowski","florin manea"]}
{"id":"2401.02164","title":"listening broadband physical model for microphones: a first step","categories":"eess.as cs.sd","abstract":"we will present a first step in design of a broadband physical model for microphones. within the proposed model, classical directivity patterns (omnidirectional, bidirectional and cardioids family) are refound as limit cases: monochromatic excitation, low frequency and far-field approximation. monophonic pieces of music are used as sources for the model so we can listen the simulation of the associated recorded sound field in realtime thanks to a max\/msp application. listening and subbands analysis show that the directivity is a function of frequential subband and source location. this model also exhibits an interesting proximity effect. audio demonstrations will be given.paper 6638 presented at the 120th convention of the audio engineering society, paris, 2006","doi":"","created":1704326400000,"updated":"","authors":["laurent millot","antoine valette","manuel lopes","gérard pelé","mohammed elliq","dominique lambert"]}
{"id":"2401.02167","title":"fake news: no ban, no spread -- with sequestration","categories":"physics.soc-ph cs.si","abstract":"fake news is today a major threat to free and democratic making of public opinion. to curb their spread, all efforts by institutions and policy makers rely mainly on imposing restriction, prohibition and fact checking sites, which end up to an effective limitation of freedom of speech. this policy of prohibition, supported by a wide consensus, has been recently broken by the controversial policy applied by elon musk to regulate the social media x, with a backlash accusing him of promoting hate speech. here, notwithstanding these two policies, i explore another avenue denoted ``no ban, no spread - with sequestration\", which amounts at the same time preserving full freedom of speech and neutralization of fake news impact. to investigate the feasibility of my proposal, i tackle the issue within the galam model of opinion dynamics. in addition to the basic ingredients of the model, i explore for the first time the effect on the dynamics of opinion of a simultaneous activation of prejudice tie breaking and contrarian behavior. the results show that indeed most pieces of fake news do not propagate beyond small groups of people and thus pose no global threat. however, i have unveiled some peculiar sets of parameters for which fake news, even if initially shared by only a handful of agents, spreads ``naturally\" to invade a whole community with no resistance. based on these findings, i am able to outline a path to neutralize such invasive fake news by blocking \"naturally\" its spread, effectively sequestering it in very small social networks of people. the scheme relies on reshaping the social geometry of the landscape in which fake news evolves. no prohibition is required with fake news left free to prosper but being sequestrated. next challenging step will be designing measures to implement the model's findings into the real world of social media.","doi":"","created":1704326400000,"updated":"","authors":["serge galam"]}
{"id":"2401.02170","title":"non-conforming fem for the quasi-static contact problem","categories":"math.na cs.na","abstract":"in this article, we addressed the numerical solution of a non-linear evolutionary variational inequality, which is encountered in the investigation of quasi-static contact problems. our study encompasses both the semi-discrete and fully-discrete schemes, where we employ the backward euler method for time discretization and utilize the lowest order crouzeix-raviart nonconforming finite element method for spatial discretization. by assuming appropriate regularity conditions on the solution, we establish \\emph{a priori} error analysis for these schemes, achieving the optimal convergence order for linear elements. to illustrate the numerical convergence rates, we provide numerical results on a two-dimensional test problem.","doi":"","created":1704326400000,"updated":"","authors":["kamana porwal","tanvi wadhawan"]}
{"id":"2401.02171","title":"real-and-present: investigating the use of life-size 2d video avatars in   hmd-based ar teleconferencing","categories":"cs.hc","abstract":"augmented reality (ar) teleconferencing allows separately located users to interact with each other in 3d through agents in their own physical environments. existing methods leveraging volumetric capturing and reconstruction can provide a high-fidelity experience but are often too complex and expensive for everyday usage. other solutions target mobile and effortless-to-setup teleconferencing on ar head mounted displays (hmd). they directly transplant the conventional video conferencing onto an ar-hmd platform or use avatars to represent remote participants. however, they can only support either a high fidelity or a high level of co-presence. moreover, the limited field of view (fov) of hmds could further influence users' immersive experience. to achieve a balance between fidelity and co-presence, we explore using life-size 2d video-based avatars (video avatars for short) in ar teleconferencing. specifically, with the potential effect of fov on users' perception of proximity, we first conduct a pilot study to explore the local-user-centered optimal placement of video avatars in small-group ar conversations. with the placement results, we then implement a proof-of-concept prototype of video-avatar-based teleconferencing. we conduct user evaluations with the prototype to verify its effectiveness in balancing fidelity and co-presence. following the indication in the pilot study, we further quantitatively explore the effect of fov size on the video avatar's optimal placement through a user study involving more fov conditions in a vr-simulated environment. we regress placement models to serve as references for computationally determining video avatar placements in such teleconferencing applications on various existing ar hmds and future ones with bigger fovs.","doi":"","created":1704326400000,"updated":"","authors":["xuanyu wang","weizhan zhang","christian sandor","hongbo fu"]}
{"id":"2401.02172","title":"recognition of unit segment and polyline graphs is   $\\exists\\mathbb{r}$-complete","categories":"cs.cg","abstract":"given a set of objects o in the plane, the corresponding intersection graph is defined as follows. a vertex is created for each object and an edge joins two vertices whenever the corresponding objects intersect. we study here the case of unit segments and polylines with exactly k bends. in the recognition problem, we are given a graph and want to decide whether the graph can be represented as the intersection graph of certain geometric objects. in previous work it was shown that various recognition problems are $\\exists\\mathbb{r}$-complete, leaving unit segments and polylines as few remaining natural cases. we show that recognition for both families of objects is $\\exists\\mathbb{r}$-complete.","doi":"","created":1704326400000,"updated":"2024-06-04","authors":["michael hoffmann","tillmann miltzow","simon weber","lasse wulf"]}
{"id":"2401.02173","title":"prompt decoupling for text-to-image person re-identification","categories":"cs.cv cs.ai","abstract":"text-to-image person re-identification (tireid) aims to retrieve the target person from an image gallery via a textual description query. recently, pre-trained vision-language models like clip have attracted significant attention and have been widely utilized for this task due to their robust capacity for semantic concept learning and rich multi-modal knowledge. however, recent clip-based tireid methods commonly rely on direct fine-tuning of the entire network to adapt the clip model for the tireid task. although these methods show competitive performance on this topic, they are suboptimal as they necessitate simultaneous domain adaptation and task adaptation. to address this issue, we attempt to decouple these two processes during the training stage. specifically, we introduce the prompt tuning strategy to enable domain adaptation and propose a two-stage training approach to disentangle domain adaptation from task adaptation. in the first stage, we freeze the two encoders from clip and solely focus on optimizing the prompts to alleviate domain gap between the original training data of clip and downstream tasks. in the second stage, we maintain the fixed prompts and fine-tune the clip model to prioritize capturing fine-grained information, which is more suitable for tireid task. finally, we evaluate the effectiveness of our method on three widely used datasets. compared to the directly fine-tuned approach, our method achieves significant improvements.","doi":"","created":1704326400000,"updated":"","authors":["weihao li","lei tan","pingyang dai","yan zhang"]}
{"id":"2401.02176","title":"pointwise a posteriori error control of quadratic discontinuous galerkin   methods for the unilateral contact problem","categories":"math.na cs.na","abstract":"an a posteriori error bound for the pointwise error of the quadratic discontinuous galerkin method for the unilateral contact problem on polygonal domain is presented. the pointwise a posteriori error analysis is based on the direct use of a priori estimates of the green's matrix for the divergence type operators and the suitable construction of the discrete contact force density $\\b{\\sigma}_h$ and barrier functions for the continuous solution. several numerical experiments (in two dimension) are presented to illustrate the reliability and efficiency properties of the proposed aposteriori error estimator.","doi":"","created":1704326400000,"updated":"","authors":["rohit khandelwal","kamana porwal","tanvi wadhawan"]}
{"id":"2401.02180","title":"proven distributed memory parallelization of particle methods","categories":"cs.dc cs.ds cs.se","abstract":"we provide a mathematically proven parallelization scheme for particle methods on distributed-memory computer systems. particle methods are a versatile and widely used class of algorithms for computer simulations and numerical predictions in various applications, ranging from continuum fluid dynamics and granular flows, using methods such as smoothed particle hydrodynamics (sph) and discrete element methods (dem) to molecular dynamics (md) simulations in molecular modeling. particle methods naturally lend themselves to implementation on parallel-computing hardware. so far, however, a mathematical proof of correctness and equivalence to sequential implementations was only available for shared-memory parallelism. here, we leverage a formal definition of the algorithmic class of particle methods to provide a proven parallelization scheme for distributed-memory computers. we prove that these parallelized particle methods on distributed memory computers are formally equivalent to their sequential counterpart for a well-defined class of particle methods. notably, the here analyzed parallelization scheme is well-known and commonly used. our analysis is, therefore, of immediate practical relevance to existing and new parallel software implementations of particle methods and places them on solid theoretical grounds.","doi":"","created":1704326400000,"updated":"","authors":["johannes pahlke","ivo f. sbalzarini"]}
{"id":"2401.02181","title":"supremum norm a posteriori error control of quadratic finite element   method for the signorini problem","categories":"math.na cs.na","abstract":"in this paper, we develop a new residual-based pointwise a posteriori error estimator of the quadratic finite element method for the signorini problem. the supremum norm a posteriori error estimates enable us to locate the singularities locally to control the pointwise errors. in the analysis the discrete counterpart of contact force density is constructed suitably to exhibit the desired sign property. we employ a priori estimates for the standard green's matrix for the divergence type operator and introduce the upper and lower barriers functions by appropriately modifying the discrete solution. finally, we present numerical experiments that illustrate the excellent performance of the proposed error estimator.","doi":"","created":1704326400000,"updated":"","authors":["rohit khandelwal","kamana porwal","tanvi wadhawan"]}
{"id":"2401.02183","title":"fairgridsearch: a framework to compare fairness-enhancing models","categories":"cs.lg cs.ai cs.cy","abstract":"machine learning models are increasingly used in critical decision-making applications. however, these models are susceptible to replicating or even amplifying bias present in real-world data. while there are various bias mitigation methods and base estimators in the literature, selecting the optimal model for a specific application remains challenging.   this paper focuses on binary classification and proposes fairgridsearch, a novel framework for comparing fairness-enhancing models. fairgridsearch enables experimentation with different model parameter combinations and recommends the best one. the study applies fairgridsearch to three popular datasets (adult, compas, and german credit) and analyzes the impacts of metric selection, base estimator choice, and classification threshold on model fairness.   the results highlight the significance of selecting appropriate accuracy and fairness metrics for model evaluation. additionally, different base estimators and classification threshold values affect the effectiveness of bias mitigation methods and fairness stability respectively, but the effects are not consistent across all datasets. based on these findings, future research on fairness in machine learning should consider a broader range of factors when building fair models, going beyond bias mitigation methods alone.","doi":"10.1109\/wi-iat59888.2023.00064","created":1704326400000,"updated":"","authors":["shih-chi ma","tatiana ermakova","benjamin fabian"]}
{"id":"2401.02187","title":"location aware modular biencoder for tourism question answering","categories":"cs.cl","abstract":"answering real-world tourism questions that seek point-of-interest (poi) recommendations is challenging, as it requires both spatial and non-spatial reasoning, over a large candidate pool. the traditional method of encoding each pair of question and poi becomes inefficient when the number of candidates increases, making it infeasible for real-world applications. to overcome this, we propose treating the qa task as a dense vector retrieval problem, where we encode questions and pois separately and retrieve the most relevant pois for a question by utilizing embedding space similarity. we use pretrained language models (plms) to encode textual information, and train a location encoder to capture spatial information of pois. experiments on a real-world tourism qa dataset demonstrate that our approach is effective, efficient, and outperforms previous methods across all metrics. enabled by the dense retrieval architecture, we further build a global evaluation baseline, expanding the search space by 20 times compared to previous work. we also explore several factors that impact on the model's performance through follow-up experiments. our code and model are publicly available at https:\/\/github.com\/haonan-li\/lamb.","doi":"","created":1704326400000,"updated":"","authors":["haonan li","martin tomko","timothy baldwin"]}
{"id":"2401.02191","title":"characterizing fake news targeting corporations","categories":"cs.cy","abstract":"misinformation proliferates in the online sphere, with evident impacts on the political and social realms, influencing democratic discourse and posing risks to public health and safety. the corporate world is also a prime target for fake news dissemination. while recent studies have attempted to characterize corporate misinformation and its effects on companies, their findings often suffer from limitations due to qualitative or narrative approaches and a narrow focus on specific industries. to address this gap, we conducted an analysis utilizing social media quantitative methods and crowd-sourcing studies to investigate corporate misinformation across a diverse array of industries within the s\\&p 500 companies. our study reveals that corporate misinformation encompasses topics such as products, politics, and societal issues. we discovered companies affected by fake news also get reputable news coverage but less social media attention, leading to heightened negativity in social media comments, diminished stock growth, and increased stress mentions among employee reviews. additionally, we observe that a company is not targeted by fake news all the time, but there are particular times when a critical mass of fake news emerges. these findings hold significant implications for regulators, business leaders, and investors, emphasizing the necessity to vigilantly monitor the escalating phenomenon of corporate misinformation.","doi":"","created":1704326400000,"updated":"","authors":["ke zhou","sanja scepanovic","daniele quercia"]}
{"id":"2401.02192","title":"nodule detection and generation on chest x-rays: node21 challenge","categories":"eess.iv cs.cv cs.lg","abstract":"pulmonary nodules may be an early manifestation of lung cancer, the leading cause of cancer-related deaths among both men and women. numerous studies have established that deep learning methods can yield high-performance levels in the detection of lung nodules in chest x-rays. however, the lack of gold-standard public datasets slows down the progression of the research and prevents benchmarking of methods for this task. to address this, we organized a public research challenge, node21, aimed at the detection and generation of lung nodules in chest x-rays. while the detection track assesses state-of-the-art nodule detection systems, the generation track determines the utility of nodule generation algorithms to augment training data and hence improve the performance of the detection systems. this paper summarizes the results of the node21 challenge and performs extensive additional experiments to examine the impact of the synthetically generated nodule training images on the detection algorithm performance.","doi":"","created":1704326400000,"updated":"","authors":["ecem sogancioglu","bram van ginneken","finn behrendt","marcel bengs","alexander schlaefer","miron radu","di xu","ke sheng","fabien scalzo","eric marcus","samuele papa","jonas teuwen","ernst th. scholten","steven schalekamp","nils hendrix","colin jacobs","ward hendrix","clara i sánchez","keelin murphy"]}
{"id":"2401.02194","title":"inherently robust suboptimal mpc for autonomous racing with anytime   feasible sqp","categories":"math.oc cs.ro","abstract":"in recent years, the increasing need for high-performance controllers in applications like autonomous driving has motivated the development of optimization routines tailored to specific control problems. in this paper, we propose an efficient inexact model predictive control (mpc) strategy for autonomous miniature racing with inherent robustness properties. we rely on a feasible sequential quadratic programming (sqp) algorithm capable of generating feasible intermediate iterates such that the solver can be stopped after any number of iterations, without jeopardizing recursive feasibility. in this way, we provide a strategy that computes suboptimal and yet feasible solutions with a computational footprint that is much lower than state-of-the-art methods based on the computation of locally optimal solutions. under suitable assumptions on the terminal set and on the controllability properties of the system, we can state that, for any sufficiently small disturbance affecting the system's dynamics, recursive feasibility can be guaranteed. we validate the effectiveness of the proposed strategy in simulation and by deploying it onto a physical experiment with autonomous miniature race cars. both the simulation and experimental results demonstrate that, using the feasible sqp method, a feasible solution can be obtained with moderate additional computational effort compared to strategies that resort to early termination without providing a feasible solution. at the same time, the proposed method is significantly faster than the state-of-the-art solver ipopt.","doi":"","created":1704326400000,"updated":"","authors":["logan numerow","andrea zanelli","andrea carron","melanie n. zeilinger"]}
{"id":"2401.02197","title":"projections, embeddings and stability","categories":"math.na cs.na","abstract":"in the present work, we demonstrate how the pseudoinverse concept from linear algebra can be used to represent and analyze the boundary conditions of linear systems of partial differential equations. this approach has theoretical and practical implications; the theory applies even if the boundary operator is rank deficient, or near rank deficient. if desired, the pseudoinverse can be implemented directly using standard tools like matlab. we also introduce a new and simplified version of the semidiscrete approximation of the linear pde system, which completely avoids taking the time derivative of the boundary data. the stability results are valid for general, nondiagonal summation-by-parts norms. another key result is the extension of summation-by-parts operators to multi-domains by means of carefully crafted embedding operators. no extra numerical boundary conditions are required at the grid interfaces. the aforementioned pseudoinverse allows for a compact representation of these multi-block operators, which preserves all relevant properties of the single-block operators. the embedding operators can be constructed for multiple space dimensions. numerical results for the two-dimensional maxwell's equations are presented, and they show very good agreement with theory.","doi":"","created":1704326400000,"updated":"","authors":["pelle olsson"]}
{"id":"2401.02199","title":"ladri: learning-based dynamic risk indicator in automated driving system","categories":"eess.sy cs.ai cs.lg cs.se cs.sy","abstract":"as the horizon of intelligent transportation expands with the evolution of automated driving systems (ads), ensuring paramount safety becomes more imperative than ever. traditional risk assessment methodologies, primarily crafted for human-driven vehicles, grapple to adequately adapt to the multifaceted, evolving environments of ads. this paper introduces a framework for real-time dynamic risk assessment (dra) in ads, harnessing the potency of artificial neural networks (anns).   our proposed solution transcends these limitations, drawing upon anns, a cornerstone of deep learning, to meticulously analyze and categorize risk dimensions using real-time on-board sensor (obs) data. this learning-centric approach not only elevates the ads's situational awareness but also enriches its understanding of immediate operational contexts. by dissecting obs data, the system is empowered to pinpoint its current risk profile, thereby enhancing safety prospects for onboard passengers and the broader traffic ecosystem.   through this framework, we chart a direction in risk assessment, bridging the conventional voids and enhancing the proficiency of ads. by utilizing anns, our methodology offers a perspective, allowing ads to adeptly navigate and react to potential risk factors, ensuring safer and more informed autonomous journeys.","doi":"","created":1704326400000,"updated":"","authors":["anil ranjitbhai patel","peter liggesmeyer"]}
{"id":"2401.02200","title":"compositing with 2d vector fields by using shape maps that can represent   inconsistent, impossible, and incoherent shapes","categories":"cs.gr","abstract":"in this paper, we present a new compositing approach to obtain stylized reflections and refractions with a simple control. our approach does not require any mask or separate 3d rendering. moreover, only one additional image is sufficient to obtain a composited image with convincing qualitative reflection and refraction effects. we have also developed linearized methods that are easy to compute. although these methods do not directly correspond to the underlying physical phenomena of reflection and refraction, they can provide results that are visually similar to realistic 3d rendering. the main advantage of this approach is the ability to treat images as ``mock-3d'' shapes that can be inserted into any digital paint system without any significant structural change. the core of our approach is the shape map, which encodes 2d shape and thickness information for all visible points of an image of a shape. this information does not have to be complete or consistent to obtain interesting composites. in particular, the shape maps allow us to represent impossible and incoherent shapes with 2d non-conservative vector fields.","doi":"","created":1704326400000,"updated":"","authors":["ergun akleman","youyou wang","ozgur gonen"]}
{"id":"2401.02202","title":"a pure integral-type pll with a damping branch to enhance the stability   of grid-tied inverter under weak grids","categories":"eess.sy cs.sy","abstract":"in a phase-locked loop (pll) synchronized inverter, due to the strong nonlinear coupling between the pll's parame-ters and the operation power angle, the equivalent damping coefficient will quickly deteriorate while the power angle is close to 90{\\deg} under an ultra-weak grid, which causes the synchronous instability. to address this issue, in this letter, a pure integral-type phase-locked loop (ipll) with a damping branch is proposed to replace the traditional pi-type pll. the equivalent damping coefficient of an ipll-synchronized inverter is decoupled with the steady-state power angle. as a result, the ipll-synchronized inverter can stably operate under an ultra-weak grid when the equilibrium point exists. finally, time-domain simulation results verify the effectiveness and correctness of the proposed ipll.","doi":"","created":1704326400000,"updated":"","authors":["yi zhou","zhouchen deng","shi chen","yiwei qiu","tianlei zang","buxiang zhou"]}
{"id":"2401.02203","title":"robust bilinear factor analysis based on the matrix-variate $t$   distribution","categories":"stat.ml cs.lg","abstract":"factor analysis based on multivariate $t$ distribution ($t$fa) is a useful robust tool for extracting common factors on heavy-tailed or contaminated data. however, $t$fa is only applicable to vector data. when $t$fa is applied to matrix data, it is common to first vectorize the matrix observations. this introduces two challenges for $t$fa: (i) the inherent matrix structure of the data is broken, and (ii) robustness may be lost, as vectorized matrix data typically results in a high data dimension, which could easily lead to the breakdown of $t$fa. to address these issues, starting from the intrinsic matrix structure of matrix data, a novel robust factor analysis model, namely bilinear factor analysis built on the matrix-variate $t$ distribution ($t$bfa), is proposed in this paper. the novelty is that it is capable to simultaneously extract common factors for both row and column variables of interest on heavy-tailed or contaminated matrix data. two efficient algorithms for maximum likelihood estimation of $t$bfa are developed. closed-form expression for the fisher information matrix to calculate the accuracy of parameter estimates are derived. empirical studies are conducted to understand the proposed $t$bfa model and compare with related competitors. the results demonstrate the superiority and practicality of $t$bfa. importantly, $t$bfa exhibits a significantly higher breakdown point than $t$fa, making it more suitable for matrix data.","doi":"","created":1704326400000,"updated":"","authors":["xuan ma","jianhua zhao","changchun shang","fen jiang","philip l. h. yu"]}
{"id":"2401.02208","title":"dialight: lightweight multilingual development and evaluation of   task-oriented dialogue systems with large language models","categories":"cs.cl","abstract":"we present dialight, a toolkit for developing and evaluating multilingual task-oriented dialogue (tod) systems which facilitates systematic evaluations and comparisons between tod systems using fine-tuning of pretrained language models (plms) and those utilising the zero-shot and in-context learning capabilities of large language models (llms). in addition to automatic evaluation, this toolkit features (i) a secure, user-friendly web interface for fine-grained human evaluation at both local utterance level and global dialogue level, and (ii) a microservice-based backend, improving efficiency and scalability. our evaluations reveal that while plm fine-tuning leads to higher accuracy and coherence, llm-based systems excel in producing diverse and likeable responses. however, we also identify significant challenges of llms in adherence to task-specific instructions and generating outputs in multiple languages, highlighting areas for future research. we hope this open-sourced toolkit will serve as a valuable resource for researchers aiming to develop and properly evaluate multilingual tod systems and will lower, currently still high, entry barriers in the field.","doi":"","created":1704326400000,"updated":"","authors":["songbo hu","xiaobin wang","zhangdie yuan","anna korhonen","ivan vulić"]}
{"id":"2401.02212","title":"joint multi-facts reasoning network for complex temporal question   answering over knowledge graph","categories":"cs.cl cs.ai","abstract":"temporal knowledge graph (tkg) is an extension of regular knowledge graph by attaching the time scope. existing temporal knowledge graph question answering (tkgqa) models solely approach simple questions, owing to the prior assumption that each question only contains a single temporal fact with explicit\/implicit temporal constraints. hence, they perform poorly on questions which own multiple temporal facts. in this paper, we propose \\textbf{\\underline{j}}oint \\textbf{\\underline{m}}ulti \\textbf{\\underline{f}}acts \\textbf{\\underline{r}}easoning \\textbf{\\underline{n}}etwork (jmfrn), to jointly reasoning multiple temporal facts for accurately answering \\emph{complex} temporal questions. specifically, jmfrn first retrieves question-related temporal facts from tkg for each entity of the given complex question. for joint reasoning, we design two different attention (\\ie entity-aware and time-aware) modules, which are suitable for universal settings, to aggregate entities and timestamps information of retrieved facts. moreover, to filter incorrect type answers, we introduce an additional answer type discrimination task. extensive experiments demonstrate our proposed method significantly outperforms the state-of-art on the well-known complex temporal question benchmark timequestions.","doi":"","created":1704326400000,"updated":"","authors":["rikui huang","wei wei","xiaoye qu","wenfeng xie","xianling mao","dangyang chen"]}
{"id":"2401.02216","title":"harnessing membership function dynamics for stability analysis of t-s   fuzzy systems","categories":"eess.sy cs.sy math.oc","abstract":"the main goal of this paper is to develop a new linear matrix inequality (lmi) condition for the asymptotic stability of continuous-time takagi-sugeno (t-s) fuzzy systems. a key advantage of this new condition is its independence from the bounds on the time-derivatives of the membership functions, a requirement present in the existing approaches. this is achieved by introducing a novel fuzzy lyapunov function that incorporates an augmented state vector. notably, this augmented state vector encompasses the membership functions, allowing the dynamics of these functions to be integrated into the proposed condition. this inclusion of additional information about the membership function serves to reduce the conservativeness of the suggested stability condition. to demonstrate the effectiveness of the proposed method, examples are provided.","doi":"","created":1704326400000,"updated":"2024-06-13","authors":["donghwan lee","do-wan kim"]}
{"id":"2401.02218","title":"optimizing information freshness in uplink multiuser mimo networks with   partial observations","categories":"cs.it cs.ni math.it","abstract":"this paper investigates a multiuser scheduling problem within an uplink multiple-input multi-output (mimo) status update network, consisting of a multi-antenna base station (bs) and multiple single-antenna devices. the presence of multiple antennas at the bs introduces spatial degrees-of-freedom, enabling concurrent transmission of status updates from multiple devices in each time slot. our objective is to optimize network-wide information freshness, quantified by the age of information (aoi) metric, by determining how the bs can best schedule device transmissions, while taking into account the random arrival of status updates at the device side.to address this decision-making problem, we model it as a partially observable markov decision process (pomdp) and establish that the evolution of belief states for different devices is independent.we also prove that feasible belief states can be described by finite-dimensional vectors. building on these observations, we develop a dynamic scheduling (ds) policy to solve the pomdp, and then derive an upper bound of its aoi performance, which is used to optimize the parameter configuration. to gain more design insights, we investigate a symmetric network, and put forth a fixed scheduling (fs) policy with lower computational complexity. an action space reduction strategy is applied to further reduce the computational complexity of both ds and fs policies. our numerical results validate our analyses and indicate that the ds policy with the reduced action space performs almost identically to the original ds policy, and both outperform the baseline policies.","doi":"","created":1704326400000,"updated":"","authors":["jingwei liu","qian wang","he chen"]}
{"id":"2401.02219","title":"a decentralized multiagent-based task scheduling framework for handling   uncertain events in fog computing","categories":"cs.ma","abstract":"fog computing has become an attractive research topic in recent years. as an extension of the cloud, fog computing provides computing resources for internet of things (iot) applications through communicative fog nodes located at the network edge. fog nodes assist cloud services in handling real-time and mobile applications by bringing the processing capability to where the data is generated. however, the introduction of fog nodes can increase scheduling openness and uncertainty. the scheduling issues in fog computing need to consider the geography, load balancing, and network latency between iot devices, fog nodes, as well as the parent cloud. besides, the scheduling methods also need to deal with the occurrence of uncertain events in real-time so as to ensure service reliability. this paper proposes an agent-based framework with a decentralized structure to construct the architecture of fog computing, while three agent-based algorithms are proposed to implement the scheduling, load balance, and rescheduling processes. the proposed framework is implemented by jade and evaluated on the ifogsim toolkit. experimental results show that the proposed scheduling framework can adaptively schedule tasks and resources for different service requests in fog computing and can also improve the task success rate when uncertain events occur.","doi":"","created":1704326400000,"updated":"","authors":["yikun yang","fenghui ren","minjie zhang"]}
{"id":"2401.02220","title":"sampling projections in the uniform norm","categories":"math.fa cs.na math.na","abstract":"we show that there are sampling projections on arbitrary $n$-dimensional subspaces of $b(d)$ with at most $2n$ samples and norm of order $\\sqrt{n}$, where $b(d)$ is the space of complex-valued bounded functions on a set $d$. this gives a more explicit form of the kadets-snobar theorem for the uniform norm and improves upon auerbach's lemma. we discuss consequences for optimal recovery in $l_p$.","doi":"","created":1704326400000,"updated":"","authors":["david krieg","kateryna pozharska","mario ullrich","tino ullrich"]}
{"id":"2401.02222","title":"kernel search approach to solve the minimum spanning tree problem with   conflicting edge pairs","categories":"math.oc cs.cr","abstract":"the minimum spanning tree problem with conflicts consists in finding the minimum conflict-free spanning tree of a graph, i.e., the spanning tree of minimum cost, including no pairs of edges that are in conflict. in this paper, we solve this problem using a tailored kernel search heuristic method, which consists in solving iteratively improved restrictions of the problem. the main novelty of the approach consists in using an independent set of the conflict graph within the algorithm. we test our approach on the benchmark instances and we compare our results with the ones obtained by other heuristics available in the literature.","doi":"","created":1704326400000,"updated":"","authors":["francesco carrabs","martina cerulli","domenico serra"]}
{"id":"2401.02223","title":"a bdi agent-based task scheduling framework for cloud computing","categories":"cs.ma","abstract":"cloud computing is an attractive technology for providing computing resources over the internet. task scheduling is a critical issue in cloud computing, where an efficient task scheduling method can improve overall cloud performance. since cloud computing is a large-scale and geographically distributed environment, traditional scheduling methods that allocate resources in a centralized manner are ineffective. besides, traditional methods are difficult to make rational decisions timely when the external environment changes. this paper proposes a decentralized bdi (belief-desire-intention) agent-based scheduling framework for cloud computing. bdi agents have advantages in modelling dynamic environments because bdi agents can update their beliefs, change desires, and trigger behaviours based on environmental changes. besides, to avoid communication stuck caused by environmental uncertainties, the asynchronous communication mode with a notify listener is employed. the proposed framework covers both the task scheduling and rescheduling stages with the consideration of uncertain events that can interrupt task executions. two agent-based algorithms are proposed to implement the task scheduling and rescheduling processes, and a novel recommendation mechanism is presented in the scheduling stage to reduce the impact of information synchronization delays. the proposed framework is implemented by jadex and tested on cloudsim. the experimental results show that our framework can minimize the task makespan, balance the resource utilization in a large-scale environment, and maximize the task success rate when uncertain events occur.","doi":"","created":1704326400000,"updated":"","authors":["yikun yang","fenghui ren","minjie zhang"]}
{"id":"2401.02225","title":"trajectory-oriented policy optimization with sparse rewards","categories":"cs.lg","abstract":"mastering deep reinforcement learning (drl) proves challenging in tasks featuring scant rewards. these limited rewards merely signify whether the task is partially or entirely accomplished, necessitating various exploration actions before the agent garners meaningful feedback. consequently, the majority of existing drl exploration algorithms struggle to acquire practical policies within a reasonable timeframe. to address this challenge, we introduce an approach leveraging offline demonstration trajectories for swifter and more efficient online rl in environments with sparse rewards. our pivotal insight involves treating offline demonstration trajectories as guidance, rather than mere imitation, allowing our method to learn a policy whose distribution of state-action visitation marginally matches that of offline demonstrations. we specifically introduce a novel trajectory distance relying on maximum mean discrepancy (mmd) and cast policy optimization as a distance-constrained optimization problem. we then illustrate that this optimization problem can be streamlined into a policy-gradient algorithm, integrating rewards shaped by insights from offline demonstrations. the proposed algorithm undergoes evaluation across extensive discrete and continuous control tasks with sparse and misleading rewards. the experimental findings demonstrate the significant superiority of our proposed algorithm over baseline methods concerning diverse exploration and the acquisition of an optimal policy.","doi":"","created":1704326400000,"updated":"2024-04-10","authors":["guojian wang","faguo wu","xiao zhang"]}
{"id":"2401.02227","title":"enabling digitalization in modular robotic systems integration","categories":"cs.ro","abstract":"integrating robot systems into manufacturing lines is a time-consuming process. in the era of digitalization, the research and development of new technologies is crucial for improving integration processes. numerous challenges, including the lack of standardization, as well as intricate stakeholder relationships, complicate the process of robotic systems integration. this process typically consists of acquisition, integration, and deployment of the robot systems. this thesis focuses on three areas that help automate and simplify robotic systems integration. in the first area, related to acquisition, a constraint-based configurator is demonstrated that resolves compatibility challenges between robot devices, and automates the configuration process. this reduces the risk of integrating incompatible devices and decreases the need for experts during the configuration phase. in the second area, related to integration, the interoperable modeling format, unified robot description format (urdf), is investigated, where a detailed analysis is performed, revealing significant inconsistencies and critical improvements. this format is widely used for kinematic modeling and 3d visualization of robots, and its models can be reused across simulation tools. improving this format benefits a wide range of users, including robotics engineers, researchers, and students. in the third area, related to deployment, digital twins (dts) for robot systems are explored, as these improve efficiency and reduce downtime. a comprehensive literature review of dts is conducted, and a case study of modular robot systems is developed. this research can accelerate the adoption of dts in the robotics industry. these insights and approaches improve the process of robotic systems integration, offering valuable contributions that future research can build upon, ultimately driving efficiency, and reducing costs.","doi":"","created":1704326400000,"updated":"","authors":["daniella tola"]}
{"id":"2401.02230","title":"automated test production -- complement to \"ad-hoc\" testing","categories":"cs.se","abstract":"a view on software testing, taken in a broad sense and considered a important activity is presented. we discuss the methods and techniques for applying tests and the reasons we recognize make it difficult for industry to adopt the advances observed in academia. we discuss some advances in the area and briefly point out the approach we intend to follow in the search for a solution.","doi":"","created":1704326400000,"updated":"","authors":["josé marcos gomes","luis alberto vieira dias"]}
{"id":"2401.02236","title":"u-mixer: an unet-mixer architecture with stationarity correction for   time series forecasting","categories":"cs.lg","abstract":"time series forecasting is a crucial task in various domains. caused by factors such as trends, seasonality, or irregular fluctuations, time series often exhibits non-stationary. it obstructs stable feature propagation through deep layers, disrupts feature distributions, and complicates learning data distribution changes. as a result, many existing models struggle to capture the underlying patterns, leading to degraded forecasting performance. in this study, we tackle the challenge of non-stationarity in time series forecasting with our proposed framework called u-mixer. by combining unet and mixer, u-mixer effectively captures local temporal dependencies between different patches and channels separately to avoid the influence of distribution variations among channels, and merge low- and high-levels features to obtain comprehensive data representations. the key contribution is a novel stationarity correction method, explicitly restoring data distribution by constraining the difference in stationarity between the data before and after model processing to restore the non-stationarity information, while ensuring the temporal dependencies are preserved. through extensive experiments on various real-world time series datasets, u-mixer demonstrates its effectiveness and robustness, and achieves 14.5\\% and 7.7\\% improvements over state-of-the-art (sota) methods.","doi":"","created":1704326400000,"updated":"","authors":["xiang ma","xuemei li","lexin fang","tianlong zhao","caiming zhang"]}
{"id":"2401.02239","title":"a decision method for elementary stream calculus","categories":"cs.lo","abstract":"the main result is a doubly exponential decision procedure for the first-order equality theory of streams with both arithmetic and control-oriented stream operations. this stream logic is expressive for elementary problems of stream calculus.","doi":"","created":1704326400000,"updated":"","authors":["harald ruess"]}
{"id":"2401.02241","title":"slot-guided volumetric object radiance fields","categories":"cs.cv","abstract":"we present a novel framework for 3d object-centric representation learning. our approach effectively decomposes complex scenes into individual objects from a single image in an unsupervised fashion. this method, called slot-guided volumetric object radiance fields (svorf), composes volumetric object radiance fields with object slots as a guidance to implement unsupervised 3d scene decomposition. specifically, svorf obtains object slots from a single image via a transformer module, maps these slots to volumetric object radiance fields with a hypernetwork and composes object radiance fields with the guidance of object slots at a 3d location. moreover, svorf significantly reduces memory requirement due to small-sized pixel rendering during training. we demonstrate the effectiveness of our approach by showing top results in scene decomposition and generation tasks of complex synthetic datasets (e.g., room-diverse). furthermore, we also confirm the potential of svorf to segment objects in real-world scenes (e.g., the llff dataset). we hope our approach can provide preliminary understanding of the physical world and help ease future research in 3d object-centric representation learning.","doi":"","created":1704326400000,"updated":"","authors":["di qi","tong yang","xiangyu zhang"]}
{"id":"2401.02244","title":"policy-regularized offline multi-objective reinforcement learning","categories":"cs.lg cs.ai","abstract":"in this paper, we aim to utilize only offline trajectory data to train a policy for multi-objective rl. we extend the offline policy-regularized method, a widely-adopted approach for single-objective offline rl problems, into the multi-objective setting in order to achieve the above goal. however, such methods face a new challenge in offline morl settings, namely the preference-inconsistent demonstration problem. we propose two solutions to this problem: 1) filtering out preference-inconsistent demonstrations via approximating behavior preferences, and 2) adopting regularization techniques with high policy expressiveness. moreover, we integrate the preference-conditioned scalarized update method into policy-regularized offline rl, in order to simultaneously learn a set of policies using a single policy network, thus reducing the computational cost induced by the training of a large number of individual policies for various preferences. finally, we introduce regularization weight adaptation to dynamically determine appropriate regularization weights for arbitrary target preferences during deployment. empirical results on various multi-objective datasets demonstrate the capability of our approach in solving offline morl problems.","doi":"","created":1704326400000,"updated":"","authors":["qian lin","chao yu","zongkai liu","zifan wu"]}
{"id":"2401.02245","title":"on augmenting scenario-based modeling with generative ai","categories":"cs.se","abstract":"the manual modeling of complex systems is a daunting task; and although a plethora of methods exist that mitigate this issue, the problem remains very difficult. recent advances in generative ai have allowed the creation of general-purpose chatbots, capable of assisting software engineers in various modeling tasks. however, these chatbots are often inaccurate, and an unstructured use thereof could result in erroneous system models. in this paper, we outline a method for the safer and more structured use of chatbots as part of the modeling process. to streamline this integration, we propose leveraging scenario-based modeling techniques, which are known to facilitate the automated analysis of models. we argue that through iterative invocations of the chatbot and the manual and automatic inspection of the resulting models, a more accurate system model can eventually be obtained. we describe favorable preliminary results, which highlight the potential of this approach.","doi":"","created":1704326400000,"updated":"","authors":["david harel","guy katz","assaf marron","smadar szekely"]}
{"id":"2401.02249","title":"high order lagrange-galerkin methods for the conservative formulation of   the advection-diffusion equation","categories":"math.na cs.na","abstract":"we introduce in this paper the numerical analysis of high order both in time and space lagrange-galerkin methods for the conservative formulation of the advection-diffusion equation. as time discretization scheme we consider the backward differentiation formulas up to order $q=5$. the development and analysis of the methods are performed in the framework of time evolving finite elements presented in c. m. elliot and t. ranner, ima journal of numerical analysis \\textbf{41}, 1696-1845 (2021). the error estimates show through their dependence on the parameters of the equation the existence of different regimes in the behavior of the numerical solution; namely, in the diffusive regime, that is, when the diffusion parameter $\\mu$ is large, the error is $o(h^{k+1}+\\delta t^{q})$, whereas in the advective regime, $\\mu \\ll 1$, the convergence is $o(\\min (h^{k},\\frac{h^{k+1} }{\\delta t})+\\delta t^{q})$. it is worth remarking that the error constant does not have exponential $\\mu ^{-1}$ dependence.","doi":"","created":1704326400000,"updated":"","authors":["rodolfo bermejo","manuel colera"]}
{"id":"2401.02253","title":"redriver: runtime enforcement for autonomous vehicles","categories":"cs.se","abstract":"autonomous driving systems (adss) integrate sensing, perception, drive control, and several other critical tasks in autonomous vehicles, motivating research into techniques for assessing their safety. while there are several approaches for testing and analysing them in high-fidelity simulators, adss may still encounter additional critical scenarios beyond those covered once they are deployed on real roads. an additional level of confidence can be established by monitoring and enforcing critical properties when the ads is running. existing work, however, is only able to monitor simple safety properties (e.g., avoidance of collisions) and is limited to blunt enforcement mechanisms such as hitting the emergency brakes. in this work, we propose redriver, a general and modular approach to runtime enforcement, in which users can specify a broad range of properties (e.g., national traffic laws) in a specification language based on signal temporal logic (stl). redriver monitors the planned trajectory of the ads based on a quantitative semantics of stl, and uses a gradient-driven algorithm to repair the trajectory when a violation of the specification is likely. we implemented redriver for two versions of apollo (i.e., a popular ads), and subjected it to a benchmark of violations of chinese traffic laws. the results show that redriver significantly improves apollo's conformance to the specification with minimal overhead.","doi":"10.1145\/3597503.3639151","created":1704326400000,"updated":"","authors":["yang sun","christopher m. poskitt","xiaodong zhang","jun sun"]}
{"id":"2401.02254","title":"l3cube-indicnews: news-based short text and long document classification   datasets in indic languages","categories":"cs.cl cs.lg","abstract":"in this work, we introduce l3cube-indicnews, a multilingual text classification corpus aimed at curating a high-quality dataset for indian regional languages, with a specific focus on news headlines and articles. we have centered our work on 10 prominent indic languages, including hindi, bengali, marathi, telugu, tamil, gujarati, kannada, odia, malayalam, and punjabi. each of these news datasets comprises 10 or more classes of news articles. l3cube-indicnews offers 3 distinct datasets tailored to handle different document lengths that are classified as: short headlines classification (shc) dataset containing the news headline and news category, long document classification (ldc) dataset containing the whole news article and the news category, and long paragraph classification (lpc) containing sub-articles of the news and the news category. we maintain consistent labeling across all 3 datasets for in-depth length-based analysis. we evaluate each of these indic language datasets using 4 different models including monolingual bert, multilingual indic sentence bert (indicsbert), and indicbert. this research contributes significantly to expanding the pool of available text classification datasets and also makes it possible to develop topic classification models for indian regional languages. this also serves as an excellent resource for cross-lingual analysis owing to the high overlap of labels among languages. the datasets and models are shared publicly at https:\/\/github.com\/l3cube-pune\/indic-nlp","doi":"","created":1704326400000,"updated":"2024-04-26","authors":["aishwarya mirashi","srushti sonavane","purva lingayat","tejas padhiyar","raviraj joshi"]}
{"id":"2401.02255","title":"balancing continual learning and fine-tuning for human activity   recognition","categories":"cs.lg eess.sp","abstract":"wearable-based human activity recognition (har) is a key task in human-centric machine learning due to its fundamental understanding of human behaviours. due to the dynamic nature of human behaviours, continual learning promises har systems that are tailored to users' needs. however, because of the difficulty in collecting labelled data with wearable sensors, existing approaches that focus on supervised continual learning have limited applicability, while unsupervised continual learning methods only handle representation learning while delaying classifier training to a later stage. this work explores the adoption and adaptation of cassle, a continual self-supervised learning model, and kaizen, a semi-supervised continual learning model that balances representation learning and down-stream classification, for the task of wearable-based har. these schemes re-purpose contrastive learning for knowledge retention and, kaizen combines that with self-training in a unified scheme that can leverage unlabelled and labelled data for continual learning. in addition to comparing state-of-the-art self-supervised continual learning schemes, we further investigated the importance of different loss terms and explored the trade-off between knowledge retention and learning from new tasks. in particular, our extensive evaluation demonstrated that the use of a weighting factor that reflects the ratio between learned and new classes achieves the best overall trade-off in continual learning.","doi":"","created":1704326400000,"updated":"","authors":["chi ian tang","lorena qendro","dimitris spathis","fahim kawsar","akhil mathur","cecilia mascolo"]}
{"id":"2401.02256","title":"rethinking response evaluation from interlocutor's eye for open-domain   dialogue systems","categories":"cs.cl","abstract":"open-domain dialogue systems have started to engage in continuous conversations with humans. those dialogue systems are required to be adjusted to the human interlocutor and evaluated in terms of their perspective. however, it is questionable whether the current automatic evaluation methods can approximate the interlocutor's judgments. in this study, we analyzed and examined what features are needed in an automatic response evaluator from the interlocutor's perspective. the first experiment on the hazumi dataset revealed that interlocutor awareness plays a critical role in making automatic response evaluation correlate with the interlocutor's judgments. the second experiment using massive conversations on x (formerly twitter) confirmed that dialogue continuity prediction can train an interlocutor-aware response evaluator without human feedback while revealing the difficulty in evaluating generated responses compared to human responses.","doi":"","created":1704326400000,"updated":"","authors":["yuma tsuta","naoki yoshinaga","shoetsu sato","masashi toyoda"]}
{"id":"2401.02258","title":"uncertainty-aware deep attention recurrent neural network for   heterogeneous time series imputation","categories":"cs.lg cs.ai","abstract":"missingness is ubiquitous in multivariate time series and poses an obstacle to reliable downstream analysis. although recurrent network imputation achieved the sota, existing models do not scale to deep architectures that can potentially alleviate issues arising in complex data. moreover, imputation carries the risk of biased estimations of the ground truth. yet, confidence in the imputed values is always unmeasured or computed post hoc from model output. we propose deep attention recurrent imputation (deari), which jointly estimates missing values and their associated uncertainty in heterogeneous multivariate time series. by jointly representing feature-wise correlations and temporal dynamics, we adopt a self attention mechanism, along with an effective residual component, to achieve a deep recurrent neural network with good imputation performance and stable convergence. we also leverage self-supervised metric learning to boost performance by optimizing sample similarity. finally, we transform deari into a bayesian neural network through a novel bayesian marginalization strategy to produce stochastic deari, which outperforms its deterministic equivalent. experiments show that deari surpasses the sota in diverse imputation tasks using real-world datasets, namely air quality control, healthcare and traffic.","doi":"","created":1704326400000,"updated":"","authors":["linglong qian","zina ibrahim","richard dobson"]}
{"id":"2401.02262","title":"the effects of generative ai on computing students' help-seeking   preferences","categories":"cs.hc","abstract":"help-seeking is a critical way for students to learn new concepts, acquire new skills, and get unstuck when problem-solving in their computing courses. the recent proliferation of generative ai tools, such as chatgpt, offers students a new source of help that is always available on-demand. however, it is unclear how this new resource compares to existing help-seeking resources along dimensions of perceived quality, latency, and trustworthiness. in this paper, we investigate the help-seeking preferences and experiences of computing students now that generative ai tools are available to them. we collected survey data (n=47) and conducted interviews (n=8) with computing students. our results suggest that although these models are being rapidly adopted, they have not yet fully eclipsed traditional help resources. the help-seeking resources that students rely on continue to vary depending on the task and other factors. finally, we observed preliminary evidence about how help-seeking with generative ai is a skill that needs to be developed, with disproportionate benefits for those who are better able to harness the capabilities of llms. we discuss potential implications for integrating generative ai into computing classrooms and the future of help-seeking in the era of generative ai.","doi":"","created":1704326400000,"updated":"","authors":["irene hou","sophia metille","zhuo li","owen man","cynthia zastudil","stephen macneil"]}
{"id":"2401.02265","title":"breeding protocols are advantageous for finite-length entanglement   distillation","categories":"quant-ph cs.it math.it","abstract":"bennett et al. proposed a family of protocols for entanglement distillation, namely, hashing, recurrence and breeding protocols. the last one is inferior to the hashing protocol in the asymptotic regime and has been investigated little. in this paper, we propose a framework of converting a stabilizer quantum error-correcting code to a breeding protocol, which is a generalization of the previous conversion methods by luo-devetak and wilde. then, show an example of a stabilizer that gives a breeding protocol better than hashing protocols, in which the finite number of maximally entangled pairs are distilled from the finite number of partially entangled pairs.","doi":"","created":1704326400000,"updated":"2024-02-01","authors":["ryutaroh matsumoto"]}
{"id":"2401.02268","title":"beyond self-promotion: how software engineering research is discussed on   linkedin","categories":"cs.se cs.cy","abstract":"linkedin is the largest professional network in the world. as such, it can serve to build bridges between practitioners, whose daily work is software engineering (se), and researchers, who work to advance the field of software engineering. we know that such a metaphorical bridge exists: se research findings are sometimes shared on linkedin and commented on by software practitioners. yet, we do not know what state the bridge is in. therefore, we quantitatively and qualitatively investigate how se practitioners and researchers approach each other via public linkedin discussions and what both sides can contribute to effective science communication. we found that a considerable proportion of linkedin posts on se research are written by people who are not the paper authors (39%). further, 71% of all comments in our dataset are from people in the industry, but only every second post receives at least one comment at all. based on our findings, we formulate concrete advice for researchers and practitioners to make sharing new research findings on linkedin more fruitful.","doi":"10.1145\/3639475.3640113","created":1704326400000,"updated":"","authors":["marvin wyrich","justus bogner"]}
{"id":"2401.02271","title":"towards seamless serverless computing across an edge-cloud continuum","categories":"cs.dc","abstract":"serverless computing has emerged as an attractive paradigm due to the efficiency of development and the ease of deployment without managing any underlying infrastructure. nevertheless, serverless computing approaches face numerous challenges to unlock their full potential in hybrid environments. to gain a deeper understanding and firsthand knowledge of serverless computing in edge-cloud deployments, we review the current state of open-source serverless platforms and compare them based on predefined requirements. we then design and implement a serverless computing platform with a novel edge orchestration technique that seamlessly deploys serverless functions across the edge and cloud environments on top of the knative serverless platform. moreover, we propose an offloading strategy for edge environments and four different functions for experimentation and showcase the performance benefits of our solution. our results demonstrate that such an approach can efficiently utilize both cloud and edge resources by dynamically offloading functions from the edge to the cloud during high activity, while reducing the overall application latency and increasing request throughput compared to an edge-only deployment.","doi":"10.1145\/3603166.3632537","created":1704326400000,"updated":"","authors":["emilian simion","yuandou wang","hsiang-ling tai","uraz odyurt","zhiming zhao"]}
{"id":"2401.02274","title":"shapeaug: occlusion augmentation for event camera data","categories":"cs.cv","abstract":"recently, dynamic vision sensors (dvss) sparked a lot of interest due to their inherent advantages over conventional rgb cameras. these advantages include a low latency, a high dynamic range and a low energy consumption. nevertheless, the processing of dvs data using deep learning (dl) methods remains a challenge, particularly since the availability of event training data is still limited. this leads to a need for event data augmentation techniques in order to improve accuracy as well as to avoid over-fitting on the training data. another challenge especially in real world automotive applications is occlusion, meaning one object is hindering the view onto the object behind it. in this paper, we present a novel event data augmentation approach, which addresses this problem by introducing synthetic events for randomly moving objects in a scene. we test our method on multiple dvs classification datasets, resulting in an relative improvement of up to 6.5 % in top1-accuracy. moreover, we apply our augmentation technique on the real world gen1 automotive event dataset for object detection, where we especially improve the detection of pedestrians by up to 5 %.","doi":"","created":1704326400000,"updated":"","authors":["katharina bendig","rené schuster","didier stricker"]}
{"id":"2401.02277","title":"universal approximation theorem for vector- and hypercomplex-valued   neural networks","categories":"cs.lg cs.ne","abstract":"the universal approximation theorem states that a neural network with one hidden layer can approximate continuous functions on compact sets with any desired precision. this theorem supports using neural networks for various applications, including regression and classification tasks. furthermore, it is valid for real-valued neural networks and some hypercomplex-valued neural networks such as complex-, quaternion-, tessarine-, and clifford-valued neural networks. however, hypercomplex-valued neural networks are a type of vector-valued neural network defined on an algebra with additional algebraic or geometric properties. this paper extends the universal approximation theorem for a wide range of vector-valued neural networks, including hypercomplex-valued models as particular instances. precisely, we introduce the concept of non-degenerate algebra and state the universal approximation theorem for neural networks defined on such algebras.","doi":"","created":1704326400000,"updated":"","authors":["marcos eduardo valle","wington l. vital","guilherme vieira"]}
{"id":"2401.02278","title":"lightweight fish classification model for sustainable marine management:   indonesian case","categories":"cs.cv cs.lg","abstract":"the enormous demand for seafood products has led to exploitation of marine resources and near-extinction of some species. in particular, overfishing is one the main issues in sustainable marine development. in alignment with the protection of marine resources and sustainable fishing, this study proposes to advance fish classification techniques that support identifying protected fish species using state-of-the-art machine learning. we use a custom modification of the mobilenet model to design a lightweight classifier called m-mobilenet that is capable of running on limited hardware. as part of the study, we compiled a labeled dataset of 37,462 images of fish found in the waters of the indonesian archipelago. the proposed model is trained on the dataset to classify images of the captured fish into their species and give recommendations on whether they are consumable or not. our modified mobilenet model uses only 50\\% of the top layer parameters with about 42% gtx 860m utility and achieves up to 97% accuracy in fish classification and determining its consumability. given the limited computing capacity available on many fishing vessels, the proposed model provides a practical solution to on-site fish classification. in addition, synchronized implementation of the proposed model on multiple vessels can supply valuable information about the movement and location of different species of fish.","doi":"","created":1704326400000,"updated":"","authors":["febrian kurniawan","gandeva bayu satrya","firuz kamalov"]}
{"id":"2401.02281","title":"pegasus: physically enhanced gaussian splatting simulation system for   6dof object pose dataset generation","categories":"cs.cv","abstract":"we introduce physically enhanced gaussian splatting simulation system (pegasus) for 6dof object pose dataset generation, a versatile dataset generator based on 3d gaussian splatting.   environment and object representations can be easily obtained using commodity cameras to reconstruct with gaussian splatting. <i>pegasus<\/i> allows the composition of new scenes by merging the respective underlying gaussian splatting point cloud of an environment with one or multiple objects. leveraging a physics engine enables the simulation of natural object placement within a scene through interaction between meshes extracted for the objects and the environment. consequently, an extensive amount of new scenes - static or dynamic - can be created by combining different environments and objects. by rendering scenes from various perspectives, diverse data points such as rgb images, depth maps, semantic masks, and 6dof object poses can be extracted.   our study demonstrates that training on data generated by pegasus enables pose estimation networks to successfully transfer from synthetic data to real-world data. moreover, we introduce the ramen dataset, comprising 30 japanese cup noodle items. this dataset includes spherical scans that captures images from both object hemisphere and the gaussian splatting reconstruction, making them compatible with pegasus.","doi":"","created":1704326400000,"updated":"2024-07-15","authors":["lukas meyer","floris erich","yusuke yoshiyasu","marc stamminger","noriaki ando","yukiyasu domae"]}
{"id":"2401.02285","title":"optimal real-weighted beamforming with application to linear and   spherical arrays","categories":"eess.as cs.sd","abstract":"one of the uses of sensor arrays is for spatial filtering or beamforming. current digital signal processing methods facilitate complex-weighted beamforming, providing flexibility in array design. previous studies proposed the use of real-valued beamforming weights, which although reduce flexibility in design, may provide a range of benefits, e.g., simplified beamformer implementation or efficient beamforming algorithms. this paper presents a new method for the design of arrays with real-valued weights, that achieve maximum directivity, providing closed-form solution to array weights. the method is studied for linear and spherical arrays, where it is shown that rigid spherical arrays are particularly suitable for real-weight designs as they do not suffer from grating lobes, a dominant feature in linear arrays with real weights. a simulation study is presented for linear and spherical arrays, along with an experimental investigation, validating the theoretical developments.","doi":"10.1109\/tasl.2012.2208626","created":1704326400000,"updated":"","authors":["v. tourbabin","m. agmon","b. rafaely","j. tabrikian"]}
{"id":"2401.02287","title":"distillation-based fabric anomaly detection","categories":"cs.cv","abstract":"unsupervised texture anomaly detection has been a concerning topic in a vast amount of industrial processes. patterned textures inspection, particularly in the context of fabric defect detection, is indeed a widely encountered use case. this task involves handling a diverse spectrum of colors and textile types, encompassing a wide range of fabrics. given the extensive variability in colors, textures, and defect types, fabric defect detection poses a complex and challenging problem in the field of patterned textures inspection. in this article, we propose a knowledge distillation-based approach tailored specifically for addressing the challenge of unsupervised anomaly detection in textures resembling fabrics. our method aims to redefine the recently introduced reverse distillation approach, which advocates for an encoder-decoder design to mitigate classifier bias and to prevent the student from reconstructing anomalies. in this study, we present a new reverse distillation technique for the specific task of fabric defect detection. our approach involves a meticulous design selection that strategically highlights high-level features. to demonstrate the capabilities of our approach both in terms of performance and inference speed, we conducted a series of experiments on multiple texture datasets, including mvtec ad, aitex, and tilda, alongside conducting experiments on a dataset acquired from a textile manufacturing facility. the main contributions of this paper are the following: a robust texture anomaly detector utilizing a reverse knowledge-distillation technique suitable for both anomaly detection and domain generalization and a novel dataset encompassing a diverse range of fabrics and defects.","doi":"10.1177\/00405175231206820","created":1704326400000,"updated":"","authors":["simon thomine","hichem snoussi"]}
{"id":"2401.02288","title":"low regularity estimates of the lie-totter time-splitting fourier   spectral method for the logarithmic schr\\\"odinger equation","categories":"math.na cs.na","abstract":"in this paper, we conduct rigorous error analysis of the lie-totter time-splitting fourier spectral scheme for the nonlinear schr\\\"odinger equation with a logarithmic nonlinear term $f(u)=u\\ln|u|^2$ (logse) and periodic boundary conditions on a $d$-dimensional torus $\\mathbb t^d$. different from existing works based on regularisation of the nonlinear term $ f(u)\\approx f^\\varepsilon(u)=u\\ln (|u| + \\varepsilon )^2,$ we directly discretize the logse with the understanding $f(0)=0.$ remarkably, in the time-splitting scheme, the solution flow map of the nonlinear part: $g(u)= u {\\rm e}^{-{\\rm} i t \\ln|u|^{2}}$ has a higher regularity than $f(u)$ (which is not differentiable at $u=0$ but h\\\"older continuous), where $g(u)$ is lipschitz continuous and possesses a certain fractional sobolev regularity with index $0<s<1$. accordingly, we can derive the $l^2$-error estimate: $o\\big((\\tau^{s\/2} + n^{-s})\\ln\\! n\\big)$ of the proposed scheme for the logse with low regularity solution $u\\in c((0,t]; h^s( \\mathbb{t}^d)\\cap l^\\infty( \\mathbb{t}^d)).$ moreover, we can show that the estimate holds for $s=1$ with more delicate analysis of the nonlinear term and the associated solution flow maps. furthermore, we provide ample numerical results to demonstrate such a fractional-order convergence for initial data with low regularity. this work is the first one devoted to the analysis of splitting scheme for the logse without regularisation in the low regularity setting, as far as we can tell.","doi":"","created":1704326400000,"updated":"","authors":["xiaolong zhang","li-lian wang"]}
{"id":"2401.02290","title":"path-based explanation for knowledge graph completion","categories":"cs.lg cs.ai cs.si","abstract":"graph neural networks (gnns) have achieved great success in knowledge graph completion (kgc) by modelling how entities and relations interact in recent years. however, the explanation of the predicted facts has not caught the necessary attention. proper explanations for the results of gnn-based kgc models increase model transparency and help researchers develop more reliable models. existing practices for explaining kgc tasks rely on instance\/subgraph-based approaches, while in some scenarios, paths can provide more user-friendly and interpretable explanations. nonetheless, the methods for generating path-based explanations for kgs have not been well-explored. to address this gap, we propose power-link, the first path-based kgc explainer that explores gnn-based models. we design a novel simplified graph-powering technique, which enables the generation of path-based explanations with a fully parallelisable and memory-efficient training scheme. we further introduce three new metrics for quantitative evaluation of the explanations, together with a qualitative human evaluation. extensive experiments demonstrate that power-link outperforms the sota baselines in interpretability, efficiency, and scalability.","doi":"","created":1704326400000,"updated":"","authors":["heng chang","jiangnan ye","alejo lopez avila","jinhua du","jia li"]}
{"id":"2401.02292","title":"gridformer: point-grid transformer for surface reconstruction","categories":"cs.cv","abstract":"implicit neural networks have emerged as a crucial technology in 3d surface reconstruction. to reconstruct continuous surfaces from discrete point clouds, encoding the input points into regular grid features (plane or volume) has been commonly employed in existing approaches. however, these methods typically use the grid as an index for uniformly scattering point features. compared with the irregular point features, the regular grid features may sacrifice some reconstruction details but improve efficiency. to take full advantage of these two types of features, we introduce a novel and high-efficiency attention mechanism between the grid and point features named point-grid transformer (gridformer). this mechanism treats the grid as a transfer point connecting the space and point cloud. our method maximizes the spatial expressiveness of grid features and maintains computational efficiency. furthermore, optimizing predictions over the entire space could potentially result in blurred boundaries. to address this issue, we further propose a boundary optimization strategy incorporating margin binary cross-entropy loss and boundary sampling. this approach enables us to achieve a more precise representation of the object structure. our experiments validate that our method is effective and outperforms the state-of-the-art approaches under widely used benchmarks by producing more precise geometry reconstructions. the code is available at https:\/\/github.com\/list17\/gridformer.","doi":"","created":1704326400000,"updated":"","authors":["shengtao li","ge gao","yudong liu","yu-shen liu","ming gu"]}
{"id":"2401.02296","title":"training single-layer morphological perceptron using convex-concave   programming","categories":"cs.lg","abstract":"this paper concerns the training of a single-layer morphological perceptron using disciplined convex-concave programming (dccp). we introduce an algorithm referred to as k-ddccp, which combines the existing single-layer morphological perceptron (slmp) model proposed by ritter and urcid with the weighted disciplined convex-concave programming (wdccp) algorithm by charisopoulos and maragos. the proposed training algorithm leverages the disciplined convex-concave procedure (dccp) and formulates a non-convex optimization problem for binary classification. to tackle this problem, the constraints are expressed as differences of convex functions, enabling the application of the dccp package. the experimental results confirm the effectiveness of the k-ddccp algorithm in solving binary classification problems. overall, this work contributes to the field of morphological neural networks by proposing an algorithm that extends the capabilities of the slmp model.","doi":"","created":1704326400000,"updated":"","authors":["iara cunha","marcos eduardo valle"]}
{"id":"2401.02297","title":"are llms robust for spoken dialogues?","categories":"cs.cl","abstract":"large pre-trained language models have demonstrated state-of-the-art performance in different downstream tasks, including dialogue state tracking and end-to-end response generation. nevertheless, most of the publicly available datasets and benchmarks on task-oriented dialogues focus on written conversations. consequently, the robustness of the developed models to spoken interactions is unknown. in this work, we have evaluated the performance of llms for spoken task-oriented dialogues on the dstc11 test sets. due to the lack of proper spoken dialogue datasets, we have automatically transcribed a development set of spoken dialogues with a state-of-the-art asr engine. we have characterized the asr-error types and their distributions and simulated these errors in a large dataset of dialogues. we report the intrinsic (perplexity) and extrinsic (human evaluation) performance of fine-tuned gpt-2 and t5 models in two subtasks of response generation and dialogue state tracking, respectively. the results show that llms are not robust to spoken noise by default, however, fine-tuning\/training such models on a proper dataset of spoken tods can result in a more robust performance.","doi":"","created":1704326400000,"updated":"","authors":["seyed mahed mousavi","gabriel roccabruna","simone alghisi","massimo rizzoli","mirco ravanelli","giuseppe riccardi"]}
{"id":"2401.02300","title":"robust physics informed neural networks","categories":"cs.lg cs.na math.na","abstract":"we introduce a robust version of the physics-informed neural networks (rpinns) to approximate the partial differential equations (pdes) solution. standard physics informed neural networks (pinn) takes into account the governing physical laws described by pde during the learning process. the network is trained on a data set that consists of randomly selected points in the physical domain and its boundary. pinns have been successfully applied to solve various problems described by pdes with boundary conditions. the loss function in traditional pinns is based on the strong residuals of the pdes. this loss function in pinns is generally not robust with respect to the true error. the loss function in pinns can be far from the true error, which makes the training process more difficult. in particular, we do not know if the training process has already converged to the solution with the required accuracy. this is especially true if we do not know the exact solution, so we cannot estimate the true error during the training. this paper introduces a different way of defining the loss function. it incorporates the residual and the inverse of the gram matrix, computed using the energy norm. we test our rpinn algorithm on two laplace problems and one advection-diffusion problem in two spatial dimensions. we conclude that rpinn is a robust method. the proposed loss coincides well with the true error of the solution, as measured in the energy norm. thus, we know if our training process goes well, and we know when to stop the training to obtain the neural network approximation of the solution of the pde with the true error of required accuracy.","doi":"","created":1704326400000,"updated":"2024-01-12","authors":["marcin łoś","maciej paszyński"]}
{"id":"2401.02301","title":"a generalized variable projection algorithm for least squares problems   in atmospheric remote sensing","categories":"math.na astro-ph.ep astro-ph.im cs.na physics.ao-ph","abstract":"this paper presents a solution for efficiently and accurately solving separable least squares problems with multiple datasets. these problems involve determining linear parameters that are specific to each dataset while ensuring that the nonlinear parameters remain consistent across all datasets. a well-established approach for solving such problems is the variable projection algorithm introduced by golub and leveque, which effectively reduces a separable problem to its nonlinear component. however, this algorithm assumes that the datasets have equal sizes and identical auxiliary model parameters. this article is motivated by a real-world remote sensing application where these assumptions do not apply. consequently, we propose a generalized algorithm that extends the original theory to overcome these limitations. the new algorithm has been implemented and tested using both synthetic and real satellite data for atmospheric carbon dioxide retrievals. it has also been compared to conventional state-of-the-art solvers, and its advantages are thoroughly discussed. the experimental results demonstrate that the proposed algorithm significantly outperforms all other methods in terms of computation time, while maintaining comparable accuracy and stability. hence, this novel method can have a positive impact on future applications in remote sensing and could be valuable for other scientific fitting problems with similar properties.","doi":"10.3390\/math11132839","created":1704326400000,"updated":"","authors":["adelina bärligea","philipp hochstaffl","franz schreier"]}
{"id":"2401.02306","title":"secure control of connected and automated vehicles using trust-aware   robust event-triggered control barrier functions","categories":"eess.sy cs.sy","abstract":"we address the security of a network of connected and automated vehicles (cavs) cooperating to safely navigate through a conflict area (e.g., traffic intersections, merging roadways, roundabouts). previous studies have shown that such a network can be targeted by adversarial attacks causing traffic jams or safety violations ending in collisions. we focus on attacks targeting the v2x communication network used to share vehicle data and consider as well uncertainties due to noise in sensor measurements and communication channels. to combat these, motivated by recent work on the safe control of cavs, we propose a trust-aware robust event-triggered decentralized control and coordination framework that can provably guarantee safety. we maintain a trust metric for each vehicle in the network computed based on their behavior and used to balance the tradeoff between conservativeness (when deeming every vehicle as untrustworthy) and guaranteed safety and security. it is important to highlight that our framework is invariant to the specific choice of the trust framework. based on this framework, we propose an attack detection and mitigation scheme which has twofold benefits: (i) the trust framework is immune to false positives, and (ii) it provably guarantees safety against false positive cases. we use extensive simulations (in sumo and carla) to validate the theoretical guarantees and demonstrate the efficacy of our proposed scheme to detect and mitigate adversarial attacks.","doi":"","created":1704326400000,"updated":"2024-03-25","authors":["h m sabbir ahmad","ehsan sabouni","akua dickson","wei xiao","christos g. cassandras","wenchao li"]}
{"id":"2401.02309","title":"tr-detr: task-reciprocal transformer for joint moment retrieval and   highlight detection","categories":"cs.cv cs.mm","abstract":"video moment retrieval (mr) and highlight detection (hd) based on natural language queries are two highly related tasks, which aim to obtain relevant moments within videos and highlight scores of each video clip. recently, several methods have been devoted to building detr-based networks to solve both mr and hd jointly. these methods simply add two separate task heads after multi-modal feature extraction and feature interaction, achieving good performance. nevertheless, these approaches underutilize the reciprocal relationship between two tasks. in this paper, we propose a task-reciprocal transformer based on detr (tr-detr) that focuses on exploring the inherent reciprocity between mr and hd. specifically, a local-global multi-modal alignment module is first built to align features from diverse modalities into a shared latent space. subsequently, a visual feature refinement is designed to eliminate query-irrelevant information from visual features for modal interaction. finally, a task cooperation module is constructed to refine the retrieval pipeline and the highlight score prediction process by utilizing the reciprocity between mr and hd. comprehensive experiments on qvhighlights, charades-sta and tvsum datasets demonstrate that tr-detr outperforms existing state-of-the-art methods. codes are available at \\url{https:\/\/github.com\/mingyao1120\/tr-detr}.","doi":"","created":1704326400000,"updated":"2024-01-04","authors":["hao sun","mingyao zhou","wenjing chen","wei xie"]}
{"id":"2401.02313","title":"superedge: towards a generalization model for self-supervised edge   detection","categories":"cs.cv","abstract":"edge detection is a fundamental technique in various computer vision tasks. edges are indeed effectively delineated by pixel discontinuity and can offer reliable structural information even in textureless areas. state-of-the-art heavily relies on pixel-wise annotations, which are labor-intensive and subject to inconsistencies when acquired manually. in this work, we propose a novel self-supervised approach for edge detection that employs a multi-level, multi-homography technique to transfer annotations from synthetic to real-world datasets. to fully leverage the generated edge annotations, we developed superedge, a streamlined yet efficient model capable of concurrently extracting edges at pixel-level and object-level granularity. thanks to self-supervised training, our method eliminates the dependency on manual annotated edge labels, thereby enhancing its generalizability across diverse datasets. comparative evaluations reveal that superedge advances edge detection, demonstrating improvements of 4.9% in ods and 3.3% in ois over the existing stedge method on bipedv2.","doi":"","created":1704326400000,"updated":"","authors":["leng kai","zhang zhijie","liu jie","zed boukhers","sui wei","cong yang","li zhijun"]}
{"id":"2401.02317","title":"ba-sam: scalable bias-mode attention mask for segment anything model","categories":"cs.cv","abstract":"in this paper, we address the challenge of image resolution variation for the segment anything model (sam). sam, known for its zero-shot generalizability, exhibits a performance degradation when faced with datasets with varying image sizes. previous approaches tend to resize the image to a fixed size or adopt structure modifications, hindering the preservation of sam's rich prior knowledge. besides, such task-specific tuning necessitates a complete retraining of the model, which is cost-expensive and unacceptable for deployment in the downstream tasks. in this paper, we reformulate this issue as a length extrapolation problem, where token sequence length varies while maintaining a consistent patch size for images of different sizes. to this end, we propose scalable bias-mode attention mask (ba-sam) to enhance sam's adaptability to varying image resolutions while eliminating the need for structure modifications. firstly, we introduce a new scaling factor to ensure consistent magnitude in the attention layer's dot product values when the token sequence length changes. secondly, we present a bias-mode attention mask that allows each token to prioritize neighboring information, mitigating the impact of untrained distant information. our ba-sam demonstrates efficacy in two scenarios: zero-shot and fine-tuning. extensive evaluation on diverse datasets, including dis5k, duts, isic, cod10k, and coco, reveals its ability to significantly mitigate performance degradation in the zero-shot setting and achieve state-of-the-art performance with minimal fine-tuning. furthermore, we propose a generalized model and benchmark, showcasing ba-sam's generalizability across all four datasets simultaneously. code is available at https:\/\/github.com\/zongzi13545329\/ba-sam","doi":"","created":1704326400000,"updated":"2024-03-19","authors":["yiran song","qianyu zhou","xiangtai li","deng-ping fan","xuequan lu","lizhuang ma"]}
{"id":"2401.02323","title":"multi-agent context learning strategy for interference-aware beam   allocation in mmwave vehicular communications","categories":"eess.sp cs.lg","abstract":"millimeter wave (mmwave) has been recognized as one of key technologies for 5g and beyond networks due to its potential to enhance channel bandwidth and network capacity. the use of mmwave for various applications including vehicular communications has been extensively discussed. however, applying mmwave to vehicular communications faces challenges of high mobility nodes and narrow coverage along the mmwave beams. due to high mobility in dense networks, overlapping beams can cause strong interference which leads to performance degradation. as a remedy, beam switching capability in mmwave can be utilized. then, frequent beam switching and cell change become inevitable to manage interference, which increase computational and signalling complexity. in order to deal with the complexity in interference control, we develop a new strategy called multi-agent context learning (macol), which utilizes contextual bandit to manage interference while allocating mmwave beams to serve vehicles in the network. our approach demonstrates that by leveraging knowledge of neighbouring beam status, the machine learning agent can identify and avoid potential interfering transmissions to other ongoing transmissions. furthermore, we show that even under heavy traffic loads, our proposed macol strategy is able to maintain low interference levels at around 10%.","doi":"","created":1704326400000,"updated":"","authors":["abdulkadir kose","haeyoung lee","chuan heng foh","mohammad shojafar"]}
{"id":"2401.02325","title":"a robust quantile huber loss with interpretable parameter adjustment in   distributional reinforcement learning","categories":"cs.lg stat.ml","abstract":"distributional reinforcement learning (rl) estimates return distribution mainly by learning quantile values via minimizing the quantile huber loss function, entailing a threshold parameter often selected heuristically or via hyperparameter search, which may not generalize well and can be suboptimal. this paper introduces a generalized quantile huber loss function derived from wasserstein distance (wd) calculation between gaussian distributions, capturing noise in predicted (current) and target (bellman-updated) quantile values. compared to the classical quantile huber loss, this innovative loss function enhances robustness against outliers. notably, the classical huber loss function can be seen as an approximation of our proposed loss, enabling parameter adjustment by approximating the amount of noise in the data during the learning process. empirical tests on atari games, a common application in distributional rl, and a recent hedging strategy using distributional rl, validate the effectiveness of our proposed loss function and its potential for parameter adjustments in distributional rl. the implementation of the proposed loss function is available here.","doi":"","created":1704326400000,"updated":"2024-01-07","authors":["parvin malekzadeh","konstantinos n. plataniotis","zissis poulos","zeyu wang"]}
{"id":"2401.02326","title":"classwise-sam-adapter: parameter efficient fine-tuning adapts segment   anything to sar domain for semantic segmentation","categories":"cs.cv","abstract":"in the realm of artificial intelligence, the emergence of foundation models, backed by high computing capabilities and extensive data, has been revolutionary. segment anything model (sam), built on the vision transformer (vit) model with millions of parameters and vast training dataset sa-1b, excels in various segmentation scenarios relying on its significance of semantic information and generalization ability. such achievement of visual foundation model stimulates continuous researches on specific downstream tasks in computer vision. the classwise-sam-adapter (cwsam) is designed to adapt the high-performing sam for landcover classification on space-borne synthetic aperture radar (sar) images. the proposed cwsam freezes most of sam's parameters and incorporates lightweight adapters for parameter efficient fine-tuning, and a classwise mask decoder is designed to achieve semantic segmentation task. this adapt-tuning method allows for efficient landcover classification of sar images, balancing the accuracy with computational demand. in addition, the task specific input module injects low frequency information of sar images by mlp-based layers to improve the model performance. compared to conventional state-of-the-art semantic segmentation algorithms by extensive experiments, cwsam showcases enhanced performance with fewer computing resources, highlighting the potential of leveraging foundational models like sam for specific downstream tasks in the sar domain. the source code is available at: https:\/\/github.com\/xypu98\/cwsam.","doi":"","created":1704326400000,"updated":"","authors":["xinyang pu","hecheng jia","linghao zheng","feng wang","feng xu"]}
{"id":"2401.02329","title":"not all minorities are equal: empty-class-aware distillation for   heterogeneous federated learning","categories":"cs.lg cs.cv","abstract":"data heterogeneity, characterized by disparities in local data distribution across clients, poses a significant challenge in federated learning. substantial efforts have been devoted to addressing the heterogeneity in local label distribution. as minority classes suffer from worse accuracy due to overfitting on local imbalanced data, prior methods often incorporate class-balanced learning techniques during local training. despite the improved mean accuracy across all classes, we observe that empty classes-referring to categories absent from a client's data distribution-are still not well recognized. this paper introduces feded, a novel approach in heterogeneous federated learning that integrates both empty-class distillation and logit suppression simultaneously. specifically, empty-class distillation leverages knowledge distillation during local training on each client to retain essential information related to empty classes from the global model. moreover, logit suppression directly penalizes network logits for non-label classes, effectively addressing misclassifications in minority classes that may be biased toward majority classes. extensive experiments validate the efficacy of feded, surpassing previous state-of-the-art methods across diverse datasets with varying degrees of label distribution shift.","doi":"","created":1704326400000,"updated":"","authors":["kuangpu guo","yuhe ding","jian liang","ran he","zilei wang","tieniu tan"]}
{"id":"2401.02330","title":"llava-phi: efficient multi-modal assistant with small language model","categories":"cs.cv cs.cl","abstract":"in this paper, we introduce llava-$\\phi$ (llava-phi), an efficient multi-modal assistant that harnesses the power of the recently advanced small language model, phi-2, to facilitate multi-modal dialogues. llava-phi marks a notable advancement in the realm of compact multi-modal models. it demonstrates that even smaller language models, with as few as 2.7b parameters, can effectively engage in intricate dialogues that integrate both textual and visual elements, provided they are trained with high-quality corpora. our model delivers commendable performance on publicly available benchmarks that encompass visual comprehension, reasoning, and knowledge-based perception. beyond its remarkable performance in multi-modal dialogue tasks, our model opens new avenues for applications in time-sensitive environments and systems that require real-time interaction, such as embodied agents. it highlights the potential of smaller language models to achieve sophisticated levels of understanding and interaction, while maintaining greater resource efficiency.the project is available at {https:\/\/github.com\/zhuyiche\/llava-phi}.","doi":"","created":1704326400000,"updated":"2024-02-22","authors":["yichen zhu","minjie zhu","ning liu","zhicai ou","xiaofeng mou","jian tang"]}
{"id":"2401.02331","title":"a finite difference scheme for two-dimensional singularly perturbed   convection-diffusion problem with discontinuous source term","categories":"math.na cs.na","abstract":"we propose a finite difference scheme for the numerical solution of a two-dimensional singularly perturbed convection-diffusion partial differential equation whose solution features interacting boundary and interior layers, the latter due to discontinuities in source term. the problem is posed on the unit square. the second derivative is multiplied by a singular perturbation parameter, $\\epsilon$, while the nature of the first derivative term is such that flow is aligned with a boundary. these two facts mean that solutions tend to exhibit layers of both exponential and characteristic type. we solve the problem using a finite difference method, specially adapted to the discontinuities, and applied on a piecewise-uniform (shishkin). we prove that that the computed solution converges to the true one at a rate that is independent of the perturbation parameter, and is nearly first-order. we present numerical results that verify that these results are sharp.","doi":"","created":1704326400000,"updated":"","authors":["ram shiromani","niall madden","v. shanthi"]}
{"id":"2401.02333","title":"beyond extraction: contextualising tabular data for efficient   summarisation by language models","categories":"cs.lg cs.cl","abstract":"the conventional use of the retrieval-augmented generation (rag) architecture has proven effective for retrieving information from diverse documents. however, challenges arise in handling complex table queries, especially within pdf documents containing intricate tabular structures.this research introduces an innovative approach to enhance the accuracy of complex table queries in rag-based systems. our methodology involves storing pdfs in the retrieval database and extracting tabular content separately. the extracted tables undergo a process of context enrichment, concatenating headers with corresponding values. to ensure a comprehensive understanding of the enriched data, we employ a fine-tuned version of the llama-2-chat language model for summarisation within the rag architecture. furthermore, we augment the tabular data with contextual sense using the chatgpt 3.5 api through a one-shot prompt. this enriched data is then fed into the retrieval database alongside other pdfs. our approach aims to significantly improve the precision of complex table queries, offering a promising solution to a longstanding challenge in information retrieval.","doi":"","created":1704326400000,"updated":"2024-02-10","authors":["uday allu","biddwan ahmed","vishesh tripathi"]}
